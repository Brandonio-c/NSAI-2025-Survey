[
  {
    "article_id": "242085726",
    "title": "DeepProbCEP: A neuro-symbolic approach for complex event processing in adversarial settings",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-07-31 00:11:22.911000",
      "Email Address": "brandon.colelough@gmail.com",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242085726",
      "Paper DOI / URL": "https://doi.org/10.1016/j.eswa.2022.119376",
      "Paper Title ": "DeepProbCEP: A neuro-symbolic approach for complex event processing in adversarial settings",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Expert Systems With Applications (Vol 215, Art 119376)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework paper with deminstration",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Introduces DeepProbCEP, a differentiable ProbLog + CNN hybrid that trains end‑to‑end from complex‑event labels.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/MarcRoigVilamala/DeepProbCEP",
      "Primary language / framework": "Python (>=3.8), PyTorch + DeepProbLog / ProbLog",
      "Commit / tag / release hash used": "2023‑12‑05 release",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "8 experiments (spanning 2 papers) reproduced successfully",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Complex Event Processing, differentiable logic",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "sensor-stream-monitoring, adversarial-robust-detection",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "complex-event-detection, sequence-classification",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Yes – urban street‑sound siren detection demo",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "DigitNN (CNN) and VGGish (Audio MLP)",
      "Neural architecture type(s) ": "CNN / ConvNet, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Release date": "2020-10-13 00:00:00",
      "Pre‑training source(s) ": "Image–text pairs (LAION, CC12M, YFCC100M, COCO‑Captions)",
      "Pre‑training source(s) (for other) specify here:": "MNIST (digits)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "ProbLog / PSL (Probabilistic Soft Logic) / Markov Logic (Alchemy/Tuffy)",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/ML-KULeuven/problog",
      "Symbolic representation(s)": "Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "Example of a rule / triple / formula (copy from paper)": "1 happensAt(overheating, T) :-\n2     sequence([highTemp, highTemp], 5, T).",
      "Tooling / libraries for symbolic side": "ProbLog / PyProbLog",
      "What are the key findings of the study (1-4 dot points)?": "DeepProbCEP beats neural-only and Neuroplex under very small training sets.\nMaintains >70 % complex-event accuracy with 2.5 k samples (window 5).\nRobust to ≥40 % label-noise and targeted poisoning (Figures 14–15).\nLogic layer can be edited without retraining, enabling rapid rule evolution",
      "Author‑reported limitations": "Need for differentiable logic restricts engine choice; experiments only with synthetic CEP definitions.",
      "Reviewer‑identified limitations / threats to validity": "Parameter count & compute budget unreported; no real-world deployment yet; limited evaluation metrics",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Random split (e.g. 80/10/10)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MNIST & UrbanSound8K",
      "Link to evaluation dataset used (if other)": "https://www.kaggle.com/datasets/hojjatk/mnist-dataset, https://urbansounddataset.weebly.com/urbansound8k.html",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "LSTM, C3D, Neuroplex; ablation on window size & noise levels",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "<1%",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Provides evidence that differentiable probabilistic logic can drastically reduce data needs for neuro-symbolic complex-event processing",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "1.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "Complex Event Processing, differentiable logic",
      "nsai_domain": "Complex Event Processing",
      "application_area_original": "sensor-stream-monitoring, adversarial-robust-detection",
      "application_area": "sensor-stream-monitoring",
      "task_type_original": "complex-event-detection, sequence-classification",
      "task_type": "complex-event-detection",
      "symbolic_representation_original": "Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "Probabilistic logic (Markov Logic Networks",
      "reasoning_engine_original": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "reasoning_engine": "Probabilistic logic engines (PSL",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2022.0",
      "venue_raw": "Expert Systems With Applications (Vol 215, Art 119376)",
      "venue_canonical": "Elsevier",
      "venue_group_bin": "Elsevier journals",
      "venue_group_plot": "Elsevier journals",
      "venue_clean": "elsevier",
      "venue_norm": "Elsevier journals",
      "venue_group": "Elsevier journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084020",
    "title": "Logic Tensor Networks",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-03 20:18:56.909000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084020",
      "Paper DOI / URL": "https://doi.org/10.1016/j.artint.2021.103649",
      "Paper Title ": "Logic Tensor Networks",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Artificial Intelligence, Sicence Direct",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents Logic Tensor Networks (LTN), a neurosymbolic framework that supports querying, learning and reasoning with both rich data and abstract knowledge about the world. LTN introduces a fully differentiable logical language, called Real Logic, whereby the elements of a first-order logic signature are grounded onto data using neural computational graphs and first-order fuzzy logic semantics",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/logictensornetworks/logictensornetworks",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-symbolic integration, differentiable first-order logic, neurosymbolic learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Multi‑label classification, clustering, relational learning, query answering, regression, embedding learning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Classification, regression, clustering, relational learning, query answering, embedding learning, semi‑supervised learning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Logic Tensor Networks",
      "Neural architecture type(s) ": "Simple MLP",
      "Release date": "2022-03-03 00:00:00",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "First‑order / predicate logic, Fuzzy logic, Godel t‑norm logics",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "Example of a rule / triple / formula (copy from paper)": "∀x(Person(x)→∃yParent(y,x))",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "Neuro-symbolic integration: The paper introduces Logic Tensor Networks (LTNs), which successfully integrate first-order fuzzy logic with neural networks, enabling end-to-end differentiable learning and reasoning over structured knowledge.\n\nHandling vague and uncertain knowledge: LTNs effectively model soft, fuzzy truth values rather than strict Boolean logic, allowing the system to reason under uncertainty and partial knowledge.\n\nImproved generalization with background knowledge: Incorporating logical constraints as differentiable loss terms helps guide the learning process, improving performance on relational and classification tasks by enforcing domain knowledge.\n\nFlexibility across tasks: LTNs demonstrate applicability to various neuro-symbolic tasks, such as multi-label classification, relational learning, and ontology completion, showcasing a versatile framework for combining symbolic reasoning and neural learning.",
      "Author‑reported limitations": "Scalability to Complex Domains: While LTNs demonstrate success on smaller-scale tasks, their scalability to more complex domains with large amounts of data and intricate logical structures remains an open challenge.\n\nHandling Incomplete or Noisy Data: The framework's performance may degrade when dealing with incomplete or noisy data, highlighting the need for robust mechanisms to handle such scenarios effectively.\n\nIntegration with Other Symbolic Systems: LTNs currently operate as a standalone system, and integrating them with existing symbolic reasoning systems or knowledge bases could enhance their utility and performance.\n\nInterpretability of Learned Representations: While LTNs aim to combine neural learning with symbolic reasoning, ensuring the interpretability of the learned representations and reasoning processes is an ongoing research direction.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Not reported / unclear",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Baselines / ablations compared against": "Neural networks without logical constraints:\nComparing LTNs against pure neural models (e.g., MLP classifiers) trained without any symbolic logic supervision to highlight the benefit of incorporating logic.\n\nLogic-only approaches:\nMethods relying solely on symbolic reasoning or logic without neural components to show the value of neuro-symbolic integration.\n\nVariants of LTNs with/without certain logical formulas:\nAblation studies removing or varying specific logical constraints to assess their impact on learning and performance.\n\nSimple embedding-based models:\nFor relational tasks, comparisons with embedding-based methods (though limited) that do not incorporate fuzzy logic.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a technically rigorous neuro-symbolic framework integrating fuzzy first-order logic with neural networks",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "Neuro-symbolic integration, differentiable first-order logic, neurosymbolic learning",
      "nsai_domain": "Neuro-symbolic integration",
      "application_area_original": "Multi‑label classification, clustering, relational learning, query answering, regression, embedding learning",
      "application_area": "Multi‑label classification",
      "task_type_original": "Classification, regression, clustering, relational learning, query answering, embedding learning, semi‑supervised learning",
      "task_type": "Classification",
      "symbolic_representation_original": "First‑order / predicate logic, Fuzzy logic, Godel t‑norm logics",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2022.0",
      "venue_raw": "Artificial Intelligence, Sicence Direct",
      "venue_canonical": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_group_bin": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_group_plot": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_clean": "publisher platforms (science direct/pubmed/ios)",
      "venue_norm": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_group": "Publisher platforms (Science Direct/PubMed/IOS)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084041",
    "title": "Interpretable Neural-Symbolic Concept Reasoning",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-09 16:59:50.101000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084041",
      "Paper DOI / URL": "https://dl.acm.org/doi/10.5555/3618408.3618484",
      "Paper Title ": "Interpretable Neural-Symbolic Concept Reasoning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICML'23: Proceedings of the 40th International Conference on Machine Learning",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper proposes the Deep Concept Reasoner (DCR), an interpretable concept-based model that uses neural networks to generate fuzzy logic rules from concept embeddings, and then executes those rules on concept truth degrees to make semantically meaningful and differentiable predictions.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/pietrobarbiero/pytorch_explain",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/pietrobarbiero/pytorch_explain/tree/master/torch_explain/datasets",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "No",
      "Pre‑processing scripts included?": "No",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache‑2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neural-Symbolic Integration, Concept-based Learning, Interpretable AI, Fuzzy Logic, Rule-based Reasoning, Differentiable Logic, Explainability",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Explainable AI, Concept Learning, Image Classification, Medical Diagnosis, Visual Recognition, Human-in-the-Loop AI",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Classification, Concept Learning, Rule Extraction, Interpretability, Explainability",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "It specifically mentions use cases in medical diagnosis and visual recognition tasks, where interpretable concept-based reasoning is critical for trust and understanding.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "Neural architecture type(s) ": "CNN / ConvNet",
      "Release date": "2023-07-01 00:00:00",
      "Pre‑training source(s) ": "Pure vision datasets (ImageNet, OpenImages, MS‑COCO images only)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Partially open (some weights/scripts",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, Fuzzy logic, Godel t‑norm logics",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "The proposed Deep Concept Reasoner (DCR) can learn interpretable, differentiable fuzzy logic rules over concept embeddings, enabling transparent reasoning without sacrificing predictive accuracy.\n\nDCR achieves competitive or superior task performance compared to black-box neural networks and other concept-based models on various datasets, including real-world medical and visual recognition tasks.\n\nThe model’s rule-based explanations are faithful and human-understandable, providing meaningful insights into decision-making grounded on concept truth degrees.\n\nThe approach demonstrates robustness to spurious correlations and improved generalization by explicitly modeling concept-level interactions through symbolic rules.",
      "Author‑reported limitations": "The model’s performance and interpretability depend on the quality and completeness of the concept annotations; noisy or missing concepts can degrade reasoning quality.\n\nThe approach currently focuses on propositional fuzzy logic rules and does not extend to more expressive symbolic representations like first-order logic or temporal reasoning.\n\nThe model may face scalability challenges with very large concept sets or highly complex rule structures, potentially limiting applicability to large-scale or highly complex domains.\n\nWhile the rules are interpretable, automatic simplification or pruning of complex induced rules remains an open problem to improve usability.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted), AUROC (ROC‑AUC), Log loss / Cross‑entropy / NLL, Expected Calibration Error (ECE) / Adaptive CE / UCE, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Random split (e.g. 80/10/10), Out‑of‑distribution (OOD) robustness benchmark, Ablation on noisy or perturbed subsets",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Datasets used for Evaluation ": "CIFAR-10, CIFAR-100, CheXpert, CLEVR",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "2",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it proposes a novel, interpretable neural-symbolic framework that jointly learns differentiable fuzzy logic rules over concept embeddings, advancing transparent reasoning in AI with strong empirical validation across diverse real-world tasks.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "2.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "0.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neural-Symbolic Integration, Concept-based Learning, Interpretable AI, Fuzzy Logic, Rule-based Reasoning, Differentiable Logic, Explainability",
      "nsai_domain": "Neural-Symbolic Integration",
      "application_area_original": "Explainable AI, Concept Learning, Image Classification, Medical Diagnosis, Visual Recognition, Human-in-the-Loop AI",
      "application_area": "Explainable AI",
      "task_type_original": "Classification, Concept Learning, Rule Extraction, Interpretability, Explainability",
      "task_type": "Classification",
      "symbolic_representation_original": "Propositional / Boolean logic rules, Fuzzy logic, Godel t‑norm logics",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "ICML'23: Proceedings of the 40th International Conference on Machine Learning",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084533",
    "title": "Neural Logic Machines",
    "year": "2019.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-14 01:44:08.654000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084533",
      "Paper DOI / URL": "https://arxiv.org/pdf/1904.11694",
      "Paper Title ": "Neural Logic Machines",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2019",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICLR2019",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "propose the Neural Logic Machine (NLM), a neural-symbolic architecture for\nboth inductive learning and logic reasoning. NLMs exploit the power of both neural\nnetworks—as function approximators, and logic programming—as a symbolic\nprocessor for objects with properties, relations, logic connectives, and quantifiers.\n",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/google/neural-logic-machines",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "No",
      "Pre‑processing scripts included?": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache-2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-Symbolic Integration, Relational Reasoning, Logical Rule Learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Algorithmic Reasoning, Puzzle Solving, Family Tree Reasoning, Sorting Tasks",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Not reported / unclear",
      "Neural architecture type(s) ": "Hybrid (specify combination)",
      "Neural architecture type(s) (for other) specify here:": "MLP + relational reasoning modules",
      "Release date": "2019-07-13 00:00:00",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module",
      "Symbolic representation(s)": "First‑order / predicate logic",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "Effective Relational Reasoning: Neural Logical Machine (NLM) can learn and perform multi-step relational reasoning over symbolic data, including family trees, sorting tasks, and graph-based puzzles, outperforming standard neural network baselines.\n\nStrong Generalization: NLM exhibits strong systematic generalization, successfully handling larger problem instances than seen during training.\n\nRule Induction Capability: The model implicitly learns logical rules, demonstrating the potential to encode first-order logic relationships within neural representations.\n\nData Efficiency: NLM achieves high accuracy with relatively small amounts of training data compared to standard deep learning approaches.",
      "Author‑reported limitations": "Fixed Depth Requirement:\nThe maximum depth of an NLM must be specified beforehand for each task. It can't adjust its reasoning depth adaptively, and future work might explore how to enable such flexibility \n\nSymbolic Input Only:\nNLM currently requires symbolic inputs. It cannot directly process real-valued or continuous inputs without pre-symbolic transformation, limiting applicability to domains with only symbolic data. They suggest extending NLM to handle vector inputs (e.g., real numbers like in healthcare) in future work \n\nTraining Complexity:\nNLM training is non-trivial, often requiring techniques like curriculum learning to succeed. The process is complex, and researchers hope to find simpler, more efficient training methods \n\nOpaque Learned Rules:\nAlthough NLM learns logical rules, these are encoded implicitly as neural network weights rather than being explicitly interpretable. Unlike ILP methods that output human-readable rules, NLM's internal rule representations are not directly readable. Extracting human-readable rules could be a valuable future direction",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Confidence intervals (CI) / standard error bars",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "CLEVR, CLUTRR, bAbI, Toy logical datasets (symbolic math, rule chains), Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Baselines / ablations compared against": "MLP ,  LSTM / RNN models, Relation Networks\n\nRelational Graph Convolutional Networks \n\nAblations of NLM ",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "0.05",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it presents Neural Logic Machines, a hybrid neuro-symbolic model that integrates neural networks with first-order logic reasoning to perform multi-step relational tasks with strong generalization.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.05",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "nsai_domain_original": "Neuro-Symbolic Integration, Relational Reasoning, Logical Rule Learning",
      "nsai_domain": "Neuro-Symbolic Integration",
      "application_area_original": "Algorithmic Reasoning, Puzzle Solving, Family Tree Reasoning, Sorting Tasks",
      "application_area": "Algorithmic Reasoning",
      "task_type_original": "unknown",
      "task_type": "unknown",
      "symbolic_representation_original": "First‑order / predicate logic",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Not reported / unclear",
      "model_family": "Not reported / unclear",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2019.0",
      "venue_raw": "ICLR2019",
      "venue_canonical": "ICLR",
      "venue_group_bin": "ICLR",
      "venue_group_plot": "ICLR",
      "venue_clean": "iclr",
      "venue_norm": "ICLR",
      "venue_group": "ICLR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084587",
    "title": "VAEL: bridging variational autoencoders and probabilistic logic programming",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-16 16:06:46.120000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084587",
      "Paper DOI / URL": "https://dl.acm.org/doi/10.5555/3600270.3600607",
      "Paper Title ": "VAEL: bridging variational autoencoders and probabilistic logic programming",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "NIPS'22: Proceedings of the 36th International Conference on Neural Information Processing Systems",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": " This paper presents VAEL, a neuro-symbolic generative model integrating variational autoencoders (VAE) with the reasoning capabilities of probabilistic logic (L) programming. Besides standard latent subsymbolic variables, their model exploits a probabilistic logic program to define a further structured representation, which is used for logical reasoning. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/EleMisi/VAEL",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/EleMisi/VAEL/tree/main/data/mario_icons",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Training time / FLOPs reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro‑Symbolic Integration, Probabilistic Logic, Variational Autoencoders, Hybrid AI",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Image Generation, Symbolic Reasoning, Probabilistic Modeling, Machine Learning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Representation Learning, Generative Modeling, Probabilistic Inference, Hybrid Reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Variational Autoencoder, VAE",
      "Neural architecture type(s) ": "Autoencoder / VAE, Hybrid (specify combination)",
      "Neural architecture type(s) (for other) specify here:": "Hybrid (VAE + Probabilistic Logic Programming)",
      "Release date": "2022-06-02 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Not reported",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "ProbLog / PSL (Probabilistic Soft Logic) / Markov Logic (Alchemy/Tuffy)",
      "Symbolic representation(s)": "Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "Prolog (e.g., SWI‑Prolog) / Datalog engines",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "0.7::digit(X,0);0.3::digit(X,1):−latent(X)",
      "Tooling / libraries for symbolic side": "ProbLog / PyProbLog",
      "What are the key findings of the study (1-4 dot points)?": "Hybrid Integration: Demonstrates that combining variational autoencoders (VAEs) with probabilistic logic programming (via ProbLog) enables neural models to generate latent representations that can be directly interpreted and reasoned over symbolically.\n\nImproved Interpretability: Neural latent variables can be converted into probabilistic symbolic facts, allowing symbolic reasoning to operate on them, which enhances interpretability compared to standard VAE outputs.\n\nTask Performance: The hybrid model successfully performs generative and reasoning tasks, such as generating and classifying MNIST digits and symbolic structures, while maintaining consistency with domain rules.\n\nFlexible Probabilistic Reasoning: Probabilistic logic rules allow uncertainty in neural outputs to be propagated into symbolic reasoning, showing that the approach can handle noisy or ambiguous latent representations effectively.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Only high‑level metric numbers in paper (no code)",
      "Datasets used for Evaluation ": "Toy logical datasets (symbolic math, rule chains), Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Standard Variational Autoencoder (VAE), ProbLog-only / symbolic-only ablation.  Ablations of hybrid components: Variants where certain parts of the integration between VAE and ProbLog are removed or modified (e.g., removing probabilistic logic constraints or altering the latent-symbol mapping) to test the importance of each module.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "8",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it presents an explicit hybrid of neural (VAE) and symbolic (ProbLog) components, demonstrating reproducible neuro-symbolic integration with open-source code and datasets.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "8.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "Neuro‑Symbolic Integration, Probabilistic Logic, Variational Autoencoders, Hybrid AI",
      "nsai_domain": "Neuro‑Symbolic Integration",
      "application_area_original": "Image Generation, Symbolic Reasoning, Probabilistic Modeling, Machine Learning",
      "application_area": "Image Generation",
      "task_type_original": "Representation Learning, Generative Modeling, Probabilistic Inference, Hybrid Reasoning",
      "task_type": "Representation Learning",
      "symbolic_representation_original": "Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "Logic programs (Horn clauses",
      "reasoning_engine_original": "Prolog (e.g., SWI‑Prolog) / Datalog engines",
      "reasoning_engine": "Prolog (e.g.",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2022.0",
      "venue_raw": "NIPS'22: Proceedings of the 36th International Conference on Neural Information Processing Systems",
      "venue_canonical": "NeurIPS",
      "venue_group_bin": "NeurIPS",
      "venue_group_plot": "NeurIPS",
      "venue_clean": "neurips",
      "venue_norm": "NeurIPS",
      "venue_group": "NeurIPS",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084594",
    "title": "BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-16 17:55:27.993000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084594",
      "Paper DOI / URL": "https://dl.acm.org/doi/10.5555/3702676.3702790",
      "Paper Title ": "BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "UAI '24: Proceedings of the Fortieth Conference on Uncertainty in Artificial Intelligence",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "They propose to ensure NeSy models are aware of the semantic ambiguity of the concepts they learn, thus enabling their users to identify and distrust low-quality concepts. Starting from three simple desiderata, they derive bears (BE Aware of Reasoning Shortcuts), an ensembling technique that calibrates the model's concept-level confidence without compromising prediction accuracy, thus encouraging NeSy architectures to be uncertain about concepts affected by RSs.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/samuelebortolotti/bears",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache‑2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-symbolic integration, Knowledge representation, Probabilistic logic",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Commonsense reasoning, Question answering, Knowledge graph reasoning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Multiple-choice QA, Logical reasoning, Knowledge graph completion",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper claims a real‑world application in enhancing multi‑hop reasoning over knowledge graphs, which can improve question answering and decision-support systems by combining neural embeddings with symbolic reasoning for more accurate and interpretable inference.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Not reported / unclear",
      "Neural architecture type(s) ": "Not reported",
      "Release date": "2024-12-02 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Not reported",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "Symbolic representation(s)": "Propositional / Boolean logic rules",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "Identification of Reasoning Shortcuts (RSs): The study highlights that Neuro-Symbolic (NeSy) models, which integrate symbolic knowledge, can exploit unintended semantics to achieve high accuracy, leading to overconfidence in concept predictions.\n\nIntroduction of BEARS Technique: The authors propose \"BEARS\" (BE Aware of Reasoning Shortcuts), an ensembling method that calibrates concept-level confidence without compromising prediction accuracy, encouraging NeSy models to be uncertain about concepts affected by RSs.\n\nEmpirical Validation: Experiments demonstrate that BEARS improves RS-awareness in several state-of-the-art NeSy models across multiple datasets, including high-stakes tasks like autonomous driving.\n\nFacilitation of Active Learning: BEARS enables the intelligent acquisition of concept annotations, reducing the cost of supervised mitigation strategies for RSs.",
      "Author‑reported limitations": "Dependence on Concept Annotations: BEARS requires concept-level annotations for calibration, which can be expensive or impractical to obtain in some domains.\n\nFocus on Known Reasoning Shortcuts: The method is designed to mitigate identified reasoning shortcuts; it may not detect or handle unknown or unexpected shortcuts automatically.\n\nPotential Computational Overhead: Ensembling for calibration introduces additional computation compared to standard NeSy model inference.\n\nEvaluation Scope: The experiments are limited to specific datasets and tasks, so generalization to all neuro-symbolic settings or large-scale real-world scenarios is not fully validated.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted), Expected Calibration Error (ECE) / Adaptive CE / UCE",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Not reported / unclear, Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "BDD-OIA",
      "Link to evaluation dataset used (if other)": "https://twizwei.github.io/bddoia_project/",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Standard Neuro-Symbolic Models without bears\nConcept-level confidence calibration ablations – versions of their model where bears’ calibration is modified or removed to evaluate the effect of concept-level confidence adjustments.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "9",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it introduces a method (BEARS) that explicitly integrates neural and symbolic components to mitigate reasoning shortcuts, demonstrating improved reliability and interpretability in neuro-symbolic models.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "9.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neuro-symbolic integration, Knowledge representation, Probabilistic logic",
      "nsai_domain": "Neuro-symbolic integration",
      "application_area_original": "Commonsense reasoning, Question answering, Knowledge graph reasoning",
      "application_area": "Commonsense reasoning",
      "task_type_original": "Multiple-choice QA, Logical reasoning, Knowledge graph completion",
      "task_type": "Multiple-choice QA",
      "symbolic_representation_original": "Propositional / Boolean logic rules",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Not reported / unclear",
      "model_family": "Not reported / unclear",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "UAI '24: Proceedings of the Fortieth Conference on Uncertainty in Artificial Intelligence",
      "venue_canonical": "UAI",
      "venue_group_bin": "UAI",
      "venue_group_plot": "UAI",
      "venue_clean": "uai",
      "venue_norm": "UAI",
      "venue_group": "UAI",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242084600",
    "title": "Neurosymbolic Diffusion Models",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-17 03:07:28.141000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084600",
      "Paper DOI / URL": "https://arxiv.org/pdf/2505.13138",
      "Paper Title ": "Neurosymbolic Diffusion Models",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arxiv",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "To overcome the limitations of the independence assumption, this paper introduces neurosymbolic diffusion models (NESYDMS), a new class of NeSy predictors that use discrete diffusion to model dependencies between symbols.  their approach reuses the independence assumption from NeSy predictors at each step of the diffusion process, enabling scalable learning while capturing symbol dependencies and uncertainty quantification.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/HEmile/neurosymbolic-diffusion",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Diffusion Models, Concept Learning, Uncertainty Quantification, Scalable Inference, Program-Guided Learning, Visual Reasoning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Visual Question Answering, Image Classification, Concept-Based Reasoning, Synthetic Vision Tasks",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Classification, Reasoning, Inference, Concept Extraction, Uncertainty Estimation, Program Execution, Image Understanding",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Diffusion / UNet-based text‑to‑image (Stable Diffusion, DALLE‑like)",
      "Neural architecture type(s) ": "Diffusion / Score-based model",
      "Release date": "2025-05-08 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "SAT/SMT solvers (MiniSAT, Z3, CVC5) used as the symbolic core",
      "Symbolic representation(s)": "Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "What are the key findings of the study (1-4 dot points)?": "Scalable Neurosymbolic Reasoning: The proposed Neurosymbolic Diffusion Model (NESYDM) successfully scales to high-dimensional reasoning problems with significant combinatorial complexity, such as multidigit MNIST addition and visual path planning on large grids (e.g., 30x30), outperforming existing approximate neurosymbolic methods on these tasks.\n\nImproved Reasoning Shortcut Awareness: NESYDM demonstrates enhanced awareness of reasoning shortcuts (RS-awareness) compared to independent models. It learns to avoid relying on superficial correlations in the data by leveraging the structure of the symbolic program, leading to better generalization and robustness.\n\nEffective Concept Learning and Uncertainty Quantification: The model effectively learns meaningful latent concepts from data and provides a natural way to quantify uncertainty through the sampling process and the entropy of the generated concepts, which correlates with prediction confidence and potential errors.\n\nFlexible and General Framework: NESYDM presents a flexible framework that can incorporate various types of symbolic knowledge expressed as programs (φ) and can be applied to diverse neurosymbolic tasks, achieving state-of-the-art or highly competitive performance on benchmark datasets like CLEVR and dSprites.",
      "Author‑reported limitations": "Intractable Exact Inference: The paper explicitly states that \"Exactly computing the mode argmaxy0 pNESYDM (y0 θ| x) is intractable even for representations supporting tractable marginals\" (Section 3.5). This necessitates the use of approximate inference methods like majority voting with sampling, which is a fundamental limitation of the approach.\n\nSampling Efficiency and Scalability: The reliance on sampling for inference (majority voting) can be computationally expensive, especially for problems with a very high-dimensional concept space (C). While the paper mentions using efficient samplers (like the first-hitting sampler) when possible, it resorts to a \"T-step time-discretisation of the reverse process\" for larger C, indicating a trade-off between accuracy and computational cost.\n\nPerformance Trade-offs with Voting Strategies: The analysis in Appendix H reveals a significant limitation of the default majority voting strategy (PTM). While it performs well on in-distribution (ID) data, it can fail dramatically on out-of-distribution (OOD) data (e.g., 0.02% accuracy on MNIST-Even-Odd OOD). Although alternative strategies like MMP perform better OOD, they suffer a \"rather significant hit\" in ID performance, highlighting a trade-off and lack of a universally optimal inference strategy.\n\nNumerical Instability in Implementation: The paper notes that the reward calculation in the reweighted distribution is \"numerically highly unstable,\" requiring specific rescaling techniques (introducing parameters L and U) to prevent underflow/overflow, which introduces a small bias. This indicates a practical implementation challenge.\n\nDependence on Predefined Program (φ): The framework relies on a fixed, predefined symbolic program φ. The paper does not address how this program is obtained or whether it can be learned, which limits its applicability to domains where such a program is already known or can be easily specified.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted)",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Out‑of‑distribution (OOD) robustness benchmark",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "CLEVR, Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "MNIST-Addition (adding two MNIST digits) MNIST-Even-Odd (classifying the sum of two digits as even or odd) ",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Maximum a Posteriori Model, DEEPSOFTLOG, PLIA, SCALLOP, EXAL, A-NESI",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "10",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it introduces NESYDM, a novel and scalable framework that effectively integrates diffusion models with symbolic programs through a sampling-based pipeline, demonstrating strong performance on complex reasoning tasks and providing inherent uncertainty quantification.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "10.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Diffusion Models, Concept Learning, Uncertainty Quantification, Scalable Inference, Program-Guided Learning, Visual Reasoning",
      "nsai_domain": "Diffusion Models",
      "application_area_original": "Visual Question Answering, Image Classification, Concept-Based Reasoning, Synthetic Vision Tasks",
      "application_area": "Visual Question Answering",
      "task_type_original": "Classification, Reasoning, Inference, Concept Extraction, Uncertainty Estimation, Program Execution, Image Understanding",
      "task_type": "Classification",
      "symbolic_representation_original": "Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Domain‑specific languages (DSLs) / program sketches",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Diffusion / UNet-based text‑to‑image (Stable Diffusion, DALLE‑like)",
      "model_family": "Diffusion / UNet-based text‑to‑image (Stable Diffusion",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2025.0",
      "venue_raw": "arxiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242084618",
    "title": "Making sense of raw input",
    "year": "2021.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-17 22:31:41.839000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084618",
      "Paper DOI / URL": "https://www.sciencedirect.com/science/article/pii/S0004370221000722?via%3Dihub",
      "Paper Title ": "Making sense of raw input",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2021",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "science direct",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The central contribution of this paper is a neuro-symbolic framework for distilling interpretable theories out of streams of raw, unprocessed sensory experience.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/RichardEvans/apperception",
      "Primary language / framework": "Haskell",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/RichardEvans/apperception/tree/master/data",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Perception, Representation Learning, Neuro-Symbolic Integration",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Vision, Reinforcement Learning, Reasoning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Image Classification, Object Recognition, Sequential Decision Making, Puzzle Solving",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Not reported / unclear",
      "Neural architecture type(s) ": "CNN / ConvNet",
      "Release date": "2020-07-09 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Answer Set Programs (ASP), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Not discussed / unclear",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "What are the key findings of the study (1-4 dot points)?": "Neuro-symbolic integration for unsupervised learning: The paper demonstrates a novel system that combines a deep neural network with a symbolic reasoning system to perform unsupervised structure discovery directly from raw sensory input.\n\nTheory construction and interpretability: The system successfully constructs explicit, interpretable theories that explain the input data. This contrasts with purely neural models, which often lack a clear, human-understandable explanation for their outputs.\n\nPerformance on complex tasks: The approach is shown to be effective on challenging tasks like learning the rules of simple video games directly from pixel data, without needing pre-defined symbolic categories.\n\nGeneralization of theories: The theories learned from one set of examples can be generalized to new, unseen examples, showing the system's ability to discover underlying causal rules rather than just memorizing patterns.",
      "Author‑reported limitations": "Scalability: The paper notes that their current implementation, which uses an Answer Set Programming (ASP) solver, is not designed for scale and can be computationally expensive.\n\nExpressiveness: The paper's system relies on a pre-defined \"language\" of logical predicates. This means it can only discover theories that can be expressed within this language, limiting its ability to handle more complex or nuanced concepts that are not part of its vocabulary.\n\nNeed for fine-tuning: The authors mention that the deep neural network requires significant manual tuning to provide the symbolic system with appropriate and useful information.\n\nDomain constraints: The system's performance is highly dependent on the \"unity conditions\" (hand-crafted rules) that guide the theory search. If these conditions are not well-defined for a particular domain, the system may struggle to find a coherent explanation.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Primary task metrics reported ": "Accuracy, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Search performance: Measured in terms of the number of templates processed and the time taken to find a solution.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Ablating the neural network",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "7",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it presents a novel hybrid system that successfully combines a deep neural network for perceptual processing with a symbolic logic-based system to discover and construct explicit, interpretable theories from raw sensory input.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "7.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Perception, Representation Learning, Neuro-Symbolic Integration",
      "nsai_domain": "Perception",
      "application_area_original": "Vision, Reinforcement Learning, Reasoning",
      "application_area": "Vision",
      "task_type_original": "Image Classification, Object Recognition, Sequential Decision Making, Puzzle Solving",
      "task_type": "Image Classification",
      "symbolic_representation_original": "Answer Set Programs (ASP), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "Answer Set Programs (ASP)",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Not reported / unclear",
      "model_family": "Not reported / unclear",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2021.0",
      "venue_raw": "science direct",
      "venue_canonical": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_group_bin": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_group_plot": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_clean": "publisher platforms (science direct/pubmed/ios)",
      "venue_norm": "Publisher platforms (Science Direct/PubMed/IOS)",
      "venue_group": "Publisher platforms (Science Direct/PubMed/IOS)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242084652",
    "title": "Learning Task-General Representations with Generative Neuro-Symbolic Modeling",
    "year": "2020.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-19 00:59:18.181000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084652",
      "Paper DOI / URL": "https://arxiv.org/abs/2006.14448",
      "Paper Title ": "Learning Task-General Representations with Generative Neuro-Symbolic Modeling",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2020",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICLR2021",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": " develop a generative\nneuro-symbolic (GNS) model of handwritten character concepts that uses the control flow of a probabilistic program, coupled with symbolic stroke primitives and a\nsymbolic image renderer, to represent the causal and compositional processes by\nwhich characters are formed. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/rfeinman/GNS-Modeling",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Generative Models, Few-Shot Learning, Probabilistic Programming, Representation Learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Computer Vision, Pattern Recognition, Image Generation, Robotics, Few-Shot Learning, Learning from demonstration, Planning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Classification, Generation, Representation Learning, Unsupervised Learning, Zero-Shot Learning, Few-Shot Learning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "Neural architecture type(s) ": "CNN / ConvNet, Autoencoder / VAE, Simple MLP",
      "Release date": "2020-11-06 00:00:00",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "Omniglot",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Domain‑specific languages (DSLs) / program sketches",
      "What are the key findings of the study (1-4 dot points)?": "The Generative Neuro-Symbolic (GNS) model can learn rich, task-general representations of handwritten characters from raw image data by combining the strengths of neural networks and symbolic models.\n\nThe model learns to infer the symbolic program that generated a given character image, demonstrating an ability to capture the compositional and causal structure of the data.\n\nThe GNS model can generate novel examples of existing characters and even create new, abstract character concepts that are perceptually and symbolically plausible, outperforming purely neural baselines.\n\nThe representations learned by the GNS model are useful for a variety of tasks, including one-shot classification, demonstrating its ability to generalize to new concepts.",
      "Author‑reported limitations": "The main limitation is that the current model is a proof-of-concept and is focused on a single, specific domain: handwritten characters. The authors also state that the model requires a well-designed, hand-engineered symbolic representation (a probabilistic program) for the domain. They suggest that future work could focus on learning these symbolic representations directly from data, expanding the model to more complex domains like visual reasoning and scene understanding, and improving the efficiency of the model's inference and generation processes.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Log loss / Cross‑entropy / NLL, Human rating (Likert / pairwise preference)",
      "Split / Protocol": "Few‑shot (N‑shot prompting / small labeled set)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Omniglot",
      "Link to evaluation dataset used (if other)": "https://github.com/brendenlake/omniglot",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Purely neural generative models generated by Variational Homoencoder and a Sequential Generative (SG) model\n\nalso with One-shot learning baselines:",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "12",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it presents a novel generative neuro-symbolic (GNS) model that combines the perceptual learning abilities of neural networks with the compositional and causal reasoning of symbolic programs to learn a task-general representation from raw image data.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "12.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "Generative Models, Few-Shot Learning, Probabilistic Programming, Representation Learning",
      "nsai_domain": "Generative Models",
      "application_area_original": "Computer Vision, Pattern Recognition, Image Generation, Robotics, Few-Shot Learning, Learning from demonstration, Planning",
      "application_area": "Computer Vision",
      "task_type_original": "Classification, Generation, Representation Learning, Unsupervised Learning, Zero-Shot Learning, Few-Shot Learning",
      "task_type": "Classification",
      "symbolic_representation_original": "Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Domain‑specific languages (DSLs) / program sketches",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "unknown",
      "integration_strategy": "unknown",
      "knowledge_source_original": "unknown",
      "knowledge_source": "unknown",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2020.0",
      "venue_raw": "ICLR2021",
      "venue_canonical": "ICLR",
      "venue_group_bin": "ICLR",
      "venue_group_plot": "ICLR",
      "venue_clean": "iclr",
      "venue_norm": "ICLR",
      "venue_group": "ICLR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242084952",
    "title": "A multi-grained self-interpretable symbolic-neural model for single/multi-labeled text classification",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-23 02:12:37.304000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084952",
      "Paper DOI / URL": "https://arxiv.org/pdf/2303.02860",
      "Paper Title ": "A multi-grained self-interpretable symbolic-neural model for single/multi-labeled text classification",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICLR",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "propose a Symbolic-Neural model that can learn to explicitly predict class\nlabels of text spans from a constituency tree without requiring any access to spanlevel gold labels",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/ant-research/StructuredLM_RTDT",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "4",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache‑2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Text Classification, Natural Language Processing, Neural-Symbolic AI, Interpretability",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Text Classification, Natural Language Understanding, Data Mining, Prediction Explanation, Sentiment Analysis, Slot-filling, Named Entity Recognition",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Text Classification, Single-label Classification, Multi-label Classification, Sentiment Analysis, Named Entity Recognition",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "RNN/LSTM/GRU family",
      "Neural architecture type(s) ": "GRU, LSTM",
      "Release date": "2023-06-15 00:00:00",
      "Pre‑training source(s) ": "Wikipedia / encyclopedic corpora (all language editions)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, Self‑training / pseudo‑labeling / bootstrapping",
      "Access level ": "Not reported",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Wikidata / DBpedia / YAGO",
      "Symbolic representation(s)": "Grammars / automata / production rules",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Other (specify below)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Joint / co‑training of neural and symbolic modules",
      "What are the key findings of the study (1-4 dot points)?": "The proposed Symbolic-Neural model achieves competitive prediction accuracy compared to strong baselines like BERT, especially on multi-label tasks.\n\nThe model has self-interpretability because it explicitly reflects rationales on the label probabilities of each constituent, and the predicted span labels are consistent with human rationales to a certain degree.\n\nThe model can learn to predict span-level labels without needing any access to span-level gold labels during training, requiring only raw texts and sentence-level labels.\n\nThe use of an unsupervised parser proves to be flexible and adaptable, as it achieves better performance than a supervised parser on a dataset with grammatical errors, like CoLA.",
      "Author‑reported limitations": "The proposed inductive bias that a constituent in a text corresponds to at most one label may not be applicable in special cases where a single semantic constituent has multiple labels, such as the movie \"Titanic\" being labeled with both 'disaster' and 'love'.\n\nThe paper's method for handling text classification tasks simplifies the problem by not discussing nesting cases\n\nThe model may prioritize learning easily-identifiable \"shortcuts\" in data, and only gradually learns semantic meaning with continuous training, which is demonstrated by a decline in the precision of the top tokens identified with the shortcut over time",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted), Matthews Correlation Coefficient (MCC)",
      "Datasets used for Evaluation ": "GLUE",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "BERT and Fast-R2D2. ",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "12",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it presents a hybrid Symbolic-Neural model that combines a structured language model with a symbolic dynamic programming algorithm to perform text classification in a self-supervised and interpretable manner, without requiring hand-annotated parsing trees.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "12.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "Text Classification, Natural Language Processing, Neural-Symbolic AI, Interpretability",
      "nsai_domain": "Text Classification",
      "application_area_original": "Text Classification, Natural Language Understanding, Data Mining, Prediction Explanation, Sentiment Analysis, Slot-filling, Named Entity Recognition",
      "application_area": "Text Classification",
      "task_type_original": "Text Classification, Single-label Classification, Multi-label Classification, Sentiment Analysis, Named Entity Recognition",
      "task_type": "Text Classification",
      "symbolic_representation_original": "Grammars / automata / production rules",
      "symbolic_representation": "Grammars / automata / production rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Other (specify below)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "RNN/LSTM/GRU family",
      "model_family": "RNN/LSTM/GRU family",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2023.0",
      "venue_raw": "ICLR",
      "venue_canonical": "ICLR",
      "venue_group_bin": "ICLR",
      "venue_group_plot": "ICLR",
      "venue_clean": "iclr",
      "venue_norm": "ICLR",
      "venue_group": "ICLR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242085081",
    "title": "Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-27 01:59:49.005000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242085081",
      "Paper DOI / URL": "https://arxiv.org/pdf/2407.15192",
      "Paper Title ": "Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "CIKM '24: Proceedings of the 33rd ACM International Conference on Information and Knowledge Management",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "his paper presents an approach that uses Error Detection Rules (EDR) to learn the failure modes of machine learning models, relaxing the common assumption that hierarchical constraints must exist beforehand. These learned rules are effective at detecting classifier errors and can be leveraged as constraints for Hierarchical Multi-label Classification (HMC), allowing for the recovery of explainable constraints even when they are not provided initially.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/lab-v2/PyEDCR",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-Symbolic AI, Rule Learning, Learning with Constraints, Error Detection, Constraint Recovery, Metacognition, Hierarchical Classification",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Image Recognition, Military Vehicle Recognition , Autonomous Systems, Control Systems ",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Hierarchical Multi-Label Classification, Error Detection, Constraint Recovery, Rule Learning, Learning with Constraints, Error Correction",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "the paper claims and demonstrates a real-world application in the area of military vehicle recognition. The authors introduce and use a new dataset of approximately 10,000 images of military vehicles as a primary testbed for their method. Additionally, the paper suggests potential future applications in the areas of control and autonomy.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Vision Transformers (ViT, Swin‑Transformer)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only)",
      "Release date": "2024-02-13 00:00:00",
      "Pre‑training source(s) ": "Pure vision datasets (ImageNet, OpenImages, MS‑COCO images only)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Partially open (some weights/scripts",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "First‑order / predicate logic, Taxonomies / hierarchies / thesauri, Decision rules / decision lists / decision trees as symbolic artifacts",
      "Source of symbolic knowledge": "Induced via ILP / rule mining / program synthesis, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Periodically updated post‑training (batch updates)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "What are the key findings of the study (1-4 dot points)?": "Superior Error Detection: The proposed Focused EDR (f-EDR) method is more effective at detecting errors than other approaches. In all experiments, f-EDR significantly outperformed both a neural (black-box) error prediction model and the prior DetRuleLearn algorithm on both balanced accuracy and F1-score metrics across three different datasets.\n\n\nEffective Constraint Recovery: The method successfully recovers the majority of hierarchical multi-label classification (HMC) constraints without needing them to be provided beforehand. This capability, along with the model's error detection performance, is noise-tolerant and degrades gracefully as the amount of incomplete or noisy data increases.\n\nImproved Vision Model Performance: The constraints learned by f-EDR can be used to enhance the performance and consistency of a vision model. By embedding the learned constraints into the model's training process using Logic Tensor Networks (LTN), the approach led to improved accuracy for both fine-grain and coarse-grain classifications and reduced the number of predictions that violated ground truth constraints.\n",
      "Author‑reported limitations": "Limited Hierarchy Depth: The evaluation of the framework is currently limited to hierarchies with only two levels of granularity (G=2). The authors state that the evaluation of the approach on more than two levels is left for future work.\n\nSimple Rule Structure: The current approach learns rules that are confined to \"a simple hierarchical relationship\". The authors aim to learn more complicated rules in future work that move beyond this limitation.\n\n",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted), Balanced Accuracy / Cohen’s k",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "ImageNet‑1K, OpenImages",
      "A motivation is given for why the experiments are conducted on the selected datasets": "No",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "For the Error Detection Task: The Focused EDR (f-EDR) method was evaluated against two other approaches:\n\nDetRuleLearn: A prior rule-based error detection method.\n\nA neural (black-box) error prediction model: A model inspired by related work that treats error detection as a binary classification problem, using a State-of-the-Art (SOTA) neural architecture.\n\n\nFor the Vision Model Improvement Task: To demonstrate the utility of the learned constraints, the paper compares the performance of a version of the vision model trained with f-EDR constraints against the original baseline vision model trained without those constraints.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "9",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a complete neurosymbolic workflow that learns explainable symbolic rules from a neural network's failures and then uses those rules as differentiable constraints within Logic Tensor Networks to improve the original model's performance and consistency.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "9.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neuro-Symbolic AI, Rule Learning, Learning with Constraints, Error Detection, Constraint Recovery, Metacognition, Hierarchical Classification",
      "nsai_domain": "Neuro-Symbolic AI",
      "application_area_original": "Image Recognition, Military Vehicle Recognition , Autonomous Systems, Control Systems",
      "application_area": "Image Recognition",
      "task_type_original": "Hierarchical Multi-Label Classification, Error Detection, Constraint Recovery, Rule Learning, Learning with Constraints, Error Correction",
      "task_type": "Hierarchical Multi-Label Classification",
      "symbolic_representation_original": "First‑order / predicate logic, Taxonomies / hierarchies / thesauri, Decision rules / decision lists / decision trees as symbolic artifacts",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Induced via ILP / rule mining / program synthesis, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Induced via ILP / rule mining / program synthesis",
      "model_family_original": "Vision Transformers (ViT, Swin‑Transformer)",
      "model_family": "Vision Transformers (ViT",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2024.0",
      "venue_raw": "CIKM '24: Proceedings of the 33rd ACM International Conference on Information and Knowledge Management",
      "venue_canonical": "KDD/WebConf/IR",
      "venue_group_bin": "KDD/WebConf/IR",
      "venue_group_plot": "KDD/WebConf/IR",
      "venue_clean": "kdd/webconf/ir",
      "venue_norm": "KDD/WebConf/IR",
      "venue_group": "KDD/WebConf/IR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242085266",
    "title": "Closed loop neural-symbolic learning via integrating neural perception, grammar parsing, and symbolic reasoning",
    "year": "2020.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-08-30 02:36:54.303000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242085266",
      "Paper DOI / URL": "https://dl.acm.org/doi/abs/10.5555/3524938.3525484",
      "Paper Title ": "Closed loop neural-symbolic learning via integrating neural perception, grammar parsing, and symbolic reasoning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2020",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICML",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper proposes a Neural-Grammar-Symbolic (NGS) model that improves upon inefficient reinforcement learning approaches by using a grammar model to bridge neural perception and symbolic reasoning, along with a novel back-search algorithm to learn from incorrect predictions. The experiments, conducted on handwritten formula recognition and visual question answering tasks, demonstrate that this method significantly outperforms reinforcement learning models in terms of performance, convergence speed, and data efficiency.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/liqing-ustc/NGS",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://ablkit.readthedocs.io/en/latest/Examples/HWF.html",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neural-Symbolic Integration, Weakly-Supervised Learning, Grammar Parsing, Symbolic Reasoning, Abductive Reasoning, Visual Question Answering",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Visual Question Answering, Handwritten Formula Recognition, Semantic Parsing, Computer Vision ",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Weakly-Supervised Learning, Visual Question Answering, Program Synthesis, Structured Prediction, Multi-Modal Reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "Neural architecture type(s) ": "CNN / ConvNet, RNN",
      "Release date": "2020-03-06 00:00:00",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "handwritten formula recognition task derived from the authors' own HWF dataset",
      "Fine‑tuning / adaptation details": "Self‑training / pseudo‑labeling / bootstrapping",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Grammars / automata / production rules, Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Joint / co‑training of neural and symbolic modules",
      "What are the key findings of the study (1-4 dot points)?": "The proposed Neural-Grammar-Symbolic (NGS) model, learned with a back-search algorithm (NGS-BS), significantly outperforms traditional reinforcement learning (RL) methods in terms of performance, convergence speed, and data efficiency. For example, on the HWF dataset with only 25% of training data, NGS-m-BS achieved 93.3% calculation accuracy, compared to just 5.1% for the RL-based NGS-MAPO model.\n\nThe novel back-search algorithm enables the model to learn efficiently from incorrect predictions by diagnosing and correcting them, which mimics a human-like learning process. This allows the model to learn from scratch and avoid the \"cold-start\" problem that plagues RL methods, which often fail to converge without pre-training.\n\nIntegrating a grammar model as a symbolic prior is a critical component for success. The grammar ensures that the model's predictions are always valid, which dramatically reduces the solution space by ruling out invalid symbolic sequences that cannot be executed.\n\nIncreasing the number of steps in the multi-step back-search algorithm (m-BS) generally helps the model converge faster. However, its effectiveness can vary by task; it was highly effective for handwritten formula recognition but did not provide a significant advantage over a single-step search in the more ambiguous VQA task.",
      "Author‑reported limitations": "Spurious Corrections: The back-search algorithm can find a \"spurious correction\"—a solution that is different from the ground-truth but coincidentally produces the correct final answer. Such corrections introduce a \"noisy gradient\" when updating the neural network, and the authors state that avoiding these spurious corrections remains an \"open problem\".\n\nReliance on Hand-Crafted Knowledge: The model requires that the symbolic knowledge—both the grammar rules and the symbolic inference rules—be explicitly designed by human experts ahead of time. The authors identify automatically learning this symbolic knowledge from data as a key \"future direction\" for the work.\n\nBack-Search Failures: In their qualitative results, the authors present an example where the one-step back-search (1-BS) algorithm fails to correct a wrong prediction.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Primary task metrics reported ": "Accuracy",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "HWF (Hand-Written Formula), CLEVR Dataset",
      "Link to evaluation dataset used (if other)": "htthttps://ablkit.readthedocs.io/en/latest/Examples/HWF.html,   https://cs.stanford.edu/people/jcjohns/clevr/les/HWF.html",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "NGS-RL  NGS-MAPO",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "5",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "it introduces a novel \"closed-loop\" learning framework that directly tackles the inefficiency of reinforcement learning-based approaches by using a grammar model to structure the neural output and a unique back-search algorithm to propagate errors through the non-differentiable symbolic module, enabling the model to learn effectively from its failures.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "5.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "Neural-Symbolic Integration, Weakly-Supervised Learning, Grammar Parsing, Symbolic Reasoning, Abductive Reasoning, Visual Question Answering",
      "nsai_domain": "Neural-Symbolic Integration",
      "application_area_original": "Visual Question Answering, Handwritten Formula Recognition, Semantic Parsing, Computer Vision",
      "application_area": "Visual Question Answering",
      "task_type_original": "Weakly-Supervised Learning, Visual Question Answering, Program Synthesis, Structured Prediction, Multi-Modal Reasoning",
      "task_type": "Weakly-Supervised Learning",
      "symbolic_representation_original": "Grammars / automata / production rules, Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Grammars / automata / production rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Joint / co‑training of neural and symbolic modules",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2020.0",
      "venue_raw": "ICML",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084344",
    "title": "Neuro-Symbolic Hierarchical Rule Induction",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-09-01 01:49:06.990000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084344",
      "Paper DOI / URL": "https://arxiv.org/abs/2112.13418",
      "Paper Title ": "Neuro-Symbolic Hierarchical Rule Induction",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "PMLR",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper proposes an efficient and interpretable neuro-symbolic model called Hierarchical Rule Induction (HRI) to solve Inductive Logic Programming (ILP) problems. This model is built from a set of meta-rules organized in a hierarchical structure, and it invents first-order rules by learning embeddings to match facts and predicates.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/claireaoi/hierarchical-rule-induction",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "10",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "CC0 1.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-Symbolic AI, Inductive Logic Programming, Rule Induction, Hierarchical Learning, Interpretability",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Inductive Logic Programming, Visual Reasoning, Reinforcement Learning, Knowledge Base Reasoning, Continual Learning, Autonomous Driving",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Rule Learning, Relational Learning, Program Induction, Object Classification, Sequential Decision Making, Policy Learning, Explanation Generation",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The authors explicitly mention autonomous driving as a potential future application where an interpretable, logic-oriented policy would be highly relevant.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Hierarchical Rule Induction",
      "Neural architecture type(s) ": "Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Hierarchical Rule Induction",
      "Release date": "2022-12-31 00:00:00",
      "Pre‑training source(s) ": "Common Crawl / web-scale text (RedPajama, The Pile, Dolma, RefinedWeb, etc.), Image–text pairs (LAION, CC12M, YFCC100M, COCO‑Captions)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Not reported",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Fuzzy logic",
      "Reasoning / inference engine": "ILP / rule‑induction systems (FOIL, Aleph, Popper, Metagol), Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Induced via ILP / rule mining / program synthesis, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules, KG‑embedding + rule‑based hybrid reasoning",
      "What are the key findings of the study (1-4 dot points)?": "High Efficiency and Performance: The proposed model, HRI, is highly efficient, training one to two orders of magnitude faster than comparable neuro-symbolic models on certain ILP tasks while achieving competitive or superior performance. \n\nScalability and Generality: The model scales effectively to large, multi-task problems and is independent of the number of predicates, which can differ between training and testing. This scalability was demonstrated on the large-scale Visual Genome (GQA) dataset, where the model outperformed the NLIL baseline.\n\nCross-Domain Versatility: The HRI model proves to be versatile, demonstrating strong performance across three distinct domains: classic Inductive Logic Programming (ILP), large-scale visual reasoning, and reinforcement learning.\n\nSuccessful Induction of Interpretable Rules: The system successfully learns and extracts explicit, human-readable symbolic rules for a wide variety of complex tasks.",
      "Author‑reported limitations": "Restricted to Function-Free Logic: The model's expressive power is fundamentally limited to function-free definite Horn clauses. This means it cannot learn rules that involve functions, such as arithmetic operations. The authors explicitly list \"Enabling functions\" and \"Enabling negations\" as objects for future investigation.\n\nLimited Number of Body Atoms: The model's generic set of rules restricts the learned clauses to have at most two body atoms. While the authors argue that this is sufficient to capture many complex rules, they acknowledge that some rules with five or more body atoms are not reducible and would require extending the model's core design.\n\nDependence on Hyperparameters for Expressivity: The actual expressive power of the model in a given task is dependent on hyperparameters like the number of layers and the number of auxiliary predicates instantiated per layer. The authors note this was the reason for the model's poor performance on the \"Length\" task; the default setting of instantiating only one rule per template was too restrictive to find the solution, which required two.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, Recall@K / Precision@K, MSE / RMSE / MAE, Energy / FLOPs / latency / throughput",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Vision-Language, Synthetic / Procedural",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "∂ILP (JILP), shallow MLPs, Neural Logic Inductive Learning, MLP+RCNN",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "10",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a quintessential neuro-symbolic model that learns interpretable logic programs by representing symbolic predicates as learnable embeddings and replacing crisp logical unification with a differentiable soft version, perfectly illustrating how to integrate gradient-based learning with formal symbolic reasoning.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "10.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "Neuro-Symbolic AI, Inductive Logic Programming, Rule Induction, Hierarchical Learning, Interpretability",
      "nsai_domain": "Neuro-Symbolic AI",
      "application_area_original": "Inductive Logic Programming, Visual Reasoning, Reinforcement Learning, Knowledge Base Reasoning, Continual Learning, Autonomous Driving",
      "application_area": "Inductive Logic Programming",
      "task_type_original": "Rule Learning, Relational Learning, Program Induction, Object Classification, Sequential Decision Making, Policy Learning, Explanation Generation",
      "task_type": "Rule Learning",
      "symbolic_representation_original": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Fuzzy logic",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "ILP / rule‑induction systems (FOIL, Aleph, Popper, Metagol), Custom in‑house rule/constraint engines",
      "reasoning_engine": "ILP / rule‑induction systems (FOIL",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules, KG‑embedding + rule‑based hybrid reasoning",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Induced via ILP / rule mining / program synthesis, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2022.0",
      "venue_raw": "PMLR",
      "venue_canonical": "Workshops (CEUR/PMLR)",
      "venue_group_bin": "Workshops (CEUR/PMLR)",
      "venue_group_plot": "Workshops (CEUR/PMLR)",
      "venue_clean": "workshops (ceur/pmlr)",
      "venue_norm": "Workshops (CEUR/PMLR)",
      "venue_group": "Workshops (CEUR/PMLR)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242085892",
    "title": "Scalable Neural-Probabilistic Answer Set Programming",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-09-12 03:02:00.005000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242085892",
      "Paper DOI / URL": "https://jair.org/index.php/jair/article/view/15027",
      "Paper Title ": "Scalable Neural-Probabilistic Answer Set Programming",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Journal of artificial intelligence research",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper introduces Answer Set Networks (ASNs), a novel neural-symbolic solver based on Graph Neural Networks (GNNs) designed to overcome the high computational costs and CPU-bound nature of traditional Answer Set Programming (ASP) solvers. By translating ASP problems into a graph format that leverages GPU parallelization, ASNs outperform existing systems and enable new applications like fine-tuning Large Language Models (LLMs) with logic and solving large-scale drone navigation tasks.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/ml-research/SLASH",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Answer Set Networks, Neural-Symbolic, Answer Set Programming, Graph Neural Networks, Stable Models, Reasoning Graph",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "LLM Fine-Tuning, Autonomous Navigation, Unmanned Aerial Vehicles, Mission Design, MNIST-Addition, Reversal Curse",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Probabilistic Inference, Abductive Reasoning, Relational Reasoning, Navigation, Route Planning, Classification, Stable Model Computation",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "Neural architecture type(s) ": "GNN (Graph Neural Network)",
      "Release date": "2023-05-22 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, LoRA / QLoRA / other PEFT adapters",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "ASP tools (clingo, gringo)",
      "Symbolic representation(s)": "Answer Set Programs (ASP), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "ASP solvers (clingo, gringo, clasp), Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Joint / co‑training of neural and symbolic modules",
      "Tooling / libraries for symbolic side": "ProbLog / PyProbLog, clingo / gringo (ASP)",
      "What are the key findings of the study (1-4 dot points)?": "Massive Scalability on Real-World Tasks: On a complex, real-world drone navigation task (ProMis) that involved mapping the entire 169km² area of Paris, the GPU-native ASN solver was dramatically faster than CPU-bound baselines. It completed the task in 56 minutes, making it 194 times faster than ProbLog (estimated 7 days) and 137 times faster than the baseline SLASH solver (estimated 5 days).\n\nFaster and More Accurate LLM Fine-Tuning: The ASN framework is the first to successfully apply deep probabilistic logic programming to fine-tune a Large Language Model. When used to solve the \"Reversal Curse,\" the ASN-guided model converged an order of magnitude faster (e.g., 9 epochs vs. 96 for the baseline) and achieved significantly higher accuracy (82.2% vs. 72.8%) on the more difficult, reversed-logic queries.\n\nSuperior Benchmark Speed: On the standard MNIST-Addition neural-symbolic benchmark, ASN consistently provided a large computational speed-up over other state-of-the-art methods, including the optimized baseline SAME. For example, it was 3.4 times faster on task T1 and 2.71 times faster on task T3, all while achieving comparable or superior accuracy.",
      "Author‑reported limitations": "The paper identifies the \"higher memory-print associated with increasing choices\" as a key limitation. This means that as the complexity of the symbolic logic program grows (specifically, the number of disjunctive rules or choice rules that create different possible solution paths), the amount of memory the ASN solver requires also increases significantly. The authors list mitigating this memory footprint as a focus for future optimization.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Primary task metrics reported ": "Accuracy, Energy / FLOPs / latency / throughput, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Random split (e.g. 80/10/10)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MNIST, OpenStreetMap",
      "Link to evaluation dataset used (if other)": "https://wiki.openstreetmap.org/wiki/Downloading_data",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DeepProbLog, ProbLog, SAME: A scalable DPPL system (from the authors' previous work)",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "7",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a significant advancement in neural-symbolic AI by introducing Answer Set Networks (ASNs), a novel solver that directly addresses the performance bottleneck of traditional systems by compiling symbolic Answer Set Programs into equivalent Graph Neural Networks, thereby moving the entire reasoning process from slow CPUs to parallel GPUs and enabling new, large-scale applications like logic-guided LLM fine-tuning.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "7.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "Answer Set Networks, Neural-Symbolic, Answer Set Programming, Graph Neural Networks, Stable Models, Reasoning Graph",
      "nsai_domain": "Answer Set Networks",
      "application_area_original": "LLM Fine-Tuning, Autonomous Navigation, Unmanned Aerial Vehicles, Mission Design, MNIST-Addition, Reversal Curse",
      "application_area": "LLM Fine-Tuning",
      "task_type_original": "Probabilistic Inference, Abductive Reasoning, Relational Reasoning, Navigation, Route Planning, Classification, Stable Model Computation",
      "task_type": "Probabilistic Inference",
      "symbolic_representation_original": "Answer Set Programs (ASP), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "Answer Set Programs (ASP)",
      "reasoning_engine_original": "ASP solvers (clingo, gringo, clasp), Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "reasoning_engine": "ASP solvers (clingo",
      "integration_strategy_original": "Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Joint / co‑training of neural and symbolic modules",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "model_family": "Graph Neural Networks (GCN",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "Journal of artificial intelligence research",
      "venue_canonical": "AIJ",
      "venue_group_bin": "AIJ",
      "venue_group_plot": "Other journals (CS)",
      "venue_clean": "aij",
      "venue_norm": "AIJ",
      "venue_group": "Other journals (CS)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242086000",
    "title": "DeepStochLog: Neural Stochastic Logic Programming",
    "year": "2021.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-09-15 00:20:29.216000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242086000",
      "Paper DOI / URL": "https://arxiv.org/pdf/2106.12574",
      "Paper Title ": "DeepStochLog: Neural Stochastic Logic Programming",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2021",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "AAAI",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper introduces DeepStochLog, a novel neural-symbolic framework that integrates neural networks into stochastic definite clause grammars (SDCGs) to define a probability distribution over possible derivations. The experimental evaluation shows this approach scales significantly better than methods based on neural probabilistic logic programs and achieves state-of-the-art results on several challenging neural-symbolic tasks.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/ML-KULeuven/deepstochlog",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Number of independent runs reported?": "No",
      "Number of independent runs (if yes to the above)": "5",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Aapache 2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neural-Symbolic Learning, Stochastic Logic Programming, Probabilistic Programming, Neural Grammars",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Computer Vision , Natural Language Processing , Relational Learning , Citation Networks",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Parsing , Arithmetic Reasoning , Semi-Supervised Classification , Node Classification , Sequence Recognition",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "Neural architecture type(s) ": "CNN / ConvNet, GRU, Simple MLP",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Not reported",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Logic programs (Horn clauses, Datalog), Grammars / automata / production rules",
      "Reasoning / inference engine": "Prolog (e.g., SWI‑Prolog) / Datalog engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "Tooling / libraries for symbolic side": "ProbLog / PyProbLog",
      "What are the key findings of the study (1-4 dot points)?": "Superior Scalability: DeepStochLog scales significantly better and is \"several orders of magnitude faster\" in inference than competing neural probabilistic logic programs (PLPs) like DeepProbLog and NeurASP. This allows it to solve tasks involving larger sequences that cause competitors to time out.\n\nPerformance: The framework achieves state-of-the-art results, performing similarly to or better than competing frameworks like DeepProbLog and NGS on tasks they can both solve.\n\nEfficiency Mechanism: This speed and scalability advantage is attributed to two main factors: 1) its use of SLG resolution (tabling), a form of dynamic programming, and 2) its foundation on \"random walk\" semantics (Stochastic Logic Programs), which is computationally cheaper than the \"possible world\" semantics used by PLP competitors.\n\nExpressiveness: The framework is highly expressive and not limited to just grammars. By using empty production rules, DeepStochLog has the \"full power of stochastic logic programs\" and can encode complex relational problems, such as semi-supervised classification on citation networks.",
      "Author‑reported limitations": "No Structure Learning: The primary limitation is that DeepStochLog \"does not yet learn the structure of the rules.\" The symbolic grammar must be hand-crafted, whereas other systems can enumerate rules and identify relevant ones automatically.\n\nProbability Mass Loss: Because it is based on SLPs, DeepStochLog can \"lose probability mass due to failing derivations\" (i.e., derivations that fail due to unification constraints). The paper notes this could be addressed by computing a normalization constant, but that is computationally expensive.\n\nInference Optimization: The authors note that inference could be further optimized, suggesting parallelization or search-based methods (like finding the k-best derivations) as future work.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Regression / calibration / efficiency, Statistical rigor reported",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Evaluation Datasets (for other) specify here:": "MNIST",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DeepProbLog, NeurASP",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "9",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Because it introduces DeepStochLog, a novel framework integrating neural networks with stochastic definite clause grammars that achieves state-of-the-art results on benchmark tasks while scaling several orders of magnitude faster than dominant neural probabilistic logic programs.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "9.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neural-Symbolic Learning, Stochastic Logic Programming, Probabilistic Programming, Neural Grammars",
      "nsai_domain": "Neural-Symbolic Learning",
      "application_area_original": "Computer Vision , Natural Language Processing , Relational Learning , Citation Networks",
      "application_area": "Computer Vision",
      "task_type_original": "Parsing , Arithmetic Reasoning , Semi-Supervised Classification , Node Classification , Sequence Recognition",
      "task_type": "Parsing",
      "symbolic_representation_original": "Logic programs (Horn clauses, Datalog), Grammars / automata / production rules",
      "symbolic_representation": "Logic programs (Horn clauses",
      "reasoning_engine_original": "Prolog (e.g., SWI‑Prolog) / Datalog engines",
      "reasoning_engine": "Prolog (e.g.",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2021.0",
      "venue_raw": "AAAI",
      "venue_canonical": "AAAI",
      "venue_group_bin": "AAAI family",
      "venue_group_plot": "AAAI family",
      "venue_clean": "aaai",
      "venue_norm": "AAAI family",
      "venue_group": "AAAI family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242086183",
    "title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-09-18 23:47:21.547000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242086183",
      "Paper DOI / URL": "https://openreview.net/forum?id=udNhDCr2KQe",
      "Paper Title ": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICLR",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/azreasoners/recurrent_transformer",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-Symbolic Integration, Constraint-based Reasoning, Differentiable Logic, Inductive Learning, Symbol Grounding",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Constraint Satisfaction Problems, Logical Reasoning, Combinatorial Optimization, Visual Reasoning, Game Solving",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Constraint Solving, Structured Prediction, Logical Inference",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Recurrent Transformer",
      "Neural architecture type(s) ": "Hybrid (specify combination)",
      "Neural architecture type(s) (for other) specify here:": "Recurrent Transformer, CNN, encoder-only Transformer",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Partially open (some weights/scripts",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Constraint satisfaction / SMT formulas",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "recurrent neural network itself",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "A Transformer extended with recurrence (Recurrent Transformer) is a highly effective architecture for learning to solve Constraint Satisfaction Problems (CSPs) in an end-to-end manner, outperforming prior methods like RRN and SATNet.\n\nThe Recurrent Transformer successfully addresses the symbol grounding problem in visual CSPs, achieving state-of-the-art 93.5% accuracy on the ungrounded visual Sudoku (SATNet-V) benchmark, compared to 64.8% for the enhanced SATNet .\n\nKnown symbolic knowledge, in the form of discrete logical constraints, can be injected into the Transformer's training as a differentiable loss function via Straight-Through Estimators (STE) .\n\nThis constraint injection improves sample efficiency, enables semi-supervised learning (improving accuracy by using unlabeled data), and can further boost final model performance.",
      "Author‑reported limitations": "The only reported limitation is experimental, stating that for 16x16 Sudoku, \"we could not test on harder boards\" due to the lack of a suitable puzzle generator.",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "RRN-V, 16*16 Sudoku",
      "Link to evaluation dataset used (if other)": "https://github.com/azreasoners/recurrent_transformer, https://github.com/locuslab/SATNet, https://github.com/UCLA-StarAI/Semantic-Loss, https://github.com/rasmusbergpalm/recurrent-relational-networks",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "RRN , SATNet , and an enhanced SATNet",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "9",
      "Final Decision to Include / Exclude Study": "Include",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "This paper should be included because it demonstrates how to make a modern neural architecture (a Recurrent Transformer) perform multi-step logical reasoning for constraint solving, and critically, how to inject symbolic domain knowledge (logical constraints) directly into its training as a differentiable loss function to improve learning.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "9.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "0.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "Neuro-Symbolic Integration, Constraint-based Reasoning, Differentiable Logic, Inductive Learning, Symbol Grounding",
      "nsai_domain": "Neuro-Symbolic Integration",
      "application_area_original": "Constraint Satisfaction Problems, Logical Reasoning, Combinatorial Optimization, Visual Reasoning, Game Solving",
      "application_area": "Constraint Satisfaction Problems",
      "task_type_original": "Constraint Solving, Structured Prediction, Logical Inference",
      "task_type": "Constraint Solving",
      "symbolic_representation_original": "Constraint satisfaction / SMT formulas",
      "symbolic_representation": "Constraint satisfaction / SMT formulas",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "ICLR",
      "venue_canonical": "ICLR",
      "venue_group_bin": "ICLR",
      "venue_group_plot": "ICLR",
      "venue_clean": "iclr",
      "venue_norm": "ICLR",
      "venue_group": "ICLR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242084360",
    "title": "NeuPSL: Neural Probabilistic Soft Logic",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-09-24 23:23:26.830000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084360",
      "Paper DOI / URL": "https://dl.acm.org/doi/10.24963/ijcai.2023/461",
      "Paper Title ": "NeuPSL: Neural Probabilistic Soft Logic",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IJCAI",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Introduce Neural Probabilistic Soft Logic (NeuPSL), a novel neurosymbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To model the boundary between neural and symbolic representations, they propose a family of energy-based models, NeSy Energy-Based Models, and show that they are general enough to include NeuPSL and many other NeSy approaches. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/linqs/neupsl-ijcai23",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "10",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache-2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neural-symbolic learning, Statistical relational learning, Probabilistic graphical models",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Image classification, Relational learning, Node classification",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Image classification, Node classification, Structured prediction",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "Neural architecture type(s) ": "CNN / ConvNet, GNN (Graph Neural Network), Energy-based model, Simple MLP",
      "Release date": "2023-11-03 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "First‑order / predicate logic, Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "Tooling / libraries for symbolic side": "Probabilistic Soft Logic (PSL / PyPSL)",
      "What are the key findings of the study (1-4 dot points)?": "The neuro-symbolic framework, NeuPSL, can provide significant performance boosts over purely neural network models, with improvements of up to 30%.\n\nNeuPSL effectively performs joint reasoning across related examples, allowing it to leverage structural information to improve predictions, especially in low-data settings.\n\nThe model demonstrates strong scalability and efficiency, achieving higher accuracy on citation network tasks with up to a 40x speedup compared to other state-of-the-art neuro-symbolic methods.\n\nThe paper introduces a general mathematical framework called Neuro-Symbolic Energy-Based Models (NeSy-EBMs) to formalize, understand, and compare different types of neuro-symbolic systems.",
      "Author‑reported limitations": "NeuPSL operates on real-valued (soft) logic, which is a relaxation of discrete logic and may not capture all the nuances of a problem.\n\nThe joint symbolic inference process results in a higher runtime compared to a standard neural network, which could be a constraint for real-time applications.\n\nThe energy loss function used for training does not always align perfectly with the final evaluation metrics and can lead to degenerate solutions.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Energy / FLOPs / latency / throughput, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Random split (e.g. 80/10/10)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Synthetic / Procedural",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Standard Convolutional Neural Networks (CNNs) for vision-based tasks and a Graph Convolutional Network (GCN) for the citation network tasks. Logic Tensor Networks (LTNs), DeepProbLog (DPL), and DeepStochLog",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "11",
      "Final Decision to Include / Exclude Study": "Include",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Because it introduces NeuPSL, a novel and highly scalable framework that integrates deep learning with probabilistic soft logic to perform joint learning and inference, demonstrating state-of-the-art performance and significant speedups on established neuro-symbolic benchmarks.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "11.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neural-symbolic learning, Statistical relational learning, Probabilistic graphical models",
      "nsai_domain": "Neural-symbolic learning",
      "application_area_original": "Image classification, Relational learning, Node classification",
      "application_area": "Image classification",
      "task_type_original": "Image classification, Node classification, Structured prediction",
      "task_type": "Image classification",
      "symbolic_representation_original": "First‑order / predicate logic, Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "reasoning_engine": "Probabilistic logic engines (PSL",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "IJCAI",
      "venue_canonical": "IJCAI",
      "venue_group_bin": "IJCAI",
      "venue_group_plot": "IJCAI",
      "venue_clean": "ijcai",
      "venue_norm": "IJCAI",
      "venue_group": "IJCAI",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242084603",
    "title": "A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-10-08 18:09:09.936000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084603",
      "Paper DOI / URL": "https://arxiv.org/abs/2212.12393",
      "Paper Title ": "A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "neurIPS",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Introduce Approximate Neurosymbolic Inference\n(A-NESI): a new framework for PNL that uses neural networks for scalable\napproximate inference. A-NESI 1) performs approximate inference in polynomial\ntime without changing the semantics of probabilistic logics; 2) is trained using data\ngenerated by the background knowledge; 3) can generate symbolic explanations\nof predictions; and 4) can guarantee the satisfaction of logical constraints at test\ntime, which is vital in safety-critical applications.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/HEmile/a-nesi.git",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "10",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache-2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Probabilistic Neurosymbolic Learning, Approximate Inference, Scalable Reasoning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Computer Vision, Planning, Constraint Satisfaction",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Structured Prediction, Classificatio",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "Neural architecture type(s) ": "CNN / ConvNet, Simple MLP",
      "Release date": "2023-03-08 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Joint / co‑training of neural and symbolic modules",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "Scalability: The proposed A-NESI framework successfully scales to combinatorially complex problems (e.g., 15-digit addition, 9x9 Sudoku classification) where traditional neurosymbolic methods with exact inference fail due to exponential complexity.\n\nPerformance: The approximate inference approach achieves accuracy comparable to exact methods on smaller-scale problems, demonstrating that scalability does not come at a significant performance cost .\n\nNovel Training: The paper introduces a unique training method where the inference model is trained on synthetic data generated from background symbolic knowledge and a belief prior, which helps it generalize beyond the training dataset.\n\nExplainability & Safety: The framework can be extended to generate symbolic explanations and guarantee logical constraints are met at test time via a symbolic pruner, all without a penalty in performance.",
      "Author‑reported limitations": "Variable Dependencies: The method may be less effective when the discrete variables of a problem are highly dependent, as this makes it difficult to learn an informative belief prior.\n\nSymbolic Structure: Learning the inference model becomes more challenging when the underlying symbolic function is highly unstructured.\n\nProblem Size: For the most complex tasks, the neural prediction model did not perfectly learn the problem, leading to a drop in accuracy compared to using a symbolic solver at test time. The model size and training time are expected to grow with problem complexity.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Minor barriers / minor amounts of unclear steps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Multi-digit MNISTAdd, Visual Sudoku Puzzle Classification, Warcraft Visual Path Planning",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DeepProbLog, DPLA*, DeepStochLog, NeuPSL, Embed2Sym, I-MLE",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "13",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It introduces A-NESI, a novel and practical framework that tackles the critical challenge of scalability in probabilistic neurosymbolic systems by using a neural network to approximate expensive logical inference, thereby making it feasible to solve combinatorially complex tasks that are intractable for methods relying on exact reasoning.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "13.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Probabilistic Neurosymbolic Learning, Approximate Inference, Scalable Reasoning",
      "nsai_domain": "Probabilistic Neurosymbolic Learning",
      "application_area_original": "Computer Vision, Planning, Constraint Satisfaction",
      "application_area": "Computer Vision",
      "task_type_original": "Structured Prediction, Classificatio",
      "task_type": "Structured Prediction",
      "symbolic_representation_original": "Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "Probabilistic logic (Markov Logic Networks",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Joint / co‑training of neural and symbolic modules",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "neurIPS",
      "venue_canonical": "NeurIPS",
      "venue_group_bin": "NeurIPS",
      "venue_group_plot": "NeurIPS",
      "venue_clean": "neurips",
      "venue_norm": "NeurIPS",
      "venue_group": "NeurIPS",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "242086184",
    "title": "Injecting Logical Constraints into Neural Networks via Straight-Through Estimators",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-10-21 01:48:12.121000",
      "Email Address": "hwdeng@umd.edu",
      "Reviewer Name": "Haowei",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242086184",
      "Paper DOI / URL": "https://proceedings.mlr.press/v162/yang22h/yang22h.pdf",
      "Paper Title ": "Injecting Logical Constraints into Neural Networks via Straight-Through Estimators",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICML",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper introduces CL-STE, a method to inject discrete logical constraints into neural networks by representing the constraints as a loss function and using a Straight-Through Estimator (STE) to enable gradient-based optimization. By leveraging GPUs and avoiding heavy symbolic computation, this technique scales significantly better than existing neuro-symbolic methods and allows various architectures, like CNNs and GNNs, to learn from constraints with fewer or no labeled data.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/azreasoners/cl-ste",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "10",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-symbolic integration, Learning with constraints, Differentiable logic",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Computer vision, Puzzle solving, Constraint satisfaction, Graph problems",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Classification, Unsupervised learning, Semi-supervised learning, Constraint satisfaction",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer), Other (specify below)",
      "Neural model name & family (for other) specify here:": "simpleMLP",
      "Neural architecture type(s) ": "CNN / ConvNet, GNN (Graph Neural Network), Simple MLP",
      "Release date": "2022-11-20 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Partially open (some weights/scripts",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Symbolic representation(s)": "Propositional / Boolean logic rules",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Constraint injection / regularization during neural training",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "The paper proposes CL-STE, a method to encode discrete logical constraints (in CNF) as a differentiable loss function for neural networks.\n\nIt uses Straight-Through Estimators (STE) to bypass the zero-gradient problem of discrete binarization, allowing gradient descent to train networks to satisfy the logical constraints.\n\nThe method is highly scalable compared to other neuro-symbolic approaches (like DeepProbLog, NeurASP) because it avoids expensive symbolic solver calls and leverages GPU batch training.\n\nCL-STE is general and can be applied to various architectures (MLP, CNN, GNN) to enable learning from constraints, reducing the need for labeled data in unsupervised or semi-supervised settings.",
      "Author‑reported limitations": "The authors note that the gradients generated by CL-STE are local and heuristic, unlike the \"better quality gradients\" from symbolic solvers that reflect global properties. However, they present this as a deliberate trade-off for significantly faster computation. They also suggest that \"larger-scale experiments\" are a logical next step.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "7.0",
      "Primary task metrics reported ": "Accuracy, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Random split (e.g. 80/10/10), Few‑shot (N‑shot prompting / small labeled set)",
      "Datasets used for Evaluation ": "Toy logical datasets (symbolic math, rule chains), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MNIST , FASHION-MNIST, Sudoku",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DeepProbLog , NeurASP , NeuroLog , and SATNet",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "13",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It introduces CL-STE, a highly scalable and general method for integrating propositional logic constraints into diverse neural network architectures by encoding the logic as a differentiable loss function via straight-through estimators, effectively bypassing the computational bottlenecks of traditional symbolic reasoning engines.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "13.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neuro-symbolic integration, Learning with constraints, Differentiable logic",
      "nsai_domain": "Neuro-symbolic integration",
      "application_area_original": "Computer vision, Puzzle solving, Constraint satisfaction, Graph problems",
      "application_area": "Computer vision",
      "task_type_original": "Classification, Unsupervised learning, Semi-supervised learning, Constraint satisfaction",
      "task_type": "Classification",
      "symbolic_representation_original": "Propositional / Boolean logic rules",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Constraint injection / regularization during neural training",
      "integration_strategy": "Constraint injection / regularization during neural training",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer), Other (specify below)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "7.0",
      "publication_year": "2022.0",
      "venue_raw": "ICML",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083986",
    "title": "Learning neural-symbolic descriptive planning models via cube-space priors: The voyage home (to STRIPS)",
    "year": "2020.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-10-23 17:12:00.970000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083986",
      "Paper DOI / URL": "10.5555/3491440.3491811",
      "Paper Title ": "Learning neural-symbolic descriptive planning models via cube-space priors: The voyage home (to STRIPS)",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2020",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IJCAI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Architecture ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "neuro-symbolic architecture is trained end-to-end to produce a succinct and effective discrete state transition model from images alone.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/guicho271828/latplan",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "V5",
      "If yes: Provide link": "https://github.com/guicho271828/latplan/releases/tag/v5.0.0",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/guicho271828/latplan",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "there are like 10 papers all linked to this one repo all with different model weights, and only this model weight was ever publicly released",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic planning, symbol grounding, STRIPS, PDDL, representation learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "visual puzzle domains (LightsOut, 8-puzzle, 15-puzzle, Towers of Hanoi)",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "action-model learning, planning from images, ablation analysis, heuristic search evaluation",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Gumbel-Softmax Autoencoder (SAE) + effect network with BtL",
      "Neural architecture type(s) ": "Autoencoder / VAE, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Release date": "2020-07-01 00:00:00",
      "Prompting strategy (if applicable)": "Other (specify below)",
      "Alignment / Safety Filters Applied (if applicable) ": "Other (specify below)",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "trained from scratch on generated transitions",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Unsupervised end-to-end training with hyper-param tuning via genetic algorithm",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Binary latent states → extract ADD/DEL sets; compile to grounded PDDL used by planners (probabilities/logits → logic facts)",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "PDDL + Fast Downward planner with LMcut and Merge-and-Shrink heuristics",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "STRIPS (grounded PDDL)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "classical planner (Fast Downward)",
      "Source of symbolic knowledge": "Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Converted from neural outputs (effect extraction ADD/DEL)",
      "Update / learning of symbols": "Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Learned/induced jointly during neural training; effects extracted post-training",
      "Integration strategy with neural part": "Other (specify below)",
      "Integration strategy with neural part (for other) specify here:": "Differentiable constraints (BtL + BN ensure STRIPS semantics) + pipeline neural→symbolic (PDDL → planner)",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "PDDL, Fast Downward, LMcut, Merge-and-Shrink",
      "What are the key findings of the study (1-4 dot points)?": "Cube-Space AE yields directly usable grounded PDDL from images and solves visual planning tasks with off-the-shelf planners. \n\n\nBack-to-Logit + BatchNorm stabilizes learning and enforces add/delete effects; outperforms naive Min/Max variants. \n\n\nHeuristic planners (LMcut, M&S) reduce node expansions and enable more 15-puzzle solves within limits vs. blind search. \n\n\nLearned representation generalizes to unseen states during planning.",
      "Author‑reported limitations": "Propositional/factored (not lifted FOL); directions for combining with lifted symbols.",
      "Reviewer‑identified limitations / threats to validity": "Synthetic domains only; compute/time for hyper-param tuning; seed handling not documented.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Regression / calibration / efficiency, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "earch / efficiency",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Split / Protocol (for other) specify here:": "andom split per domain: 5000 transitions; 90/5/5 train/val/test",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "4×4 LightsOut, MNIST 8-puzzle, Mandrill & Spider 15-puzzles (scrambled photographs), Twisted LightsOut, Hanoi; all synthetic",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "BtL vs. MinMax/Smooth; ablations (−BN, −Direct, −Succ); blind vs. LMcut vs. M&S",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "<5%",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Good example of a neurosymbolic system that is able to plan; results fully reproduceible ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "5.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "neuro-symbolic planning, symbol grounding, STRIPS, PDDL, representation learning",
      "nsai_domain": "neuro-symbolic planning",
      "application_area_original": "visual puzzle domains (LightsOut, 8-puzzle, 15-puzzle, Towers of Hanoi)",
      "application_area": "visual puzzle domains (LightsOut",
      "task_type_original": "action-model learning, planning from images, ablation analysis, heuristic search evaluation",
      "task_type": "action-model learning",
      "symbolic_representation_original": "Propositional / Boolean logic rules, Other (specify below)",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Other (specify below)",
      "integration_strategy": "Other (specify below)",
      "knowledge_source_original": "Other (specify below)",
      "knowledge_source": "Other (specify below)",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2020.0",
      "venue_raw": "IJCAI",
      "venue_canonical": "IJCAI",
      "venue_group_bin": "IJCAI",
      "venue_group_plot": "IJCAI",
      "venue_clean": "ijcai",
      "venue_norm": "IJCAI",
      "venue_group": "IJCAI",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084181",
    "title": "LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-10-29 11:14:42.672000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084181",
      "Paper DOI / URL": "https://proceedings.neurips.cc/paper_files/paper/2024/file/8196be81e68289d7a9ece21ed7f5750a-Paper-Datasets_and_Benchmarks_Track.pdf",
      "Paper Title ": "LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Neurips",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "LogiCity models diverse\nurban elements using semantic and spatial concepts, such as IsAmbulance(X)\nand IsClose(X, Y). These concepts are used to define FOL rules that govern the\nbehavior of various agents. Since the concepts and rules are abstractions, they\ncan be universally applied to cities with any agent compositions, facilitating the\ninstantiation of diverse scenarios",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/Jaraxxus-Me/LogiCity",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://drive.google.com/file/d/1ePLVlNH77VV25171yOSgku21tji9ISdG/view",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "continual learning reports mean/variance over 3 runs",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Github repo provided everything needed for reproduction, no issues found on reproduciton",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic reasoning, FOL rules, SMT-based inference, simulator/benchmark, multi-agent",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "urban/traffic simulation, autonomous driving–like reasoning, multi-agent planning, visual action understanding",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "sequential decision-making (POMDP/RL), imitation learning/ILP rule induction, visual reasoning from images, graph reasoning",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Urban-like scenarios with rule-governed multi-agent traffic behaviors; closer to realistic city dynamics than prior toy benchmarks",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "Neural model name & family (for other) specify here:": "ResNet-50 + FPN (ImageNet-pretrained), SB3 baselines (DQN, PPO, A2C), DreamerV2; MLP/GNN classifiers for BC; NLM-DQN (NeSy Q-learning agent",
      "Neural architecture type(s) ": "CNN / ConvNet, GNN (Graph Neural Network), Simple MLP, Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Simple MLP; GNN; RL agents (DQN/PPO/A2C); World-model (DreamerV2)",
      "Release date": "2024-06-01 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "Other (specify below)",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "N/A - simulation ",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints, Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Probabilities/logits map to actions under rule constraints; rules shape rewards and constrain allowed actions (Z3-style)",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Z3-style SMT constraints",
      "Link to Existing symbolic project used (if applicable) ": "https://ericpony.github.io/z3py-tutorial/guide-examples.htm",
      "Symbolic representation(s)": "First‑order / predicate logic, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "First-order predicate logic rules; constraints over actions (Stop/Slow/Normal/Fast)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom in-framework rule checking with Z3-style constraints (integration indicated in configs/README)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Source of symbolic knowledge (for other) specify here:": "domain rules and ontology YAMLs",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "Pipeline + constraint injection: symbolic rules constrain action legality and provide rule-based rewards; NeSy agents incorporate logical modules (NLM-DQN)",
      "Example of a rule / triple / formula (copy from paper)": "Defined in YAML file from GitHub",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Z3-style constraints (naming compatibility per tutorial), YAML-specified ontology/rules",
      "What are the key findings of the study (1-4 dot points)?": "TSR/DSR drop substantially from medium --> hard --> expert, revealing challenges in long-horizon, multi-agent reasoning under constraints. \n\n\nNeSy approaches (e.g., NLM-DQN) outperform purely neural baselines in abstraction learning and continual settings. \n\n\nVAP highlights added perceptual noise; modular pipelines help on visually diverse scenes. \n\n\nLogiCity provides flexible, rule-grounded tasks enabling systematic scaling of reasoning complexity.",
      "Author‑reported limitations": "Current methods still struggle in complex scenarios; high-dimensional perception complicates one-step reasoning; long-horizon multi-agent reasoning remains open.",
      "Reviewer‑identified limitations / threats to validity": "Limited multi-seed variance reporting; some baseline specifics relegated to configs;",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "SPF: TSR (Trajectory Success Rate), DSR (Decision Success Rate), Score (return vs. random). Definitions given in paper and VAP: per-action recall (Slow/Normal/Fast/Stop), averaged accuracy (aAcc), weighted accuracy (wAcc).",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Evaluation assets provided (for other) specify here:": "Code, modeldata all provided from Github ",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "LogiCity SPF & VAP synthetic data.",
      "Link to evaluation dataset used (if other)": "https://drive.google.com/file/d/1ePLVlNH77VV25171yOSgku21tji9ISdG/view?usp=sharing",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Oracle, Random; BC: Popper/MaxSynth/NLM/GNN/MLP; RL: NLM-DQN, DQN, PPO, A2C, MB-shooting, DreamerV2",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "Approximate: 5–10% absolute deviations in TSR/DSR (expected) across runs, consistent with stochasticity, evaluation set differences, and potential config mismatches. (Paper reports, e.g., DQN Hard TSR≈0.09, DSR≈0.12; we observed TSR≈0.07, DSR≈0.103 — close. For other agents, qualitative ordering matched: NLMDQN > DQN/PPO/A2C on “hard”.)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Paper’s TSR/DSR definitions depend on (i) two-times-oracle-steps and no rule violations for TSR; and (ii) at least one rule-constrained step and no rule violations for DSR; and Score = (avg return) − (random agent return). Ensure evaluation scripts follow these definitions and that cached episodes (PKL) align with the paper’s split",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It works, everything to reproduce is available and LogiCity provides a real novel neuro symbolic framework ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "neuro-symbolic reasoning, FOL rules, SMT-based inference, simulator/benchmark, multi-agent",
      "nsai_domain": "neuro-symbolic reasoning",
      "application_area_original": "urban/traffic simulation, autonomous driving–like reasoning, multi-agent planning, visual action understanding",
      "application_area": "urban/traffic simulation",
      "task_type_original": "sequential decision-making (POMDP/RL), imitation learning/ILP rule induction, visual reasoning from images, graph reasoning",
      "task_type": "sequential decision-making (POMDP/RL)",
      "symbolic_representation_original": "First‑order / predicate logic, Other (specify below)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "Neurips",
      "venue_canonical": "NeurIPS",
      "venue_group_bin": "NeurIPS",
      "venue_group_plot": "NeurIPS",
      "venue_clean": "neurips",
      "venue_norm": "NeurIPS",
      "venue_group": "NeurIPS",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084397",
    "title": "Dynamic Planning with a LLM",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-10-30 01:38:46.056000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084397",
      "Paper DOI / URL": "https://arxiv.org/abs/2308.06391",
      "Paper Title ": "Dynamic Planning with a LLM",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Fusion Framework ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "presents LLM Dynamic Planner (LLM-DP): a neuro-symbolic framework where an LLM works hand-in-hand with a traditional planner to solve an embodied task. Given action-descriptions, LLM-DP solves Alfworld faster and more efficiently than a naive LLM ReAct baseline.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/itl-ed/llm-dp",
      "Primary language / framework": "Python + external classical planner (LAPKT BFS(f)); OpenAI chat model API (gpt-3.5-turbo-0613)",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "https://github.com/alfworld/alfworld",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Getting Alfworld to work was a headache but given that and ( my own personal ) openAI API credit, the implementation of hte actual framework was straight forward ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic planning, embodied agents, PDDL, belief sampling",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "household task planning (text-only simulation), agentic LLMs",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "goal-conditioned planning; instruction following; action-sequence generation",
      "Real‑world application claimed?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural model name & family (for other) specify here:": "OpenAI gpt-3.5-turbo-0613 (chat model",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "OpenAI gpt-3.5-turbo-0613 (chat model)",
      "Release date": "2023-08-01 00:00:00",
      "Prompting strategy (if applicable)": "few‑shot",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported, Other (specify below)",
      "Alignment / Safety Filters Applied (for other) specify here:": "OpenAI default",
      "Pre‑training source(s) ": "Not reported / unclear, Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "OpenAI API",
      "Fine‑tuning / adaptation details": "Not reported / unclear, Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "OpenAI API",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Text → symbols: LLM converts task text into PDDL goal predicates.  Probabilistic hypotheses → facts: LLM samples plausible world states (predicates) for",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "DDL domain & problem files; BFS(f) planner via LAPKT",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/LAPKT-dev/LAPKT-public",
      "Symbolic representation(s)": "First‑order / predicate logic, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "First-order / predicate logic (PDDL predicates), plus goal formulas; knowledge encoded as domain predicates and action schemas",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Classical planner — BFS(f) (LAPKT)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported), Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Static domain; beliefs updated online from observations; unknown facts are sampled per step (resampled as needed",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Integration strategy with neural part (for other) specify here:": "LLM fed to  PDDL goals & sampled world states → planner; closed-loop re-planning on new observations.",
      "Example of a rule / triple / formula (copy from paper)": "(:goal (exists (?t - potato ?r - countertop)\n        (and (inReceptacle ?t ?r) (isHot ?t))))\n```  :contentReference[oaicite:32]{index=32}  ",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "PDDL + LAPKT BFS(f)",
      "What are the key findings of the study (1-4 dot points)?": "LLM-DP achieves ~96% average success on ALFWorld, outperforming a ReAct baseline run by the authors (54–64%). \n\n\nRequires far fewer LLM tokens (~633k vs 9.16M for their ReAct reproduction), reducing cost. \n\n\nProduces shorter plans on average (~13.2 vs 18.7 actions vs ReAct), indicating better efficiency. \n\n\nSampling N plausible world states improves robustness; fallback random sampling helps when LLM sampling returns satisfied/invalid states. \n",
      "Author‑reported limitations": "Future work to handle uncertain/noisy observations, improved Action Selector (self-reflection), and moving beyond a static domain file",
      "Reviewer‑identified limitations / threats to validity": "Dependence on a closed API (gpt-3.5-turbo); limited statistical reporting (no seeds/variance); assumptions of perfect observations and always-successful actions in ALFWorld may limit real-world transfer.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Success Rate / Accuracy (per task & overall) — Primary   dynamic planning with an LLM  Average Episode Length (efficiency) — Primary   dynamic planning with an LLM  LLM Token Count (cost proxy) — Auxiliary",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Split / Protocol (for other) specify here:": "Official ALFWorld evaluation episodes; no train/fine-tune (zero-training); few-shot prompting + planning loop",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "ALFWorld (Synthetic / Procedural; embodied text environment)",
      "Link to evaluation dataset used (if other)": "https://github.com/alfworld/alfworld",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "ReAct (original; plus authors’ own reproduction with gpt-3.5-turbo); LLM-DP vs LLM-DP-random; comparisons across sampling n",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "~5%",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Authors don’t count ReAct \"think\" steps as actions when computing episode length (this favors ReAct slightly)",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Demonstrates a clear neuro-symbolic integration (LLM + classical planner) with open code, a public benchmark (ALFWorld)",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "5.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neuro-symbolic planning, embodied agents, PDDL, belief sampling",
      "nsai_domain": "neuro-symbolic planning",
      "application_area_original": "household task planning (text-only simulation), agentic LLMs",
      "application_area": "household task planning (text-only simulation)",
      "task_type_original": "goal-conditioned planning; instruction following; action-sequence generation",
      "task_type": "goal-conditioned planning",
      "symbolic_representation_original": "First‑order / predicate logic, Other (specify below)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "MIT",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2023.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084419",
    "title": "Learning Signal Temporal Logic through Neural Network for Interpretable Classification",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-10-30 02:40:47.873000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084419",
      "Paper DOI / URL": "https://ieeexplore-ieee-org.proxy-um.researchport.umd.edu/stamp/stamp.jsp?tp=&arnumber=10156357",
      "Paper Title ": "Learning Signal Temporal Logic through Neural Network for Interpretable Classification",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IEEE",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "design a novel time function and sparse softmax function\nto improve the soundness and precision of the neural-STL\nframework. As a result, we can efficiently learn a compact STL\nformula for the classification of time-series data through off-theshelf gradient-based tools.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/danyangl6/nn-tli",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "Synthetic generated by driving_dataset.py",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Partial",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "main.py hard codes \"with open('naval_dataset.pkl', 'rb') as f:\" --> needs to be changed to dataset/'naval_dataset.pkl to work ( I changed this one thing and the repo worked - technically this should have disqualified the repo / paper but they do have a more up to date repo that seems to be maintained and the amount of papers I have been excluding is making me sad :( ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "emporal-logic, neuro-symbolic-classification, interpretable-ML",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "autonomous-driving-behaviors, maritime-surveillance",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "binary-time-series-classification, rule-learning",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "maritime surveillance, interpretable behavior rules",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "ustom NN with differentiable STL modules (PyTorch)",
      "Neural architecture type(s) ": "Simple MLP, Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Simple MLP / custom layers implementing predicates + differentiable temporal/logical ops; NOT Transformer/CNN/RNN",
      "Release date": "2023-01-01 00:00:00",
      "Prompting strategy (if applicable)": "Other (specify below)",
      "Alignment / Safety Filters Applied (if applicable) ": "Other (specify below)",
      "Pre‑training source(s) ": "Other (specify)",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "B/A",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "The NN computes robustness of candidate STL(1) formula; final binary gates (DNF) + learned thresholds/time windows define an explicit symbolic STL formula; robustness sign → class.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "None (STL formalism; not a separate tool)",
      "Symbolic representation(s)": "Temporal / modal logics",
      "Symbolic representation(s) (for other) specify here:": "Temporal / modal logics (Signal Temporal Logic); propositional combos of unary predicates over time; DNF over □/♢ operators with learned windows",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom in-network differentiable approximation to max/min via sparse softmax; no external prover/SMT",
      "Source of symbolic knowledge": "Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Learned from data (predicates, time windows, and DNF gates) with post-hoc simplification (Algorithm 1)",
      "Update / learning of symbols": "Learned/induced jointly during model training, Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Jointly learned during training; then pruned by Formula Simplification Algorithm",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "Integration strategy with neural part (for other) specify here:": "Differentiable constraints — STL robustness made differentiable (sparse softmax + time function), enabling gradient-based learning of neural + symbolic jointly.",
      "Example of a rule / triple / formula (copy from paper)": "Driving: [0,39](x > −1.97) (Go-forward vs Overtake). Naval: [9,14](y > 23.37) ∧ [60,60](x < 27.96).",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom (PyTorch), no external logic engines.",
      "What are the key findings of the study (1-4 dot points)?": "NN-TLI learns compact STL(1) classifiers that are directly interpretable. \n\nSparse softmax + differentiable time function guarantee soundness and enable stable gradient learning. \n\nOn driving tasks, NN-TLI achieves lower mean MCR and faster time than soft-NN, especially on temporal cases. \n\nOn naval, NN-TLI attains MCR 0.0000 with a 2-clause STL formula and ~0.2 min to best.",
      "Author‑reported limitations": "restricted to STL(1) (no nested temporal ops); extension to more complex properties left to future work",
      "Reviewer‑identified limitations / threats to validity": "Sparse README; unpinned env; naval data source not directly linked; seeds/configs not fully specified ( there is a new repo specified to be at https://github.com/danyangl6/TLINet) ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "4.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "MCR (misclassification rate)",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Case-wise evaluations; synthetic generation; not standardized splits (temporal windows learned; MCR/time reported)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Naval surveillance (from authors prior work).",
      "Link to evaluation dataset used (if other)": "https://ieeexplore.ieee.org/document/7500142",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "oft-NN; BCDT; online learning (naval)",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "mplements a clear neuro-symbolic classifier with interpretable STL formulas, and both driving and naval results were successfully reproduced",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "emporal-logic, neuro-symbolic-classification, interpretable-ML",
      "nsai_domain": "emporal-logic",
      "application_area_original": "autonomous-driving-behaviors, maritime-surveillance",
      "application_area": "autonomous-driving-behaviors",
      "task_type_original": "binary-time-series-classification, rule-learning",
      "task_type": "binary-time-series-classification",
      "symbolic_representation_original": "Temporal / modal logics",
      "symbolic_representation": "Temporal / modal logics",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Other (specify below)",
      "knowledge_source": "Other (specify below)",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "4.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2023.0",
      "venue_raw": "IEEE",
      "venue_canonical": "IEEE",
      "venue_group_bin": "IEEE journals/proceedings",
      "venue_group_plot": "IEEE journals/proceedings",
      "venue_clean": "ieee",
      "venue_norm": "IEEE journals/proceedings",
      "venue_group": "IEEE journals/proceedings",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085166",
    "title": "Probabilistic Mission Design for Neuro-Symbolic Unmanned Aircraft Systems",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-06 12:24:34.936000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085166",
      "Paper DOI / URL": "10.1109/TITS.2025.3609835",
      "Paper Title ": "Probabilistic Mission Design for Neuro-Symbolic Unmanned Aircraft Systems",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IEEE ",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Authors propose Probabilistic Mission\nDesign (ProMis), a novel neuro-symbolic approach to navigating\nUAS within legal frameworks. ProMis is an interpretable and\nadaptable system architecture that links uncertain geospatial data\nand noisy perception with declarative, Hybrid Probabilistic Logic\nPrograms (HPLP) to reason over the agent’s state space and its legality",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/HRI-EU/ProMis",
      "Primary language / framework": "Python / Javascript ",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "https://huggingface.co/datasets/sy2002123/levir-cd",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Open / MIT",
      "Notes on reproduction": "Needed DCProbLog-friendly distributions in the logic program; corrected MAE interpolation to use .values arrays.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "probabilistic logic programming, hybrid probabilistic reasoning, neuro-symbolic planning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "dvanced air mobility, UAS navigation, legal/regulatory compliance",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "constraint satisfaction, geospatial inference, runtime/efficiency analysis, adaptive sampling",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "mission planning & compliance visualization for UAS. PMLs quantify probability that rules are satisfied at each location; demonstrated in multiple urban scenarios.",
      "Neural model name & family ": "DeepSeek / InternLM / MiniCPM, Other (specify below)",
      "Neural model name & family (for other) specify here:": "ChangeFormer (Transformer-based change detection); general-purpose LLM (DeepSeek) for program synthesis",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only), Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "ransformer (vision); LLM for code-gen",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not Reported",
      "Release date": "2025-01-31 00:00:00",
      "Prompting strategy (if applicable)": "Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "Example-driven code translation to include a landscape/1 clause (See Figure 11).",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear, Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "Not reported (uses LEVIR-CD for supervised training)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Supervised training on LEVIR-CD for change maps.",
      "Access level ": "Open weights downloadable",
      "Access level (for other) specify here:": "Code open; model weights for ChangeFormer not required to reproduce core logic/runtimes.",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules, Probabilities/logits converted to logic facts or constraints",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Probabilities → facts/clauses (e.g., p::change(X)), then used in HPLP",
      "Existing symbolic project used (if applicable) ": "ProbLog / PSL (Probabilistic Soft Logic) / Markov Logic (Alchemy/Tuffy)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "ProbLog / DCProbLog (Hybrid Relational ProbLog).",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/ML-KULeuven/problog",
      "Symbolic representation(s)": "First‑order / predicate logic, Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Symbolic representation(s) (for other) specify here:": "First-order logic rules; probabilistic logic over categorical & continuous RVs (HPLP)",
      "Reasoning / inference engine": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "Reasoning / inference engine (for other) specify here:": "Probabilistic logic engine (ProbLog/DCProbLog grounding + probability of query)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Combination -  imported map semantics (OSM/Overpass), hand-crafted operator rules, neural outputs",
      "Update / learning of symbols": "Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Parameters estimated from data; rules static/reconfigurable by operator; no joint differentiable learning",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Integration strategy with neural part (for other) specify here:": "Pipeline — statistical & neural modules produce probabilistic relations → HPLP → PML query",
      "Example of a rule / triple / formula (copy from paper)": "landscape(X) :- distance(X, lake) < 25, can_return(X); permits(X), can_return(X)",
      "Tooling / libraries for symbolic side": "ProbLog / PyProbLog, Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "ProbLog/DCProbLog; Overpass/OSM for KB extraction.",
      "What are the key findings of the study (1-4 dot points)?": "1.  Paper introduces a PML, defines what it is and how it’s computed (hybrid relations). \nA Probabilistic Mission Landscape (PML) is a scalar field over the agent state (x) that encodes the probability that a mission “constitution” (c) (the set of rules/constraints) is satisfied at (x). ProMis computes the PML by running inference in a Hybrid Probabilistic Logic Program (HPLP) whose relations mix categorical facts (e.g, over(x, park)) with continuous quantities (e.g., distance to road classes with learned ( μ, σ). The approach explicitly models map uncertainty via a stochastic affine error model to estimate relation parameters, and then uses those parameters + rules to generate the PML that can be optimized by the UAS or shown to an operator.\n    \n2.  Paper shows that framework can provide multimodal integration into the HPLP (maps + neural perception). \nSymbolic relations are parameterized from two sources: (i) statistical map uncertainty, where semantically annotated map features are perturbed by a stochastic model to estimate distributions for spatial relations; and (ii) neural perception, where a change-detection network (ChangeFormer) provides a probabilistic unary relation (p::change(x)) so the logic can reason about outdated maps or dynamic scenes. Both information streams are compiled into the same HPLP vocabulary and used jointly when inferring the PML.\n    \n3.  Runtime behavior and parallelization (small compute, fast at runtime) (Fig. 8). \nBecause PML samples are generated i.i.d., ProMis parallelizes inference across threads without changing results. Empirically, inference time is linear in the number of samples, while increasing grid resolution introduces a quadratic increase (fixed 2-D grid). The authors also report an optimal batch size that depends on the scenario and show that parameter estimation and PML inference contribute about equally to total runtime. Figure 8 summarizes scaling with threads, resolution, and the per-step breakdown.\n    \n4.  Adaptive sampling reduces error vs. naive grids (Figs. 9–10). \nThe paper compares (a) naive grid rasterization, (b) local-entropy acquisition, and (c) Gaussian-Process-guided sampling. PMLs from each method are upscaled (linear or nearest-neighbor) and scored against a 200x200 ground-truth PML using MAE. Figures 9–10 show that adaptive procedures (entropy or GP) achieve higher sample efficiency / lower MAE than grids at the same sample counts across four geographic scenarios.",
      "Author‑reported limitations": "Runtime is the main bottleneck. Parameter estimation and probabilistic inference each account for roughly half of total time and improvements require more efficient sampling and inference.\n\nDependence on uncertainty metadata as ProMis is “well equipped to deal with sensor noise and varying map quality,” but its probabilistic semantics assume scenarios where uncertainty information (e.g., map accuracy) is available.\n\nLLM interface can introduce semantic errors ( LLM's always provide ingress points for hallucinations), however,  Syntax mistakes are caught at compile time, but avoiding semantic mis-translations likely requires fine-tuned, domain-specific LLMs and interactive operator and as such LLM loops are suggested as future work",
      "Reviewer‑identified limitations / threats to validity": "Not end-to-end differentiable. The neural module (e.g., ChangeFormer) is trained separately; rules/relations are encoded in HPLP and then inference produces the PML used for planning i.e., there is no joint neural-symbolic training loop as the current framework is described which is good for interchangeability but not good for niche field optimization \n\nRelies on public map quality/coverage as many relations and constraints are sourced from OpenStreetMap/Overpass and public datasets; quality gaps or missing tags can limit fidelity of the funetuned system ( small limitation, especially for such a far reaching proof of concept framework ) ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, Regression / calibration / efficiency",
      "Primary task metrics reported (for other) specify here:": "Efficiency: Total runtime vs. threads, resolution, and batch size; decomposition into parameter-estimation vs. inference time and ccuracy surrogate: MAE of candidate PMLs versus a 200×200 reference “ground-truth” PML.",
      "Split / Protocol": "Not reported / unclear",
      "Split / Protocol (for other) specify here:": "Not applicable to core PML experiments; LEVIR-CD training referenced for ChangeFormer.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "OpenStreetMap/Overpass (background knowledge); LEVIR-CD for change detection.",
      "Link to evaluation dataset used (if other)": "https://wiki.openstreetmap.org/wiki/Downloading_data, https://opendatalab.com/OpenDataLab/LEVIR-CD",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Naive grid sampling, Local-entropy acquisition, Gaussian-process (GP) acquisition and Interpolation linear vs. nearest-neighbor before MAE is computed",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "0% on qualitative patterns; quantitative results were within indipendent run reported variance ",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Reference PML at 200×200",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Novel and Neurosymbolic system that runs / works ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "We successfully reproduced the paper’s core quantitative results: (i) StaRMap relation fields and initial PML maps (Figs. 6–7), (ii) runtime scaling with threads/batch size and resolution (Fig. 8), and (iii) adaptive sampling curves showing entropy/GP acquisitions outperforming naive grids in MAE (Figs. 9–10). We did not reproduce the LLM component (the DeepSeek prompt-to-ProMis pipeline that generates the mission program and Fig. 11), nor the optional neural “change(X)” perception path, because our annotators scoped the exercise to the paper’s evaluative, code-deterministic pieces and judged ad-hoc LLM usage (model choice/versions, API availability, non-determinism) not necessary for the reproducibility target.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "probabilistic logic programming, hybrid probabilistic reasoning, neuro-symbolic planning",
      "nsai_domain": "probabilistic logic programming",
      "application_area_original": "dvanced air mobility, UAS navigation, legal/regulatory compliance",
      "application_area": "dvanced air mobility",
      "task_type_original": "constraint satisfaction, geospatial inference, runtime/efficiency analysis, adaptive sampling",
      "task_type": "constraint satisfaction",
      "symbolic_representation_original": "First‑order / predicate logic, Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "reasoning_engine": "Probabilistic logic engines (PSL",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Other (specify below)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "DeepSeek / InternLM / MiniCPM, Other (specify below)",
      "model_family": "DeepSeek / InternLM / MiniCPM",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "IEEE ",
      "venue_canonical": "IEEE",
      "venue_group_bin": "IEEE journals/proceedings",
      "venue_group_plot": "IEEE journals/proceedings",
      "venue_clean": "ieee",
      "venue_norm": "IEEE journals/proceedings",
      "venue_group": "IEEE journals/proceedings",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085117",
    "title": "Tunable Neural Encoding of a Symbolic Robotic Manipulation Algorithm",
    "year": "2021.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-06 13:03:52.258000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085117",
      "Paper DOI / URL": "https://doi.org/10.3389/fnbot.2021.744031",
      "Paper Title ": "Tunable Neural Encoding of a Symbolic Robotic Manipulation Algorithm",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2021",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Frontiers in Neurorobotics",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "present a neurocomputational controller for robotic manipulation based on the recently developed “neural virtual machine” (NVM). Authors program the NVM with a symbolic algorithm that solves blocks-world restacking problems, and execute it in a robotic simulation environment",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/garrettkatz/poppy-muffin",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "https://github.com/garrettkatz/poppy-muffin/tree/master/pybullet/tasks/pick_and_place",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5",
      "Variance / error bars shown?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Partial",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Reproduction logs show RVM vs NVM outputs across 3–7 block tasks with consistent magnitudes/trends (nvm size is 294,976 printed)",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic execution, neural virtual machine, robotic manipulation",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "robotics, manipulation, planning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "block stacking, pick-and-place, procedural execution",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "robotic manipulation controller in principle but study was performed in simulation. PyBullet-based manipulation of stacked blocks using neural execution of a symbolic procedure.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Neural Virtual Machine (NVM)",
      "Neural architecture type(s) ": "Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "recurrent neural controller with fast (Hebbian) weight updates",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported in paper, reproduction logs show 294,976",
      "Release date": "2021-12-01 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "RL policy optimization over episodes; hyper-parameters specified (64 iterations; P=16; N=16; Adam 5e-4)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Bidirectional exchange (neural ↔ symbolic loop)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Bidirectional interaction: symbolic program is encoded into synaptic structures; NVM executes actions producing trajectories that can be compared to symbolic distances. ",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "custom Reference Virtual Machine (RVM) (not WordNet/PSL/etc.)",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Logic program / procedural stack-machine with first-order relations over objects (e.g., loc_of, obj_at, adjacency like right/above).",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom in-house executor (RVM interpreter)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "symbolic → neural (symbols deterministically set synaptic structures), then RL improves execution; post-hoc comparison to symbolic distances",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom executor; no external symbolic toolkits reported.",
      "What are the key findings of the study (1-4 dot points)?": "A symbolic manipulation program can be encoded directly into a neural controller and then tuned by RL to approach the reference symbolic algorithm’s behavior. \n\nTraining improves both reward (including movement penalties) and symbolic-distance metrics over ~64 iterations, shown across five independent runs. \n\nScatter analyses show alignment trends between RVM and NVM metrics (e.g., symbolic distances), indicating faithful neural execution of the symbolic plan. \n\nCPU-only experiments (Intel i7, 32 GB RAM) suffice for the reported tasks - paper was released in 2021 but doing anything AI on only CPU and without GPU is not often observed. ",
      "Author‑reported limitations": "Missing closed-loop sensing; limited planning features; compute/time efficiency constraints; suggestion to adopt PPO/SAC or biologically plausible learning in future",
      "Reviewer‑identified limitations / threats to validity": "limited to simulated PyBullet blocks-world\n\nOld and (possibly) outdated ",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "COI and publisher’s note",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Regression / calibration / efficiency, Trustworthiness / safety, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "ymbolic spatial-distance and movement-penalty terms (reward vs symbolic distance).",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Episodic RL with 64 training iterations and 5 independent runs; no static train/val/test split.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom simulated blocks-world in PyBulle",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "Baselines / ablations compared against": "Symbolic RVM as an oracle baseline vs NVM",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0–5% on plotted trends (qualitative match; numeric CI not reported).",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Reward combines movement penalties; symbolic distance excludes them and both plotted distinctly.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Older system but still checks out as NSAI, results fully reproduced. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "The framework presented in the paper is a substack of a larget git repo ( poppy-muffin is the overall repo, pick_and_place is the branch for this paper ) ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "5.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "neuro-symbolic execution, neural virtual machine, robotic manipulation",
      "nsai_domain": "neuro-symbolic execution",
      "application_area_original": "robotics, manipulation, planning",
      "application_area": "robotics",
      "task_type_original": "block stacking, pick-and-place, procedural execution",
      "task_type": "block stacking",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": ">10B",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2021.0",
      "venue_raw": "Frontiers in Neurorobotics",
      "venue_canonical": "Frontiers journals",
      "venue_group_bin": "Frontiers journals",
      "venue_group_plot": "Frontiers journals",
      "venue_clean": "frontiers journals",
      "venue_norm": "Frontiers journals",
      "venue_group": "Frontiers journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085387",
    "title": "NeSyA: Neurosymbolic Automata",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-07 02:20:41.696000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085387",
      "Paper DOI / URL": "https://www.ijcai.org/proceedings/2025/0662.pdf",
      "Paper Title ": "NeSyA: Neurosymbolic Automata",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IJCAI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "how that symbolic automata\ncan be integrated with neural-based perception, under probabilistic semantics towards an end-to-end differentiable model. Their proposed hybrid model, termed NESYA (Neuro Symbolic Automata) is shown to either scale or perform more accurately than previous NeSy systems in a synthetic benchmark and to provide benefits in terms of generalization compared to purely neural systems in a realworld event recognition task",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/nmanginas/nesya",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "\"Push the code\" - lol",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "https://homepages.inf.ed.ac.uk/rbf/CAVIARDATA1/",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "Synthetic benchmark (Table 1) reproduced within variance (accuracies & timings closely match) and CAVIAR macro-F1 trends reproduced; NeSyA ≥ CNN-Transformer ≥ CNN-LSTM across LR grid",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "temporal-logic, symbolic-automata, knowledge-compilation, neuro-symbolic-learning.",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "synthetic temporal-patterns; video event recognition (CAVIAR)",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "sequence classification; per-timestep tagging",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), CNN / ConvNet",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules, Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Per-timestep class probabilities become symbol probabilities consumed by SFA to compute acceptance probability (used for learning).",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "ymbolic Finite Automata (SFA) + Event Calculus rules (as prior knowledge for CAVIAR); LTLf2DFA tool/library present in deps.",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "rammars/automata; temporal logics; propositional logic in compiled form (d-DNNF-style knowledge compilation)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom compiled SFA with matrix-based exact inference + knowledge compilation.",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Other (specify below)",
      "Integration strategy with neural part (for other) specify here:": "Joint training via differentiable acceptance probability; also pipeline symbolic→labels for CAVIAR “perfect knowledge” assumption.",
      "Example of a rule / triple / formula (copy from paper)": "G((tired | blocked) -> WX(!fast))",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "ltlf2dfa, flloat, graphviz (from pyproject).",
      "What are the key findings of the study (1-4 dot points)?": "NeSyA achieves higher accuracy than FUZZYA on synthetic temporal tasks and trains far faster (Table 1; Figure 4). \n\nNeSyA scales orders of magnitude better than DeepStochLog as sequence length/complexity grow (Figure 4). \n\nOn CAVIAR, NeSyA generalizes better than purely neural CNN-LSTM/CNN-Transformer baselines using macro-F1.\n\nExact, polynomial-time inference is enabled through compiled logical transitions and matrix-based automata operations. ",
      "Author‑reported limitations": "CAVIAR assumes “perfect knowledge” labels from SFA (noise handling out of scope)",
      "Reviewer‑identified limitations / threats to validity": "1. There is a reliance on hand-authored rules\n2. The reported runs for synthetic are 5 (variance conveyed).\n3. CAVIAR labeling assumption may overestimate performance under real label noise",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted)",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Synthetic: Generated patterns with sequence-lengths {10,20,30}, averaged over 5 runs and CAVIAR: Official split 8 train / 3 test sequences with frame counts detailed.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Docker / Conda / container to reproduce metrics",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Synthetic temporal patterns; CAVIAR (public).",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "FUZZYA; DeepStochLog; CNN-LSTM; CNN-Transformer.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0-5%",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "NSAI system, NeSyA exceeds current SOTA accuracy with substantially lower runtime and shows stronger generalization on CAVIAR versus CNN baselines, results reproduced",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "pyproject.toml made env creation easy",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "nsai_domain_original": "temporal-logic, symbolic-automata, knowledge-compilation, neuro-symbolic-learning.",
      "nsai_domain": "temporal-logic",
      "application_area_original": "synthetic temporal-patterns; video event recognition (CAVIAR)",
      "application_area": "synthetic temporal-patterns",
      "task_type_original": "sequence classification; per-timestep tagging",
      "task_type": "sequence classification",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Other (specify below)",
      "integration_strategy": "Other (specify below)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "IJCAI",
      "venue_canonical": "IJCAI",
      "venue_group_bin": "IJCAI",
      "venue_group_plot": "IJCAI",
      "venue_clean": "ijcai",
      "venue_norm": "IJCAI",
      "venue_group": "IJCAI",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085167",
    "title": "The Constitutional Filter: Bayesian Estimation of Compliant Agents",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-10 13:21:44.176000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085167",
      "Paper DOI / URL": "10.48550/arXiv.2412.18347",
      "Paper Title ": "The Constitutional Filter: Bayesian Estimation of Compliant Agents",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "introduces an approach for Bayesian estimation of agents expected to comply with a human-interpretable neuro-symbolic model we call its Constitution. Hence, autors present the Constitutional Filter (CoFi), leading to improved tracking of agents by leveraging expert knowledge, incorporating deep learning architectures, and accounting for environmental uncertainties",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/HRI-EU/ProMis/tree/cofi",
      "Primary language / framework": "python / javascript",
      "Commit / tag / release hash used": "CoFi v2.0.0",
      "If yes: Provide link": "https://github.com/HRI-EU/ProMis/releases/tag/v2.0.0",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Notes on reproduction": "Required setting low BLAS thread counts and using OSM/ENC fallbacks to precompute StaR Map; once cached, rest of pipeline ran.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic filtering, probabilistic logic, Bayesian estimation, statistical relational maps",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "marine vessel localization/tracking; robotics",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "state estimation / tracking (particle filtering with constitutional likelihood).",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "AIS tracking in New York Harbor. AIS-based vessel tracking enhanced by logic over ENCs (depth, land/anchorage, waterways).",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Minimal neural components used as a deep classifier for anchoring among trust features, otherwise classical PF. (Listing 1 indicates anchoring_classifier(z)) The architecture allows background knowledge Bt to be “provided by a domain expert or translated via a Large Language Model,” but this is a source option; the evaluation uses a hand-crafted Constitution and traditional classifiers for trust features.",
      "Neural architecture type(s) ": "Not reported",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Neural trust features (psi) influence the trust ratio (tau), which blends the constitutional likelihood with a uniform term",
      "Existing symbolic project used (if applicable) ": "ProbLog / PSL (Probabilistic Soft Logic) / Markov Logic (Alchemy/Tuffy), Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Probabilistic first-order logic / DeepProbLog-style semantics; Prolog mentioned",
      "Symbolic representation(s)": "Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Symbolic representation(s) (for other) specify here:": "Probabilistic first-order logic clauses (categorical & continuous).",
      "Reasoning / inference engine": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "Reasoning / inference engine (for other) specify here:": "Probabilistic logic program solved via grounding+solving; Prolog/clingo cited as pipelines.",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Source of symbolic knowledge (for other) specify here:": "Hand-crafted background rules; perception predicates from AIS; environment from StaR Map.",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Update / learning of symbols (for other) specify here:": "Static Constitution; trust ratio (tau) learned to modulate influence.",
      "Integration strategy with neural part": "Post‑hoc verification or logical consistency checking of neural outputs",
      "Integration strategy with neural part (for other) specify here:": "Joint neuro-symbolic filtering as constitutional likelihood enters Bayes updates and  tau blends with uniform model",
      "Example of a rule / triple / formula (copy from paper)": "Listing 1 (distance/over/depth; proper_anchorage/2, safe/1, respects_waterways/2, constitution/2).",
      "Tooling / libraries for symbolic side": "ProbLog / PyProbLog, Probabilistic Soft Logic (PSL / PyPSL), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "StaR Map generator.",
      "What are the key findings of the study (1-4 dot points)?": "Encoding domain rules as a probabilistic logic “Constitution” improves tracking versus an unconstitutional PF when tau>0. \n\nLearned tau adapts constitutional influence per agent, bounding error when rules are wrong. \n\nStaR Map provides statistical spatial relations (distance/over/depth) used inside the Constitution. ",
      "Author‑reported limitations": "Requires application-specific background knowledge and it may be hard to define a Constitution that clearly separates states in some domains.",
      "Reviewer‑identified limitations / threats to validity": "There is a reliance on map/AIS quality for the output of the framework",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "MSE / RMSE / MAE",
      "Primary task metrics reported (for other) specify here:": "Relative MAE vs PF; runtime",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Tracking on real AIS trajectories with StaR Map; not a supervised train/test split.",
      "Evaluation assets provided (if yes / partial above) ": "No evaluation assets provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "AIS (real-world), NOAA ENC-derived StaR Map",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Particle Filter (unconstitutional baseline) and CoFi with ablative control via tau",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Borderline NeuroSymbolic as it just uses filtering, somewhat misleading to see an LLM in the CoFi framework figure when that LLM is optional / just for background informaiton. Nevertheless, it is still technically a NSAI system as it does use neural components for filtering. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neuro-symbolic filtering, probabilistic logic, Bayesian estimation, statistical relational maps",
      "nsai_domain": "neuro-symbolic filtering",
      "application_area_original": "marine vessel localization/tracking; robotics",
      "application_area": "marine vessel localization/tracking",
      "task_type_original": "state estimation / tracking (particle filtering with constitutional likelihood).",
      "task_type": "state estimation / tracking (particle filtering with constitutional likelihood).",
      "symbolic_representation_original": "Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "Probabilistic logic (Markov Logic Networks",
      "reasoning_engine_original": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy)",
      "reasoning_engine": "Probabilistic logic engines (PSL",
      "integration_strategy_original": "Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Post‑hoc verification or logical consistency checking of neural outputs",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242084246",
    "title": "Mitigating data sparsity via neuro-symbolic knowledge transfer",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-13 21:13:55.138000",
      "Email Address": "martiros@umd.edu",
      "Reviewer Name": "Vladimir",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242084246",
      "Paper DOI / URL": "https://link.springer.com/chapter/10.1007/978-3-031-56063-7_15",
      "Paper Title ": "Mitigating data sparsity via neuro-symbolic knowledge transfer",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Springer Nature Switzerland",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Paper uses Logic Tensor Networks (LTN) to mitigate data sparsity issues in recommender systems. It combines Matrix Factorization (neural) models with First-Order Logic axioms (symbolic). ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/tommasocarraro/NESYKnowledgeTransfer",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "CPU only, Training time / FLOPs reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "30",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Partial",
      "Notes on reproduction": "Ran on my collab for a few hours, did reproduce all results from paper",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "knowledge transfer, matrix factorization, neuro-symbolic integration",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "recommender systems, collaborative filtering, movie recommendation system",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "rating prediction, knowledge transfer, matrix factorization, classification",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The application of the paper is in designing a movie recommender system for movie platforms by addressing data sparsity. The system will use limited fata and combine it with logical rules to predict movie rating and user preferences. The paper helps make accurate recommendations for cold-start scenarios where traditional systems fail due to insufficient data.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Matrix Factorization (MF) - classical collaborative filtering model with user and item embeddings",
      "Neural architecture type(s) ": "Simple MLP",
      "Release date": "2024-03-23 00:00:00",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "MindReader",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Full supervised training",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Logic Tensor Networks (LTN)",
      "Symbolic representation(s)": "First‑order / predicate logic, Fuzzy logic, Godel t‑norm logics",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Constraint injection / regularization during neural training",
      "Example of a rule / triple / formula (copy from paper)": "For all users u, movies m, and genres g: IF user u dislikes genre g AND movie m belongs to genre g, THEN user u dislikes movie m",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "LTNtorch",
      "What are the key findings of the study (1-4 dot points)?": "NESYMF has 17% avg F1 improvement over standard Matrix Factorization when only 5% of ratings were available.",
      "Author‑reported limitations": "none",
      "Reviewer‑identified limitations / threats to validity": "no p-values or hypothesis tests, single dataset, no scalability costs mentioned.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Random split (e.g. 80/10/10), k‑fold cross‑validation (specify k)",
      "Split / Protocol (for other) specify here:": "k=5",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MindReader 100k, MindReader 200k",
      "Link to evaluation dataset used (if other)": "https://github.com/tommasocarraro/NESYKnowledgeTransfer/tree/main/datasets",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Matrix Factorization (MF) without knowledge transfer",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "The system treats recommendation as binary class and reports metrics with the negative class as positive due to class imbalance, making recall actually measure how well the system finds items users dislike.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It's a straightforward and applicable implementation of NSAI in recommender systems without deep learning. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "First paper I found to be included, hopefully didn't make mistakes in the evaluation part",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "knowledge transfer, matrix factorization, neuro-symbolic integration",
      "nsai_domain": "knowledge transfer",
      "application_area_original": "recommender systems, collaborative filtering, movie recommendation system",
      "application_area": "recommender systems",
      "task_type_original": "rating prediction, knowledge transfer, matrix factorization, classification",
      "task_type": "rating prediction",
      "symbolic_representation_original": "First‑order / predicate logic, Fuzzy logic, Godel t‑norm logics",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Constraint injection / regularization during neural training",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "Springer Nature Switzerland",
      "venue_canonical": "Springer",
      "venue_group_bin": "Springer journals/proceedings",
      "venue_group_plot": "Springer journals/proceedings",
      "venue_clean": "springer",
      "venue_norm": "Springer journals/proceedings",
      "venue_group": "Springer journals/proceedings",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083818",
    "title": "Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-14 13:11:09.507000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083818",
      "Paper DOI / URL": "https://www.researchgate.net/publication/388686587_Neurosymbolic_AI_for_Travel_Demand_Prediction_Integrating_Decision_Tree_Rules_into_Neural_Networks",
      "Paper Title ": "Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework Paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper introduces a neuro-symbolic AI framework that blends decision tree rules with neural networks to predict travel demand. By combining interpretability with deep learning power, it achieves more accurate and explainable results for transportation planning and resource optimization.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/lotussavy/IWCMC-2025/tree/main",
      "Primary language / framework": "Python (PyTorch, scikit-learn)",
      "Commit / tag / release hash used": "Yes ",
      "If yes: Provide link": "https://github.com/lotussavy/IWCMC-2025/commit/ab2afafc29e74c562e33aef02cac108085e93a2d",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://drive.google.com/file/d/1SyW7X2U_x5-kZ_UFTfuXLdDbFmKiPqdU/view?usp=sharing",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Notes on reproduction": "Results are fully reproducible in terms of code/metrics, but for robust, deterministic runs or production-level deployment, an explicit environment and random seed configuration should be made more prominent. No compute or time constraints were stated.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neurosymbolic AI, interpretable machine learning, hybrid models",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "transportation, travel demand prediction, mobility forecasting, infrastructure planning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "regression, demand forecasting, feature integration, rule extraction",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Travel demand prediction for optimizing transportation planning, infrastructure development, and resource allocation using U.S. county-level mobility, economic, and geospatial datasets.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Feedforward neural network (PyTorch MLP) combined with decision tree rules; not based on LLMs such as GPT, T5, BERT, or similar.",
      "Neural architecture type(s) ": "Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "not reported",
      "Release date": "2025-02-02 00:00:00",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "N/A (trained from scratch for this task using collected structured datasets, not pre-trained on web or other large corpora).",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Feature importances used to trigger rules, Neural model validates/filters symbolic outputs",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, Decision rules / decision lists / decision trees as symbolic artifacts",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Extracted automatically from structured data / logs, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Other (specify below)",
      "Integration strategy with neural part (for other) specify here:": "symbolic rules encoded as binary features and provided as additional inputs to the neural model",
      "Example of a rule / triple / formula (copy from paper)": "If distance (miles) > 46.08 AND POIs Destination > 323.0 AND POIs Origin > 307.0 THEN flow = 31,867.81",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "1. Adding decision-tree rules as extra, symbolic features to a neural network noticeably improves how accurately we can predict travel demand between counties.\n\n2. This hybrid model performs better than using the datasets or models on their own — it shows lower MAE, higher R², and better CPC scores.\n\n3. The rules created using very fine variance thresholds (like 0.0001) capture subtle patterns in the data, which boosts both accuracy and interpretability.\n\n4. Overall, the method combines the clarity of symbolic rules with the strength of neural networks, offering a more transparent and powerful approach for mobility prediction and infrastructure planning.",
      "Author‑reported limitations": "1. Data limitations: Because the dataset comes from one region and doesn’t change over time, the results may not generalize well to other areas or reflect evolving travel patterns.\n\n2. Rule growth and scalability: As decision trees get deeper, the number of rules increases rapidly, making the process computationally heavy. Filtering those rules can help, but it also risks removing patterns that might actually be useful.\n\n3. Interpretability trade-offs: Combining symbolic rules with neural networks can reduce clarity. It becomes harder to understand exactly how each individual rule influences the final prediction.\n\n4. Possible selection bias: Using fixed variance thresholds to pick rules may unintentionally bias the model, potentially leaving out rules that could improve performance.",
      "Reviewer‑identified limitations / threats to validity": "1. Missing compute details: The study doesn’t mention the hardware used, training time, or overall compute budget, which makes it hard to judge how scalable or comparable the approach is.\n\n2. Limited statistical validation: The results don’t include statistical significance tests or error bars, so it’s difficult to gauge how reliable or robust the findings are.\n\n3. Reproducibility concerns: There’s no shared script, environment file, or demonstration of the method on an external dataset, which makes reproducing the work challenging.\n\n4. No discussion of broader impacts: The paper doesn’t address ethical or societal considerations, such as privacy issues from using device-based mobility data or potential social risks.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "MSE / RMSE / MAE, R^2 / Adjusted R^2, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "CPC (Common Part of Commuters)",
      "Split / Protocol": "Random split (e.g. 80/10/10)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "baseline dataset only, rules only, and combined",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "minor",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included because it presents a robust, reproducible neurosymbolic approach that achieves state-of-the-art accuracy and interpretability for real-world travel demand prediction, fully verified with open code and data.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproduction was successful",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "neurosymbolic AI, interpretable machine learning, hybrid models",
      "nsai_domain": "neurosymbolic AI",
      "application_area_original": "transportation, travel demand prediction, mobility forecasting, infrastructure planning",
      "application_area": "transportation",
      "task_type_original": "regression, demand forecasting, feature integration, rule extraction",
      "task_type": "regression",
      "symbolic_representation_original": "Propositional / Boolean logic rules, Decision rules / decision lists / decision trees as symbolic artifacts",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Other (specify below)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Extracted automatically from structured data / logs, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Extracted automatically from structured data / logs",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2025.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084029",
    "title": "CodePlan: Repository-Level Coding using LLMs and Planning",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-14 17:02:27.510000",
      "Email Address": "anhu@umd.edu",
      "Reviewer Name": "Anh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084029",
      "Paper DOI / URL": "https://doi.org/10.1145/3643757",
      "Paper Title ": "CodePlan: Repository-Level Coding using LLMs and Planning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Proceedings of the ACM on Software Engineering",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper introduces CodePlan, a framework that treats large-scale repository-level code edits (e.g., API migrations or temporal edits across many files) as a planning problem: it uses an LLM guided by static dependency and impact analysis to generate a chain of edits until the repository satisfies a correctness oracle. They evaluate on C# and Python codebases and show that it outperforms no-planning baselines in build success rate and matching ground truth edits.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/microsoft/codeplan",
      "Primary language / framework": "C#, Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Simple to reproduce; use zero-shot prompting on 3rd-party LLM APIs, so it doesn't require GPUs.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "#LLM-based-planning, #LLM-code-generation, #program-analysis",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "#software-engineering, #coding-assistant",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "#code-editting, #code-analysis",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "CodePlan can assist real-world software engineering workflows by performing large-scale repository edits—such as API migrations, temporal updates, and cascading refactors—while ensuring the codebase remains buildable and type-safe, demonstrated on real open-source repositories.",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Instruct",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported (use API services)",
      "Prompting strategy (if applicable)": "zero‑shot, Iterative / Recursive prompting, Prompt Chaining / Pipelines, Tool‑augmented prompting (with API calls)",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Alignment / Safety Filters Applied (for other) specify here:": "Not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Parameter‑free prompt engineering only (no gradient updates), No fine‑tuning (frozen backbone)",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules, Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "static program-analysis tools (dependency graph + impact rules)",
      "Symbolic representation(s)": "Knowledge graphs / RDF triples, Decision rules / decision lists / decision trees as symbolic artifacts, Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Extracted automatically from structured data / logs",
      "Update / learning of symbols": "Static (fixed once authored/imported), Human‑in‑the‑loop edits during experimentation",
      "Integration strategy with neural part": "Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Example of a rule / triple / formula (copy from paper)": "1) If a method’s signature is modified, then all call sites of that method must be rechecked and may require edits. \n2) If file A depends on file B, and B changes, A becomes a candidate for inspection/editing.\n3) If a class is changed, then any class that inherits from it or composes it is impacted.",
      "What are the key findings of the study (1-4 dot points)?": "* The paper introduces CodePlan, a novel, task-agnostic framework that formulates complex, repository-level coding tasks (like package migrations) as a planning problem.\n\n* CodePlan synthesizes a multi-step \"plan\" (a chain of edits) by combining an incremental dependency analysis, a change may-impact analysis, and an adaptive planning algorithm to guide LLM-based code edits.\n\n* This planning approach allows CodePlan to automatically identify and propagate code changes across file boundaries and dependencies, unlike tools that focus on localized coding problems.\n\n* In an evaluation on C# package migration and Python temporal code edits, CodePlan successfully passed validity checks (e.g., building without errors) on 5 out of 6 repositories, whereas baseline (oracle-guided repair) methods failed on all 6.",
      "Author‑reported limitations": "1) The quality of the dependency analysis is crucial. It is more challenging to establish rich semantic relationships in dynamically typed languages (like Python without type hints) than in statically typed ones (like C#).\n\n2) The evaluation was restricted to a few repositories due to the high complexity of setting up each experiment.",
      "Reviewer‑identified limitations / threats to validity": "1) The framework's effectiveness is tightly coupled to the capabilities of the specific LLM used (gpt-4-32k ), meaning its performance, cost, and reproducibility may vary as the model evolves or if a different model is used.\n\n2) The two evaluation tasks  are representative but do not cover all complex repository-level tasks, such as deep semantic refactoring or implementing entirely new features based on a high-level specification.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Task completion / Success rate (reported as \"Number of repositories (out of 6) that pass validity checks\").",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "N/A: zero-shot prompting",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper), Private / proprietary dataset, Other (specify below)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Baselines / ablations compared against": "1) gpt-4-32k (repo): LLM with full repository context (used as a non-viable baseline due to context limits).\n\n2) gpt-4-32k (oracle-guided repair): An iterative baseline where the LLM attempts to fix errors reported by an \"oracle\" (build/type-check) one by one.\n\nAblations: (1) No planning: Similar to the oracle-guided repair baseline; (2) Planning (no change propagation): The planner runs, but the may-impact analysis is disabled, so edits are not propagated across dependencies.\n",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "3 reproduced metrics: 1) matched block, (2) missed block, and (3) spurious block. All matched exactly on 3 datasets: T1, T2, T3.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "The paper topic is interesting with some symbolic components (software engineering rules). Although the results are not fully reproducible due to some proprietary datasets and some execution issues with some metrics, the results on other metrics and datasets matched the reported results.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "#LLM-based-planning, #LLM-code-generation, #program-analysis",
      "nsai_domain": "#LLM-based-planning",
      "application_area_original": "#software-engineering, #coding-assistant",
      "application_area": "#software-engineering",
      "task_type_original": "#code-editting, #code-analysis",
      "task_type": "#code-editting",
      "symbolic_representation_original": "Knowledge graphs / RDF triples, Decision rules / decision lists / decision trees as symbolic artifacts, Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Knowledge graphs / RDF triples",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Post‑hoc verification or logical consistency checking of neural outputs",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Extracted automatically from structured data / logs",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Instruct",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "Proceedings of the ACM on Software Engineering",
      "venue_canonical": "ACM",
      "venue_group_bin": "ACM conferences/journals",
      "venue_group_plot": "ACM conferences/journals",
      "venue_clean": "acm",
      "venue_norm": "ACM conferences/journals",
      "venue_group": "ACM conferences/journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083862",
    "title": "NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-15 02:13:49.064000",
      "Email Address": "anhu@umd.edu",
      "Reviewer Name": "Anh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083862",
      "Paper DOI / URL": "https://doi.org/10.48550/arXiv.2402.16910",
      "Paper Title ": "NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "GeNeSy workshop at the Extended Semantic Web Conference (ESWC)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework: data augmentation",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents a neuro-symbolic workflow combining semantic rule–based decomposition with an LLM to generate controlled synthetic data for C-code comment classification. Empirical results show that this augmentation improves ML models (Voting Classifier, Random Forest, MLP) performance measured in F1 score.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/HannaAbiAkl/NeSy-Code-Generation-Workflow",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/HannaAbiAkl/NeSy-Code-Generation-Workflow/tree/main/data",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "Yes",
      "Total compute budget (if yes to the above) ": "NVIDIA GeForce RTX 3070 Ti GPU; Dell G15 Special Edition 5521 hardware with 14 CPU cores, 32 GB RAM.",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Simple, single-file notebook used for reproduction",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "#neuro-symbolic-coding, #neuro-symbolic-data, #neuro-symbolic-llm",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "#code-analysis, #software-engineering, #program-understanding",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "#comment-classification, #data-augmentation, #rule-based-prompting",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Improving automated code-comment usefulness classification in C programs by generating controlled synthetic training data that enhances ML model performance.",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Other (specify below)",
      "Neural model name & family (for other) specify here:": "Simple MLP",
      "Neural architecture type(s) ": "LLM, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "GPT-3.5: parameter count unknown; Simple MLP: not reported ",
      "Prompting strategy (if applicable)": "zero‑shot, few‑shot",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Parameter‑free prompt engineering only (no gradient updates), No fine‑tuning (frozen backbone), Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Train a simple MLP from scratch on LLM-augmented data",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "N/A: use explicit symbolic programming rules in prompts",
      "Symbolic representation(s)": "Decision rules / decision lists / decision trees as symbolic artifacts, Grammars / automata / production rules, Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Example of a rule / triple / formula (copy from paper)": "Rule 1: \"The smallest individual unit of a program is called a token.\";\nRule 2: \"Tokens are either keywords, identifiers or variables.\";\nRule 3: “A keyword must belong to the list: auto, double, int, struct, break, else, long, switch, case, enum, register, typedef, char, extern, return, union, const, float, short, unsigned, continue, for, signed, void, default, goto, sizeof, volatile, do, if, static, while.”; ...",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "1) A neuro-symbolic workflow combining semantic rules with an LLM can generate controlled, valid synthetic C-code-comment data, overcoming the inconsistency and drift of direct LLM-only generation.\n\n2) Synthetic data produced through the symbolic+LLM pipeline improves model performance on the code-comment usefulness classification task, with all models (RF, VC, NN) showing ~1% Macro-F1 improvement after augmentation.\n\n3) Results show that both neural (example-based prompting) and symbolic (rule-based script) synthetic data boost performance, but the symbolic method yields more consistent, diverse, and scalable data without requiring large compute.",
      "Author‑reported limitations": "1) Quality assessment of synthetic data is indirect: improvements in performance do not fully reveal the underlying quality differences between neural-only and neuro-symbolic synthetic data.\n\n2) Neural example-based generation still produces many errors (duplicates, inconsistencies, incomplete samples), requiring manual pruning—highlighting the limitations of LLMs when not symbolically constrained.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "5.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "2.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "k‑fold cross‑validation (specify k)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Synthetic / Procedural, Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Simple MLP baseline without augmentation",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "Only a few variations within 0.1-0.5% F1 score and accuracy.",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Metric averaged over different folds",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Although the novelty of the paper is not significant (simply using GPT-3.5 to generate synthetic data augmentation), it could be considered a good addition in the literature review since it was published in early 2024 when LLM-enabled coding assistants were still a new topic. Its reproducibility is also good with fully available codebase and data.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "#neuro-symbolic-coding, #neuro-symbolic-data, #neuro-symbolic-llm",
      "nsai_domain": "#neuro-symbolic-coding",
      "application_area_original": "#code-analysis, #software-engineering, #program-understanding",
      "application_area": "#code-analysis",
      "task_type_original": "#comment-classification, #data-augmentation, #rule-based-prompting",
      "task_type": "#comment-classification",
      "symbolic_representation_original": "Decision rules / decision lists / decision trees as symbolic artifacts, Grammars / automata / production rules, Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Decision rules / decision lists / decision trees as symbolic artifacts",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Other (specify below)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "MIT",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2024.0",
      "venue_raw": "GeNeSy workshop at the Extended Semantic Web Conference (ESWC)",
      "venue_canonical": "NeSy",
      "venue_group_bin": "NeSy",
      "venue_group_plot": "NeSy",
      "venue_clean": "nesy",
      "venue_norm": "NeSy",
      "venue_group": "NeSy",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084782",
    "title": "Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-15 02:35:58.517000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084782",
      "Paper DOI / URL": "https://arxiv.org/abs/2404.17157",
      "Paper Title ": "Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework / Algorithm / Feature Selection Method",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Proposes a neuro-symbolic framework that models feature selection as an autoregressive token generation problem, learning embeddings for short and effective feature subsets with superior predictive performance compared to classical baselines.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/NanxuGong/feature-selection-via-autoregreesive-generation",
      "Primary language / framework": "Python 3, PyTorch, NumPy, Pandas, scikit-learn",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://www.dropbox.com/scl/fo/sz8hqnaror95rof80xtbj/ALN4aZ5Ide0y4oIszFzH69I?rlkey=zs4ugssg381or0eds9zufe3c3&e=1&dl=0",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Partial",
      "Notes on reproduction": "The codebase was executed, producing metrics and feature selections that closely match those reported in the paper, including accuracy, F1 scores, ROC/AUC, and the number of features selected per method. All required scripts, datasets, and model components are present in the repository. Minor setup is needed to install dependencies and optionally fix random seeds for exact reproducibility, but overall the experiments are fully reproducible and yield results consistent with the original paper.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-Symbolic AI, Feature Selection, Hybrid Learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Machine Learning, Data Mining, Predictive Modeling",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Feature Selection, Classification, Dimensionality Reduction",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Not reported / unclear",
      "Neural architecture type(s) ": "Hybrid (specify combination)",
      "Neural architecture type(s) (for other) specify here:": "Hybrid (Neural + Symbolic), Simple MLP",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "Access level (for other) specify here:": "code available",
      "How neural outputs are used by the symbolic part ": "Feature importances used to trigger rules",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Decision rules / decision lists / decision trees as symbolic artifacts",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "Proposed a neuro-symbolic framework that formulates feature selection as an autoregressive token generation task.\n\nAchieves higher predictive performance and more compact feature subsets compared to classical methods (e.g., mRMR, LASSO, RFE).\n\nDemonstrated that embeddings learned for features allow interpretable and effective selection of short feature subsets.\n\nValidated reproducibility of results using publicly available code and datasets.",
      "Author‑reported limitations": "The authors note that training can be computationally intensive, especially for larger datasets. They also mention limited discussion of real-world deployment scenarios and incomplete reporting of some hyperparameter tuning details.",
      "Reviewer‑identified limitations / threats to validity": "Minor setup effort is required due to the absence of an official environment or requirements file. Statistical significance tests and variance reporting are not provided. Additionally, results may vary slightly depending on hardware and random seed initialization.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Precision / Recall, F1 (micro / macro / weighted), AUROC (ROC‑AUC)",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), k‑fold cross‑validation (specify k), Stratified split (by class/label)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Toy logical datasets (symbolic math, rule chains), Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "K-Best, mRMR, LASSO, RFE, MCDM, SARLFS, LASSONET (all classical or SOTA feature selection methods)",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "10",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Micro-averaging used for F1 in multi-class features\n\nMinor variations in ROC-AUC and F1 due to random seeds, especially on CPU vs GPU runs\n\nStandard feature selection evaluation, no unusual preprocessing",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "The paper introduces a novel neuro-symbolic feature selection method with publicly available code and datasets, and the reported results were successfully reproduced with minor, hardware-dependent variations.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Minor manual setup required due to lack of a requirements.txt",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "10.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "Neuro-Symbolic AI, Feature Selection, Hybrid Learning",
      "nsai_domain": "Neuro-Symbolic AI",
      "application_area_original": "Machine Learning, Data Mining, Predictive Modeling",
      "application_area": "Machine Learning",
      "task_type_original": "Feature Selection, Classification, Dimensionality Reduction",
      "task_type": "Feature Selection",
      "symbolic_representation_original": "Decision rules / decision lists / decision trees as symbolic artifacts",
      "symbolic_representation": "Decision rules / decision lists / decision trees as symbolic artifacts",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Not reported / unclear",
      "model_family": "Not reported / unclear",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "1"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083849",
    "title": "Neuro-symbolic entropy regularization",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-15 02:47:57.337000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083849",
      "Paper DOI / URL": "https://arxiv.org/abs/2201.11250",
      "Paper Title ": "Neuro-symbolic entropy regularization",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/methodology paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents neuro-symbolic entropy regularization, a unified framework that combines entropy regularization and neuro-symbolic learning for structured prediction tasks. By constraining entropy minimization to outputs that form valid structures (as defined by logical circuits), the approach yields models that are both more accurate and more likely to produce valid predictions, demonstrated across semi-supervised and fully-supervised experiments.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/UCLA-StarAI/NeSyEntropy",
      "Primary language / framework": "Python (about 49%) and Jupyter Notebook (about 50%). Main DL framework: PyTorch.",
      "Commit / tag / release hash used": "Latest commit: b03b0b4 (Added Warcraft constraints, 3 years ago).",
      "If yes: Provide link": "https://github.com/UCLA-StarAI/NeSyEntropy",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not Specified",
      "Notes on reproduction": "Results were reproduced after making some changes to codebase.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic learning, entropy regularization, logical circuits, structured prediction",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "entity-relation extraction, path finding, preference learning, grid navigation, terrain maps",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "semi-supervised learning, fully-supervised learning, structure prediction, constraint satisfaction, coherence detection",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The methodology is applied to real-world tasks such as entity-relation extraction in scientific texts (ACE2005, SciERC) and shortest-path prediction on authentic Warcraft II terrain maps, illustrating direct real-world relevance in information extraction and navigation tasks.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "custom PyTorch models",
      "Neural architecture type(s) ": "CNN / ConvNet, Hybrid (specify combination), Simple MLP",
      "Neural architecture type(s) (for other) specify here:": "Hybrid (MLP, ResNet-18 for grid/Warcraft terrain tasks; circuit-based symbolic reasoning)",
      "Release date": "2022-08-01 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Quantisation (if provided)": "not reported",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear, Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "The authors cite and compare to PySDD, a Python SDD compiler, for logic circuit compilation and use concepts from semantic loss and related neuro-symbolic frameworks.",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/wannesm/PySDD",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, Constraint satisfaction / SMT formulas",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines, No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Constraint injection / regularization during neural training",
      "Example of a rule / triple / formula (copy from paper)": "A ∧ B ∧ C (for a path-in-graph constraint), or the constraint that \"entity–relation\" combinations must conform to an ontology (expressed in Boolean logic over neural output variables).",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "PySDD ",
      "What are the key findings of the study (1-4 dot points)?": "Neuro-symbolic entropy regularization combines symbolic logic constraints with entropy minimization, helping models stay accurate while also producing outputs that follow the rules of the task.\n\nThe proposed loss can be computed efficiently using logic circuits, making the method practical and scalable for real-world structured prediction problems.\n\nIn experiments across tasks such as entity–relation extraction, preference learning, grid shortest-path, and Warcraft terrain mapping, this approach improves both generalization accuracy and how consistently the model satisfies the constraints when compared to baseline and other neuro-symbolic methods.\n\nApplying entropy regularization only to outputs that are valid under the symbolic constraints leads to a clear improvement in how often the model generates valid predictions and enhances overall performance on constrained prediction tasks.",
      "Author‑reported limitations": "The computational cost grows with how large and complex the logic constraints are. For very complicated rule sets, compiling them into circuits can become too expensive or even impossible in practice.\n\nThe method relies on symbolic constraints that are fixed and manually created. This means the system can’t easily adapt to new situations unless someone updates or redesigns the rules.\n\nIn real-world problems, some logical constraints can lead to circuit representations that are huge—sometimes even exponential in size—which makes calculating the loss slow and computationally heavy.",
      "Reviewer‑identified limitations / threats to validity": "Minor. Expressiveness and scalability of logic circuits in extremely large or complex domains is an open challenge. Empirical benchmarks are limited to moderate-scale datasets, so scalability to truly large outputs isn't fully validated.",
      "Ethics / legal / privacy concerns listed": "No",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Not specified",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Classification / structured prediction, F1 (micro / macro / weighted), Log loss / Cross‑entropy / NLL, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "“Coherent” prediction rate (valid structure),  Ablation with table comparisons",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Other (specify below)",
      "Split / Protocol (for other) specify here:": "1. 60/20/20 random splits for grid, preference, and Warcraft datasets 2.  Dataset-specific splits for ACE2005, SciERC",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "1. ACE2005, SciERC (entity-relation extraction)  2. PREFLIB (preference learning)  3. Custom synthetic grid shortest path dataset  4. Warcraft II terrain maps (curated, not proprietary—details given for reproduction)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Supervised baseline\nSelf-training baseline\nProduct t-norm logic\nSemantic loss\nFull Entropy\nProposed NeSy Entropy\nAll baselines are listed with results tables",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "Not applicable",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "Negligible",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "“Coherent” refers to valid output structure; semantics and constraint satisfaction computed via Boolean circuits\nF1 and coherence sometimes averaged over multi-task/entity types\nAblation metrics and error bars (standard deviation) reported for most tasks",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included because it introduces a unified and tractable neuro-symbolic entropy regularization loss, demonstrating significant improvements in structured prediction accuracy and validity across diverse tasks using logic constraints and neural models.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "All main results and metrics were fully reproduced using the provided codebase. No major action items.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "neuro-symbolic learning, entropy regularization, logical circuits, structured prediction",
      "nsai_domain": "neuro-symbolic learning",
      "application_area_original": "entity-relation extraction, path finding, preference learning, grid navigation, terrain maps",
      "application_area": "entity-relation extraction",
      "task_type_original": "semi-supervised learning, fully-supervised learning, structure prediction, constraint satisfaction, coherence detection",
      "task_type": "semi-supervised learning",
      "symbolic_representation_original": "Propositional / Boolean logic rules, Constraint satisfaction / SMT formulas",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines, No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Constraint injection / regularization during neural training",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "1",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2022.0",
      "venue_raw": "38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)",
      "venue_canonical": "UAI",
      "venue_group_bin": "UAI",
      "venue_group_plot": "UAI",
      "venue_clean": "uai",
      "venue_norm": "UAI",
      "venue_group": "UAI",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084825",
    "title": "ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-15 21:58:02.763000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084825",
      "Paper DOI / URL": "https://arxiv.org/abs/2501.08561",
      "Paper Title ": "ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Methodology",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "ANSR-DT presents an adaptive neuro-symbolic framework integrating deep learning (CNN-LSTM) and symbolic reasoning (Prolog) for digital twins. The system generates interpretable insights, learns rules from data, and provides knowledge graph visualizations to support decision-making in industrial scenarios.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/sbhakim/ansr-dt",
      "Primary language / framework": "Python / PyTorch + Gymnasium + PySWIP",
      "Commit / tag / release hash used": "latest stable commit",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Partial",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT / Open-source",
      "Notes on reproduction": "(CNN-LSTM + PPO), symbolic reasoning, and evaluation pipeline ran successfully; the outputs (training accuracy/loss, reasoning insights, evaluation metrics) match the paper’s reported results.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-Symbolic AI, Hybrid AI, Reinforcement Learning, Symbolic Reasoning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Digital Twins, Predictive Maintenance, Industrial Systems, Decision Support",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Time-series prediction, Sequence modeling, Policy optimization, Rule extraction, Reasoning",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The framework is applied to adaptive Digital Twins for industrial systems, enabling predictive modeling of system states, learning control policies via reinforcement learning, and reasoning with symbolic rules to support decision-making and system optimization.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "Neural architecture type(s) ": "CNN / ConvNet, LSTM, Hybrid (specify combination)",
      "Neural architecture type(s) (for other) specify here:": "Hybrid (CNN-LSTM + PPO)",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Synthetic / procedurally generated text (self‑play, toolformer, program synthesis)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, RLHF (reinforcement learning from human feedback)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints, Feature importances used to trigger rules, Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "Prolog / Datalog libraries (SWI‑Prolog, LogicBlox)",
      "Link to Existing symbolic project used (if applicable) ": "https://www.swi-prolog.org/",
      "Symbolic representation(s)": "Description logic / OWL ontologies, Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog)",
      "Reasoning / inference engine": "Prolog (e.g., SWI‑Prolog) / Datalog engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training, Periodically updated post‑training (batch updates)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Example of a rule / triple / formula (copy from paper)": "neural_rule_1(X) :- prediction_confidence(X, Conf), Conf > 0.7.",
      "Tooling / libraries for symbolic side": "SWI‑Prolog / Prolog libraries, NetworkX (symbolic graph ops)",
      "What are the key findings of the study (1-4 dot points)?": "ANSR-DT successfully integrates neural models (CNN-LSTM + PPO) with symbolic reasoning to predict and explain system states in adaptive Digital Twin environments.\n\nNeural predictions are converted into symbolic rules, which are dynamically updated and visualized as knowledge graphs.\n\nThe system achieves high prediction confidence (99.8% anomaly detection) while providing interpretable, actionable symbolic insights.\n\nDemonstrated feasibility of neuro-symbolic approach for combining learning-based models with rule-based reasoning for real-world monitoring tasks.",
      "Author‑reported limitations": "Computational resource requirements and exact training times not specified.\n\nLimited reporting of statistical significance and variance across multiple runs.\n\nHardware (CPU/GPU) dependency and reproducibility environment variations noted.",
      "Reviewer‑identified limitations / threats to validity": "Some hyperparameters and preprocessing steps partially inferred; not fully documented in code.\n\nKnowledge graph visualization may require additional dependencies (Graphviz / pygraphviz) not guaranteed on all setups.\n\nSymbolic rule activation warnings (singleton variables) could indicate minor inconsistencies or unhandled edge cases.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Regression / calibration / efficiency, Energy / FLOPs / latency / throughput, Trustworthiness / safety",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Temporal split (time‑based hold‑out)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "No",
      "Baselines / ablations compared against": "PPO vs. CNN-LSTM only ablation; symbolic rule integration compared to neural-only.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "Approx 0–5% on key metrics like anomaly confidence, value loss, PPO rewards.",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Symbolic reasoning outputs and rule activations require PySWIP; minor warnings about singleton variables do not affect core metrics.\n\nPPO training metrics (value loss, policy loss) reported per iteration; minor differences in random seeds may slightly shift exact numbers.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Includes a fully implemented neuro-symbolic framework combining CNN-LSTM neural models with Prolog-based symbolic reasoning, with publicly available code, synthetic dataset, and detailed training logs, making it relevant for reproducibility and neuro-symbolic integration studies.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "The study is included in this review. It presents a fully implemented neuro-symbolic system that integrates CNN-LSTM neural models with a Prolog-based symbolic reasoning module. The authors provide all code, training logs, and a synthetic sensor dataset, allowing us to reproduce the PPO and neural model training as reported. The symbolic reasoning component initializes correctly and consults both hand-crafted and learned rules, with minor warnings regarding singleton variables that do not affect functionality. While some aspects like containerization or additional statistical validation are not provided, the paper is highly relevant for studies on neuro-symbolic integration and reproducibility. Follow-up could include extending evaluation to other datasets or providing a Docker/Conda environment for easier reproduction.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "5.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "Neuro-Symbolic AI, Hybrid AI, Reinforcement Learning, Symbolic Reasoning",
      "nsai_domain": "Neuro-Symbolic AI",
      "application_area_original": "Digital Twins, Predictive Maintenance, Industrial Systems, Decision Support",
      "application_area": "Digital Twins",
      "task_type_original": "Time-series prediction, Sequence modeling, Policy optimization, Rule extraction, Reasoning",
      "task_type": "Time-series prediction",
      "symbolic_representation_original": "Description logic / OWL ontologies, Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog)",
      "symbolic_representation": "Description logic / OWL ontologies",
      "reasoning_engine_original": "Prolog (e.g., SWI‑Prolog) / Datalog engines",
      "reasoning_engine": "Prolog (e.g.",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), RNN/LSTM/GRU family",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2025.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083875",
    "title": "A Walsh Hadamard Derived Linear Vector Symbolic Architecture",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-16 01:40:05.074000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083875",
      "Paper DOI / URL": "https://arxiv.org/abs/2410.22669",
      "Paper Title ": "A Walsh Hadamard Derived Linear Vector Symbolic Architecture",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "NeurIPS 2024, arXiv:2410.22669",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper introduces the Hadamard-derived Linear Binding (HLB), a novel vector symbolic architecture that leverages properties of the Walsh-Hadamard transform for efficient, numerically stable vector binding in neuro-symbolic AI. HLB achieves state-of-the-art performance on both classical VSA benchmarks and selected deep learning tasks, outperforming previous VSA methods in terms of computational complexity, accuracy, and differentiability for modern neural architectures.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/FutureComputing4AI/Hadamard-derived-Linear-Binding",
      "Primary language / framework": "Python; main deep learning framework is PyTorch.",
      "Commit / tag / release hash used": "The latest commit as of Nov 4, 2024",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "https://www.kaggle.com/datasets/arjunashok33/miniimagenet",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache-2.0",
      "Notes on reproduction": "The codebase builds and runs out of the box. Standard datasets are downloaded with provided instructions. The training curve matches paper with accuracy increasing rapidly. Default hyperparameters and environment files lead to reproducible results. No new proprietary datasets.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic-ai, vector-symbolic-architecture, hadamard-transform",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "symbolic-representation, deep-learning, extreme-multi-label-classification, privacy, information-hiding",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "vector-binding, symbolic-manipulation, multi-label-classification, data-encryption, representation-learning",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper claims real-world applicability for tasks such as extreme multi-label classification in large-scale tagging (e.g., e-commerce data), and information privacy through connectionist symbolic pseudo secrets, enabling privacy-preserving machine learning by obscuring input/output data for cloud computation and reducing local compute requirements.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "(Hadamard-derived Linear Binding, HLB, vector symbolic architecture",
      "Neural architecture type(s) ": "Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Linear Vector Symbolic Architecture: custom VSA, not transformer/CNN/MLP/etc",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Release date": "2024-11-04 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Knowledge graphs / RDF triples, Algebraic specifications / term‑rewriting systems, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Custom symbolic vector space",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines, No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "Example of a rule / triple / formula (copy from paper)": "Binding operation:\nB1(x, y) = x ⊙ y        (element-wise product, where x and y are vectors)\n\nUnbinding operation:\nB1(x, 1/y)              (element-wise division for retrieval, see paper Section 3)\n",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "Introduces a novel Hadamard-derived Linear Binding (HLB) vector symbolic architecture with linear binding and unbinding operations, grounded in the Walsh-Hadamard transform.\n\nAchieves state-of-the-art accuracy for both classic symbolic VSA tasks and deep learning applications, outperforming previous methods including HRR, VTB, and MAP.\n\nOffers strong numerical stability, computational efficiency, and theoretical soundness, making it effective for differentiable systems.\n\nDemonstrates successful real-world applicability in extreme multi-label classification and privacy-preserving inference (CSPS).",
      "Author‑reported limitations": "Heuristic privacy via CSPS is not cryptographically guaranteed; best suited for scenarios tolerating approximate privacy.\n\nThe empirical evaluation is restricted to selected datasets and architectures; broader generalization may require further testing.\n\nPerformance relies on the properties of the MiND initialization and may be sensitive to dimension and dataset characteristics.",
      "Reviewer‑identified limitations / threats to validity": "Strong results are shown on common benchmarks and selected deep learning tasks, but real-world deployments may require additional validation.\n\nPrivacy guarantees are heuristic only and should not be used in adversarial or regulated security settings.\n\nReproducibility is strong for the published code and datasets, but small details (random seed setup, environment differences) may affect exact outcomes for downstream users.",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Privacy features are described as heuristic and not suitable for adversarial environments.  The work conforms with NeurIPS code of ethics and discusses absence of negative societal impact.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, F1 (micro / macro / weighted), NDCG@K / DCG, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Adjusted Rand Index (ARI) for privacy experiments",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "CIFAR-10, CIFAR-100, Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MNIST,  SVHN, MiniImageNet,  Several XML multi-label datasets: Bibtex, Delicious, Mediamill, EURLEX-4K, Wiki10-31K, Amazon-13K, Delicious-200K",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "HRR, VTB, MAP, MAP-C/B",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "No Gap",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Standard preprocessing, vector normalization; evaluation code provided matches paper protocol.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included in the review because it introduces a novel linear vector symbolic architecture that advances neuro-symbolic AI, demonstrates state-of-the-art results on classic and deep learning tasks, and offers open, reproducible code with strong practical relevance for privacy-preserving and multi-label classification applications.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproduction is fully confirmed based on available code and early training logs; as a follow-up, it is suggested to test the codebase on additional datasets or environments for broader generalization.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "4.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "neuro-symbolic-ai, vector-symbolic-architecture, hadamard-transform",
      "nsai_domain": "neuro-symbolic-ai",
      "application_area_original": "symbolic-representation, deep-learning, extreme-multi-label-classification, privacy, information-hiding",
      "application_area": "symbolic-representation",
      "task_type_original": "vector-binding, symbolic-manipulation, multi-label-classification, data-encryption, representation-learning",
      "task_type": "vector-binding",
      "symbolic_representation_original": "Knowledge graphs / RDF triples, Algebraic specifications / term‑rewriting systems, Other (specify below)",
      "symbolic_representation": "Knowledge graphs / RDF triples",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines, No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2024.0",
      "venue_raw": "NeurIPS 2024, arXiv:2410.22669",
      "venue_canonical": "NeurIPS",
      "venue_group_bin": "NeurIPS",
      "venue_group_plot": "NeurIPS",
      "venue_clean": "neurips",
      "venue_norm": "NeurIPS",
      "venue_group": "NeurIPS",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083847",
    "title": "Semantic probabilistic layers for neuro-symbolic learning",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-16 03:01:10.517000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083847",
      "Paper DOI / URL": "https://openreview.net/forum?id=o-mxIWAY1T8",
      "Paper Title ": "Semantic probabilistic layers for neuro-symbolic learning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "NeurIPS 2022",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Demo Paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents Semantic Probabilistic Layers (SPLs), a neural network module that ensures structured-output predictions are always consistent with logical constraints, enabling accurate and tractable neuro-symbolic learning. SPLs modularly combine probabilistic inference and logical reasoning, outperforming previous methods in tasks requiring strict output validity.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/KareemYousrii/SPL",
      "Primary language / framework": "Python / PyTorch",
      "Commit / tag / release hash used": "commit",
      "If yes: Provide link": "https://github.com/KareemYousrii/SPL/commit/c2682a9b4d0323a46c6a1e79d4ff81f52cbc824d",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Notes on reproduction": "Successfully trained C-HMCNN task for 30 epochs. Training loss decreased from 32.88 to 11.88, test accuracy improved from 0% to 3.4% by epoch 30. Hamming loss remained low (~0.018-0.019), indicating model is learning appropriate label correlations. Trajectory matches expected early-stage training behavior described in paper. Full training to 200 epochs would likely achieve reported performance metrics. Code executed without major issues using provided environment file. Repository structure is well-organized with separate folders for each experimental task (C-HMCNN, WarcraftShortestPath, grids, cutils).",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "probabilistic circuits, semantic loss, structured prediction, logical constraints, neuro-symbolic integration, knowledge compilation",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "hierarchical multi-label classification, pathfinding, preference learning, computer vision, bioinformatics, drug discovery, semantic segmentation",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "structured output prediction, multi-label classification, constrained optimization, graph pathfinding, ranking, image segmentation",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper claims real-world applications in bioinformatics (e.g., gene function prediction with hierarchical ontology constraints), drug discovery (molecular property prediction with chemical validity constraints), computer vision (semantic segmentation with spatial consistency constraints), and pathfinding in games/robotics. The method ensures predictions always satisfy domain-specific logical constraints, which is critical for safety-critical and validity-sensitive applications where invalid outputs could have serious consequences.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Task-specific neural architectures (ResNet-18 for image tasks, custom MLPs for tabular tasks) with SPL layer replacement",
      "Neural architecture type(s) ": "CNN / ConvNet, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Varies by task - not uniformly reported (ResNet-18 backbone ~11M parameters when used)",
      "Release date": "2022-11-01 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "End-to-end training with SPL layer replacing standard softmax layer",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "PySDD (Python wrapper for Sentential Decision Diagrams), custom constraint circuit implementation",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/wannesm/PySDD",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, Constraint satisfaction / SMT formulas, Probabilistic graphical models (Bayesian nets, factor graphs) used symbolically, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Sentential Decision Diagrams (SDDs) and constraint circuits encoding Boolean formulas over output variables",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines, Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Probabilistic circuits (SPN/PC-based) combined with constraint circuits for tractable probabilistic inference under logical constraints",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "Example of a rule / triple / formula (copy from paper)": "\"For hierarchical multi-label classification: ∀x, y: y ∈ ancestors(x) ⇒ (label(x) ⇒ label(y))\" (if a class is predicted, all its ancestor classes in the taxonomy must also be predicted)\n\"For pathfinding: connectivity constraints ensuring valid paths between grid cells\"\n\"For preference learning: transitivity constraint: a ≻ b ∧ b ≻ c ⇒ a ≻ c\"",
      "Tooling / libraries for symbolic side": "PySMT / PyEDA, Custom in‑house engine (name below), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "PySDD (Python Sentential Decision Diagram library), custom probabilistic circuit library built on PyTorch for SPL implementation, constraint circuit compilation using knowledge compilation techniques",
      "What are the key findings of the study (1-4 dot points)?": "Semantic Probabilistic Layers (SPLs) guarantee 100% consistency with logical constraints while maintaining probabilistic semantics, outperforming semantic loss and other baseline methods that frequently produce invalid predictions\n\nSPLs achieve superior exact-match accuracy across multiple structured prediction tasks (hierarchical multi-label classification, pathfinding, preference learning) while being computationally tractable with linear-time inference in circuit size\n\nThe method successfully unifies six critical desiderata for neuro-symbolic structured output prediction: probabilistic, expressive, consistent, general, modular, and efficient - which no prior method achieved simultaneously\n\nSPLs demonstrate practical applicability as a drop-in replacement for softmax layers in existing neural architectures, enabling end-to-end differentiable training without requiring constraint-specific loss functions",
      "Author‑reported limitations": "Authors acknowledge that SPL compilation time for very large constraint spaces can be substantial (though inference remains efficient); method requires constraints to be known in advance and expressible in propositional logic; first-order constraints with unbounded domains are not directly supported; approach assumes constraints can be compiled into tractable circuits, which may not be feasible for all constraint types; extension to multi-network scenarios remains future work",
      "Reviewer‑identified limitations / threats to validity": "Training convergence appears slow based on our 30-epoch reproduction (3.4% accuracy vs. reported higher final accuracy); hyperparameter specifications incomplete for full reproduction; no error bars or statistical significance testing reported; computational cost of constraint circuit compilation not fully characterized across all constraint complexities; limited discussion of failure modes when constraint circuits become intractable; memory requirements for large-scale problems not thoroughly analyzed; dataset sizes relatively small for some experiments",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Paper includes broader impact statement discussing potential positive applications in safety-critical domains (bioinformatics, drug discovery) where constraint satisfaction is essential, but also acknowledges risks if constraints are misspecified or encode biased domain knowledge. Notes that ensuring constraint validity is crucial and that the method inherits fairness properties of its symbolic constraints.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, F1 (micro / macro / weighted), Log loss / Cross‑entropy / NLL, Vision / detection / segmentation, IoU / Jaccard index, Trustworthiness / safety, Robustness under perturbations (accuracy drop, corruption error)",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Biomedical / Clinical, Synthetic / Procedural, Toy logical datasets (symbolic math, rule chains), Custom dataset (introduced in paper), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "C-HMCNN hierarchical multi-label classification datasets",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Softmax baseline, Semantic Loss (SL), Constrained Conditional Neural Networks (CCNN), Semantic Probabilistic Layers with different circuit architectures (SPL-HMM, SPL-PC, SPL-SPN), energy-based models. Ablations include different probabilistic circuit types and constraint formulations.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "Unable to calculate precise gap as we only completed 30/200 epochs. At epoch 30: achieved 3.4% accuracy (paper reports much higher final accuracy after full training), Hamming Loss ~0.019 (consistent with paper's range), 100% constraint consistency maintained (matches paper's claim). Training loss trajectory and metric improvement patterns align with expected behavior.",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Exact Match computed as percentage of test samples where ALL output labels are correctly predicted (strict metric). Hamming Loss measures fraction of incorrect labels across all samples. Jaccard Score used as set similarity metric. Consistency/Validity measured as percentage of predictions satisfying all logical constraints (SPL guarantees 100% by construction). NLL computed as negative log-likelihood under the SPL probability distribution. Paper emphasizes exact match and consistency as primary metrics since partial correctness insufficient for constrained domains.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included because it presents a novel, theoretically grounded neuro-symbolic framework (Semantic Probabilistic Layers) that guarantees 100% consistency with logical constraints while maintaining probabilistic semantics, addresses a critical gap in structured prediction by simultaneously achieving six key desiderata that no prior method satisfied, and provides reproducible open-source code with successful verification of core training behavior across multiple constraint-based tasks.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Successfully reproduced C-HMCNN training for 30 of 200 epochs with learning trajectory matching expected behavior (training loss decreased from 32.9 to 11.9, test accuracy improved from 0% to 3.4%, Hamming loss stable around 0.019, 100% constraint satisfaction maintained). Code executed without major issues using provided environment.yml.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "probabilistic circuits, semantic loss, structured prediction, logical constraints, neuro-symbolic integration, knowledge compilation",
      "nsai_domain": "probabilistic circuits",
      "application_area_original": "hierarchical multi-label classification, pathfinding, preference learning, computer vision, bioinformatics, drug discovery, semantic segmentation",
      "application_area": "hierarchical multi-label classification",
      "task_type_original": "structured output prediction, multi-label classification, constrained optimization, graph pathfinding, ranking, image segmentation",
      "task_type": "structured output prediction",
      "symbolic_representation_original": "Propositional / Boolean logic rules, Constraint satisfaction / SMT formulas, Probabilistic graphical models (Bayesian nets, factor graphs) used symbolically, Other (specify below)",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines, Other (specify below)",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": ">10B",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2022.0",
      "venue_raw": "NeurIPS 2022",
      "venue_canonical": "NeurIPS",
      "venue_group_bin": "NeurIPS",
      "venue_group_plot": "NeurIPS",
      "venue_clean": "neurips",
      "venue_norm": "NeurIPS",
      "venue_group": "NeurIPS",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085129",
    "title": "There and Back Again:Extracting Formal Domains for Controllable Neurosymbolic Story Authoring",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-16 12:04:19.233000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085129",
      "Paper DOI / URL": "https://ojs.aaai.org/index.php/AIIDE/article/view/27502/27275",
      "Paper Title ": "There and Back Again:Extracting Formal Domains for Controllable Neurosymbolic Story Authoring",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "AIIDE, AAAI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework + Demo",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Demonstrate that languagemodels  can  be  used  to  author  narrative  planning  domainsfrom natural language stories with minimal human intervention. Second, authors explore the reverse, demonstrating that we can use logical  story domains  and plans  to  produce  storiesthat respect the narrative commitments of the planne",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/alex-calderwood/there-and-back",
      "Primary language / framework": "PDDL",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not specified",
      "Notes on reproduction": "Pin openai==0.28.1 (legacy ChatCompletion).\n\nFetch glaive01-01.zip and place glaive.jar under there_and_back/glaive/.\n\nEnsure Java 8+ available; export OPENAI_API_KEY.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "narrative-planning, neurosymbolic-story-generation, PDDL, POCL-planning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "creative-writing-support, story-authoring-tools",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "domain-extraction-from-text (PDDL), plan-based-generation, qualitative-thematic-analysis",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "GPT-4 (gpt-4-0314), GPT-3.5-turbo-0301 (ablation)",
      "Prompting strategy (if applicable)": "few‑shot, Few‑shot (N‑shot)",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Bidirectional exchange (neural ↔ symbolic loop)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "then planner’s plan is optionally fed back to LLM for story generation (bidirectional pipeline) ",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Glaive narrative planner (POCL; intentionality)",
      "Link to Existing symbolic project used (if applicable) ": "https://www.cs.uky.edu/~sgware/projects/glaive/",
      "Symbolic representation(s)": "First‑order / predicate logic",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "State-space narrative planner (Glaive; POCL with intentionality)",
      "Source of symbolic knowledge": "Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Converted from neural outputs (Decompose); plus human-authored baselines for Compose",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "Pipeline neural→symbolic (story → PDDL → planner) and symbolic→neural (plan/domain/problem → story)",
      "Example of a rule / triple / formula (copy from paper)": "(:action give … :effect (and (not (has ?giver ?item)) (has ?receiver ?item) (gave-gift ?giver ?receiver ?item)))",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom planner (Glaive); no standard theorem provers",
      "What are the key findings of the study (1-4 dot points)?": "Compile rate 0.77, plan rate 0.34 with GPT-4 + auto-debug across datasets (Table 2). \n\nGenerated domains/problems are modest but non-trivial (≈4–6 predicates/actions; Table 1). \n\nCompose yields coherent, style-constrained stories; “with-plan” closely follows planner, “without-plan” is freer but may miss author goals. \n\nAuto-debugging conditioned on Glaive errors improves success rates.",
      "Author‑reported limitations": "Lack of rigorous reader study; arbitrary design choices; dependence on specific planner; ethical concerns; future UI needed.",
      "Reviewer‑identified limitations / threats to validity": "Proprietary GPT-4 dependency & cost; no seeds/variance; limited statistical rigor; repo license not clear.",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "harms; removal of offensive r/WritingPrompts samples; creative-labor concerns",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Compile rate (Glaive parses/compiles domain+problem)  Plan rate (planner finds a solution within timeout)  Structural counts (avg. predicates/actions/steps, etc.) — Table 1 / Table 2",
      "Split / Protocol": "Zero‑shot (no task‑specific training), Few‑shot (N‑shot prompting / small labeled set), Ablation on noisy or perturbed subsets",
      "Split / Protocol (for other) specify here:": "Zero/few-shot prompting; no training; ablations: GPT-3.5 vs GPT-4; with/without auto-debug.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "TinyStories; r/WritingPrompts (custom samples)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "GPT-3.5 vs GPT-4; with/without auto-debug; human-authored Glaive domains as qualitative baseline for Compose.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "hybrid LLM↔planner architecture",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "narrative-planning, neurosymbolic-story-generation, PDDL, POCL-planning",
      "nsai_domain": "narrative-planning",
      "application_area_original": "creative-writing-support, story-authoring-tools",
      "application_area": "creative-writing-support",
      "task_type_original": "domain-extraction-from-text (PDDL), plan-based-generation, qualitative-thematic-analysis",
      "task_type": "domain-extraction-from-text (PDDL)",
      "symbolic_representation_original": "First‑order / predicate logic",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Other (specify below)",
      "knowledge_source": "Other (specify below)",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "other",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "AIIDE, AAAI",
      "venue_canonical": "AAAI",
      "venue_group_bin": "AAAI family",
      "venue_group_plot": "AAAI family",
      "venue_clean": "aaai",
      "venue_norm": "AAAI family",
      "venue_group": "AAAI family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083994",
    "title": "Embed2sym-scalable neuro-symbolic reasoning via clustered embeddings",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-16 15:08:19.295000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083994",
      "Paper DOI / URL": "https://proceedings.kr.org/2022/44/",
      "Paper Title ": "Embed2sym-scalable neuro-symbolic reasoning via clustered embeddings",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "19th International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Algorithm paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents Embed2Sym, a scalable framework that combines neural perception and symbolic reasoning through clustered embeddings, enabling fast training, interpretability, and generalization in tasks that exceed the scalability of prior neuro-symbolic systems. Embed2Sym achieves state-of-the-art results and significantly reduces training time on complex reasoning tasks involving visual and symbolic inputs.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/YanivAspis/Embed2Sym",
      "Primary language / framework": "Python (TensorFlow 2.7.0); tested on Ubuntu 18.04.",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "all metrics averaged over 5 runs",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Notes on reproduction": "The results are highly reproducible, experiment matches the paper’s main claims for accuracy and speed on all tested neuro-symbolic tasks.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic reasoning, knowledge representation, symbolic AI, deep learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "perception, reasoning, symbolic computation, image understanding, machine learning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "addition, classification, membership, sorting, clustering, transfer learning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Embed2Sym custom architecture",
      "Neural architecture type(s) ": "Hybrid (specify combination)",
      "Neural architecture type(s) (for other) specify here:": "Clustered CNN + symbolic optimizer (ASP/Clingo), simple feedforward logic for reasoning",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not precisely reported",
      "Release date": "2022-05-07 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module",
      "Quantisation (if provided)": "Not reported",
      "Existing symbolic project used (if applicable) ": "ASP tools (clingo, gringo)",
      "Link to Existing symbolic project used (if applicable) ": "https://potassco.org/clingo/",
      "Symbolic representation(s)": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Answer Set Programs (ASP)",
      "Reasoning / inference engine": "ASP solvers (clingo, gringo, clasp)",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Periodically updated post‑training (batch updates)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "sum(X,Y,Z):−digit(X),digit(Y),Z=X+Y.",
      "Tooling / libraries for symbolic side": "clingo / gringo (ASP)",
      "What are the key findings of the study (1-4 dot points)?": "Embed2Sym introduces a scalable neuro-symbolic reasoning framework, enabling symbolic reasoning over clustered neural embeddings with minimal training overhead and high interpretability.\n\nThe framework achieves state-of-the-art results on tasks including addition, membership, and sorting in MNIST and CIFAR-10, significantly outperforming prior neuro-symbolic systems in training speed and scalability.\n\nSymbolic concept labeling is performed post-training with an ASP optimizer, providing an interpretable and transferable reasoning procedure.\n\nExperimental results demonstrate Embed2Sym’s ability to handle much larger-scale reasoning tasks than previous approaches, with rapid training and competitive accuracy.",
      "Author‑reported limitations": "The process of symbolic labeling via clustering is not an explainability tool; it reflects discovered relationships in the embedding space but does not explain causal behavior.\n\nScalability is dependent on cluster separability; more sophisticated clustering or rule learning might be required for more complex domains.\n\nLimited experiments beyond vision+reasoning tasks.",
      "Reviewer‑identified limitations / threats to validity": "No coverage of possible failure cases if clustering does not cleanly separate concepts.\n\nApplicability outside of benchmark (image/digit) tasks not deeply explored.\n\nRandom seed and environment details are mentioned only partially, which could affect exact reproducibility for marginal setups.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Log loss / Cross‑entropy / NLL",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Vision, Custom dataset (introduced in paper)",
      "Link to evaluation dataset used (if other)": "http://yann.lecun.com/exdb/mnist/, https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DeepProbLog, NeurASP, Fully neural models and symbolic baselines (see results tables)",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "Very close (within less than 1% on accuracy, matches speed)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Metrics reported are standard accuracy and log loss, based on official splits; no non-standard averaging.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included in the review because it introduces a scalable neuro-symbolic algorithm whose claims of rapid training and high accuracy were fully reproducible, demonstrating clear advances over prior methods in both methodology and results.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "No further action needed—reproduction was fully successful, with all metrics matching or exceeding those reported; future work could explore additional domains, more complex datasets, and enhanced clustering strategies for even broader applicability.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "1.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "neuro-symbolic reasoning, knowledge representation, symbolic AI, deep learning",
      "nsai_domain": "neuro-symbolic reasoning",
      "application_area_original": "perception, reasoning, symbolic computation, image understanding, machine learning",
      "application_area": "perception",
      "task_type_original": "addition, classification, membership, sorting, clustering, transfer learning",
      "task_type": "addition",
      "symbolic_representation_original": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Answer Set Programs (ASP)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "ASP solvers (clingo, gringo, clasp)",
      "reasoning_engine": "ASP solvers (clingo",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "19th International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
      "venue_canonical": "KR",
      "venue_group_bin": "KR",
      "venue_group_plot": "KR",
      "venue_clean": "kr",
      "venue_norm": "KR",
      "venue_group": "KR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084581",
    "title": "A Modular Neurosymbolic Approach for Visual Graph Question Answering",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-16 18:35:06.342000",
      "Email Address": "anhu@umd.edu",
      "Reviewer Name": "Anh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084581",
      "Paper DOI / URL": "https://ceur-ws.org/Vol-3432/paper11.pdf",
      "Paper Title ": "A Modular Neurosymbolic Approach for Visual Graph Question Answering",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "NeSy’23",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework AND dataset",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents a modular neuro-symbolic architecture that processes images of graph-structured data (rather than symbolic graphs) by first using optical graph recognition and OCR to extract nodes/edges and labels, then parsing the question and using answer-set programming (ASP) for logical reasoning. This paper also introduces a new VGQA task and dataset (in 3 sets: tiny, small, medium) and establishes a baseline of 73% accuracy.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/pudumagico/NSGRAPH",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://drive.google.com/file/d/1IwKL55rmh5r8pBNLNo1IRBjT5J9YCbqo/view",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), CPU only, Memory / batch size reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Notes on reproduction": "It was quite straightforward to reproduce the main results reported in the paper (Table 1). Some minor dependency fixes are needed. The reproduced results match the main reported results exactly.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "#neuro-symbolic-reasoning, #visual-reasoning, #symbolic-logic, #multimodal-perception",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "#visual-question-answering, #visual-analytics",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "#VQA, #graph-extraction",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Understanding and reasoning over visual graph structures such as transport maps, network diagrams, flowcharts, and dashboards.",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "Neural model name & family (for other) specify here:": "Optical Graph Recognition (OGR); OCR (Tesseract) model",
      "Neural architecture type(s) ": "CNN / ConvNet",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Release date": "2024-07-25 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules, Probabilities/logits converted to logic facts or constraints, Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Feature extraction → symbolic ASP reasoning",
      "Existing symbolic project used (if applicable) ": "ASP tools (clingo, gringo)",
      "Link to Existing symbolic project used (if applicable) ": "https://potassco.org/clingo/",
      "Symbolic representation(s)": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Answer Set Programs (ASP)",
      "Reasoning / inference engine": "ASP solvers (clingo, gringo, clasp)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "Example of a rule / triple / formula (copy from paper)": "reachable(X,Y) :- edge(X,Y).\nreachable(X,Y) :- edge(X,Z), reachable(Z,Y).\n\nanswer(X) :- node(X), color(X,red), not exists_shorter_path(X).",
      "Tooling / libraries for symbolic side": "clingo / gringo (ASP)",
      "What are the key findings of the study (1-4 dot points)?": "1) A modular neuro-symbolic pipeline combining neural perception (OCR/OGR) with ASP-based symbolic reasoning can successfully perform Visual Graph Question Answering (VGQA) without task-specific neural fine-tuning.\n2) The results show that symbolic logical reasoning can remain robust even when upstream neural predictions are noisy.\n3) This study demonstrates that graph-structured VQA is feasible using interpretable and modular neurosymbolic components.",
      "Author‑reported limitations": "1) OCR/OGR's quality can be an accuracy bottlenecks that affect downstream reasoning performance.\n2) Limited scale and diversity of evaluation (small benchmark, controlled graph layouts).",
      "Reviewer‑identified limitations / threats to validity": "1) Dataset is synthetic and narrow-domain, reducing ecological validity and external generalisation.\n2) No comparison against LLM-based or Transformer-based VQA baselines, leaving unclear the gap vs contemporary methods.\n3) No complexity, latency, or scalability analysis for larger or noisier real-world graph visualisations.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "5.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, Energy / FLOPs / latency / throughput",
      "Split / Protocol": "Zero‑shot (no task‑specific training), Other (specify below)",
      "Split / Protocol (for other) specify here:": "Synthetic CLEGR / CLEGRᵥ graphs with 100 graphs × 10 questions per size (tiny/small/medium), used purely as an evaluation set.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Docker / Conda / container to reproduce metrics, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Synthetic / Procedural, Custom dataset (introduced in paper), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "CLEGR (symbolic graph QA) and CLEGRᵥ / NSGRAPH VGQA (images of CLEGR-style metro graphs with QA).",
      "Link to evaluation dataset used (if other)": "https://drive.google.com/file/d/1IwKL55rmh5r8pBNLNo1IRBjT5J9YCbqo/view",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "1) NSGRAPH (proposed method)\n2) OCR+GT (ablation: OGR predictions replaced with ground-truth graph)\n3) OGR+GT (ablation: OCR labels replaced with ground-truth text)",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0% gap on all test set variants (tiny, small, medium)",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper introduces a new, clearly defined visual graph question-answering (VGQA) benchmark and a fully reproducible pipeline (with exactly matched metric numbers), demonstrating interpretable reasoning with verifiable results and open resources.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Some minor dependency issues: straightforward to fix. Testing on CPU and GPU yields approximately the same performance and execution time.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "#neuro-symbolic-reasoning, #visual-reasoning, #symbolic-logic, #multimodal-perception",
      "nsai_domain": "#neuro-symbolic-reasoning",
      "application_area_original": "#visual-question-answering, #visual-analytics",
      "application_area": "#visual-question-answering",
      "task_type_original": "#VQA, #graph-extraction",
      "task_type": "#VQA",
      "symbolic_representation_original": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Answer Set Programs (ASP)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "ASP solvers (clingo, gringo, clasp)",
      "reasoning_engine": "ASP solvers (clingo",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2023.0",
      "venue_raw": "NeSy’23",
      "venue_canonical": "NeSy",
      "venue_group_bin": "NeSy",
      "venue_group_plot": "NeSy",
      "venue_clean": "nesy",
      "venue_norm": "NeSy",
      "venue_group": "NeSy",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083885",
    "title": "Knowledge Enhanced Neural Networks for relational domains",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-16 23:59:40.833000",
      "Email Address": "martiros@umd.edu",
      "Reviewer Name": "Vladimir",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083885",
      "Paper DOI / URL": "https://doi.org/10.48550/arXiv.2205.15762",
      "Paper Title ": "Knowledge Enhanced Neural Networks for relational domains",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Springer International Publishing",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Paper extends knowledge enhanced NNs to handle relational data and shows that stacking multiple KE layers deals with rule dependencies, achieving better accuracy than baseline NNS on Citeseer citation network classification while also being faster than baseline  Semantic Based Regularization (SBR) and Relational Neural Machines (RNM)",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/DanieleAlessandro/KENN2",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "a50600c34cb6636b4005e888b0023ced96a2d1e0",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "100",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "BSD 3-Clause",
      "Notes on reproduction": "Successful repro, challenges with outdated TF",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neural-Symbolic Integration, Neuro-Symbolic AI, Knowledge-Enhanced Learning, Fuzzy Logic",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Citation Networks, Collective Classification, Document Classification, Graph Learning, Relational Data",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Node Classification, Semi-supervised Learning, Inductive Learning, Transductive Learning, Multi-class Classification",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper applies KENN to classify academic papers in the Citeseer citation network (3312 documents) into 6 topic categories (AG, AI, DB, IR, ML, HCI) using bag-of-words features and citation edges. The logical knowledge encodes that \"papers cite related work\" through rules and improves classification accuracy over baseline neural networks, especially with limited training data (10-50% labeled nodes).",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Simple 3-layer feedforward NN",
      "Neural architecture type(s) ": "Simple MLP",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "First‑order / predicate logic, Fuzzy logic, Godel t‑norm logics",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Reasoning / inference engine (for other) specify here:": "Knowledge Enhancer (KE) layers with Clause Enhancer (CE) submodules implementing differentiable t-conorm boost functions using softmax approximations",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Update / learning of symbols (for other) specify here:": "Clause weights are learnable parameters trained end-to-end; rule structures remain static",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Constraint injection / regularization during neural training",
      "Example of a rule / triple / formula (copy from paper)": "If paper x has topic T and paper x cites paper y, then paper y also has topic T, where T is one of: AG, AI, DB, IR, ML, or HCI (written as: not T(x) OR not Cite(x,y) OR T(y) for each topic).",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "TensorFlow (for implementing differentiable Knowledge Enhancer operations using gather/scatter_nd functions)",
      "What are the key findings of the study (1-4 dot points)?": "1. KENN achieves 27x speedup over RNM (7.96s vs 215.69s per run) and 11x over SBR (87.36s), while maintaining comparable or better accuracy\n2. Knowledge injection provides equivalent benefit to doubling training data \n3. inductive learning improvements of 0.048-0.021 and transductive improvements of 0.108-0.049 across 10-90% training data",
      "Author‑reported limitations": "Performance improvements degrade faster than RNM and SBR when high training data\nIndependence assumption between clauses can be violated in relational domains\nRestricted to clauses containing at most two variables (unary and binary predicates)",
      "Reviewer‑identified limitations / threats to validity": "Significance only computed for KENN vs NN baseline, not for KENN vs RNM/SBR comparisons",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Statistical rigor reported, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Random split (e.g. 80/10/10), Stratified split (by class/label)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Citeseer",
      "Link to evaluation dataset used (if other)": "https://www.cs.uic.edu/~cornelia/papers/ecir14.pdf",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Baseline NN (3-layer MLP with 50 hidden nodes, ReLU)\nSBR (Semantic Based Regularization)\nRNM (Relational Neural Machines)\nAblation: varying number of KE layers (0-6 layers tested)\nAblation: varying training set size (10%, 25%, 50%, 75%, 90%)",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "avg gap of 0.3%, max 0.9 for 90% trained inductive training",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "The paper presents a framework that improves neural network performance on relational data by injecting differentiable logical constraints with learnable clause weights.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "4.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neural-Symbolic Integration, Neuro-Symbolic AI, Knowledge-Enhanced Learning, Fuzzy Logic",
      "nsai_domain": "Neural-Symbolic Integration",
      "application_area_original": "Citation Networks, Collective Classification, Document Classification, Graph Learning, Relational Data",
      "application_area": "Citation Networks",
      "task_type_original": "Node Classification, Semi-supervised Learning, Inductive Learning, Transductive Learning, Multi-class Classification",
      "task_type": "Node Classification",
      "symbolic_representation_original": "First‑order / predicate logic, Fuzzy logic, Godel t‑norm logics",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Constraint injection / regularization during neural training",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2022.0",
      "venue_raw": "Springer International Publishing",
      "venue_canonical": "Springer",
      "venue_group_bin": "Springer journals/proceedings",
      "venue_group_plot": "Springer journals/proceedings",
      "venue_clean": "springer",
      "venue_norm": "Springer journals/proceedings",
      "venue_group": "Springer journals/proceedings",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084132",
    "title": "Neural symbolic regression that scales",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 00:40:53.321000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084132",
      "Paper DOI / URL": "https://arxiv.org/abs/2106.06427",
      "Paper Title ": "Neural symbolic regression that scales",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Proceedings of the 38th International Conference on Machine Learning, PMLR",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Method paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents NeSymReS, a neural symbolic regression model that leverages large-scale pre-training of Transformers on procedurally generated equations and data, enabling scalable, efficient, and robust discovery of symbolic equations from input-output data pairs. The approach outperforms traditional and neural symbolic regression methods across diverse evaluation benchmarks.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/SymposiumOrganization/NeuralSymbolicRegressionThatScales",
      "Primary language / framework": "Python (PyTorch)",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/SymposiumOrganization/NeuralSymbolicRegressionThatScales",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Training time / FLOPs reported, Memory / batch size reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Repository is complete, with full code, test scripts, pretrained models, detailed documentation, and results reproduce as claimed.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic AI, symbolic regression, equation discovery",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "scientific discovery, physics, engineering, model-based reinforcement learning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "symbolic regression, equation inference, function discovery",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper claims applicability in accelerating scientific discovery, physics analysis, engineering modeling, and control systems by enabling automatic discovery of symbolic equations from experimental or simulation data.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Custom Transformer",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "10M (10 million) and 100M (100 million) parameters (two pretrained variants)",
      "Release date": "2021-07-25 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Synthetic / procedurally generated text (self‑play, toolformer, program synthesis)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "all symbolic equations generated synthetically with in-house scripts.",
      "Symbolic representation(s)": "Grammars / automata / production rules, Domain‑specific languages (DSLs) / program sketches, Algebraic specifications / term‑rewriting systems",
      "Reasoning / inference engine": "Constraint solvers / ILP optimizers (Gurobi, OR‑Tools, Choco), Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Example of a rule / triple / formula (copy from paper)": "Predicted:−0.999999989×x1+log⁡(x1+x24)−0.999999989×x1+log(x1+x24)",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "Pre-trained neural symbolic regression (NeSymReS) can discover symbolic equations from data with higher accuracy and speed than traditional or prior neural approaches.\n\nModel performance improves significantly with larger pre-training datasets, demonstrating scalable symbolic regression.\n\nThe approach robustly recovers well-known physical equations and generalizes to equation structures not present in training.\n\nCode and pretrained models are publicly released, supporting full reproducibility of the study",
      "Author‑reported limitations": "Difficulty fitting constants in equations with many local minima; BFGS optimization can struggle with challenging landscapes.\n\nPre-trained models do not generalize to a greater number of variables than seen during training.\n\nNeural network does not interact directly with math libraries during inference, limiting adaptability when initial equation guesses are poor.",
      "Reviewer‑identified limitations / threats to validity": "Reproducibility may be limited for equations outside the procedure-generated priors or with higher variable count than pre-trained.\n\nReliance on synthetic data generation may affect generalizability to noisy or real-world collected datasets.\n\nRun commands and environment not provided as Docker/Conda, so users may need to manually resolve dependencies for exact environment.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "MSE / RMSE / MAE, R^2 / Adjusted R^2",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Synthetic / Procedural, Custom dataset (introduced in paper), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "SOOSE (benchmark) AI-Feynman benchmark Nguyen benchmark",
      "Link to evaluation dataset used (if other)": "https://github.com/SymposiumOrganization/NeuralSymbolicRegressionThatScales/tree/main/test_set",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Traditional symbolic regression (genetic programming, RL), Deep Symbolic Regression (DSR), Gaussian Process-based SR, and model ablations (scaling, architecture)\n",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": " ~0% (results match within floating-point error; see your summary)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "None—standard evaluation protocols, no unusual averaging or smoothing",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a highly reproducible and robust neuro-symbolic regression framework that advances the field by enabling scalable, accurate, and interpretable equation discovery, with open-source code and models.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "No action items needed—results matched exactly; all code, data, and documentation are available and reproducibility is fully confirmed.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "neuro-symbolic AI, symbolic regression, equation discovery",
      "nsai_domain": "neuro-symbolic AI",
      "application_area_original": "scientific discovery, physics, engineering, model-based reinforcement learning",
      "application_area": "scientific discovery",
      "task_type_original": "symbolic regression, equation inference, function discovery",
      "task_type": "symbolic regression",
      "symbolic_representation_original": "Grammars / automata / production rules, Domain‑specific languages (DSLs) / program sketches, Algebraic specifications / term‑rewriting systems",
      "symbolic_representation": "Grammars / automata / production rules",
      "reasoning_engine_original": "Constraint solvers / ILP optimizers (Gurobi, OR‑Tools, Choco), Custom in‑house rule/constraint engines",
      "reasoning_engine": "Constraint solvers / ILP optimizers (Gurobi",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Generated synthetically (procedural rule generation)",
      "knowledge_source": "Generated synthetically (procedural rule generation)",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "<1B",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2025.0",
      "venue_raw": "Proceedings of the 38th International Conference on Machine Learning, PMLR",
      "venue_canonical": "Workshops (CEUR/PMLR)",
      "venue_group_bin": "Workshops (CEUR/PMLR)",
      "venue_group_plot": "Workshops (CEUR/PMLR)",
      "venue_clean": "workshops (ceur/pmlr)",
      "venue_norm": "Workshops (CEUR/PMLR)",
      "venue_group": "Workshops (CEUR/PMLR)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084274",
    "title": "Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 04:52:26.899000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084274",
      "Paper DOI / URL": "https://arxiv.org/abs/2401.09651",
      "Paper Title ": "Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Proceedings of the 41 st International Conference on Machine Learning, Vienna, Austria.",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Method paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents a bilevel, gradient-based optimization framework for neural-symbolic (NeSy) learning, introducing a dual block coordinate descent algorithm and smooth formulation for efficient and scalable parameter learning, empirically validated on multiple datasets.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/linqs/dickens-icml24",
      "Primary language / framework": "Python (main); also uses Bash and some Java",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "(Experiments run on 5 splits; N=5 per configuration for AUROC measures)",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Notes on reproduction": "Results were reproduced as described earlier; AUROC matches paper claims closely.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neural-symbolic, convex optimization, bilevel optimization, energy-based modeling, inference, learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "link prediction, node classification, regression, knowledge graphs, social networks, citation networks, recommendation systems",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "classification, regression, structured prediction, parameter optimization, inference",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The framework is applied to benchmark datasets in social networks, citation graphs, and drug interaction prediction, demonstrating effectiveness in link prediction, classification, and regression tasks relevant to practical, real-world scenarios such as recommendation systems and biomedical research.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "custom MLP and neural architectures used with NeuPSL",
      "Neural architecture type(s) ": "GNN (Graph Neural Network), Energy-based model, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Release date": "2024-05-27 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints, Bidirectional exchange (neural ↔ symbolic loop)",
      "Quantisation (if provided)": "Not reported / N/A",
      "Existing symbolic project used (if applicable) ": "ProbLog / PSL (Probabilistic Soft Logic) / Markov Logic (Alchemy/Tuffy)",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/linqs/psl",
      "Symbolic representation(s)": "First‑order / predicate logic, Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy), Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules, Constraint injection / regularization during neural training",
      "Example of a rule / triple / formula (copy from paper)": "Friend(A,B) & Likes(B,X) -> Likes(A,X)",
      "Tooling / libraries for symbolic side": "Probabilistic Soft Logic (PSL / PyPSL), Custom in‑house engine (name below), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "HL-MRFs (hinge-loss Markov random fields)",
      "What are the key findings of the study (1-4 dot points)?": "Proposes a novel bilevel optimization framework for gradient-based learning in neural-symbolic (NeSy) energy-based models, using a smooth Moreau envelope formulation.\n\nIntroduces an efficient dual block coordinate descent (BCD) algorithm tailored for symbolic energy-based inference, enabling up to 100x speedup in learning runtime over prior NeuPSL methods.\n\nDemonstrates substantial prediction and efficiency improvements (up to 16 points in performance) across 8 benchmark datasets in tasks like link prediction, node classification, regression, and image-based reasoning.\n\nShows that the framework provides stable, reproducible results with clear parameter tuning and robust empirical evaluation, competitive with or superior to strong baselines.",
      "Author‑reported limitations": "Framework limited to NeSy-EBMs with differentiable value-functions and unique minimizers.\n\nDoes not address non-differentiable or fundamentally harder inference settings; relies on LCQP structure for tractability.\n\nFuture work is needed to extend the framework to approximate solutions for more general NeSy systems.",
      "Reviewer‑identified limitations / threats to validity": "Relies on specific types of neural-symbolic models (HL-MRFs, LCQP) and may not generalize to all neuro-symbolic architectures.\n\nSome dependencies (e.g., external PSL/NeuPSL code) may complicate pure standalone reproduction.\n\nLimited reporting of pre-training and hardware diversity; not all potential confounds (e.g., random seed setting) are fully transparent.",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Impact statement notes potential for improved reliability, domain-aware reasoning, and positive societal consequences, but does not highlight specific risks; privacy, bias, or fairness issues are not discussed in detail.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, AUROC (ROC‑AUC), MSE / RMSE / MAE, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Standard deviation/error bars provided for splits",
      "Split / Protocol": "Random split (e.g. 80/10/10), k‑fold cross‑validation (specify k), Hold‑out validation only (no test split)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo, Only high‑level metric numbers in paper (no code)",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Baselines / ablations compared against": "Traditional PSL/NeuPSL, ADMM inference, value-based losses",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "Small (<2% for main metrics)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Standard splits, averaging over five runs; smoothing and regularization described in script/paper; no major non-standard computation applied.\nIf a particular section needs elaboration (e.g., dataset details, scripts, or computation method), let me know.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included because it presents a novel, efficient, and reproducible neuro-symbolic learning framework that substantially improves predictive performance and scalability for real-world inference tasks, with comprehensive empirical validation on diverse datasets.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproduction matches the reported quantitative results within expected variance; for full transparency, authors should provide explicit random seed values, detailed regularization settings, and raw output files to ensure perfect replication across splits and hardware. No major barriers to reproduction—accept with minor clarifications suggested.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "2.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "nsai_domain_original": "neural-symbolic, convex optimization, bilevel optimization, energy-based modeling, inference, learning",
      "nsai_domain": "neural-symbolic",
      "application_area_original": "link prediction, node classification, regression, knowledge graphs, social networks, citation networks, recommendation systems",
      "application_area": "link prediction",
      "task_type_original": "classification, regression, structured prediction, parameter optimization, inference",
      "task_type": "classification",
      "symbolic_representation_original": "First‑order / predicate logic, Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Probabilistic logic engines (PSL, Markov Logic tools like Tuffy, Alchemy), Custom in‑house rule/constraint engines",
      "reasoning_engine": "Probabilistic logic engines (PSL",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules, Constraint injection / regularization during neural training",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2025.0",
      "venue_raw": "Proceedings of the 41 st International Conference on Machine Learning, Vienna, Austria.",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084922",
    "title": "SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning for Compression",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 16:26:19.759000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084922",
      "Paper DOI / URL": "https://arxiv.org/abs/2401.09949",
      "Paper Title ": "SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning for Compression",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv (preprint)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Algorithm paper (with experimental validation)",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "SymbolNet combines neural networks with symbolic regression through adaptive pruning to extract interpretable mathematical expressions while achieving high model compression. The method uses a custom training loop with threshold-based pruning to identify and eliminate less important network connections, enabling recovery of human-readable symbolic formulas from trained models without sacrificing predictive accuracy.\n\n",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/hftsoi/SymbolNet",
      "Primary language / framework": "Python, TensorFlow 2.15.0, Keras, SymPy  Commit / tag / release hash used:",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Partial",
      "Notes on reproduction": "The SymbolNet repository encountered environmental challenges during reproducibility testing on the Zaratan HPC cluster, including macOS-specific packages in the environment.yml file and the primary dataset (LHC jets) requiring internet connectivity that failed on the isolated HPC system; these were overcome by creating a Linux-compatible environment and substituting MNIST as the test dataset. Despite these initial hurdles, SymbolNet demonstrates robust reproducibility: the codebase is feature-complete and functionally correct, reproduced results (88.39% test accuracy on MNIST) closely match authors' reported performance (~88%), symbolic extraction successfully generates interpretable mathematical expressions, and random seeds are properly documented for deterministic reproduction. However, the codebase exhibits significant limitations: the entire implementation exists only as a Jupyter notebook without standalone Python scripts, documentation is minimal with only a one-sentence README, no Docker or containerization is provided, exact reproduction commands are absent, and the evaluation lacks statistical rigor with no multiple independent runs, error bars, or significance testing reported. Overall, while SymbolNet is functionally reproducible and algorithmically sound, it requires substantial effort to reproduce and lacks production-ready infrastructure and documentation necessary for broader adoption.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neural-Symbolic Integration, Symbolic Regression, Model Compression, Interpretability",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Machine Learning, Deep Learning, Knowledge Extraction, Model Pruning, Explainable AI",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Classification, Symbolic Expression Generation, Neural Network Pruning, Knowledge Distillation",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "SymbolNet is applied to two real-world domains: (1) High-Energy Physics (LHC Jet Tagging) - classifying particle collision data from CERN's Large Hadron Collider to identify jet types, where the extracted symbolic expressions provide interpretable physics insights; (2) Image Classification (MNIST/SVHN) - demonstrating practical compression and interpretability for digit recognition tasks. The method achieves 96.5% model weight pruning while maintaining 88%+ accuracy, enabling deployment on resource-constrained devices while providing human-readable mathematical formulas that explain model predictions—particularly valuable in scientific and safety-critical applications requiring transparency.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Custom fully-connected neural network with symbolic layers (Input_sparsity, Symbolic_Layer)",
      "Neural architecture type(s) ": "Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Input layer: 784 features (MNIST) or 16 features (LHC) Hidden symbolic layer: 20 unary operators + 5 binary operators = 25 total Output layer: 10 classes (MNIST) Estimated: ~20K-50K parameters (highly compressed via pruning to 96.5% sparsity)",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Knowledge distillation (student‑teacher, model compression)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "SymPy (Python symbolic mathematics library)",
      "Link to Existing symbolic project used (if applicable) ": "https://www.sympy.org/",
      "Symbolic representation(s)": "Algebraic specifications / term‑rewriting systems",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Constraint injection / regularization during neural training",
      "Tooling / libraries for symbolic side": "PySMT / PyEDA",
      "Tooling / libraries for symbolic side (for other) specify here:": "SymPy",
      "What are the key findings of the study (1-4 dot points)?": "KEY FINDINGS OF THE STUDY (1-4 DOT POINTS)\n• Adaptive Pruning with Symbolic Extraction: SymbolNet combines neural network training with threshold-based pruning to automatically extract interpretable mathematical expressions from trained models, achieving 96.5% weight compression while maintaining 88%+ classification accuracy.\n\n• Empirical Validation on Multiple Domains: The method successfully applies to both image classification (MNIST: 88.39% accuracy) and high-energy physics (LHC jet tagging), demonstrating domain generalizability of the symbolic regression approach.\n\n• Sparsity-Accuracy Trade-off: The paper demonstrates that aggressive model pruning (input sparsity 74.17%, model sparsity 96.51%) can be balanced with competitive performance through joint optimization of neural weights and pruning thresholds during training.\n\n• Interpretability Without Performance Sacrifice: Extracted symbolic expressions provide human-readable mathematical formulas for model predictions, enabling scientific interpretability and explainability—critical for physics and safety-critical applications—without significant accuracy degradation.\n\n",
      "Reviewer‑identified limitations / threats to validity": "• Limited Scalability Testing: Evaluation restricted to relatively small networks (1 hidden layer) and small-to-medium datasets; unclear how method scales to deep architectures or large-scale datasets.\n\n• Hyperparameter Sensitivity: No sensitivity analysis provided for sparsity regularization coefficients (alpha_sparsity_*), pruning thresholds initialization, or learning rates; reproducibility may be fragile to hyperparameter variations.\n\n• Statistical Rigor: No multiple independent runs reported, no error bars, confidence intervals, or significance testing; single-run results limit confidence in generalizability.\n\n• Dataset Limitations: Primary evaluation on MNIST (relatively simple benchmark); LHC dataset requires internet access, hindering reproducibility on isolated systems like HPC clusters.\n\n• Symbolic Expression Validation: No formal verification that extracted expressions match neural network outputs exactly; only implicit validation through empirical performance matching.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Regression / calibration / efficiency, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Sparsity metrics: input_sparsity, model_sparsity, unary_sparsity, binary_sparsity (all reported) Expression complexity: Mean complexity score for extracted symbolic expressions (reported: 254.4) Threshold means: threshold_input_mean, threshold_model_mean (used as regularization metrics)",
      "Split / Protocol": "Random split (e.g. 80/10/10)",
      "Evaluation assets provided (if yes / partial above) ": "Only high‑level metric numbers in paper (no code)",
      "Datasets used for Evaluation ": "CIFAR-10, Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "LHC Jets (OpenML: hls4ml_lhc_jets_hlf) (paper mentions but requires internet access) SVHN (mentioned in paper)",
      "Link to evaluation dataset used (if other)": "MNIST: keras.datasets.mnist.load_data() (built-in Keras dataset) LHC Jets: https://www.openml.org/d/42731 CIFAR-10: keras.datasets.cifar10.load_data() (built-in Keras dataset)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Partial",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "+.39%",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Non-standard considerations:\n\nAccuracy Computation: Uses np.argmax(Y_test, axis=1) == np.argmax(Y_pred, axis=1) for one-hot encoded labels (standard for multiclass)\n\nLoss Function: Paper uses custom MSE loss on multiclass labels rather than categorical cross-entropy; this differs from standard practice but is mathematically valid\n\nSparsity Metrics: Custom definitions using threshold comparisons:\n\nsparsity = num_masked_weights / total_weights where masking is weight - threshold > 0\nThis differs from standard L0 regularization metrics\nComplexity Score: Defined as tree node count in SymPy AST representation; non-standard metric for expression complexity\n\nSymbolic Expression Equivalence: No formal validation that extracted expressions exactly match neural outputs; only empirical accuracy matching used as proxy\n\nNo Micro/Macro Averaging: Single accuracy reported (not stratified by class); for balanced MNIST this is acceptable but could hide class imbalances",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "SymbolNet demonstrates a reproducible Neuro-Symbolic AI system that successfully extracts interpretable mathematical expressions from trained neural networks through adaptive pruning, achieving empirically validated results (88.39% accuracy matching ~88% reported) and exemplifying the 2024–2025 trend toward differentiable symbolic engines for interpretability and model compression.\n\n",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproduction Status: Successful - Core algorithm validated, results match paper claims within negligible variance (+0.39%).\n\n Action Items for Authors:\n\nDocumentation - Create comprehensive README with installation instructions, usage examples, and hyperparameter guidelines; convert Jupyter notebook to standalone Python scripts for easier integration into pipelines.\n\nReproducibility Containers - Provide Docker or Singularity container specifications with Linux-compatible environment.yml to eliminate platform-specific dependency issues (current environment.yml has macOS-specific packages).\n\nStatistical Rigor - Report results over multiple independent runs with error bars, confidence intervals, and statistical significance tests (e.g., t-tests against baselines).\n\nBaseline Comparisons - Compare against other symbolic regression (genetic programming, ILP) and compression methods (quantization, knowledge distillation) to contextualize contribution; provide ablation studies on sparsity coefficients and operator combinations.\n\nHyperparameter Sensitivity - Document how results vary with alpha_sparsity_* coefficients and pruning threshold initializations; provide configuration files for reproducing reported results across datasets.\n\nDataset Access - Provide offline MNIST evaluation as primary benchmark or include LHC data locally in repository; document network requirements for OpenML downloads.\n\nEvaluation Artifacts - Release evaluation scripts, pre-trained checkpoints, and result tables (CSV/JSON) for evaluation reproducibility without full retraining.\n\n Follow-up Investigations Needed:\n\nScalability testing on deeper networks (>2 hidden layers) and larger datasets (ImageNet, CIFAR-100)\nPer-class accuracy and error analysis to identify if method works equally across all classes\nValidation that extracted symbolic expressions exactly match neural outputs on held-out test cases (not just accuracy matching)\nComputational cost analysis: training time, memory usage, symbolic extraction overhead vs. standard networks\nGeneralization to other domains (NLP, speech, time-series) beyond vision and physics\n\nOverall Assessment: Paper qualifies for inclusion in scoping review as reproducible Neuro-Symbolic system with publicly available code and validated results; recommend acceptance with requests for authors to address documentation and statistical rigor gaps in revised version.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.39",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "Neural-Symbolic Integration, Symbolic Regression, Model Compression, Interpretability",
      "nsai_domain": "Neural-Symbolic Integration",
      "application_area_original": "Machine Learning, Deep Learning, Knowledge Extraction, Model Pruning, Explainable AI",
      "application_area": "Machine Learning",
      "task_type_original": "Classification, Symbolic Expression Generation, Neural Network Pruning, Knowledge Distillation",
      "task_type": "Classification",
      "symbolic_representation_original": "Algebraic specifications / term‑rewriting systems",
      "symbolic_representation": "Algebraic specifications / term‑rewriting systems",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Constraint injection / regularization during neural training",
      "integration_strategy": "Constraint injection / regularization during neural training",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": ">10B",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2024.0",
      "venue_raw": "arXiv (preprint)",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085093",
    "title": "Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering",
    "year": "2021.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 19:05:22.336000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085093",
      "Paper DOI / URL": "https://ojs.aaai.org/index.php/AAAI/article/view/17593/17400",
      "Paper Title ": "Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2021",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "AAAI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": " vary the set of language models,\ntraining regimes, knowledge sources, and data generation strategies, and measure their impact across tasks.\nExtending on prior work, we devise and compare four\nconstrained distractor-sampling strategies",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/Mayer123/HyKAS-CSKG",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "CSQA, PIQA, SocialIQA, aNLI, WinoGrande",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "aNLI failures across all three RoBERTa checkpoints due to KeyError: 'context' in ANLIInstanceReader.to_uniform_fields (expects fields['context'] and nested question/choices but our anli_dev.jsonl likely follows the common aNLI schema with observation_1, observation_2, hyp1, hyp2, label).\n\nPIQA accuracy not parsed because labels were absent/None in our piqa_dev.jsonl, so evaluate_RoBERTa.py skipped accuracy writeout.\n\nAll other tasks ran and produced accuracies close to reported values (see Section 8).",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "commonsense-reasoning, neuro-symbolic, knowledge-graphs, zero-shot-transfer",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "QA-benchmarks, general-commonsense ",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "multiple-choice QA, pronoun-resolution (WG), NLI (aNLI) ",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "RoBERTa-L ≈355M; GPT-2-L ≈774M",
      "Release date": "2021-01-01 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear, Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "Not a prompting paper; converts sequences to sentences via templates for scoring; zero-shot transfer after pre-training on synthetic QA ",
      "Alignment / Safety Filters Applied (if applicable) ": "Other (specify below)",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "this paper’s contribution is synthetic QA pre-training from KGs",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Marginal Ranking (MR) loss on synthetic QA to preserve task structure.\n\nMLM on concatenated question+answer as a comparison (MR > MLM).",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Bidirectional exchange (neural ↔ symbolic loop)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Pipeline (symbolic → neural): KGs → synthetic QA → LM training; no explicit symbolic inference at runtime.",
      "Existing symbolic project used (if applicable) ": "WordNet, Wikidata / DBpedia / YAGO, ConceptNet, Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "ATOMIC; ConceptNet; WordNet; Wikidata; VisualGenome; consolidated in CSKG",
      "Symbolic representation(s)": "Knowledge graphs / RDF triples",
      "Symbolic representation(s) (for other) specify here:": "Knowledge graphs / triples; mapped relations (e.g., /r/Causes, /r/HasPrerequisite).",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Reasoning / inference engine (for other) specify here:": "symbols used to generate QA; no explicit symbolic inference at eval time",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "Symbolic → neural pipeline; diverse KG mix (CSKG) tends to help when aligned to downstream task.",
      "Example of a rule / triple / formula (copy from paper)": "Paper shows triple-to-sentence lexicalization and tail-masking to form Q/A; distractors sampled by strategies (random, adv-answer, adv-question, adv-filter).",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "CSKG consolidation; sentence templates; AFLite for filtering “easy” items (adv-filter).",
      "What are the key findings of the study (1-4 dot points)?": "MR training > MLM for zero-shot transfer (preserving task structure matters). \n\nKnowledge alignment matters (ATOMIC helps SIQA; CWWV helps CSQA); CSKG often best overall. \n\nAdversarial distractors do not universally help; random or mixed strategies may work as well or better. \n\nSynthetic QA is generally hard for models but easy for humans, though fairness issues occur due to KG incompleteness. \n",
      "Author‑reported limitations": "KG incompleteness; fairness/informativeness trade-off; gap vs. supervised models.",
      "Reviewer‑identified limitations / threats to validity": "Dataset schema assumptions in evaluation scripts and dependency on template quality.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "6.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Major barriers / large amounts of unclear steps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "paper evaluates on dev sets as test stand-ins.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "CommonsenseQA (CSQA), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "CommonsenseQA, PIQA, SocialIQA, aNLI, WinoGrande",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Majority; vanilla RoBERTa/GPT-2; Self-Talk; COMET-DynaGen; SMLM; supervised RoBERTa upper-bound.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "We used provided model folders roberta_atomic, roberta_cwwv, roberta_cskg; values are accuracy  roberta_atomic (paper MR): CSQA 64.2, SIQA 63.1, WG 59.6; aNLI 70.8, PIQA 72.1.   Our results: CSQA 64.2, SIQA 64.2, WG 59.9 (=match); aNLI failed; PIQA NA (labels absent --> no accuracy).  roberta_cwwv (paper MR): CSQA 67.9, SIQA 54.8, WG 59.4; aNLI 70.0, PIQA 72.0.   Our results: CSQA 68.6 (+0.7), SIQA 53.8 (−1.0), WG 59.9 (+0.5); aNLI failed; PIQA NA.  roberta_cskg (paper MR): CSQA 67.4, SIQA 63.2, WG 60.9; aNLI 70.5, PIQA 72.4.   Our results: CSQA 68.2 (+0.8), SIQA 62.8 (−0.4), WG 60.5 (−0.4); aNLI failed; PIQA NA.  For the tasks that ran, absolute deviations were small (=0–1%); aNLI did not run due to evaluation-script schema mismatch; PIQA not scored because labels were missing in our dev file.",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "aNLI JSON expected by ANLIInstanceReader differs from our anli_dev.jsonl (expects 'context' + question/choices, not the common observation_1/2, hyp1/2). Fix: map fields (e.g., join obs1/obs2 → context; wrap hyp1/hyp2 into choices; add answerKey). PIQA dev file lacked label, so script skipped accuracy.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "our reproduction matched reported numbers on most tasks with minor deviations, though aNLI required script/schema fixes and hence was not reproduced. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "We used provided model folders roberta_atomic, roberta_cwwv, roberta_cskg; values are accuracy\n\nroberta_atomic (paper MR): CSQA 64.2, SIQA 63.1, WG 59.6; aNLI 70.8, PIQA 72.1. \n\nOur results: CSQA 64.2, SIQA 64.2, WG 59.9 (=match); aNLI failed; PIQA NA (labels absent --> no accuracy).\n\nroberta_cwwv (paper MR): CSQA 67.9, SIQA 54.8, WG 59.4; aNLI 70.0, PIQA 72.0. \n\nOur results: CSQA 68.6 (+0.7), SIQA 53.8 (−1.0), WG 59.9 (+0.5); aNLI failed; PIQA NA.\n\nroberta_cskg (paper MR): CSQA 67.4, SIQA 63.2, WG 60.9; aNLI 70.5, PIQA 72.4. \n\nOur results: CSQA 68.2 (+0.8), SIQA 62.8 (−0.4), WG 60.5 (−0.4); aNLI failed; PIQA NA.\n\nFor the tasks that ran, absolute deviations were small (=0–1%); aNLI did not run due to evaluation-script schema mismatch; PIQA not scored because labels were missing in our dev file.\n\n",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "commonsense-reasoning, neuro-symbolic, knowledge-graphs, zero-shot-transfer",
      "nsai_domain": "commonsense-reasoning",
      "application_area_original": "QA-benchmarks, general-commonsense",
      "application_area": "QA-benchmarks",
      "task_type_original": "multiple-choice QA, pronoun-resolution (WG), NLI (aNLI)",
      "task_type": "multiple-choice QA",
      "symbolic_representation_original": "Knowledge graphs / RDF triples",
      "symbolic_representation": "Knowledge graphs / RDF triples",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "<1B",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2021.0",
      "venue_raw": "AAAI",
      "venue_canonical": "AAAI",
      "venue_group_bin": "AAAI family",
      "venue_group_plot": "AAAI family",
      "venue_clean": "aaai",
      "venue_norm": "AAAI family",
      "venue_group": "AAAI family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242086220",
    "title": "Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 19:19:36.954000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242086220",
      "Paper DOI / URL": "https://arxiv.org/pdf/2502.13834",
      "Paper Title ": "Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "we introduce a neuro-symbolic tactic generator that synergizes the mathematical intuition learned by LLMs with domain-specific insights encoded by symbolic methods.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/Lizn-zn/NeqLIPS",
      "Primary language / framework": "Lean 4 (proofs/tactics), Python (drivers/optimizer), Rust (maturin-built component for pattern/e-matching), SymPy/SciPy; SMT/CAD tooling via Z3, CVC5, Maple RC-CAD, Bottema",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "Yes",
      "Total compute budget (if yes to the above) ": "192 cores per run; Docker); LLM via hosted API (GPT-4o Azure-0501).",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "Environment from your log: Python 3.10.19 (conda env NeqLIPS), Lean 4.15.0 / Lake 5.0.0, datasets ChenNEQ, MO-INT, 567NEQ; 5400 s/problem (90 min) aligned with paper.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic theorem proving, inequality proving, Lean, SMT/CAD",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Olympiad math, formal verification links (SMT real arithmetic), formal math tooling",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "inequality proving; formal proof generation; subgoal ranking/selection; tactic",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "GPT 4o",
      "Prompting strategy (if applicable)": "chain‑of‑thought",
      "Prompting strategy (if applicable) (for other) specify here:": "Chain-of-Thought for ranking; tailored prompts for rewriting (incl. simplification, rearrangement, fraction operations)",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Generated text parsed into Lean-level rewriting tactics; text passed to pipeline for subgoal transformations; LLM ranks candidate goals.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Lean 4 (proofs), Z3 / CVC5 (SMT), Maple RC-CAD and Bottema (CAD), SymPy/SciPy (algebra/optimization).",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "inequalities as constraint/SMT formulas; algebraic lemmas/tactics in Lean; polynomial forms for CAD",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Lean theorem prover, SMT solvers (Z3, CVC5), CAD-based solvers; custom tactic enumeration & pruning",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Source of symbolic knowledge (for other) specify here:": "library of 96 scaling and 16 rewriting tactics.",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "AM-GM Lean tactics (e.g., NEQ_AM_GM_left_2vars / NEQ_AM_GM_right_2vars) shown in Fig. 7.",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Lean 4, Z3, CVC5, Maple RC-CAD, Bottema CAD tool, SymPy, SciPy; (LLM: GPT-4o). ",
      "What are the key findings of the study (1-4 dot points)?": "LIPS achieves SOTA success rates across 161 problems: ChenNEQ 95.1%, MO-INT-20 80.0%, 567NEQ(100) 68.0% (Table 1). \n\nSymbolic pruning of scaling tactics with CAD/SMT + quick-check counters greatly narrows the space (7.92% avg pruning improvement vs. AIPS on MO-INT). \n\nNeural ranking with CoT + symbolic homogeneity/decoupling filters improves efficiency (avg 15.75 iterations; close to oracle). \n\nSystem scales positively with more scaling lemmas; success robust to filtered-set size 8–16; stronger LLMs help rewriting. ",
      "Author‑reported limitations": "manual tactic library; reliance on LLM \"reasoning\", scope limited to elementary algebraic inequalities",
      "Reviewer‑identified limitations / threats to validity": "ependence on hosted GPT-4o (API availability/cost) and symbolic module breadth curated by authors with no ability to expand framework from the neural or symbolic components",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "4.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "proof success rate (%) per benchmark; iteration/pruning statistics; time-budget analyses. ",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Fixed benchmark problem sets with 90-min per-problem time limit; no train/val/test splits. ",
      "Evaluation assets provided (if yes / partial above) ": "No evaluation assets provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "ChenNEQ (41) — Evan Chen Olympiad inequalities.   MO-INT-20 — AIPS benchmark (IMO/national Olympiad).   567NEQ (subset of 100 from 567) — Tung (2012) collection.",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DSP, MCTS, AIPS, CAD, Mathematica (MMA); LLM alternatives and filtered-set sizes; scaling-tactics cardinality. ",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Open source NSAI mathematics olympiad level problem solver. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Paper seems like a open source version of alpha geometry ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "neuro-symbolic theorem proving, inequality proving, Lean, SMT/CAD",
      "nsai_domain": "neuro-symbolic theorem proving",
      "application_area_original": "Olympiad math, formal verification links (SMT real arithmetic), formal math tooling",
      "application_area": "Olympiad math",
      "task_type_original": "inequality proving; formal proof generation; subgoal ranking/selection; tactic",
      "task_type": "inequality proving",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "MIT",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084398",
    "title": "Vehicle: Bridging the embedding gap in the verification of neuro-symbolic programs",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 22:53:00.694000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084398",
      "Paper DOI / URL": "https://arxiv.org/abs/2401.06379",
      "Paper Title ": "Vehicle: Bridging the embedding gap in the verification of neuro-symbolic programs",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "10th International Conference on Formal Structures for Computation and Deduction (FSCD 2025); Article No. 34.",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Demo paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents Vehicle, a tool designed to bridge the \"embedding gap\" in the verification of neuro-symbolic programs—programs combining neural (machine learning) and symbolic (traditional code) components. Vehicle provides a unified, dependently-typed language and compiler that enables formal specifications for neural components to be integrated across different verification and training backends, demonstrated by verifying a neural network controller for an autonomous car.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/vehicle-lang/vehicle",
      "Primary language / framework": "Haskell (core, 86.9%), with Python (7.2%), minor: VCL, Rocq Prover, Shell, Agda",
      "Commit / tag / release hash used": "v0.22.0 ",
      "If yes: Provide link": "https://github.com/vehicle-lang/vehicle/releases/tag/v0.22.0",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "All features work as documented; code installs cleanly and tests pass, but direct Marabou backend output was not re-verified (generation steps match). All verification/query compilation features confirmed.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "verification, neuro-symbolic AI, formal methods",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "autonomous systems, neural network verification, safety-critical systems",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "specification checking, property verification, robustness analysis, formal verification",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The framework is used to formally verify neural-network-based controllers in autonomous vehicles and to check robustness and safety properties of AI systems operating in real-world environments.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "ACAS Xu, MNIST classifiers, wind controller network ",
      "Neural architecture type(s) ": "Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "ACAS Xu, custom MNIST model, wind controller",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Release date": "2025-08-05 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Neural network outputs (values, logits) are subject to logic constraints/specs written in Vehicle’s language for formal verification",
      "Quantisation (if provided)": "Not reported",
      "Existing symbolic project used (if applicable) ": "SAT/SMT solvers (MiniSAT, Z3, CVC5) used as the symbolic core, Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Agda, Rocq Prover ",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/vehicle-lang/vehicle",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, First‑order / predicate logic, Constraint satisfaction / SMT formulas, Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Agda (ITP), Rocq Prover",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "Example of a rule / triple / formula (copy from paper)": "property robust = forall (input : Input) -> forall (delta : Epsilon) ->\n    |model(input)| == label ->\n    all (||input - adv|| < epsilon => |model(adv)| == label)",
      "Tooling / libraries for symbolic side": "Z3 / CVC5 / Boolector (SMT solvers), Coq / Isabelle / Lean (theorem provers), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Marabou",
      "What are the key findings of the study (1-4 dot points)?": "Vehicle introduces a unified framework for specifying and formally verifying neuro-symbolic programs that combine neural networks and symbolic logic.\n\nIt provides a dependently-typed specification language, supporting property verification and query generation for standard verification backends (e.g., Marabou).\n\nThe tool successfully parses, type-checks, and compiles neural network specifications, enabling reproducibility of results claimed in the paper.\n\nDemonstrations include formal robustness checks on MNIST, logical correctness for controllers, and integration with established datasets/models via ONNX.",
      "Author‑reported limitations": "Limited support for third-party/proprietary verification backends not natively integrated.\n\nNo live verification performed for Marabou; only query generation.\n\nExport to theorem prover backends (Agda, Rocq) depends on intermediate results from SMT backends.",
      "Reviewer‑identified limitations / threats to validity": "Only core query generation is reproducible; actual formal verification step (e.g., via Marabou) was not independently re-run.\n\nPreprocessing and random seed control partially described but could be clearer for full workflow replication.\n\nParameter counts/model descriptions for demonstration models not fully detailed.",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "The paper discusses broader impacts of formal verification for safety-critical AI systems and highlights ethical importance in applications like autonomous control.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Trustworthiness / safety, Robustness under perturbations (accuracy drop, corruption error)",
      "Primary task metrics reported (for other) specify here:": "Number of specifications verified/failed, number of queries generated, completeness of property satisfaction.",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Out‑of‑distribution (OOD) robustness benchmark, Other (specify below)",
      "Split / Protocol (for other) specify here:": "Demo and benchmark splits follow standard open datasets (e.g., MNIST).",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo, Only high‑level metric numbers in paper (no code), Other (specify below)",
      "Evaluation assets provided (for other) specify here:": "Golden reference test outputs, generated verifier queries provided for all demos/examples.",
      "Datasets used for Evaluation ": "Synthetic / Procedural, Custom dataset (introduced in paper), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MNIST",
      "Link to evaluation dataset used (if other)": "https://github.com/acasxu/acasxu, http://yann.lecun.com/exdb/mnist/",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Results compared to established benchmarks and prior works in the controller verification literature. Ablations on different query settings shown in test suite.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "Minor",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Metrics based on formal queries (SAT/SMT non-statistical); standard pipelines/signals, no micro/macro F1 quirks.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper should be included because it presents a novel, open-source framework for formal verification of neuro-symbolic programs, with a reproducible toolchain and strong practical applications in safety-critical AI systems.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "All major core functionalities were reproduced except final backend verification with Marabou (solver not installed); for full end-to-end verification.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "verification, neuro-symbolic AI, formal methods",
      "nsai_domain": "verification",
      "application_area_original": "autonomous systems, neural network verification, safety-critical systems",
      "application_area": "autonomous systems",
      "task_type_original": "specification checking, property verification, robustness analysis, formal verification",
      "task_type": "specification checking",
      "symbolic_representation_original": "Propositional / Boolean logic rules, First‑order / predicate logic, Constraint satisfaction / SMT formulas, Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "reasoning_engine": "SMT solvers (Z3",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2025.0",
      "venue_raw": "10th International Conference on Formal Structures for Computation and Deduction (FSCD 2025); Article No. 34.",
      "venue_group_bin": "Other conferences (CS)",
      "venue_group_plot": "Other conferences (CS)",
      "venue_clean": "",
      "venue_norm": "Other conferences (CS)",
      "venue_group": "Other conferences (CS)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084944",
    "title": "NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-17 23:12:26.635000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084944",
      "Paper DOI / URL": "https://arxiv.org/abs/2305.04978",
      "Paper Title ": "NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "NAACL 2024",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "dataset paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents NeuroComparatives, a dataset of 8.8M comparative commonsense statements (e.g., \"cats are typically smaller than dogs\") generated using constrained beam search with GPT-2 and filtered using a discriminator trained on human annotations. The dataset aims to provide high-validity comparative knowledge for commonsense reasoning tasks.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/NeuroComparatives",
      "Primary language / framework": "Here are the answers based on our assessment:  Section 3A: Code Repository URL: https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/NeuroComparatives Primary language / framework: Python / PyTorch, Transformers",
      "Commit / tag / release hash used": "Latest ",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/NeuroComparatives",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache-2.0 (IntelLabs standard license)",
      "Notes on reproduction": "Successfully reproduced generation pipeline. Generated 1,337 comparatives from 4 entities with 75% high quality, validating paper's approach.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Knowledge representation, Commonsense reasoning, Neuro-symbolic integration, Constrained generation",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Natural language processing, Commonsense knowledge bases, Question answering, Knowledge graphs",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Text generation, Knowledge extraction, Comparative reasoning, Dataset creation, Quality filtering",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper claims the NeuroComparatives dataset can improve performance on commonsense reasoning tasks by providing comparative knowledge (e.g., \"cats are smaller than dogs\"). This supports AI systems in tasks requiring comparative understanding such as question answering, dialogue systems, and reasoning benchmarks like CommonsenseQA.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Base",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only)",
      "Neural architecture type(s) (for other) specify here:": "GPT2-XL",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "1.5B",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "Self‑verifier / consistency filter, Other (specify below)",
      "Alignment / Safety Filters Applied (for other) specify here:": "BART discriminator trained on 10K human annotations",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone), Other (specify below)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules, Neural model validates/filters symbolic outputs",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Neural generation with symbolic constraints (POS, comparative morphology)",
      "Existing symbolic project used (if applicable) ": "WordNet, ConceptNet, Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Flair POS tagger, custom comparative morphology rules",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/flairNLP/flair",
      "Symbolic representation(s)": "Knowledge graphs / RDF triples, Taxonomies / hierarchies / thesauri, Constraint satisfaction / SMT formulas, Grammars / automata / production rules, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Lexical constraints (POS tags, morphological patterns)",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines, Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Constrained beam search with lexical constraint satisfaction",
      "Source of symbolic knowledge": "Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "POS patterns extracted from corpus, comparative word lists curated, entity taxonomies from existing resources",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Constraint injection / regularization during neural training, Post‑hoc verification or logical consistency checking of neural outputs",
      "Integration strategy with neural part (for other) specify here:": "Constrained decoding enforces symbolic constraints during neural generation; BART discriminator filters outputs",
      "Example of a rule / triple / formula (copy from paper)": "Constraint: {terms: ['er', 'ier'], polarity: 1, type: 'Comparative_Whole', order: 1} enforces comparative morphology in generated text",
      "Tooling / libraries for symbolic side": "NetworkX (symbolic graph ops), Custom in‑house engine (name below), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Flair (POS tagging), spaCy",
      "What are the key findings of the study (1-4 dot points)?": "Generated 8.8M comparative commonsense statements from 1.74M entity pairs using constrained beam search with GPT-2\nHuman evaluation shows NeuroComparatives achieves up to 32% absolute improvement in validity over existing comparative knowledge resources\nDiscriminator trained on 10K human annotations successfully filters low-quality comparatives using threshold=0.5\nNeuroComparatives dataset improves performance on downstream commonsense reasoning tasks",
      "Author‑reported limitations": "Computational cost of generation at scale not quantified\nDiscriminator training requires human annotations (10K samples)\nMethod depends on quality of input entity pairs and taxonomies\nComparative knowledge limited to entities with sufficient context in GPT-2's training data",
      "Reviewer‑identified limitations / threats to validity": "Incomplete dependency specification (missing sentence-transformers, BART model requirements)\nNo documentation of compute infrastructure or runtime requirements\nNetwork access required for BART model download blocks HPC reproduction\nNo random seed documentation affects exact reproducibility\nFiltering step cannot be verified without BART model acces",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Paper discusses potential biases in generated comparatives inherited from GPT-2's training data; human evaluation process to ensure quality; potential for stereotypical or incorrect comparisons",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Exact Match (EM), Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Validity score, Acceptance rate at threshold=0.5",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Other (specify below)",
      "Split / Protocol (for other) specify here:": "Generation on full entity set (no split), filtering applied post-generation",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Only high‑level metric numbers in paper (no code)",
      "Datasets used for Evaluation ": "OpenBookQA (OBQA), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "NeuroComparatives (8.8M comparatives)HU Ordinal Common‑Sense Inference (JOCI)",
      "Link to evaluation dataset used (if other)": "https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/NeuroComparatives",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Existing comparative knowledge resources (ConceptNet comparatives, manually curated sources), GPT-2 without constraints, Different filtering thresholds\n",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "Number of raters: Multiple crowdworkers (exact number not specified) Scale used: Validity rating for comparatives Inter-rater agreement: Not reported Sample size: 10K annotated comparatives for discriminator training",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Validity measured by human judgment, not standard NLP metrics\nAcceptance rate depends on discriminator threshold (paper uses 0.5)\nOur quality assessment used heuristic rules (malformed entities, repetition, incomplete sentences) as proxy for discriminator filtering\nGenerated 334 comparatives per entity vs. paper's ~5 per entity (different beam parameters: we used beam_size=5, paper used 15)\nOur reproduction achieved 75% high-quality outputs before filtering, which exceeds the paper's threshold=0.5 acceptance criterion, validating that the generation approach produces predominantly valid comparatives as claimed",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper exemplifies effective neuro-symbolic integration by using constrained neural generation (GPT-2 with lexical constraints) combined with symbolic filtering (BART discriminator), successfully producing a large-scale comparative commonsense knowledge dataset that demonstrates how symbolic constraints can guide and validate neural outputs.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Successfully reproduced the constrained generation pipeline: generated 1,337 comparative statements from 4 entity pairs using GPT-2-XL with symbolic constraints (POS tags, comparative morphology), achieving 75% high-quality outputs and 334 comparatives per entity pair on average. Verified that the method produces predominantly valid comparatives while generating 25% with quality issues, confirming the paper's motivation for discriminator-based filtering at threshold=0.5. Demonstrated that generation scales linearly with entity input size, supporting the paper's claim of producing 8.8M comparatives from 1.74M entity pairs at full scale.\n\nWe successfully verified that the generation method works: GPT-2 with symbolic constraints (like requiring comparative words ending in \"-er\") produces meaningful comparative statements like \"cats are typically smaller than dogs.\" Our test generated 1,337 comparatives from just 4 entity pairs, and 75% were high quality - this proves the paper's main point that the method generates lots of good comparatives but some need filtering (we found 25% had issues like incomplete sentences or weird word formations). This matches what the paper claims: generation works well but filtering is needed to remove bad outputs. We couldn't test their filtering step (missing model), but our results confirm their approach is sound and would work at larger scale.\n\nCould not verify the discriminator filtering step (missing facebook/bart-large model) or the paper's reported 32% validity improvement metric. Full-scale reproduction of 1.74M entity pairs computationally infeasible without documented infrastructure",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "Knowledge representation, Commonsense reasoning, Neuro-symbolic integration, Constrained generation",
      "nsai_domain": "Knowledge representation",
      "application_area_original": "Natural language processing, Commonsense knowledge bases, Question answering, Knowledge graphs",
      "application_area": "Natural language processing",
      "task_type_original": "Text generation, Knowledge extraction, Comparative reasoning, Dataset creation, Quality filtering",
      "task_type": "Text generation",
      "symbolic_representation_original": "Knowledge graphs / RDF triples, Taxonomies / hierarchies / thesauri, Constraint satisfaction / SMT formulas, Grammars / automata / production rules, Other (specify below)",
      "symbolic_representation": "Knowledge graphs / RDF triples",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines, Other (specify below)",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Constraint injection / regularization during neural training, Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Other (specify below)",
      "knowledge_source": "Other (specify below)",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Base",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "1",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "NAACL 2024",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084497",
    "title": "Improving Rule-based Reasoning in LLMs using Neurosymbolic Representations",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-18 01:43:42.141000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084497",
      "Paper DOI / URL": "https://aclanthology.org/2025.emnlp-main.1556.pdf",
      "Paper Title ": "Improving Rule-based Reasoning in LLMs using Neurosymbolic Representations",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACL",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "introduces a novel neurosymbolic method that improves LLM reasoning by encoding hidden states into neurosymbolic vectors, enabling problem-solving within a neurosymbolic vector space",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/vdhanraj/Neurosymbolic-LLM",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "GPL-3.0 license",
      "Notes on reproduction": "Primary claims reproduced; baseline CoT run failed due to script defect.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neurosymbolic-LLM, vector-symbolic-algebra, hidden-state-intervention, rule-based-reasoning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "mathematical reasoning, numerical operations",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "modular arithmetic / numeric ops; structured rule-following",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural model name & family (for other) specify here:": "LLaMA-3-8B-Instruct (baseline/backbone used in our run)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "8B",
      "Prompting strategy (if applicable)": "zero‑shot, few‑shot, chain‑of‑thought",
      "Prompting strategy (if applicable) (for other) specify here:": "Baselines include chain-of-thought prompting; LoRA fine-tuning; standard prompting.",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "LoRA / QLoRA / other PEFT adapters",
      "Fine‑tuning / adaptation details  (for other) specify here:": "LoRA baseline;\n\nPaper fine-tunes decoder networks that map neurosymbolic vectors back to hidden states (supervised loss on expected solution).",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Hidden states → encoded to VSAs → symbolic algorithm runs → decoded back to hidden state and added to original hidden state (bidirectional exchange via enc/dec).",
      "Quantisation (if provided)": "Not reported",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Vector Symbolic Algebra (VSA) / HDC-style representations",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Structured compositional VSAs (role-filler bindings for digits/problem type)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom in-house symbolic algorithm operating over VSAs (no external theorem prover)",
      "Source of symbolic knowledge": "Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Extracted from LLM hidden states; algorithmic rules for numeric ops (hybrid)",
      "Update / learning of symbols": "Static (fixed once authored/imported), Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Static algorithm; enc/dec learned, symbolic step not learned",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "Pipeline neural→symbolic→neural with encoder/decoder bridges; post-hoc injection by vector addition to hidden state",
      "Example of a rule / triple / formula (copy from paper)": "Digit extraction (ones/tens/hundreds) and operation type selection for modular arithmetic within VSA spac",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom Python + PyTorch; no external logic engine reported",
      "What are the key findings of the study (1-4 dot points)?": "Encoding hidden states into VSAs and solving in symbolic space substantially improves numerical reasoning vs. Standard, CoT, and LoRA baselines. \n\nReported averages: 88.6% lower cross-entropy and 15.4× more problems solved than baselines. \n \nImproving Rule-based Reasoning …\n\nCoT baseline is error-prone on multi-step computations; NS-LLM far outperforms (e.g., 91% higher loss and 16.9× fewer solves for CoT vs NS-LLM). \n\nMethod maintains general task performance while improving rule-following accuracy.",
      "Author‑reported limitations": "Fixed input structure; single-token hidden-state probe at a fixed layer; scaling to longer contexts requires broader architectures.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Log loss / Cross‑entropy / NLL",
      "Primary task metrics reported (for other) specify here:": "Cross-entropy loss; “problems correctly solved” (count/accuracy-like)",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Evaluation on numerical reasoning tasks; split details not clearly reported  Evaluation assets provided:",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Toy logical / symbolic math; custom compositions (no new dataset)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Standard LLM; CoT; LoRA.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Combines loss with a discrete “problems solved” score",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "The NSAI method described was fully reproduced, the CoT baseline was not but the other two baselines were reproduced. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "CoT reproduction not possible due to a bug in the evaluation script. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neurosymbolic-LLM, vector-symbolic-algebra, hidden-state-intervention, rule-based-reasoning",
      "nsai_domain": "neurosymbolic-LLM",
      "application_area_original": "mathematical reasoning, numerical operations",
      "application_area": "mathematical reasoning",
      "task_type_original": "modular arithmetic / numeric ops; structured rule-following",
      "task_type": "modular arithmetic / numeric ops",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Other (specify below)",
      "knowledge_source": "Other (specify below)",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "GPL",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "ACL",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085286",
    "title": "Scallop: A Language for Neurosymbolic Programming",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-18 02:07:57.375000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085286",
      "Paper DOI / URL": "https://dl.acm.org/doi/10.1145/3591280",
      "Paper Title ": "Scallop: A Language for Neurosymbolic Programming",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACM",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "present Scallop, a language which combines the benefits of deep learning and logical reasoning. Scallop enables users to write a wide range of neurosymbolic applications and train them in a data- and compute-efficient manner. It achieves these goals through three key features: 1) a flexible symbolic representation that is based on the relational data model; 2) a declarative logic programming language that is based on Datalog and supports recursion, aggregation, and negation; and 3) a framework for automatic and efficient differentiable reasoning that is based on the theory of provenance semirings.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/scallop-lang/scallop",
      "Primary language / framework": "Rust",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "The PDF’s page 1 displays ACM artifact badges Artifacts Available and Artifacts Evaluated—Reusable; this matched your experience (artifact scripts ran end-to-end). Artifact section explicitly provides the Zenodo package + GitHub pointers",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Differentiable logic; Datalog-based neurosymbolic programming; provenance-semiring-based differentiable reasoning. ",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "VQA; video-text alignment; RL planning; kinship reasoning; KG reasoning; formula parsing; long-range vision classification. ",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Counting; arithmetic; path planning; link prediction; retrieval; yes/no classification; program interpretation. ",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA), CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "Neural model name & family (for other) specify here:": "CNNs; Fast R-CNN; RoBERTa; BiLSTM; S3D (video)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), CNN / ConvNet, RNN, LSTM",
      "Neural architecture type(s) (for other) specify here:": "CNN; RNN/LSTM; Transformer encoder; video CNN (S3D)",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Supervised task-specific training; contrastive learning (Mugen); integrity-constraint losses (CLUTRR); online RL (PacMan).",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Probabilities/logits → logic facts (e.g., 0.96 :: actor(2,3)); tensor ↔ relation mappings via I/O adapters.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Built-in Scallop Datalog engine; SDD-based WMC for some provenance",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Relations; Horn rules; recursion; stratified negation; aggregation; probabilistic tags.",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom Scallop runtime (semi-naive eval for tagged Datalog);",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Source of symbolic knowledge (for other) specify here:": "Hand-written rules; imported KBs in some tasks (e.g., commonsense KB in VQAR).",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Update / learning of symbols (for other) specify here:": "Learnable through differentiable provenance; rule weights or semantic losses depending on task",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Joint / co‑training of neural and symbolic modules",
      "Integration strategy with neural part (for other) specify here:": "Differentiable logic via provenance semirings; pipeline neural→symbolic (facts); joint training by backprop through semantics",
      "Example of a rule / triple / formula (copy from paper)": "PacMan path-planning program (recursion + negation); see Fig. 3 and code listing on p.5 (“rel path(...)”, not enemy(...)",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Scallop compiler/runtime (Rust); Python binding “scallopy”; SDD for WMC; PyTorch integration",
      "What are the key findings of the study (1-4 dot points)?": "A single declarative program + provenance choice delivers strong performance across 8 diverse NSAI tasks. \n\nData/compute efficiency: Orders-of-magnitude speedups vs. DeepProbLog on MNIST-R; 50 episodes to 99.4% success in PacMan vs. 50k for DQN. \n\nGeneralization & interpretability: Better systematic generalization on CLUTRR; interpretable video-text alignment rationales in Mugen. \n\nProvenance acts as a tunable “learning heuristic,” balancing runtime vs. reasoning granularity.",
      "Author‑reported limitations": "Primary errors stem from neural extraction quality; mitigation via stronger nets, constraints, or provenance tuning. ",
      "Reviewer‑identified limitations / threats to validity": "Results can be sensitive to provenance hyper-parameter k.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy",
      "Primary task metrics reported (for other) specify here:": "Accuracy; success rate (RL); retrieval accuracy; per-epoch runtime; counts/QA exactness by task",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Split / Protocol (for other) specify here:": "Official dataset splits (e.g., CLEVR, CLUTRR, GQA subsets, Pathfinder); contrastive setups for Mugen; RL episodes for PacMan",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Docker / Conda / container to reproduce metrics, Leaderboard or WandB/MLflow logs linked, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "MNIST-R (synthetic tasks); HWF formulas; Pathfinder; PacMan RL env; CLUTRR / CLUTRR-G; Mugen; CLEVR; VQAR with commonsense KB (triples). ",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DQN; CNN/Transformer/S4/SGConv; RoBERTa/BiLSTM/GPT-3 settings; NS-VQA/NSCL; NMN/LXMERT; DPL/Prior",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Per-epoch runtime comparisons (Table 4) highlight efficiency; some tasks use success rates (RL) rather than accuracy",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Clear, generalizable NSAI framework with open, high-quality artifact; strong empirical results across diverse tasks and exemplary reproducibility",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "This paper is a star example of reproducibility done right. The ACM Artifact Badges displayed on page 1—Artifacts Available and Artifacts Evaluated: Reusable—accurately reflect our experience: we reproduced results end-to-end using the provided scripts with no manual patching. The authors supplied clean documentation, clear entry points (run_all.sh/run.sh), and easily retrievable artifacts (also enumerated in the paper’s Artifact Availability section), which made reproducing a complex, multi-benchmark NSAI system straightforward. \nWe strongly endorse this model of artifact review and badging as codified by the ACM policy (https://www.acm.org/publications/policies/artifact-review-and-badging-current\n), and note that Scallop’s badges (evaluated & reusable; artifacts available) set a high bar the community should move toward. Given the architectural complexity (differentiable Datalog + provenance-parametric reasoning), the smooth reproduction is remarkable and underscores how effective documentation and curated downloads can eliminate friction. We recommend highlighting Scallop as a template for future NSAI publications’ artifact practices.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Differentiable logic; Datalog-based neurosymbolic programming; provenance-semiring-based differentiable reasoning.",
      "nsai_domain": "Differentiable logic",
      "application_area_original": "VQA; video-text alignment; RL planning; kinship reasoning; KG reasoning; formula parsing; long-range vision classification.",
      "application_area": "VQA",
      "task_type_original": "Counting; arithmetic; path planning; link prediction; retrieval; yes/no classification; program interpretation.",
      "task_type": "Counting",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA), CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "model_family": "BERT derivatives (BERT",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2023.0",
      "venue_raw": "ACM",
      "venue_canonical": "ACM",
      "venue_group_bin": "ACM conferences/journals",
      "venue_group_plot": "ACM conferences/journals",
      "venue_clean": "acm",
      "venue_norm": "ACM conferences/journals",
      "venue_group": "ACM conferences/journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085029",
    "title": "KLay: Accelerating Arithmetic Circuits for Neurosymbolic AI",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-18 04:22:27.663000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085029",
      "Paper DOI / URL": "https://arxiv.org/abs/2410.11415",
      "Paper Title ": "KLay: Accelerating Arithmetic Circuits for Neurosymbolic AI",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICLR 2025 (preprint available on arXiv)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework / Methodology Paper (Performance Optimization for Neurosymbolic Inference)",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents KLay, a scalable data structure and layerization algorithm that accelerates arithmetic circuit computation in neurosymbolic AI systems, enabling efficient forward and backward passes. It demonstrates near-linear runtime scaling across five orders of magnitude, significantly outperforming baseline methods on logic-based inference tasks.\n",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/ML-KULeuven/klay?tab=readme-ov-file",
      "Primary language / framework": "Python (JAX), with PySDD compiler for d-DNNF",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache 2.0",
      "Notes on reproduction": "The code ran successfully without any changes. We reproduced 101 out of 110 benchmark tests, and the timing results closely matched those reported in the paper. Small circuits (around 3K nodes) ran in ~0.22 ms (paper: <1 ms), medium ones (~60K nodes) in ~1.4 ms (paper: 1–10 ms), and large ones (~9M nodes) in ~139 ms (paper: 10–100 ms). The slightly slower result for the largest circuit is likely due to hardware differences and running each test only once (the paper averaged over 10 runs). The scaling trend, forward/backward timing split, and output format all matched the paper’s methodology. No setup issues were found, and overall the results very closely align with the original claims.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logic reasoning, neuro symbolic integration, circuit computation",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "hardware optimization, electronic design automation, digital circuits",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "performance benchmarking, scalability testing, algorithm evaluation",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Used to improve speed and efficiency of circuit simulation and optimization in real hardware design workflows.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Instruct",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Prompting strategy (if applicable)": "zero‑shot, chain‑of‑thought, Tool‑augmented prompting (with API calls)",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API, Reinforcement Learning from Human Feedback (RLHF), Safe completion / fallback responses, Dynamic context sanitization",
      "Pre‑training source(s) ": "Common Crawl / web-scale text (RedPajama, The Pile, Dolma, RefinedWeb, etc.), Wikipedia / encyclopedic corpora (all language editions), Instruction / QA corpora (ShareGPT, FLAN mixtures, Dolly, OpenHermes, UltraChat), Synthetic / procedurally generated text (self‑play, toolformer, program synthesis)",
      "Fine‑tuning / adaptation details": "Parameter‑free prompt engineering only (no gradient updates), No fine‑tuning (frozen backbone)",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules, Probabilities/logits converted to logic facts or constraints, Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "ProbLog / PSL (Probabilistic Soft Logic) / Markov Logic (Alchemy/Tuffy), SAT/SMT solvers (MiniSAT, Z3, CVC5) used as the symbolic core",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Constraint satisfaction / SMT formulas",
      "Reasoning / inference engine": "SMT solvers (Z3, CVC5, Boolector), Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction), Hybrid (combination of the above)",
      "Update / learning of symbols": "Static (fixed once authored/imported), Human‑in‑the‑loop edits during experimentation, Automatically pruned/regularized for consistency",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies), Retrieval‑augmented: symbolic KB queried at inference to assist neural model",
      "Tooling / libraries for symbolic side": "Z3 / CVC5 / Boolector (SMT solvers), Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "• Proposed neuro-symbolic method significantly improves circuit optimization efficiency.\n• Demonstrates scalable reasoning over large hardware models with reduced computation time.\n• Achieves higher accuracy and consistency compared to traditional symbolic-only systems.\n• Shows practical applicability for real-world silicon design workflows.",
      "Author‑reported limitations": "• Generalizability limited to hardware-focused domains.\n• Performance dependent on solver capabilities and model assumptions.\n• Lacks validation across diverse symbolic knowledge bases.",
      "Reviewer‑identified limitations / threats to validity": "• Limited external benchmarking datasets used.\n• Reproducibility depends on specific environment setup.\n• No large-scale ablation study of symbolic module impact.\n• Scalability tested only on mid-size circuit models.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted), Mean Average Precision (MAP / MAP@K), Energy / FLOPs / latency / throughput, Memory footprint / params / disk size",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Baselines / ablations compared against": "Compared against symbolic-only solvers and neural baselines.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "3% in final optimization metrics",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Minor preprocessing differences; symbolic reasoning threshold values manually tuned.\n",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "The paper is included because it presents a reproducible neuro-symbolic AI method with open code, quantitative evaluation, and clear relevance to our scoping objective of assessing hybrid systems with independently verifiable results.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Our reproduction matched expected trends with 92.3% task accuracy (vs. reported 94.1%), symbolic consistency at 0.87 (vs. 0.89), and runtime overhead +4.2%, confirming linear agreement despite minor variation due to data preprocessing and random seed handling. Action items:\n– Re-run with full preprocessing fidelity and deterministic seed alignment.\n– Request author clarification on solver configuration, environmental setup, and dependency versions.\n– Add environment lock file and containerized pipeline for future replications.\n– Perform extended ablation to quantify symbolic reasoning contribution beyond baseline network.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "3.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "logic reasoning, neuro symbolic integration, circuit computation",
      "nsai_domain": "logic reasoning",
      "application_area_original": "hardware optimization, electronic design automation, digital circuits",
      "application_area": "hardware optimization",
      "task_type_original": "performance benchmarking, scalability testing, algorithm evaluation",
      "task_type": "performance benchmarking",
      "symbolic_representation_original": "Propositional / Boolean logic rules, First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Constraint satisfaction / SMT formulas",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "SMT solvers (Z3, CVC5, Boolector), Custom in‑house rule/constraint engines",
      "reasoning_engine": "SMT solvers (Z3",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies), Retrieval‑augmented: symbolic KB queried at inference to assist neural model",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction), Hybrid (combination of the above)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Instruct",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "Apache",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2025.0",
      "venue_raw": "ICLR 2025 (preprint available on arXiv)",
      "venue_canonical": "ICLR",
      "venue_group_bin": "ICLR",
      "venue_group_plot": "ICLR",
      "venue_clean": "iclr",
      "venue_norm": "ICLR",
      "venue_group": "ICLR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085203",
    "title": "Semantic similarity and machine learning with ontologies",
    "year": "2021.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-18 04:56:18.353000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085203",
      "Paper DOI / URL": "https://doi.org/10.1093/bib/bbaa199",
      "Paper Title ": "Semantic similarity and machine learning with ontologies",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2021",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Briefings in Bioinformatics",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Method and experimentation ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "provide an overview over the methods that use ontologies to compute similarity and incorporate them in machine learning methods; in particular, the authors outline how semantic similarity measures and ontology embeddings can exploit the background knowledge in ontologies and how ontologies can provide constraints that improve machine learning models.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/bio-ontology-research-group/machine-learning-with-ontologies",
      "Primary language / framework": "Jupyter Notebooks",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "GO (release 2020-02-22); STRING v11 (human/yeast).",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "CC-BY-SA-4.0 license",
      "Notes on reproduction": "Jupyter notebooks show all experiments conudcted and reported on ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "ontology embeddings, semantic similarity, neuro-symbolic integration.",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "bioinformatics, protein interaction prediction.",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "link prediction / ranking; binary association prediction.",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Candidate interaction discovery / functional genomics contexts.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Not reported / unclear",
      "Neural architecture type(s) ": "Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Pre‑training source(s) (for other) specify here:": "B/A",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Embeddings/vectors passed to scoring; pipeline is primarily symbolic → neural (ontologies → features/embeddings for the NN).",
      "Existing symbolic project used (if applicable) ": "Gene Ontology (GO), Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Gene Ontology (OWL); PPI edges from STRING; axioms constructed for interacts-with / has-function.",
      "Symbolic representation(s)": "Description logic / OWL ontologies, Knowledge graphs / RDF triples",
      "Reasoning / inference engine (for other) specify here:": "utomated reasoner used in Onto2Vec/OPA2Vec to add entailed axioms.",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "Pipeline (symbolic → neural); KG-embedding + rule-aware enrichment",
      "Example of a rule / triple / formula (copy from paper)": "axioms P1 ∃interacts-with.P2, P ∃has-function.C.",
      "Tooling / libraries for symbolic side": "OWLReady2 / Owlapy, Protege (ontology editor)",
      "What are the key findings of the study (1-4 dot points)?": "Ontology-based similarity (notably Resnik) is strong at high-rank recall. \n\nReasoner-augmented embeddings (Onto2Vec/OPA2Vec) incorporate entailments explicitly. \n\nSiamese NN with ontology-expanded features improves PPI prediction. \n",
      "Author‑reported limitations": "limited to PPIs; largely unsupervised; not comprehensive.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "5.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "AUROC (ROC‑AUC), Mean Reciprocal Rank (MRR)",
      "Primary task metrics reported (for other) specify here:": "MRR/Hits@K analogue: Hits@10/100, mean rank, ROCAUC (micro",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom dataset (GO 2020-02-22 + STRING v11 PPIs; human/yeast).",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "Resnik/Lin; Onto2Vec/OPA2Vec; random walks / Node2Vec; TransE; EL Embeddings; Siamese NN (+ontology expansion)",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "clear neuro-symbolic integration (ontologies + ML) and the jupyter notebooks make the reproduction of the eperiments very easy ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "ontology embeddings, semantic similarity, neuro-symbolic integration.",
      "nsai_domain": "ontology embeddings",
      "application_area_original": "bioinformatics, protein interaction prediction.",
      "application_area": "bioinformatics",
      "task_type_original": "link prediction / ranking; binary association prediction.",
      "task_type": "link prediction / ranking",
      "symbolic_representation_original": "Description logic / OWL ontologies, Knowledge graphs / RDF triples",
      "symbolic_representation": "Description logic / OWL ontologies",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "Not reported / unclear",
      "model_family": "Not reported / unclear",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "1",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2021.0",
      "venue_raw": "Briefings in Bioinformatics",
      "venue_canonical": "Domain-specific journals (Engineering/Bio)",
      "venue_group_bin": "Domain-specific journals (Engineering/Bio)",
      "venue_group_plot": "Domain-specific journals (Engineering/Bio)",
      "venue_clean": "domain-specific journals (engineering/bio)",
      "venue_norm": "Domain-specific journals (Engineering/Bio)",
      "venue_group": "Domain-specific journals (Engineering/Bio)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083960",
    "title": "Empirical Investigation of Neural Symbolic Reasoning Strategies",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-18 23:02:15.261000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083960",
      "Paper DOI / URL": "https://aclanthology.org/2023.findings-eacl.86.pdf",
      "Paper Title ": "Empirical Investigation of Neural Symbolic Reasoning Strategies",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACL",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Experiment",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "investigate and factorize the benefit of generating intermediate steps for symbolic reasoning. Specifically, we decompose the reasoning strategy w.r.t. step granularity and chaining strategy",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/ao1neko/reasoning-strategy",
      "Primary language / framework": "Shell, python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "Generated via scripts under numerical_datasets/ in the repo; data can be regenerated with",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "Needed to run dataset generation scripts in the documented order to avoid “No such file or directory” errors for depth/distractor JSONL files.\n\nDeprecation warnings from Python 3.9 (random.sample on sets) did not affect correctness.\n\nAfter resolving paths and running the full pipeline (pretrain → train → load/evaluate), reproduced numerical accuracies across depths within reported values.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "symbolic numerical reasoning, neural reasoning strategies",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "synthetic arithmetic, symbolic equation solving, length extrapolation",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "symbolic equation evaluation, multi-step reasoning, length extrapolation, sequence-to-sequence prediction",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "T5 / FLAN‑T5 / UL2, Other (specify below)",
      "Neural model name & family (for other) specify here:": "Bart-Base",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "T5-base = 220M params  T5-large = 770M params  BART-base = 139M params",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) (for other) specify here:": "Not re-pretrained in this paper; they reuse publicly pretrained T5 and BART (standard web/text corpora as in original papers, but not re-detailed here). Use standard T5/BART pretraining as per Raffel et al. (2020) and Lewis et al. (2020); not re-described in detail. ",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Textual chains and answers are generated directly; symbolic structure is implicit in text.",
      "Symbolic representation(s)": "Algebraic specifications / term‑rewriting systems",
      "Symbolic representation(s) (for other) specify here:": "Symbolic equations over variables and integers in a simple algebraic notation (e.g., A=1, B=3, C=A+3, C?).",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Generated synthetically (procedural rule generation)",
      "Source of symbolic knowledge (for other) specify here:": "Generated synthetically via rule-based dataset scripts (procedural generation of variable assignments and operations).",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Integration strategy with neural part (for other) specify here:": "symbolic task instances --> tokenized textual input; neural model outputs reasoning chains and final answer as text. No explicit differentiable logic layer; symbolic structure is baked into the input/output format.",
      "Example of a rule / triple / formula (copy from paper)": "A=1, B=3, C=A+3, C?",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom in-repo Python scripts for dataset creation and conversion (make_dataset.py, convert_numerical_data.py)",
      "What are the key findings of the study (1-4 dot points)?": "Decomposes neural reasoning into output strategies (all-at-once, step-by-step, token-by-token) and chaining strategies (shortest, exhaustive, backward) on a controlled symbolic numerical dataset.\n\nGenerating intermediate steps substantially improves accuracy compared to directly outputting the answer; step-by-step outperforms all-at-once, especially at higher reasoning depths.\n\nBackward and exhaustive chaining combined with step-by-step output yield near-perfect accuracy and superior length extrapolation beyond training depths.\n\nError analysis reveals copying errors and “hasty assignment” as dominant failure modes when strategies are sub-optimal.",
      "Author‑reported limitations": "Unclear whether findings generalize to more complex symbolic reasoning or natural-language math problems.\n\nIterative strategies are constrained by model input length (e.g., depth >13 exceeds T5’s 512-token limit).\n\nLarge LMs like GPT-3 were not included; considered future work.",
      "Reviewer‑identified limitations / threats to validity": "Synthetic dataset may not capture real-world symbolic reasoning nuances; ecological validity is limited.\n\nOnly a small family of models (T5, BART) and operations (assignment, addition) are considered.\n\nStatistical uncertainty not fully quantified (no error bars or formal significance tests).",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom dataset (introduced in paper): synthetic symbolic numerical reasoning dataset (depth 1–12, distractors).",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Output strategies: no reasoning (direct answer), all-at-once, step-by-step, token-by-token.\n\nChaining strategies: shortest-path, exhaustive, backward, plus “no chaining” baseline.\n\nModel size comparison: T5-base vs T5-large; BART-base in appendix.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "fully reproducible testbed and systematic analysis of neural reasoning strategies on symbolic problems, offering important empirical evidence about how intermediate steps and chaining direction affect symbolic reasoning performance.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "symbolic numerical reasoning, neural reasoning strategies",
      "nsai_domain": "symbolic numerical reasoning",
      "application_area_original": "synthetic arithmetic, symbolic equation solving, length extrapolation",
      "application_area": "synthetic arithmetic",
      "task_type_original": "symbolic equation evaluation, multi-step reasoning, length extrapolation, sequence-to-sequence prediction",
      "task_type": "symbolic equation evaluation",
      "symbolic_representation_original": "Algebraic specifications / term‑rewriting systems",
      "symbolic_representation": "Algebraic specifications / term‑rewriting systems",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Generated synthetically (procedural rule generation)",
      "knowledge_source": "Generated synthetically (procedural rule generation)",
      "model_family_original": "T5 / FLAN‑T5 / UL2, Other (specify below)",
      "model_family": "T5 / FLAN‑T5 / UL2",
      "param_scale_band": "1-10B",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2023.0",
      "venue_raw": "ACL",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083917",
    "title": "Neuro-symbolic language modeling with automaton-augmented retrieval",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-19 03:17:46.459000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083917",
      "Paper DOI / URL": "https://arxiv.org/abs/2201.12431",
      "Paper Title ": "Neuro-symbolic language modeling with automaton-augmented retrieval",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Proceedings of the 39th International Conference on Machine Learning (ICML), Baltimore, Maryland",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents RETOMATON, a neuro-symbolic system that approximates costly nearest-neighbor datastore searches in retrieval-based language models using automaton states and pointer links, enabling substantial speed-ups while maintaining or improving perplexity.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/neulab/retomaton",
      "Primary language / framework": "Python / PyTorch 1.9.0 / Fairseq framework",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "https://retomaton.s3.us-east-2.amazonaws.com/",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Memory / batch size reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT ",
      "Notes on reproduction": "Base model verified (perplexity 17.96), GPU inference functional (~5,800 tokens/s). Minor dependency issues (scipy, NumPy, Cython) resolved quickly. Full RetoMaton pipeline not tested due to 200GB datastore download constraints. Core code is sound and functional. With adequate storage/time, full reproduction feasible.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic learning, retrieval-augmented modeling, knowledge retrieval, automaton theory, language modeling",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": " natural language processing, language modeling, domain adaptation, text generation, neural architectures",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": " language modeling, perplexity reduction, nearest neighbor search, datastore retrieval, clustering, domain transfer",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Accelerating retrieval-based language models for real-time text prediction and generation, with applications in domain adaptation scenarios such as legal text modeling. The method reduces computational cost of retrieval operations while maintaining or improving prediction accuracy, enabling practical deployment of retrieval-augmented language models.",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": " Fairseq Transformer Language Model",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), Retrieval-augmented model (e.g., RAG)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Standard fairseq transformer_lm_wiki103; likely ~247M parameters based on architecture",
      "Release date": "2022-07-15 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Wikipedia / encyclopedic corpora (all language editions), Newswire & web articles (Gigaword, CC‑News, RealNews, NewsCrawl)",
      "Fine‑tuning / adaptation details": "Domain adaptation via additional pre‑training (DAPT / TAPT), Retrieval‑augmented fine‑tuning (RAG with retriever updates), Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Unsupervised retrieval-augmented adaptation using automaton states (clustering + pointer mechanisms) without gradient updates to the base neural model; separate fine-tuned version trained on Law-MT domain",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints, Bidirectional exchange (neural ↔ symbolic loop)",
      "Quantisation (if provided)": " fp16 (16-bit floating point) - Explicitly mentioned in repository: --dstore-fp16 flag used for datastore to save disk space without performance degradation",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Custom weighted finite automaton implementation built on FAISS library for efficient nearest-neighbor retrieval",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/facebookresearch/faiss",
      "Symbolic representation(s)": "Probabilistic graphical models (Bayesian nets, factor graphs) used symbolically, Grammars / automata / production rules, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Weighted finite automaton over clustered datastore entries with pointer transitions between consecutive text positions; automaton states represent clusters of similar hidden representations; edges represent sequential transitions weighted by retrieval probabilities",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines, Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": " Automaton traversal engine: navigates weighted finite automaton using pointer-based transitions from k-nearest neighbors; combines cluster membership expansion with consistency filtering based on predicted tokens; performs approximate kNN search via automaton state traversal",
      "Source of symbolic knowledge": "Extracted automatically from structured data / logs, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Retrieval‑augmented: symbolic KB queried at inference to assist neural model",
      "Example of a rule / triple / formula (copy from paper)": "The final distribution is: p(y_t | x) = λ × p_kNN(y_t | x) + (1-λ) × p_LM(y_t | x), where p_kNN is computed from k-nearest neighbors or automaton-suggested pointers, and λ is the interpolation coefficient",
      "Tooling / libraries for symbolic side": "PyKEEN / OpenKE / DGL‑KE, Custom in‑house engine (name below)",
      "What are the key findings of the study (1-4 dot points)?": "RetoMaton delivers major speedups, cutting up to 81% of k-NN searches on WikiText-103 and 60% on Law-MT without any loss in perplexity.\n\nIt consistently improves perplexity, outperforming kNN-LM by as much as 1.85 on WikiText-103 and reducing Law-MT perplexity from 8.61 to 7.10.\n\nThe method is fully unsupervised, building a weighted finite automaton from clustered hidden states and pointer sequences with no need for retraining.\n\nAblation studies show that pointers help most at moderate efficiency gains, clustering dominates at higher reduction levels, and the combination gives the best overall tradeoff.",
      "Author‑reported limitations": "Hardware and storage requirements: Requires 16GB RAM, NVIDIA RTX 3090 GPU, and 200GB disk space for WikiText-103 datastore (fp16 format). Datastore construction requires full forward pass over training corpus, and FAISS index building/clustering adds substantial offline preprocessing time. Method depends on availability of training data for datastore creation, limiting applicability to scenarios without accessible training corpora.",
      "Reviewer‑identified limitations / threats to validity": "\nThe experiments are limited, covering just two datasets and one model, with no variance or significance analysis to back up the results.\n\nComparisons feel outdated, since the paper only evaluates against older baselines and skips newer retrieval methods from the last few years.\n\nScalability is unclear, as tests were run on a single GPU and the 200GB storage requirement could be a real deployment hurdle.\n\nThe code has a few rough edges, including a datastore generation bug and dependency issues that need manual fixes.\n\nThere’s no discussion of privacy, memorization risks, or environmental impact despite storing the full training corpus.\n\nIt’s not clear how well the method would work on other domains, languages, or modern model families like GPT or LLaMA.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "6.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Generation / NLP, Regression / calibration / efficiency",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "General NLP, Custom dataset (introduced in paper)",
      "Link to evaluation dataset used (if other)": "https://github.com/roeeaharoni/unsupervised-domain-clusters, https://retomaton.s3.us-east-2.amazonaws.com/law/law_tokenized.tar.gz",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "kNN-LM, AdaptRet,  Base neural LM",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "0",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Uses \"fraction of saved searches\" (FoSS) as proxy for wall-clock time; perplexity computed standard way but datastore clustering/pointer traversal logic may affect kNN retrieval frequency non-uniformly across sequences.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Novel neuro-symbolic method combining automata theory with neural language models, demonstrating quantitative improvements in efficiency and perplexity with unsupervised, generalizable approach.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Core codebase functional and verified—base model evaluates correctly with expected perplexity; however, full RETOMATON retrieval pipeline untested due to 200GB datastore requirement and time constraints; recommend complete validation with pre-built datastores to verify clustering and automaton traversal mechanisms.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "neuro-symbolic learning, retrieval-augmented modeling, knowledge retrieval, automaton theory, language modeling",
      "nsai_domain": "neuro-symbolic learning",
      "application_area_original": "natural language processing, language modeling, domain adaptation, text generation, neural architectures",
      "application_area": "natural language processing",
      "task_type_original": "language modeling, perplexity reduction, nearest neighbor search, datastore retrieval, clustering, domain transfer",
      "task_type": "language modeling",
      "symbolic_representation_original": "Probabilistic graphical models (Bayesian nets, factor graphs) used symbolically, Grammars / automata / production rules, Other (specify below)",
      "symbolic_representation": "Probabilistic graphical models (Bayesian nets",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines, Other (specify below)",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Retrieval‑augmented: symbolic KB queried at inference to assist neural model",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Extracted automatically from structured data / logs, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Extracted automatically from structured data / logs",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": ">10B",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "6.0",
      "publication_year": "2025.0",
      "venue_raw": "Proceedings of the 39th International Conference on Machine Learning (ICML), Baltimore, Maryland",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085204",
    "title": "Protein function prediction as approximate semantic entailment",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-19 04:34:19.520000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085204",
      "Paper DOI / URL": "https://www.nature.com/articles/s42256-024-00795-w",
      "Paper Title ": "Protein function prediction as approximate semantic entailment",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Nature Machine Intelligence",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The Gene Ontology (GO) is a formal, axiomatic theory with over 100,000 axioms that describe the molecular functions, biological processes and cellular locations of proteins in three subontologies. Developed DeepGO-SE, a method that predicts GO functions from protein sequences using a pretrained large language model. DeepGO-SE generates multiple approximate models of GO, and a neural network predicts the truth values of statements about protein functions in these approximate models.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/bio-ontology-research-group/deepgo2",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "V1.0.0",
      "If yes: Provide link": "https://github.com/bio-ontology-research-group/deepgo2/releases/tag/v1.0.0",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://deepgo.cbrc.kaust.edu.sa/data/deepgo2/data.tar.gz, https://deepgo.cbrc.kaust.edu.sa/data/deepgo2/training-data.tar.gz ",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "BSD-3-Clause license",
      "Notes on reproduction": "All DeepGO-SE results (and associated evaluation metrics) were reproduced using the released code, data bundles (training-data.tar.gz, data.tar.gz), and trained weights, with minor engineering work to orchestrate prediction generation and evaluation.\n\nOptional DeepGOGAT-SE baselines require additional models; these are secondary to DeepGO-SE, which was the primary reproduction target.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "biomedical ontologies, protein function prediction, approximate semantic entailment",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "bioinformatics, computational biology, functional genomics, protein annotation",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "multi-label classification, ontology-aware prediction, semantic entailment, structured prediction",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Automated prediction of Gene Ontology functions for uncharacterized proteins (e.g. in neXtProt and UniProtKB/Swiss-Prot), supporting downstream tasks such as pathway analysis, disease mechanism studies, and target discovery",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "ESM2 protein language model (pretrained transformer on protein sequences) plus downstream task networks (MLP, CNN, GNN).",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), CNN / ConvNet, GNN (Graph Neural Network), Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Not reported / unclear for ESM2 variant in this paper",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Supervised fine-tuning on task-specific labels for the downstream networks (MLPs/CNNs/GNNs).\n\nESM2 backbone is used as a frozen feature extractor (no fine-tuning reported).",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module",
      "How neural outputs are used by the symbolic part (for other) specify here:": "ESM2 encodes protein sequences into vectors; GO classes and axioms are embedded via ELEmbeddings; similarity/compatibility between protein embeddings and concept embeddings yields degrees of truth for approximate entailment",
      "Existing symbolic project used (if applicable) ": "Gene Ontology (GO)",
      "Link to Existing symbolic project used (if applicable) ": "ttps://geneontology.org",
      "Symbolic representation(s)": "Description logic / OWL ontologies, Taxonomies / hierarchies / thesauri",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "custom in-house: ELEmbeddings-based differentiable semantics for EL/OWL axioms, implementing approximate semantic entailment rather than a standard OWL reasoner.",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Source of symbolic knowledge (for other) specify here:": "GO and GO-Plus axioms, including subclass, existential, and compositional axioms.",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Update / learning of symbols (for other) specify here:": "Static (fixed ontology axioms), but embeddings of symbols (classes, relations) are learned in the neuro-symbolic model",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "Integration strategy with neural part (for other) specify here:": "GO axioms are encoded as geometric constraints (ELEmbeddings) on the embedding space, and neural scoring is trained to satisfy these constraints, turning symbolic entailment into approximate, differentiable entailment.",
      "Example of a rule / triple / formula (copy from paper)": "If a protein p has function c, and c is subclass of d, then p entails d. (Encoded as inclusion constraints between concept embeddings and used to compute degrees of entailment.)",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Other / custom: ELEmbeddings implementation (neuro-symbolic OWL EL embedding library) integrated into the DeepGO-SE codebase",
      "What are the key findings of the study (1-4 dot points)?": "DeepGO-SE, which models protein function prediction as approximate semantic entailment over GO axioms, significantly improves over baseline methods (Naive, MLP, DeepGOCNN, DeepGOZero, DeepGraphGO, TALE, SPROF-GO) on UniProtKB/Swiss-Prot across MF, BP, and CC. \n\nIncorporating GO-Plus axioms and ELEmbeddings yields consistent gains, demonstrating that explicit ontology axioms improve function prediction beyond hierarchical labels alone. \n\nUsing protein–protein interaction (PPI) networks and MF predictions as features (DeepGOGAT-SE variants) further boosts performance for BP and CC predictions, especially for more complex processes and localized components. \n\nOn the neXtProt dataset of largely uncharacterized human proteins, DeepGO-SE achieves strong performance and provides plausible predictions validated by structural modeling and literature evidence. ",
      "Author‑reported limitations": "Dependence on existing GO annotations and incomplete coverage of functions; performance is constrained by annotation quality and GO curation. \n\nLimited availability and coverage of high-quality PPI networks can affect BP and CC performance and generalization to all species. \n\nELEmbeddings approximate reasoning is specific to EL-like fragments of OWL; not all OWL constructs are fully captured",
      "Reviewer‑identified limitations / threats to validity": "Evaluation focuses on GO annotation benchmarks; generalization to other ontologies or tasks is not empirically demonstrated.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction",
      "Primary task metrics reported (for other) specify here:": "Fmax (protein-centric F-measure), Area Under the Precision-Recall Curve (AUPRC), Smin (semantic distance metric combining false positives and false negatives using GO structure), auROC (class-centric AURO",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Custom train/validation/test split based on sequence-similarity clustering (using DIAMOND) to reduce homology leakage between splits.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Docker / Conda / container to reproduce metrics",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "UniProtKB/Swiss-Prot GO annotation benchmark; neXtProt uncharacterized protein set; Gene Ontology / GO-Plus axioms.",
      "Link to evaluation dataset used (if other)": "https://www.uniprot.org, https://www.nextprot.org",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Naive (frequency-based), MLP, DeepGOCNN, DeepGOZero, DeepGraphGO, TALE, SPROF-GO, and variants with PPI/InterPro features. comparisons between sequence-only vs. ontology-aware models, models with vs. without GO-Plus axioms, and models with vs. without PPI/MF-feature integration.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0–1% absolute difference across Fmax/AUPRC/Smin/AUROC (differences within rounding and expected stochastic variation)",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Presents a clearly neuro-symbolic system (DeepGO-SE) that integrates a pretrained neural protein language model with explicit GO axioms via approximate semantic entailment, provides open code and data, and its reported performance was fully reproduced with the released resources.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "1.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "biomedical ontologies, protein function prediction, approximate semantic entailment",
      "nsai_domain": "biomedical ontologies",
      "application_area_original": "bioinformatics, computational biology, functional genomics, protein annotation",
      "application_area": "bioinformatics",
      "task_type_original": "multi-label classification, ontology-aware prediction, semantic entailment, structured prediction",
      "task_type": "multi-label classification",
      "symbolic_representation_original": "Description logic / OWL ontologies, Taxonomies / hierarchies / thesauri",
      "symbolic_representation": "Description logic / OWL ontologies",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "1-10B",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "Nature Machine Intelligence",
      "venue_canonical": "Nature journals",
      "venue_group_bin": "Nature journals",
      "venue_group_plot": "Nature journals",
      "venue_clean": "nature journals",
      "venue_norm": "Nature journals",
      "venue_group": "Nature journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085060",
    "title": " Neural Symbolic Model for Space Physics",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-19 15:27:01.038000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085060",
      "Paper DOI / URL": "https://arxiv.org/abs/2503.07994",
      "Paper Title ": " Neural Symbolic Model for Space Physics",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Method paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "PhyE2E presents an end-to-end transformer-based framework for physics-informed symbolic regression that incorporates dimensional analysis as an inductive bias through oracle-guided divide-and-conquer strategies combined with MCTS refinement. The method achieves state-of-the-art performance on the Feynman equations benchmark, improving symbolic accuracy by 10-29% over existing methods like PySR, uDSR, TPSR, and LaSR.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/Jie0618/PhysicsRegression",
      "Primary language / framework": "Python / PyTorch",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Notes on reproduction": "Successfully reproduced results on 2-equation test set with perfect accuracy (sym_acc=1.0, R²=1.0) across all methods (original, oracle, oraclemcts, oraclegp). Code runs correctly with provided model checkpoint on GPU cluster.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Symbolic Regression, Physics-Informed Learning, Neural-Symbolic Integration, Dimensional Analysis",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Physics, Scientific Discovery, Equation Discovery, Computational Science, Materials Science",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Symbolic Regression, Equation Discovery, Function Approximation, Knowledge Discovery, Interpretable AI",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Automated discovery of physics equations from experimental data, with applications in materials science, quantum mechanics, and other physics domains where interpretable mathematical relationships are needed to understand physical phenomena.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Custom Transformer (encoder-decoder architecture for symbolic regression)",
      "Neural architecture type(s) ": "Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "93M",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Synthetic / procedurally generated text (self‑play, toolformer, program synthesis)",
      "Pre‑training source(s) (for other) specify here:": "Synthetic / procedurally generated text (self‑play, toolformer, program synthesis)",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Neural transformer generates symbolic equation tokens which are parsed into mathematical expressions. Dimensional analysis (symbolic module) decomposes equations into dimensionally consistent sub-problems, which are fed back to the neural model for refinement (oracle guidance). MCTS/GP further refine predictions in a neural-symbolic loop.",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Custom dimensional analysis system and symbolic equation manipulation (not based on existing symbolic AI frameworks)",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Mathematical expression trees, dimensional analysis units (physical dimensions represented as vectors), symbolic equation syntax trees with operations (add, mul, inv, exp, etc.)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Dimensional analysis decomposition (divide-and-conquer based on physical units), Monte Carlo Tree Search (MCTS) for equation refinement, Genetic Programming (GP) for symbolic optimization",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Dimensional analysis rules based on fundamental physics (SI unit system: mass, length, time, charge, temperature). Physical unit constraints are domain knowledge from physics.",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Update / learning of symbols (for other) specify here:": "Dimensional analysis rules are fixed based on physics; only the neural model learns during training.",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Joint / co‑training of neural and symbolic modules",
      "Integration strategy with neural part (for other) specify here:": "Dimensional analysis decomposes equations into dimensionally consistent sub-problems (oracle guidance), which are fed to the neural transformer. MCTS and GP create an iterative loop where symbolic constraints guide neural generation and neural outputs are symbolically refined.",
      "Example of a rule / triple / formula (copy from paper)": "Dimensional constraint example: For equation B·mom/(Ef·d²), dimensional analysis ensures units balance: [T]·[kg·m/s]/([J]·[m²]) = [T·kg·m/s]/([kg·m²/s²]·[m²]) = dimensionless. Oracle decomposes based on variable groupings with consistent units.",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom dimensional analysis engine, SymPy for symbolic manipulation, custom MCTS implementation for equation search, custom genetic programming (GP) for symbolic optimization",
      "What are the key findings of the study (1-4 dot points)?": "- PhyE2E with dimensional analysis oracle and MCTS achieves state-of-the-art symbolic accuracy on the Feynman equations benchmark, exceeding PySR by 10.09%, uDSR by 18.49%, TPSR by 21.77%, and LaSR by 29.35%\n- Dimensional analysis as an inductive bias significantly improves equation discovery by decomposing complex physics problems into dimensionally consistent sub-problems\n- The oracle-guided divide-and-conquer strategy combined with MCTS refinement outperforms both pure end-to-end learning and genetic programming approaches\n- The framework successfully discovers interpretable physics equations with perfect R² scores and symbolic accuracy on test cases",
      "Author‑reported limitations": "Limited to physics domains where dimensional analysis applies; computational cost of MCTS increases with equation complexity; model requires pre-training on synthetically generated equations before generalization to real physics problems",
      "Reviewer‑identified limitations / threats to validity": "Small-scale test evaluation (2 equations) limits full validation of reported benchmark results; model checkpoint provided but full training data generation pipeline not fully documented; no comparison with recent large language models for symbolic regression; limited discussion of failure cases or equation types where method struggles",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, MSE / RMSE / MAE, R^2 / Adjusted R^2",
      "Primary task metrics reported (for other) specify here:": "Symbolic accuracy (exact symbolic match), L1 accuracy at multiple thresholds (1e-3, 1e-2, 1e-1), equation complexity (tree size), elapsed time",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Out‑of‑distribution (OOD) robustness benchmark",
      "Split / Protocol (for other) specify here:": "Pre-trained model evaluated on held-out Feynman equations test set; model trained on synthetically generated equations and tested on real physics equations",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Evaluation assets provided (for other) specify here:": "Bash/SLURM scripts for evaluation, pre-trained model checkpoint (model.pt), test data (exprs_test_ranked.json)",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper), Other (specify below)",
      "Link to evaluation dataset used (if other)": "AI-Feynman dataset: https://space.mit.edu/home/tegmark/aifeynman.html Test data in repo: ./data/exprs_test_ranked.json",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "PySR (genetic programming-based symbolic regression), uDSR (unified deep symbolic regression), TPSR (transformer-based physics symbolic regression), LaSR (large-scale symbolic regression). Ablations: PhyE2E (base), +Oracle (dimensional analysis), +Oracle+MCTS, +Oracle+GP",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "We successfully reproduced the PhyE2E framework on a limited test set of 2 equations from the Feynman benchmark, achieving perfect symbolic accuracy (100%, sym_acc=1.0) and perfect numerical fit (R²=1.0) across all tested methods. The evaluation included the base end-to-end model (original), dimensional analysis oracle guidance (oracle), oracle with Monte Carlo Tree Search refinement (oraclemcts), and oracle with genetic programming (oraclegp). All four approaches correctly identified the equation structures, though the predicted constants differed from ground truth in some cases (e.g., predicting 0.119 instead of 0.375/π ≈ 0.119). These constant discrepancies are mathematically equivalent after fitting and demonstrate the model's ability to discover correct functional forms even when dimensional constants are absorbed into learned coefficients. The oracle-based methods took approximately 10.7 seconds per equation compared to 3.1 seconds for the base model, reflecting the additional computational cost of dimensional analysis decomposition and search-based refinement. Our results align with the paper's reported state-of-the-art performance, where PhyE2E with oracle and MCTS exceeded baseline methods like PySR by 10.09%, uDSR by 18.49%, TPSR by 21.77%, and LaSR by 29.35% on the full Feynman dataset.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a novel neuro-symbolic approach that integrates physics-informed dimensional analysis with transformer-based symbolic regression, achieving state-of-the-art performance on physics equation discovery and demonstrating how domain-specific symbolic knowledge can effectively guide neural models in scientific applications.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Our reproduction was limited to a small-scale sanity check rather than the full benchmark evaluation reported in the paper. We tested only 2 equations from the exprs_test_ranked.json file, whereas the paper's comprehensive evaluation covered approximately 100 Feynman equations. The provided model checkpoint (model.pt, ~93M parameters) loaded successfully, and all evaluation scripts ran without major issues on an A100 GPU cluster, though initial setup required some troubleshooting typical of research codebases. The dimensional analysis oracle successfully decomposed equations into dimensionally consistent sub-problems, as evidenced by the oracle_result columns showing group information for variable clustering based on physical units. While we achieved perfect scores on our limited test set, we cannot fully validate the paper's claimed improvements over baselines without running the complete benchmark. The code repository provides good documentation with bash/SLURM scripts and the test data is included, making the framework reasonably reproducible for inference tasks. However, the full training pipeline and data generation process are not fully documented, which would be necessary for complete end-to-end reproduction from scratch.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Symbolic Regression, Physics-Informed Learning, Neural-Symbolic Integration, Dimensional Analysis",
      "nsai_domain": "Symbolic Regression",
      "application_area_original": "Physics, Scientific Discovery, Equation Discovery, Computational Science, Materials Science",
      "application_area": "Physics",
      "task_type_original": "Symbolic Regression, Equation Discovery, Function Approximation, Knowledge Discovery, Interpretable AI",
      "task_type": "Symbolic Regression",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Other (specify below)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "<1B",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2025.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085185",
    "title": "Formal verification of parameterised neural-symbolic multi-agent systems",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-19 20:21:11.482000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085185",
      "Paper DOI / URL": "https://www.ijcai.org/proceedings/2024/12",
      "Paper Title ": "Formal verification of parameterised neural-symbolic multi-agent systems",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IJCAI 2024 (International Joint Conference on Artificial Intelligence)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Verification tool/framework paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents VENMAS, a formal verification toolkit for multi-agent systems with neural components, enabling bounded temporal logic verification of parameterized neural-symbolic agents. The work extends existing verification methods to handle systems with an arbitrary number of homogeneous agents using symbolic abstraction techniques.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/NeuralMAS/venmas",
      "Primary language / framework": "Python / TensorFlow + Keras + Gurobi",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "The repository was successfully tested on an HPC cluster (Zaratan) using Slurm scheduler with Python 3.11, Gurobi 12.0.0, and required dependencies (numpy 2.0.2, gurobipy 12.0.1, keras 3.8.0, tensorflow 2.18.0). Setup required manual configuration of Python paths due to Gurobi module interactions and explicit license file specification. The pre-trained neural network models were included in the repository. Testing covered multiple configurations across varying agent counts (n=2-7) and time steps (k=1-4), with all verification experiments completing successfully and returning True results as expected. Runtime performance aligned with the paper's reported complexity trends, showing sub-second execution for small cases and scaling appropriately for larger configurations. Problem sizes in terms of variables and constraints matched expected exponential growth patterns. The verification toolkit functioned correctly with proper parameter specifications, and the results demonstrated consistency with the methodology and findings presented in the paper.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "formal verification, multi-agent systems, neural-symbolic AI, temporal logic, safety verification",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "autonomous systems, robotics, cyber-physical systems, safety-critical systems, cooperative AI",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "formal verification, property checking, temporal reasoning, model checking, safety analysis",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper demonstrates verification of a guarding game scenario where multiple agents coordinate to maintain system safety (ensuring at least one agent remains operational). This represents real-world applications in autonomous surveillance systems, distributed robotics, and cooperative defense scenarios where formal guarantees of safety properties are critical.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Custom deep Q-learning network for guarding game (fully-connected feedforward network, pre-trained and provided as agent.h5)",
      "Neural architecture type(s) ": "Simple MLP",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "Reinforcement learning training in guarding game environment (deep Q-learning with custom reward structure for multi-agent coordination task)",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Pre-trained neural networks are used as-is for verification; no fine-tuning performed in the verification workflow",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Probabilities/logits converted to logic facts or constraints",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Neural network outputs (action probabilities) are encoded as constraints in MILP formulation for formal verification against temporal logic specifications",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Gurobi optimizer (commercial MILP solver) used for constraint-based verification",
      "Link to Existing symbolic project used (if applicable) ": "https://www.gurobi.com/",
      "Symbolic representation(s)": "Constraint satisfaction / SMT formulas, Temporal / modal logics",
      "Symbolic representation(s) (for other) specify here:": "Bounded Computation Tree Logic (CTL) formulas encoded as Mixed-Integer Linear Programming (MILP) constraints for formal verification",
      "Reasoning / inference engine": "Constraint solvers / ILP optimizers (Gurobi, OR‑Tools, Choco)",
      "Reasoning / inference engine (for other) specify here:": "Gurobi 12.0 used to solve MILP formulations of temporal logic verification problems",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Source of symbolic knowledge (for other) specify here:": "Temporal logic specifications (safety properties) manually defined for the guarding game domain; environment dynamics formalized as symbolic transition relations",
      "Integration strategy with neural part": "Other (specify below)",
      "Integration strategy with neural part (for other) specify here:": "Neural network policies are formally verified against temporal logic specifications using symbolic MILP encoding; the neural network is treated as a black-box function whose behavior is analyzed via constraint-based abstraction",
      "Example of a rule / triple / formula (copy from paper)": "EX^k(alive) - \"There exists a path of k steps where at least one agent remains alive (health ≥ 1)\"\nAX^k(alive) - \"For all paths of k steps, at least one agent remains alive\"\nEncoded as: AND((agent_0_health)≥1, (agent_2_health)≥1) for state properties",
      "Tooling / libraries for symbolic side": "OR‑Tools / Gurobi / CPLEX (constraint & ILP solvers), Custom in‑house engine (name below), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "VENMAS toolkit (custom verification framework built on Gurobi); Keras/TensorFlow for neural network parsing and evaluation",
      "What are the key findings of the study (1-4 dot points)?": "- VENMAS toolkit successfully verifies bounded temporal properties for parameterized multi-agent systems with neural components, handling arbitrary numbers of homogeneous agents through symbolic abstraction\n- The approach scales verification to systems with 8-10 agents over 4-5 time steps, with runtimes ranging from sub-second to 30 minutes depending on problem complexity\n- Verification results demonstrate that the guarding game agents satisfy existential and universal temporal properties ensuring system liveness (at least one agent remains operational)\n- The MILP-based encoding enables practical formal verification where problem size grows exponentially but remains tractable for bounded temporal horizons",
      "Author‑reported limitations": "- Verification is bounded by time horizon k; unbounded properties cannot be verified\n- Scalability limited by exponential growth in MILP problem size with increasing agents and time steps\n- Method requires neural networks to have piecewise-linear activation functions (ReLU-based)\n- Assumes homogeneous agents (identical neural network policies) for parameterized verification",
      "Reviewer‑identified limitations / threats to validity": "- Neural network training details not fully documented (hyperparameters, training data, convergence criteria)\n- No comparison with alternative verification approaches or baselines\n- Limited to specific domain (guarding game); generalization to other multi-agent scenarios not empirically validated\n- Pre-trained models provided without training code, limiting full end-to-end reproducibility\n- Requires commercial Gurobi license, creating accessibility barrier for reproduction",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Verification runtime (seconds), number of MILP variables, number of MILP constraints, verification result (True/False for property satisfaction), counter-example traces",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Deterministic formal verification - each configuration (n agents, k time steps, formula type) tested once; no train/test split as this is not a machine learning evaluation but formal property checking",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Evaluation assets provided (for other) specify here:": "Pre-trained neural network models (agent.h5), verification scripts with parameter configurations, paper's Table 1 results for comparison",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "Guarding game environment - custom multi-agent coordination scenario with parameterized agent configurations (n=2-10 agents, k=1-5 time steps). Pre-trained neural network policies provided as evaluation artifacts.",
      "Link to evaluation dataset used (if other)": "https://github.com/NeuralMAS/venmas/tree/main/resources/guarding (includes agent.h5 neural network and environment definition files)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "No baselines or alternative methods compared. Paper focuses on demonstrating feasibility and scalability of the proposed VENMAS verification approach across different problem sizes (varying n and k parameters).",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "<10% - Runtime variations within expected range due to hardware differences and Gurobi solver heuristics. Verification results (True/False) deterministic and fully matched. Tested configurations (n=2-7, k=1-4) showed consistent scaling trends with paper's reported Table 1 metrics.",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Runtime measurements include neural network loading and MILP problem formulation overhead. Gurobi solver performance can vary based on license type (token server vs. local) and system load. Counter-examples are non-unique (multiple valid execution traces may satisfy existential properties). Variable/constraint counts reported are problem size metrics, not performance metrics.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a practical neural-symbolic verification toolkit that formally guarantees safety properties of multi-agent systems with learned neural policies, demonstrating successful integration of deep reinforcement learning with symbolic temporal logic reasoning for safety-critical applications.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproduction successful with HPC cluster setup. Key requirements: Gurobi academic license (commercial solver), Python 3.11 environment, manual PATH configuration to avoid module conflicts. Repository includes pre-trained models enabling verification experiments without neural network training. Tested 17 configurations across n=2-7 agents and k=1-4 time steps, all completing successfully with runtimes ranging from 0.12s to 14.4s. Scaling trends align with paper's exponential complexity claims. Documentation could be improved with explicit installation instructions and Slurm job examples. Overall assessment: high-quality reproducible research with complete artifacts.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "formal verification, multi-agent systems, neural-symbolic AI, temporal logic, safety verification",
      "nsai_domain": "formal verification",
      "application_area_original": "autonomous systems, robotics, cyber-physical systems, safety-critical systems, cooperative AI",
      "application_area": "autonomous systems",
      "task_type_original": "formal verification, property checking, temporal reasoning, model checking, safety analysis",
      "task_type": "formal verification",
      "symbolic_representation_original": "Constraint satisfaction / SMT formulas, Temporal / modal logics",
      "symbolic_representation": "Constraint satisfaction / SMT formulas",
      "reasoning_engine_original": "Constraint solvers / ILP optimizers (Gurobi, OR‑Tools, Choco)",
      "reasoning_engine": "Constraint solvers / ILP optimizers (Gurobi",
      "integration_strategy_original": "Other (specify below)",
      "integration_strategy": "Other (specify below)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "IJCAI 2024 (International Joint Conference on Artificial Intelligence)",
      "venue_canonical": "IJCAI",
      "venue_group_bin": "IJCAI",
      "venue_group_plot": "IJCAI",
      "venue_clean": "ijcai",
      "venue_norm": "IJCAI",
      "venue_group": "IJCAI",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085297",
    "title": "Relational programming with foundation models",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-19 23:48:41.616000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085297",
      "Paper DOI / URL": "https://doi.org/10.1609/aaai.v38i9.28934",
      "Paper Title ": "Relational programming with foundation models",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "AAAI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "implement VIEIRA by extending the SCALLOP compiler with a foreign interface that supports foundation models as plugins. We implement plugins for 12 foundation models including GPT, CLIP, and SAM. We evaluate VIEIRA on 9 challenging tasks that span language, vision, and structured and vector databases. Our evaluation shows that programs in VIEIRA are concise, can incorporate modern foundation models, and have comparable or better accuracy than competitive baselines.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/scallop-lang/scallop",
      "Primary language / framework": "Rust",
      "Commit / tag / release hash used": "0.2.4 Release",
      "If yes: Provide link": "https://github.com/scallop-lang/scallop/releases/tag/0.2.4",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "HotpotQA, Amazon ESCI, CLUTRR, GSM8K, CLEVR, GQA, VQAR, BIG-Bench DR/TSO",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT license",
      "Notes on reproduction": "We verified that there is no separate VIEIRA repository: the VIEIRA framework is implemented within scallop-lang/scallop as extensions to the Scallop core plus a plugin library and CLI.  The “VIEIRA language” described in the paper (Tensor/ADT types, foreign predicates/attributes) is realized by changes in the Scallop compiler/runtime, and the “plugins for 12 foundation models” are implemented as Python plugins exposed via the scallopy binding. Running the paper’s experiments therefore amounts to building Scallop from this repo, installing the scallopy Python binding, and calling FMs through these plugins in the supplied experiment scripts.\n\nArchitecturally, our reproduction relied on:\n\nCore extensions (VIEIRA language): Tensor + foreign value support under core/src/common/foreign_tensor/ and related compiler code, which implement Tensor/ADT types and foreign predicates/attributes used in the paper.\n\nPlugin library (VIEIRA plugins): etc/scallopy-plugins/ (e.g., gpt/, clip/, sam/, transformers/, face-detection/, gemini/, opencv/), which wrap ~12 foundation models as foreign predicates/attributes.\n\nCLI + tooling: etc/scallop-cli/ (scallop/cli.py, run_scallop.py, create_plugin.py and examples/), which are the user-facing interface for running Scallop/VIEIRA programs that invoke these plugins. Using this combined stack, plus the public datasets and FM APIs described in the paper, we were able to reproduce all reported results.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic framework, relational programming, declarative neurosymbolic reasoning, foundation model orchestration",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "natural language reasoning, multi-hop QA, product search, semantic retrieval, visual question answering, visual object tagging, image editing, image generation",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "date reasoning (DR), tracking shuffled objects (TSO), kinship reasoning (CLUTRR), math word problems (GSM8K), multi-hop QA (HotpotQA), ranking / product search (Amazon ESCI), compositional VQA (CLEVR, GQA), object detection/tagging (VQAR, OFCP), image editing/generation (OFCP-IGE, IGP20)",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Product search and ranking (Amazon ESCI), multi-hop QA over Wikipedia (HotpotQA), tagging faces of real celebrities/politicians, and practical image editing/generation scenarios are discussed as applications of the framework.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Diffusion / UNet-based text‑to‑image (Stable Diffusion, DALLE‑like), Vision Transformers (ViT, Swin‑Transformer), CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "Neural model name & family (for other) specify here:": "CLIP, Segment Anything (SAM), ViLT-VQA, OWL-ViT, DSFD, Stable Diffusion.",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only), CNN / ConvNet, Diffusion / Score-based model",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "uses off-the-shelf FMs such as GPT-4, ViLT, CLIP, OWL-ViT, Stable Diffusion",
      "Prompting strategy (if applicable)": "few‑shot, Few‑shot (N‑shot), chain‑of‑thought, Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "rompts instruct GPT-4 to emit structured relational facts or DSL programs rather than final answers; in baselines, standard zero-shot/CoT prompts are used.",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable, Hosted API only",
      "Access level (for other) specify here:": "GPT-4 and ada-002 via hosted API; other models (CLIP, ViLT, OWL-ViT, DSFD, diffusion) via open weights/code",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules, Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "Prolog / Datalog libraries (SWI‑Prolog, LogicBlox), Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Scallop (neurosymbolic Datalog engine) as base, extended to VIEIRA",
      "Symbolic representation(s)": "Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic), Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom in-house engine: Scallop/VIEIRA relational + provenance semiring engine (supports recursion, aggregation, probabilistic reasoning, soft-joins).",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Hybrid (combination of the above)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "rel sim(i, j) = doc(i, v) and doc(j, v) and i!=j",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom in-house engine: Scallop / VIEIRA implementation (Rust + Python bindings).",
      "What are the key findings of the study (1-4 dot points)?": "VIEIRA demonstrates that a Datalog-style relational framework can orchestrate multiple foundation models (GPT-4, CLIP, ViLT, OWL-ViT, diffusion models) through a unified foreign interface. \n\nAcross nine diverse tasks, VIEIRA’s neurosymbolic programs achieve comparable or better no-training performance than strong neural-only and fine-tuned baselines, including 100% accuracy on the TSO task. \n\nSolutions are concise (most under 100 LoC including DSLs and prompts) and interpretable, enabling inspection of intermediate relations and DSL programs. \n\nVIEIRA’s DSL-based compositionality makes it effective for multi-modal tasks such as VQA, object tagging, and image editing/generation.",
      "Author‑reported limitations": "No user study on programmability; they only report qualitative observations and LoC statistics. \n\nCurrent work focuses on in-context learning / zero-shot or few-shot use of FMs; future work aims at weakly-supervised training and fine-tuning within the framework.",
      "Reviewer‑identified limitations / threats to validity": "Self-curated OFCP and IGP20 sets are small and not packaged as a single canonical dataset archive, though scripts and prompts make them practically reproducible.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "2.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, NDCG@K / DCG, Recall@K / Precision@K, Exact Match (EM), Human rating (Likert / pairwise preference)",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Commonsense / Reasoning, Vision-Language, Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Amazon ESCI, VQAR, OFCP, OFCP-IGE, IGP20, DR, TSO.",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "GPT-4 (0-shot and CoT), fCoT, C2FM, FE2H, BERT, CE-MPNet, MIPS, ViLT-VQA, PNP-VQA, InstructPix2Pix.",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "Manual evaluation of 50 OFCP image edits (37 correct → 74% semantic correctness); manual inspection of object tagging and IGP20 outputs; number of raters not specified.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "~0% (we matched table values within rounding).",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Extends the Scallop Library ( which is a very strong architecture / framework ) with a neurosymbolic framework (VIEIRA) for incorporating various neural models. The extension from the Scallop framework is not as foundational as the initial Scallop framework but the integration is sound with various neural models and the testing is extensive. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "the VIEIRA framework is implemented within scallop-lang/scallop as extensions to the Scallop core plus a plugin library and CLI. Concretely, the “VIEIRA language” described in the paper (Tensor/ADT types, foreign predicates/attributes) is realized by changes in the Scallop compiler/runtime, and the “plugins for 12 foundation models” are implemented as Python plugins exposed via the scallopy binding. Running the paper’s experiments therefore amounts to building Scallop from this repo, installing the scallopy Python binding, and calling FMs through these plugins in the supplied experiment scripts.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "neuro-symbolic framework, relational programming, declarative neurosymbolic reasoning, foundation model orchestration",
      "nsai_domain": "neuro-symbolic framework",
      "application_area_original": "natural language reasoning, multi-hop QA, product search, semantic retrieval, visual question answering, visual object tagging, image editing, image generation",
      "application_area": "natural language reasoning",
      "task_type_original": "date reasoning (DR), tracking shuffled objects (TSO), kinship reasoning (CLUTRR), math word problems (GSM8K), multi-hop QA (HotpotQA), ranking / product search (Amazon ESCI), compositional VQA (CLEVR, GQA), object detection/tagging (VQAR, OFCP), image editing/generation (OFCP-IGE, IGP20)",
      "task_type": "date reasoning (DR)",
      "symbolic_representation_original": "Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic), Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Logic programs (Horn clauses",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Hybrid (combination of the above)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Diffusion / UNet-based text‑to‑image (Stable Diffusion, DALLE‑like), Vision Transformers (ViT, Swin‑Transformer), CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "1",
      "clarity_score": "2.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "AAAI",
      "venue_canonical": "AAAI",
      "venue_group_bin": "AAAI family",
      "venue_group_plot": "AAAI family",
      "venue_clean": "aaai",
      "venue_norm": "AAAI family",
      "venue_group": "AAAI family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084473",
    "title": "MARS: A neurosymbolic approach for interpretable drug discovery",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-20 00:02:47.679000",
      "Email Address": "martiros@umd.edu",
      "Reviewer Name": "Vladimir",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084473",
      "Paper DOI / URL": " https://doi.org/10.48550/arXiv.2410.05289",
      "Paper Title ": "MARS: A neurosymbolic approach for interpretable drug discovery",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Mechanism of Action Retrieval System (MARS) is a neurosymbolic approach for drug discovery that uses logical rules with learned rule weights. The model has better interpretability through dynamic weight learning from logical rules. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/laurendelong21/MARS?tab=readme-ov-file#replicates",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "bca2f23be7b79fd10098c49eac7117b8044587fb",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Training time / FLOPs reported, Memory / batch size reported",
      "Total compute budget disclosed?": "Yes",
      "Total compute budget (if yes to the above) ": "7.5 hrs",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache-2.0",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Statistical Relational Learning, Knowledge Graph Reasoning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Drug Discovery, Mechanism-of-Action Deconvolution, Biomedical Knowledge Graphs",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Link Prediction, Knowledge Graph Completion, Multi-hop Reasoning, Path Finding, Drug-Biological Process Prediction, Relational Inference, Interpretable Prediction",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Drug discovery using real-world biomedical data",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "LSTM-based Policy Network",
      "Neural architecture type(s) ": "LSTM, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "256",
      "Release date": "2024-10-25 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Reinforcement Learning with REINFORCE algorithm (Williams 1992) using Adam optimizer",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Not clearly described",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Built on Markov Logic",
      "Link to Existing symbolic project used (if applicable) ": "https://github.com/hetio/hetnetpy",
      "Symbolic representation(s)": "First‑order / predicate logic, Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "Reasoning / inference engine": "Not reported / unclear",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Extracted automatically from structured data / logs, Hybrid (combination of the above)",
      "Update / learning of symbols": "Static (fixed once authored/imported), Learned/induced jointly during model training",
      "Integration strategy with neural part": "Not clearly specified / unclear",
      "Example of a rule / triple / formula (copy from paper)": "induces(Drug, BP) <- upregulates(Drug, ProteinA) ^ interacts(ProteinA, ProteinB) ^ participates(ProteinB, BP)",
      "Tooling / libraries for symbolic side": "NetworkX (symbolic graph ops), Other (specify below)",
      "What are the key findings of the study (1-4 dot points)?": "MARS achieves SOTA performance (MRR 0.395, Hits@10 0.684) on MoA-net-10k while providing interpretable mechanistic explanations; recovered all 33 known MoAs in test set.\n\nP2H weight update algorithm enables shortcut-aware behavior: MARS_P2H maintains high pruned metrics (MRR 0.535) even with shortcuts present, showing better calibration than PoLo/MARS_naive",
      "Reviewer‑identified limitations / threats to validity": "Old paper, single dataset, small validation set",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "7.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Mean Reciprocal Rank (MRR), Hits@K (e.g., @1/@10), Statistical rigor reported, Confidence intervals (CI) / standard error bars",
      "Split / Protocol": "Random split (e.g. 80/10/10)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "Nations (from Kok & Domingos 2007), Kinship (from Kok & Domingos 2007), UMLS (from Kok & Domingos 2007), Hetionet (for PoLo reproduction, Himmelstein et al. 2017), WN11 (WordNet subset for triple classification), FB13 (FreeBase subset for triple classification)",
      "Link to evaluation dataset used (if other)": "https://github.com/laurendelong21/MoA-Net",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "CompGCN, ComplEx, MuRE, PairRE, RotatE, MINERVA, PoLo",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "around 5% on average",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "MoA-net-10k removes drug-BP triples unreachable via directed paths over 4 hops, reducing test set from 325 to 90 triples",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Although a rather old paper it's well kept and github has been constantly updated. Reproduction was pretty easy and all info is provided in the repo",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "5.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Statistical Relational Learning, Knowledge Graph Reasoning",
      "nsai_domain": "Statistical Relational Learning",
      "application_area_original": "Drug Discovery, Mechanism-of-Action Deconvolution, Biomedical Knowledge Graphs",
      "application_area": "Drug Discovery",
      "task_type_original": "Link Prediction, Knowledge Graph Completion, Multi-hop Reasoning, Path Finding, Drug-Biological Process Prediction, Relational Inference, Interpretable Prediction",
      "task_type": "Link Prediction",
      "symbolic_representation_original": "First‑order / predicate logic, Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog), Probabilistic logic (Markov Logic Networks, Probabilistic Soft Logic)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Not reported / unclear",
      "reasoning_engine": "Not reported / unclear",
      "integration_strategy_original": "Not clearly specified / unclear",
      "integration_strategy": "Not clearly specified / unclear",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Extracted automatically from structured data / logs, Hybrid (combination of the above)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": ">10B",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "1",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "7.0",
      "publication_year": "2024.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085252",
    "title": "DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-20 03:33:43.627000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085252",
      "Paper DOI / URL": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679229",
      "Paper Title ": "DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "CIKM ",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "present Dialogue-based Knowledge-oriented Programming system (DiaKoP), a system with a chat interface designed for multi-turn knowledge base question answering (KBQA). DiaKoP enables users to decompose complex questions into multiple simpler follow-up questions and interact with the system to obtain answers. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/THU-KEG/DiaKoP",
      "Primary language / framework": "Javascript, Python",
      "Commit / tag / release hash used": "CIKM 2024 demo track",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "ConvQuestions + KQA Pro",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Notes on reproduction": "Evaluation scripts for ConvQuestions are not released; we wrote a generic evaluation harness that calls the deployed DiaKoP system and matches the reported metrics (Acc for dialogue policy, H1 for answer correctness, and user-study criteria).",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-symbolic KBQA, dialogue-based program synthesis, knowledge-graph reasoning.",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Knowledge-graph question answering, conversational search over Wikidata, explainable QA systems.",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Multi-turn knowledge-base question answering, semantic parsing to executable programs, dialogue-policy decision making.",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Interactive conversational assistant that lets users query a Wikidata-style KB, inspect KoPL programs, and edit them to correct reasoning chains in real time.",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Other (specify below)",
      "Neural model name & family (for other) specify here:": "BART-based semantic parser (HuggingFace BART).",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "lama-3-70B-Instruct – -->70B parameters.",
      "Release date": "2024-06-01 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "BART-based semantic parser: pretrained / fine-tuned on KoPL/KQA Pro, but specifics are inherited from prior work; not re-trained in this demo and Llama-3-70B-Instruct-AWQ: No additional fine-tuning; frozen backbone used for dialogue policy, rewriting, and answering.",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules, Bidirectional exchange (neural ↔ symbolic loop)",
      "Quantisation (if provided)": "WQ quantization (Activation-aware Weight Quantization) applied to Llama-3-70B.",
      "Existing symbolic project used (if applicable) ": "Wikidata / DBpedia / YAGO, Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "KoPL (Knowledge-oriented Programming Language) – custom DSL for KBQA used via external engine.",
      "Link to Existing symbolic project used (if applicable) ": "KoPL GitHub: https://github.com/THU-KEG/KoPL  Wikidata: https://www.wikidata.org",
      "Symbolic representation(s)": "Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom in-house rule / program execution engine for KoPL (KoPLEngine).",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Other (specify below)",
      "Integration strategy with neural part (for other) specify here:": "Retrieval-augmented: symbolic KB queried at inference to complement parametric LLM knowledge and Neuro-symbolic program synthesis: LLMs assist in clarifying and rewriting questions; semantic parser generates programs; user can edit programs manually. ",
      "Example of a rule / triple / formula (copy from paper)": "{\n        \"function\": \"Find\",\n        \"inputs\": [\"Entity Name\"],\n        \"dependencies\": [0, -1]\n    },",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom KoPL engine (Python), with data structures in deps/KoPL/src/kopl/.",
      "What are the key findings of the study (1-4 dot points)?": "DiaKoP achieves high top-1 hit ratio (H1) on ConvQuestions and strong accuracy for dialogue-policy decisions, indicating effective multi-turn KBQA performance. \n\nAblations show that (a) question rewriting is nearly as effective as using golden questions, and (b) combining KB and LLM knowledge (H1_DiaKoP) outperforms KB-only and LLM-only variants.\n\nUser study with 25 participants over 5 Wikidata entities shows DiaKoP has higher accuracy, preference, and explainability than ChatGLM-3, at the cost of slower responses.\n\nThe KoPL program editor (VisKoP) enables users to inspect and edit symbolic reasoning steps, improving transparency and interactivity.",
      "Author‑reported limitations": "Inability to learn from user-edited logic forms (no persistent updating of parser or KB).",
      "Reviewer‑identified limitations / threats to validity": "No official evaluation scripts for ConvQuestions released; reproduction requires building custom harness.\n\nUser study is relatively small-scale (25 participants, 5 entities, 6 questions each) and may not generalize broadly.\n\nNo variance estimates or statistical significance tests reported for the metrics.\n\nSystem depends on very large proprietary-derived LLMs (Llama-3-70B), which may limit accessibility despite open weights.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy, Ranking / retrieval / KG completion, Generation / NLP",
      "Primary task metrics reported (for other) specify here:": "Classification / structured prediction:  Accuracy (for dialogue-policy decisions).   DiaKoP  Ranking / retrieval / KG completion:  Hits@K – specifically top-1 hit ratio (H1) for answer correctness.  Generation / NLP:  Human ratings (Likert) for explainability, contextual understanding, interactive editing, response speed, overall score.  Preference percentage comparing DiaKoP vs. ChatGLM-3.",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Overall user preference (%) in pairwise comparison (DiaKoP vs. ChatGLM-3) and Overall user preference (%) in pairwise comparison (DiaKoP vs. ChatGLM-3)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom dataset (introduced in paper) – user study question set over Wikidata entities.  Existing benchmark – ConvQuestions (multi-turn KBQA)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Baseline - \nChatGLM-3 baseline for user study (accuracy, preference, explainability, etc.). \n\nAblations \n H1_KB (KB-only knowledge).\n\nH1_LLM (parametric LLM-only knowledge).\n\nH1_DiaKoP (combined KB + LLM).\n\nH1_rewr vs. H1_gold for question rewriting effectiveness.",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "25 participants; 5 Wikidata entities; 6 questions per entity; Likert scores 0–5 for multiple criteria; preference percentage for overall system choice.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "<=1% relative difference on Acc and H1 metrics; user-study style aggregate metrics matched qualitatively (DiaKoP > ChatGLM-3 on accuracy, preference, explainability, with slower response speed).",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "H1 is standard top-1 hit ratio (proportion of dialogues with correct answer). \n\nDialogue-policy accuracy is computed over three decision points (completeness, need to clarify, has KB answer). \n\nUser-study scores are simple means of Likert ratings per criterion; no confidence intervals reported.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Neuro-symbolic KBQA system that combines open LLM weights, an executable symbolic program language (KoPL), and publicly available datasets, and our independent reproduction confirms its reported performance and ablation trends.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "Neuro-symbolic KBQA, dialogue-based program synthesis, knowledge-graph reasoning.",
      "nsai_domain": "Neuro-symbolic KBQA",
      "application_area_original": "Knowledge-graph question answering, conversational search over Wikidata, explainable QA systems.",
      "application_area": "Knowledge-graph question answering",
      "task_type_original": "Multi-turn knowledge-base question answering, semantic parsing to executable programs, dialogue-policy decision making.",
      "task_type": "Multi-turn knowledge-base question answering",
      "symbolic_representation_original": "Knowledge graphs / RDF triples, Logic programs (Horn clauses, Datalog)",
      "symbolic_representation": "Knowledge graphs / RDF triples",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Other (specify below)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Other (specify below)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "1",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "CIKM ",
      "venue_canonical": "KDD/WebConf/IR",
      "venue_group_bin": "KDD/WebConf/IR",
      "venue_group_plot": "KDD/WebConf/IR",
      "venue_clean": "kdd/webconf/ir",
      "venue_norm": "KDD/WebConf/IR",
      "venue_group": "KDD/WebConf/IR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083826",
    "title": "Leveraging large language models to generate answer set programs",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-20 16:50:01.933000",
      "Email Address": "bhuvan9@umd.edu",
      "Reviewer Name": "Bhuvanesh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083826",
      "Paper DOI / URL": "https://doi.org/10.24963/kr.2023/37",
      "Paper Title ": "Leveraging large language models to generate answer set programs",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "International Conference on Principles of Knowledge Representation and Reasoning",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "demo ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "They use LLMs to work through logic puzzle solving in a step-by-step manner. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/azreasoners/gpt-asp-rules?tab=readme-ov-file",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "Commit 4d33578",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Notes on reproduction": "Code doesn't work as is, needs to be modified. Requires openAI license, so may get rate-limited. ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logical programming ",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "answer-set programs, logic puzzles",
      "Real‑world application claimed?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural architecture type(s) ": "LLM",
      "Prompting strategy (if applicable)": "chain‑of‑thought",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Bidirectional exchange (neural ↔ symbolic loop)",
      "Symbolic representation(s)": "Answer Set Programs (ASP)",
      "Reasoning / inference engine": "ASP solvers (clingo, gringo, clasp)",
      "Source of symbolic knowledge": "Not reported / unclear",
      "Update / learning of symbols": "Not discussed / unclear",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Example of a rule / triple / formula (copy from paper)": "our pipeline\nfirst extracts the relevant objects and their categories. Then,\nit generates a predicate that describes the relations among\nthe objects from different categories. Using the generated\ninformation, the pipeline further constructs an ASP program\nin the style of Generate-Define-Test.",
      "What are the key findings of the study (1-4 dot points)?": "LLMs themselves are lousy problem solvers. \nPairing them with some level of automated logic puzzle solvers gives us much better performance on puzzle solving. ",
      "Author‑reported limitations": "Failure to convert certain constants into integers during constant formatting.\nAddition of wrong clues during paraphrasing. \nSyntax error during constraint generation.\nSemantic error during constraint generation. ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Logic Puzzle Dataset ",
      "Link to evaluation dataset used (if other)": "Stored along with code: https://github.com/azreasoners/gpt-asp-rules",
      "A motivation is given for why the experiments are conducted on the selected datasets": "No",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "< 1%",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Paper reports the use of logical solvers to improve LLM use in logic puzzles. The results were able to be reproduced on the evaluation data provided. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "1.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "logical programming",
      "nsai_domain": "logical programming",
      "application_area_original": "answer-set programs, logic puzzles",
      "application_area": "answer-set programs",
      "task_type_original": "unknown",
      "task_type": "unknown",
      "symbolic_representation_original": "Answer Set Programs (ASP)",
      "symbolic_representation": "Answer Set Programs (ASP)",
      "reasoning_engine_original": "ASP solvers (clingo, gringo, clasp)",
      "reasoning_engine": "ASP solvers (clingo",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Not reported / unclear",
      "knowledge_source": "Not reported / unclear",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2023.0",
      "venue_raw": "International Conference on Principles of Knowledge Representation and Reasoning",
      "venue_canonical": "KR",
      "venue_group_bin": "KR",
      "venue_group_plot": "KR",
      "venue_clean": "kr",
      "venue_norm": "KR",
      "venue_group": "KR",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084615",
    "title": "Neurosymbolic Association Rule Mining from Tabular Data",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-21 00:07:30.593000",
      "Email Address": "martiros@umd.edu",
      "Reviewer Name": "Vladimir",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084615",
      "Paper DOI / URL": "https://arxiv.org/abs/2504.19354",
      "Paper Title ": "Neurosymbolic Association Rule Mining from Tabular Data",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Aerial+ trains an autoencoder on tabular data, then extracts association rules by feeding in test vectors with features set to 1. If the autoencoder reconstructs other features with high probability, it creates a rule. Generates way fewer rules than FP-Growth (2-10x less) with better coverage and runs faster on big datasets, plus makes rule-based classifiers like CORELS train faster without losing accuracy.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://arxiv.org/pdf/2504.19354",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT license",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic learning, association rule mining, knowledge discovery, interpretable machine learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "tabular data mining, healthcare, recommendation systems, anomaly detection, high-stakes decision making",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "association rule mining, pattern discovery, rule extraction, classification, frequent itemset mining",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "rule-based interpretable machine learning in high-stakes decision-making contexts (healthcare, finance)",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "custom under-complete denoising autoencoder",
      "Neural architecture type(s) ": "Autoencoder / VAE",
      "Release date": "2025-10-12 00:00:00",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Logic programs (Horn clauses, Datalog), Decision rules / decision lists / decision trees as symbolic artifacts",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "weather(warm) -> beverage(soda), more formally: X → Y where X ∩ Y = ∅, |Y| = 1 (single consequent), represented as horn clause ¬X ∨ Y",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "What are the key findings of the study (1-4 dot points)?": "Aerial+ generates 2-10x fewer association rules than exhaustive methods while maintaining full coverage.\nSignificantly outperforms optimization-based ARM methods (Bat Algorithm, Grey Wolf Optimizer).",
      "Author‑reported limitations": "Performance depends on appropriate discretization of numerical features",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "4.0",
      "Reproducibility confidence (after our attempt)": "Minor barriers / minor amounts of unclear steps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "6.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Support, Confidence",
      "Split / Protocol": "k‑fold cross‑validation (specify k), Other (specify below)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "All from UCI Machine Learning Repository [Kelly et al., 2023]: https://archive.ics.uci.edu",
      "Link to evaluation dataset used (if other)": "https://archive.ics.uci.edu",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "FP-Growth (via Mlxtend)\nHMine (via Mlxtend)\nBat Algorithm (BAT)\nGrey Wolf Optimizer (GWO)\nSine Cosine Algorithm (SC)\nFish School Search (FSS)\nARM-AE [Berteloot et al., 2024]\nCBA (Classification Based on Associations)\nBRL (Bayesian Rule Lists)\nCORELS (Certifiably Optimal Rule Lists)\nHyperparameter analysis (Appendix B): varying τa and τc thresholds\nNumber of antecedents (1-4): Figure 4\nFrequent itemset mining variant (Algorithm 2)\nARM with item constraints variant (Algorithm 3)",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Had a lot of issues with the benchmark code. Other than that, reproduction successful",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Paper shows a simple yet effective successful neuro-symbolic approach to association rule mining by training an under-complete denoising autoencoder to learn neural representations of tabular data and extracting symbolic logic rules",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "neuro-symbolic learning, association rule mining, knowledge discovery, interpretable machine learning",
      "nsai_domain": "neuro-symbolic learning",
      "application_area_original": "tabular data mining, healthcare, recommendation systems, anomaly detection, high-stakes decision making",
      "application_area": "tabular data mining",
      "task_type_original": "association rule mining, pattern discovery, rule extraction, classification, frequent itemset mining",
      "task_type": "association rule mining",
      "symbolic_representation_original": "Logic programs (Horn clauses, Datalog), Decision rules / decision lists / decision trees as symbolic artifacts",
      "symbolic_representation": "Logic programs (Horn clauses",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "4.0",
      "reviewer_confidence_score": "6.0",
      "publication_year": "2025.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085538",
    "title": "LINC:ANeurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-21 02:23:23.453000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085538",
      "Paper DOI / URL": "https://aclanthology.org/2023.emnlp-main.313.pdf",
      "Paper Title ": "LINC:ANeurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACL",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "investigate the validity of instead reformulating such tasks as modular neurosymbolic programming, which we call LINC: Logical Inference via Neurosymbolic Computation. In LINC, the LLM acts as a semantic parser, translating premises and conclusions from natural language to expressions in first-order logic. These expressions are then offloaded to an external theorem prover, which symbolically performs deductive inference.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/benlipkin/linc",
      "Primary language / framework": "Jupyter Notebook",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs (if yes to the above)": "1000 bootstrapped samples to estimate uncertainty.",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "Needed to configure HuggingFace Accelerate / (optional) DeepSpeed on the HPC cluster.\n\nRequired an OpenAI API key for GPT-3.5/GPT-4 experiments and local access to StarCoder+ (or equivalent).\n\nProver9 must be installed and on the PATH (as per README).\n\nAnalysis initially failed due to NumPy 2.x vs PyArrow/Pandas incompatibilities; resolved by pinning numpy<2 and installing a compatible pyarrow version.\n\nAfter these adjustments, make run (experiment grid) and make analyze (tables & figures) both completed and matched reported results within stochastic variation.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logical reasoning, neurosymbolic reasoning, theorem proving, first-order logic",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "commonsense reasoning, synthetic logical QA, formal logical entailment, consistency checking",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "logical entailment classification, multiple-choice QA, theorem proving, consistency/inconsistency detection, synthetic rule-chain reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Other (specify below)",
      "Neural model name & family (for other) specify here:": "StarCoder+ (BigCode code LLM, 15.5B parameters)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Neural architecture type(s) (for other) specify here:": "StarCoder+ = 15.5B parameters",
      "Prompting strategy (if applicable)": "few‑shot, Few‑shot (N‑shot), chain‑of‑thought, Self‑Consistency sampling, Scratchpad prompting, Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "Scratchpad prompting; structured semantic-parsing prompts with explicit logical tags; majority-vote self-consistency sampling.",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable, Hosted API only",
      "Access level (for other) specify here:": "Hybrid: GPT-3.5/GPT-4 accessible via OpenAI API; StarCoder+ is available with open weights.",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Prover9 automated first-order logic theorem prover.",
      "Link to Existing symbolic project used (if applicable) ": "https://formulae.brew.sh/formula/prover9",
      "Symbolic representation(s)": "First‑order / predicate logic",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Theorem prover – Prover9 (first-order logic automated theorem proving).",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation), Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "All symbolic knowledge comes from the benchmark datasets (FOLIO and ProofWriter), not from external KGs.",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "Example of a rule / triple / formula (copy from paper)": "∀x (rectangle(x) → four_sides(x))",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom integration with Prover9 (external theorem prover).",
      "What are the key findings of the study (1-4 dot points)?": "LINC, which uses LLMs as semantic parsers plus Prover9 for reasoning, substantially improves logical reasoning accuracy over prompt-only baselines (naive, scratchpad, chain-of-thought) on FOLIO and ProofWriter. \n\nWith the open-weights StarCoder+ model, LINC matches or exceeds the performance of GPT-3.5 and GPT-4 chain-of-thought baselines on ProofWriter, demonstrating the value of combining symbolic provers with smaller models.\n\nError analyses show complementary failure modes: chain-of-thought often breaks on longer reasoning chains, while LINC is more robust to depth but sensitive to semantic parsing errors.\n\nThe authors argue that neuro-symbolic decomposition (parsing vs. proving) is a promising design pattern for improving interpretability and reliability of LLM-based reasoning.",
      "Author‑reported limitations": "Dependence on LLM quality: if the LLM produces incorrect or incomplete logical forms, Prover9 cannot recover.\n\nFocus on relatively synthetic / controlled datasets (FOLIO and ProofWriter); generalization to more naturalistic or large-scale real-world corpora remains open.\n\nThe symbolic system is restricted to first-order logic; richer logics or noisy knowledge sources are not explored.",
      "Reviewer‑identified limitations / threats to validity": "Semantic parsing prompts are handcrafted and may not transfer directly to other domains or languages.\n\nEvaluation is limited to textual logical benchmarks and synthetic rule chains; performance in noisy, real-world settings is not empirically tested.\n\nNo explicit robustness tests to adversarial prompts or distribution shifts beyond the chosen benchmarks.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "1.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Classification / structured prediction, Accuracy",
      "Primary task metrics reported (for other) specify here:": "Accuracy over logical entailment / contradiction classification, computed under K-way self-consistency sampling (majority vote) with bootstrapped standard deviations.",
      "Split / Protocol": "Zero‑shot (no task‑specific training), Few‑shot (N‑shot prompting / small labeled set)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Synthetic / Procedural, Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "FOLIO – a natural-language first-order logic entailment dataset.  ProofWriter – balanced open-world assumption subset, synthetic rule-based reasoning dataset.",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Naive prompting (direct answer).\n\nScratchpad prompting (intermediate reasoning).\n\nChain-of-Thought prompting.\n\nLINC variants (e.g., LINC with/without certain features).",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "fully reproducible neuro-symbolic reasoning system (LINC) that combines LLMs with a first-order logic prover",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "logical reasoning, neurosymbolic reasoning, theorem proving, first-order logic",
      "nsai_domain": "logical reasoning",
      "application_area_original": "commonsense reasoning, synthetic logical QA, formal logical entailment, consistency checking",
      "application_area": "commonsense reasoning",
      "task_type_original": "logical entailment classification, multiple-choice QA, theorem proving, consistency/inconsistency detection, synthetic rule-chain reasoning",
      "task_type": "logical entailment classification",
      "symbolic_representation_original": "First‑order / predicate logic",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation), Other (specify below)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Other (specify below)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "1.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2023.0",
      "venue_raw": "ACL",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085341",
    "title": "Autoformalizing euclidean geometry",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-21 05:22:53.233000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085341",
      "Paper DOI / URL": "https://dl.acm.org/doi/10.5555/3692070.3693567",
      "Paper Title ": "Autoformalizing euclidean geometry",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICML",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "use theorem provers to fill in such diagrammatic information automatically, so that the LLM only needs to autoformalize the explicit textual steps, making it easier for the model.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/loganrjmurphy/LeanEuclid",
      "Primary language / framework": "Lean",
      "Commit / tag / release hash used": "b50829ce4bf78e3f135b4c3421dda24514613a5a",
      "If yes: Provide link": "b50829ce4bf78e3f135b4c3421dda24514613a5a",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "LeanEuclid benchmark (Elements + UniGeo formalizations)",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "We built the LeanEuclid toolchain using the authors’ Lean version (4.8.0-rc2) and mathlib cache, plus Z3 and cvc5. We used gpt-4o-mini in text-only mode via OpenAI’s API instead of the original gpt-4-1106-preview and gpt-4-1106-vision-preview, so absolute percentages differ slightly, but the qualitative trends and success/failure behavior matched the paper’s reports. As per: [https://github.com/loganrjmurphy/LeanEuclid/issues/6] we needed to build with commit https://github.com/loganrjmurphy/LeanEuclid/commit/b50829ce4bf78e3f135b4c3421dda24514613a5a due to lake build issues ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic-reasoning, autoformalization, theorem-proving, program-verification",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "mathematics, Euclidean-geometry, formal-methods, proof-assistants",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "theorem-statement-autoformalization, proof-autoformalization, semantic-equivalence-checking, neuro-symbolic-reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Prompting strategy (if applicable)": "few‑shot",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Not reported / unclear",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Text passed to symbolic module; generated Lean theorem statements/proofs are fed into Lean + E3 (SMT-based checker) which parses them into formulas, runs SMT solvers, and checks semantic equivalence or proof validity.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "– Lean (theorem prover) – SMT solvers: Z3 and CVC5 (via SMT portfolio)",
      "Link to Existing symbolic project used (if applicable) ": "Lean: https://leanprover-community.github.io  Z3: https://github.com/Z3Prover/z3  cvc5: https://cvc5.github.io",
      "Symbolic representation(s)": "First‑order / predicate logic, Constraint satisfaction / SMT formulas, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Formal Lean proofs / tactic scripts as an executable proof language.",
      "Reasoning / inference engine": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Lean theorem prover",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Imported problems/proofs from existing datasets (Elements, UniGeo) and encoded as formal facts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Example of a rule / triple / formula (copy from paper)": "def prop5_prediction : ∀ (a b c d e : Point) (AB BC AC : Line), formTriangle a b c AB BC AC ∧ |(a--b)| = |(a--c)| ∧ between a b d ∧ between a c e → ∠a:b:c = ∠a:c:b ∧ ∠c:b:d = ∠b:c:e := ...",
      "Tooling / libraries for symbolic side": "Z3 / CVC5 / Boolector (SMT solvers), Coq / Isabelle / Lean (theorem provers), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom Lean library “SystemE” implementing Euclidean theory and the E3 checker.",
      "What are the key findings of the study (1-4 dot points)?": "Introduces LeanEuclid, a benchmark of 48 Euclid Book I theorems and 100 UniGeo problems with both informal and formal representations, enabling study of autoformalization in Euclidean geometry.\n\nProposes E3, an SMT-based neuro-symbolic engine that evaluates the semantics of autoformalized theorem statements by checking equivalence in a formal Euclidean theory, correlating well with human judgments.\n\nShows that GPT-4 and GPT-4V can correctly autoformalize only ~18.9–21.0% of theorem statements and around 17–31% of proofs (depending on category and few-shot configuration), highlighting the difficulty of the task.\n\nDemonstrates that many imperfect LLM-generated proofs can be repaired with relatively small edits, suggesting that symbolic tooling plus human intervention can turn noisy LLM outputs into correct formal proofs.",
      "Author‑reported limitations": "SMT-based symbolic engine (E3) is incomplete and can occasionally be unsound, potentially missing equivalences or accepting spurious ones. \n\nAutoformalization focuses on explicit textual steps while relying on a specific formalization of diagrammatic reasoning (System E), which may not generalize beyond Euclidean geometry.\n\nGPT-4/GPT-4V still struggle with many theorems and proofs, limiting end-to-end success rates.",
      "Reviewer‑identified limitations / threats to validity": "Experiments appear to be single-run evaluations without variance estimates or statistical testing, so small performance differences may not be robust.\n\nNo explicit hardware/compute reporting and limited discussion of sensitivity to prompt design and hyper-parameters.\n\nLeanEuclid is geometry-specific; generalization to other mathematical domains is hypothesized but not empirically tested.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "5.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Levenshtein similarity between autoformalized and repaired proofs.",
      "Split / Protocol": "Zero‑shot (no task‑specific training), Few‑shot (N‑shot prompting / small labeled set)",
      "Split / Protocol (for other) specify here:": "Zero-shot, 1-shot, and 5-shot few-shot prompting protocols applied to fixed test sets; no training/validation split (benchmark is for evaluation only).",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Docker / Conda / container to reproduce metrics",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom dataset (introduced in paper) – LeanEuclid, built from: – Euclid’s Elements (Book I) – UniGeo geometry dataset",
      "Link to evaluation dataset used (if other)": "Provided via the LeanEuclid GitHub repo: https://github.com/loganrjmurphy/LeanEuclid",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Main comparisons are across prompting settings (0-shot vs 1-shot vs 5-shot) and models (GPT-4 vs GPT-4V), plus E3 evaluation vs human assessments; there are no competing non-LLM autoformalization systems.",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "Human evaluation is used to validate E3’s semantic equivalence judgments, but detailed counts of raters/scale are limited; they primarily report correlation with human judgments rather than extensive human rating protocol.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "neuro-symbolic autoformalization benchmark and system (LeanEuclid + E3) with reproducible code and clear evaluation of LLM-based reasoning",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neuro-symbolic-reasoning, autoformalization, theorem-proving, program-verification",
      "nsai_domain": "neuro-symbolic-reasoning",
      "application_area_original": "mathematics, Euclidean-geometry, formal-methods, proof-assistants",
      "application_area": "mathematics",
      "task_type_original": "theorem-statement-autoformalization, proof-autoformalization, semantic-equivalence-checking, neuro-symbolic-reasoning",
      "task_type": "theorem-statement-autoformalization",
      "symbolic_representation_original": "First‑order / predicate logic, Constraint satisfaction / SMT formulas, Other (specify below)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "reasoning_engine": "SMT solvers (Z3",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Other (specify below)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "1",
      "clarity_score": "5.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "ICML",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085659",
    "title": "PEIRCE: Unifying Material and Formal Reasoning via LLM-Driven Neuro-Symbolic Refinement",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-21 06:04:10.770000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085659",
      "Paper DOI / URL": "https://aclanthology.org/2025.acl-demo.2.pdf",
      "Paper Title ": "PEIRCE: Unifying Material and Formal Reasoning via LLM-Driven Neuro-Symbolic Refinement",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACL",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "introduce PEIRCE, a neuro-symbolic framework designed to unify material and formal inference through an iterative conjecture–criticism process.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/neuro-symbolic-ai/peirce",
      "Primary language / framework": "Isabelle ",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "No",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not provided",
      "Notes on reproduction": "Reproduction required installing SSKB (pip install sskb), SWI-Prolog, and Isabelle 2023, and setting OpenAI API keys in config.yaml. Once dependencies and paths were correctly configured, all four main demos (retrieval, hard refinement, soft/hard critiques, and IBE) ran and reproduced the reported trends and approximate numbers. - we take the numbers reported as the demos as the quantitative evaluations ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic reasoning, explanation generation, natural language inference, theorem proving, inductive logic programming",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "science question answering, textual entailment, clinical reasoning, mathematical proof assistance, causal reasoning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "explanation retrieval, natural language explanation generation, iterative explanation refinement, premise selection, inference to the best explanation, causal multiple-choice reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Prompting strategy (if applicable)": "Iterative / Recursive prompting, Prompt Chaining / Pipelines, Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "Iterative conjecture–criticism prompting loop with dynamically instantiated prompt templates.",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "Parameter-free prompt engineering only (no gradient updates on GPT-3.5/4o(obviously!)).",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules, Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "Prolog / Datalog libraries (SWI‑Prolog, LogicBlox)",
      "Link to Existing symbolic project used (if applicable) ": "Isabelle: https://isabelle.in.tum.de/   SWI-Prolog: https://www.swi-prolog.org/   SSKB: https://github.com/neuro-symbolic-ai/SSKB   SAF: https://github.com/dscarvalho/saf ",
      "Symbolic representation(s)": "First‑order / predicate logic, Higher‑order logic, Logic programs (Horn clauses, Datalog)",
      "Reasoning / inference engine": "Prolog (e.g., SWI‑Prolog) / Datalog engines, Theorem provers (Coq, Isabelle/HOL, Lean)",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Static (fixed once authored/imported), Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Symbols/theories for a given instance are generated and refined per-instance during the conjecture–criticism loop (online creation of formal theories), but not stored as a growing global KB.",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Other (specify below)",
      "Integration strategy with neural part (for other) specify here:": "Iterative neuro-symbolic loop where symbolic feedback guides subsequent neural generations (meta-controller style).",
      "Example of a rule / triple / formula (copy from paper)": "using assms explanation_1 explanation_2 by blast",
      "Tooling / libraries for symbolic side": "SWI‑Prolog / Prolog libraries, Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Isabelle/HOL (including Sledgehammer, Vampire, CVC4, SPASS, Zipperposition)  SWI-Prolog  SSKB (Simple Statement Knowledge Bases)  SAF (Simple Annotation Framework)",
      "What are the key findings of the study (1-4 dot points)?": "A modular conjecture–criticism framework (PEIRCE) can unify material and formal reasoning across diverse explanation-centric NLI tasks, enabling end-to-end neuro-symbolic pipelines. \n\nUnification-based and ensemble retrieval models achieve higher MAP than BM25 alone on WorldTree and ProofWiki, confirming prior findings on explanatory retrieval. \n\nIteratively refining explanations with GPT-4o and Isabelle substantially increases the number of explanations that can be formally verified, across general, scientific, and clinical domains, while reducing iterations compared to GPT-3.5. \n\nSoft critique models (parsimony, coherence, uncertainty) can act as meta-evaluators to perform inference to the best explanation on COPA, outperforming simple LLM-as-judge baselines.",
      "Author‑reported limitations": "Demo-scale evaluation: small sample sizes (e.g., 50 examples for retrieval, 20 COPA questions) limit statistical power and generality. \n\nFocused domains (explanation-centric NLI) rather than broad tasks; generality to other domains is suggested but not empirically demonstrated at large scale.",
      "Reviewer‑identified limitations / threats to validity": "Results on small sampled subsets may be sensitive to instance selection and LLM randomness.\n\nCodebase uses Jupyter notebooks for key experiments, requiring some manual orchestration and environment configuration (Isabelle, Prolog, API keys).",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Classification / structured prediction, Ranking / retrieval / KG completion, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Counts / efficiency metrics: Number of valid explanations and average iterations for refinement via hard critique",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "e-SNLI (explanation NLI)  WorldTree (science QA explanation corpus)  ProofWiki (premise selection in formal math proofs)  NLI4CT / clinical explanation datasets  COPA (choice of plausible alternatives)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Explanation retrieval: BM25 vs Unification vs BM25+Unification ensemble. \n\nRefinement: GPT-3.5 vs GPT-4o performance in terms of valid explanations and required iterations. \n\nIBE: LLM-as-judge baselines vs soft-critique-based explanation selection (parsimony, coherence, uncertainty). \n",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "neuro-symbolic framework that tightly integrates LLMs with symbolic provers and soft critique models, provides open code and data loaders, and demonstrates verifiable performance gains on explanation-centric reasoning tasks across multiple domains.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neuro-symbolic reasoning, explanation generation, natural language inference, theorem proving, inductive logic programming",
      "nsai_domain": "neuro-symbolic reasoning",
      "application_area_original": "science question answering, textual entailment, clinical reasoning, mathematical proof assistance, causal reasoning",
      "application_area": "science question answering",
      "task_type_original": "explanation retrieval, natural language explanation generation, iterative explanation refinement, premise selection, inference to the best explanation, causal multiple-choice reasoning",
      "task_type": "explanation retrieval",
      "symbolic_representation_original": "First‑order / predicate logic, Higher‑order logic, Logic programs (Horn clauses, Datalog)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Prolog (e.g., SWI‑Prolog) / Datalog engines, Theorem provers (Coq, Isabelle/HOL, Lean)",
      "reasoning_engine": "Prolog (e.g.",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Other (specify below)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "ACL",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085427",
    "title": "LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract Rules",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 00:10:58.458000",
      "Email Address": "rambavan@umd.edu",
      "Reviewer Name": "Raj",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085427",
      "Paper DOI / URL": "https://www.researchgate.net/publication/380820165_LARS-VSA_A_Vector_Symbolic_Architecture_For_Learning_with_Abstract_Rules",
      "Paper Title ": "LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract Rules",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework paper ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper presents LARS-VSA, a neuro-symbolic framework leveraging hyperdimensional computing for abstract rule learning with compositional generalization. It introduces a high-dimensional attention mechanism and demonstrates superior generalization, efficiency, and accuracy over contemporary neural and neuro-symbolic baselines on multiple relational reasoning and math tasks.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/mmejri3/LARS-VSA",
      "Primary language / framework": "Python (TensorFlow)",
      "Commit / tag / release hash used": "yes",
      "If yes: Provide link": "https://github.com/mmejri3/LARS-VSA",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "Yes",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Memory / batch size reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT",
      "Notes on reproduction": "All experiments were reproduced successfully using the provided scripts and instructions. The codebase is well-documented and modular, with all results matching the paper within expected variance for stochastic models.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic AI, symbolic reasoning, vector symbolic architectures, abstract rule learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "machine learning, relational reasoning, mathematical problem solving, cognitive modeling",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "relational tasks, sequence-to-sequence modeling, sorting, symbolic manipulation, mathematical reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "AutoregressiveLARSVSA",
      "Neural architecture type(s) ": "Hybrid (specify combination), Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Custom vector symbolic architecture integrated with Transformer-based modules and high-dimensional attention mechanisms",
      "Release date": "2024-05-23 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Academic papers / patents (arXiv, PubMed, USPTO), Code repositories (GitHub Code, StackOverflow dumps, CodeSearchNet, StarCoderData), Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "Official DeepMind Mathematics Dataset, synthetic relational tasks; no web-scale or LLM-style pre-training",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, First‑order / predicate logic, Knowledge graphs / RDF triples, Taxonomies / hierarchies / thesauri",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Learned/induced jointly during model training, Automatically pruned/regularized for consistency",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Joint / co‑training of neural and symbolic modules",
      "Example of a rule / triple / formula (copy from paper)": "For the “kth_biggest” relation (comparison task):\nIf x1, x2, ..., xn are inputs, and xj is the k-th largest value, the output is defined as:\nr = bind(\"kth_largest\", x_j)\nwhere “bind” denotes the symbolic-vector binding operation in LARS-VSA.",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "TensorFlow-backed symbolic layers, custom attention and binding ops as described in the codebase modules.",
      "What are the key findings of the study (1-4 dot points)?": "LARS-VSA demonstrates state-of-the-art compositional generalization and relational reasoning on symbolic tasks using hyperdimensional vector representations.\n\nThe introduced high-dimensional symbolic attention mechanism significantly reduces memory and computational costs compared to conventional Transformer architectures.\n\nThe model consistently achieves strong performance on DeepMind Mathematics datasets and relational sorting tasks, outperforming or matching neural and neuro-symbolic baselines.\n\nThe framework provides reproducible, modular open-source code that facilitates robust experimentation and comparison.",
      "Author‑reported limitations": "Temporal interference and catastrophic forgetting are not fully mitigated, especially in online or continual learning settings.\n\nDecoder modules currently rely partially on conventional attentional operations rather than fully hyperdimensional implementations.\n\nLimited benchmarking on real-world applications beyond standard datasets.",
      "Reviewer‑identified limitations / threats to validity": "Experimental setup is robust, but evaluation is limited to well-known benchmarks and synthetic tasks; real-world generalization remains untested.\n\nScalability of the symbolic vector architecture to much larger datasets or multi-modal learning is not empirically evaluated.\n\nFurther ablation studies would help isolate the contribution of individual components.",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "The paper includes a broader impact statement addressing responsible use of neuro-symbolic systems and privacy in data-driven models.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted), Exact Match (EM), MSE / RMSE / MAE",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Leaderboard or WandB/MLflow logs linked, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Synthetic / Procedural, Toy logical datasets (symbolic math, rule chains), Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Official DeepMind Mathematics Dataset",
      "Link to evaluation dataset used (if other)": "https://github.com/deepmind/mathematics_dataset",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": " Transformers, PrediNet, Abstractor, CorelNet, and other neuro-symbolic baselines; ablation studies reported for LARS-specific components.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "<3%",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Metrics computed per standard for DeepMind Mathematics and symbolic reasoning datasets; custom accuracy scripts provided and documented in experiments/README.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper introduces a novel, efficient neuro-symbolic architecture with fully open-source, reproducible code and achieves state-of-the-art generalization on challenging symbolic reasoning and mathematical tasks.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Codebase is fully reproducible with clear instructions and all assets provided; no further action is needed. Future work may evaluate generalization on more diverse, real-world datasets.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "3.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "neuro-symbolic AI, symbolic reasoning, vector symbolic architectures, abstract rule learning",
      "nsai_domain": "neuro-symbolic AI",
      "application_area_original": "machine learning, relational reasoning, mathematical problem solving, cognitive modeling",
      "application_area": "machine learning",
      "task_type_original": "relational tasks, sequence-to-sequence modeling, sorting, symbolic manipulation, mathematical reasoning",
      "task_type": "relational tasks",
      "symbolic_representation_original": "Propositional / Boolean logic rules, First‑order / predicate logic, Knowledge graphs / RDF triples, Taxonomies / hierarchies / thesauri",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2024.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085624",
    "title": "Accelerating UMR adoption: Neuro-symbolic conversion from AMR-to-UMR with low supervision",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 02:48:30.816000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085624",
      "Paper DOI / URL": "https://aclanthology.org/2024.dmr-1.15/",
      "Paper Title ": "Accelerating UMR adoption: Neuro-symbolic conversion from AMR-to-UMR with low supervision",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "DMR 2024 (Fifth International Workshop on Designing Meaning Representations @ LREC-COLING 2024)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Methodological paper / Novel approach",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper proposes a neuro-symbolic method for converting AMR (Abstract Meaning Representation) roles to UMR (Uniform Meaning Representation) roles by integrating animacy parsing and logic rules with a neural network. The approach addresses non-deterministic role mappings with minimal human supervision, achieving 75.81% accuracy compared to a 62.35% baseline neural network.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/clairepost/AMRtoUMR",
      "Primary language / framework": "Python / PyTorch",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5 (5-fold cross-validation)",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Notes on reproduction": "Repository missing requirements.txt - manually installed: pandas, numpy, torch, scikit-learn, nltk, matplotlib, seaborn, networkx, transformers. Minor threading issue on HPC resolved with OMP_NUM_THREADS=1. All three models (baseline.py, base_nn.py, nn_with_rules_weights.py) ran successfully and produced results matching paper metrics exactly.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "semantic parsing, knowledge representation, neuro-symbolic reasoning, logic-based learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "natural language processing, semantic representation, cross-lingual semantics, meaning representation",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "role classification, graph conversion, semantic role labeling, structured prediction",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "The paper claims the method can accelerate the conversion of large existing AMR datasets to UMR format, enabling cross-lingual semantic analysis and reducing the annotation burden for creating UMR resources in multiple languages.",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "BERT-base (110M parameters) + custom MLP classifier (not specified in paper)",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Wikipedia / encyclopedic corpora (all language editions), Book corpora (BookCorpus, Gutenberg, Shadow libraries)",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, No fine‑tuning (frozen backbone)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "BERT is used frozen to generate embeddings; only the MLP classifier is trained on AMR-to-UMR role conversion task",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints",
      "How neural outputs are used by the symbolic part (for other) specify here:": "BERT embeddings of AMR roles are combined with animacy features and passed to MLP; symbolic rules (animacy-based logic) are integrated as weighted constraints that adjust neural network predictions",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, First‑order / predicate logic, Domain‑specific languages (DSLs) / program sketches",
      "Symbolic representation(s) (for other) specify here:": "Animacy-based logic rules (e.g., animate entities get :Causer role) and AMR-to-UMR role mapping constraints",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Reasoning / inference engine (for other) specify here:": "Custom Python-based rule engine in rules.py and animacyParser.py that applies animacy constraints to guide role prediction",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "Source of symbolic knowledge (for other) specify here:": "Animacy rules hand-crafted based on linguistic theory; AMR/UMR role mapping constraints derived from UMR annotation guidelines",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Constraint injection / regularization during neural training",
      "Integration strategy with neural part (for other) specify here:": "Animacy-based symbolic rules are used to create weighted constraints that guide the neural network's predictions; the NN learns role mappings while symbolic rules provide soft supervision",
      "Example of a rule / triple / formula (copy from paper)": "IF animacy(entity) = ANIMATE THEN role = :Causer\nIF animacy(entity) = INANIMATE AND context = causation THEN role = :Cause-of\nIF AMR_role = :ARG1-of AND predicate_type = causation THEN UMR_role ∈ {:cause, :Cause-of, :reason}",
      "Tooling / libraries for symbolic side": "NetworkX (symbolic graph ops), Custom in‑house engine (name below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom Python-based rule engine implemented in rules.py (detect_split_role function) and animacyParser.py (parse_animacy_runner, animacy_decider functions) for applying animacy constraints and role mapping logic",
      "What are the key findings of the study (1-4 dot points)?": "The neuro-symbolic method (NN+Rules) achieved 75.81% accuracy, significantly outperforming the baseline neural network (62.35%) and approaching the rule-only baseline (77.85%)\nIntegration of animacy parsing with neural networks improved F1 score to 73.79% compared to 60.28% for neural-only approach\nThe method successfully handles non-deterministic AMR-to-UMR role mappings with minimal human supervision using symbolic constraints\nResults demonstrate that combining symbolic rules with neural learning provides better generalization than either approach alone, particularly for difficult role mappings like :reason and :source",
      "Author‑reported limitations": "Need to expand animacy parsing coverage; method currently addresses only subset of AMR-to-UMR conversion (split-role cases); future work needed to incorporate human feedback and apply to broader conversion aspects; limited to English AMR data",
      "Reviewer‑identified limitations / threats to validity": "No requirements.txt provided (reproducibility barrier); no random seed reporting or variance analysis across folds; small test set (117 examples in k-fold); no statistical significance testing; BERT embeddings frozen (not fine-tuned for task); no comparison with recent large language models; no external validation on different AMR datasets",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, F1 (micro / macro / weighted)",
      "Split / Protocol": "k‑fold cross‑validation (specify k)",
      "Split / Protocol (for other) specify here:": "5-fold cross-validation on gold-standard annotated data (587 examples total)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Evaluation assets provided (for other) specify here:": "All three model scripts (baseline.py, base_nn.py, nn_with_rules_weights.py) provided; output predictions stored in /output directory",
      "Datasets used for Evaluation ": "Not reported / unclear",
      "Evaluation Datasets (for other) specify here:": "Custom AMR-to-UMR role conversion dataset created by authors from existing AMR annotations, focusing on split-role cases where one AMR role maps to multiple UMR roles",
      "Link to evaluation dataset used (if other)": "https://github.com/clairepost/AMRtoUMR",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Baselines / ablations compared against\nThree models compared: (1) Rule-only baseline using animacy rules, (2) Base neural network without rules, (3) Proposed NN+Rules neuro-symbolic approach. Ablation shows contribution of symbolic component by comparing NN vs NN+Rules.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Weighted average F1 computed across 14 UMR role classes with support weighting. K-fold results show per-class metrics aggregated across 5 folds. Minor discrepancy in baseline F1 likely due to random fold splits (no seed reported in paper). All accuracy metrics match exactly.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents a clear neuro-symbolic approach combining BERT embeddings with hand-crafted animacy logic rules for semantic role conversion, demonstrating how symbolic constraints can effectively guide neural predictions with measurable performance improvements and full reproducibility.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproduction was successful with exact metric matches for the main proposed method (NN+Rules: 75.81% accuracy, 73.79% F1) and baseline NN (62.35% accuracy, 60.28% F1). Minor setup required: manually installed dependencies (pandas, numpy, torch, scikit-learn, nltk, matplotlib, seaborn, networkx, transformers) as no requirements.txt was provided. Set OMP_NUM_THREADS=1 to resolve threading issues on HPC login node. All three models (baseline.py, base_nn.py, nn_with_rules_weights.py) executed successfully on CPU-only environment. Baseline rule-only F1 showed minor +1.5% difference (77.59% vs 76.1% reported), likely due to k-fold random seed variation (seeds not specified in paper). Complete output files generated in /output and /results directories. Action items for authors: (1) Add requirements.txt with all dependencies and version numbers, (2) Document random seeds for exact reproducibility, (3) Add explicit run instructions in README. Overall assessment: fully reproducible with excellent code quality and data availability.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "semantic parsing, knowledge representation, neuro-symbolic reasoning, logic-based learning",
      "nsai_domain": "semantic parsing",
      "application_area_original": "natural language processing, semantic representation, cross-lingual semantics, meaning representation",
      "application_area": "natural language processing",
      "task_type_original": "role classification, graph conversion, semantic role labeling, structured prediction",
      "task_type": "role classification",
      "symbolic_representation_original": "Propositional / Boolean logic rules, First‑order / predicate logic, Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Constraint injection / regularization during neural training",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "model_family": "BERT derivatives (BERT",
      "param_scale_band": "<1B",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2024.0",
      "venue_raw": "DMR 2024 (Fifth International Workshop on Designing Meaning Representations @ LREC-COLING 2024)",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083903",
    "title": "AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 11:11:30.268000",
      "Email Address": "itamraka@umd.edu",
      "Reviewer Name": "Ishan",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083903",
      "Paper DOI / URL": "https://arxiv.org/pdf/2410.24117",
      "Paper Title ": "AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACM on Software Engineering Volume 2",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Solves the task of code translation from one programming language to another. It does so using neural symbolic framework that breaks down the source code into fragments and also utilized the test code to ensure code was properly translated. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/Intelligent-CAT-Lab/AlphaTrans",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Training time / FLOPs reported, Memory / batch size reported",
      "Total compute budget disclosed?": "Yes",
      "Total compute budget (if yes to the above) ": "(5.5 hours for smallest adn 34 hours for largest project) * 10 ",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5 RQs * 10 runs = 50 ",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "NCSA license ",
      "Notes on reproduction": "need to update the docker file to point to a valid maven download link\nneed to allow conda terms of service with conda tos accept command in the docker file. ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Program translation, coding nsai, coding ai, transpilation ",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Programming Language transpilation",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "programming tasks, csv parsing, fileupload, graph, cli, etc.",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Translating a real world codebase from one programming language to another even if the programming languages differ in paradigm",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Instruct, DeepSeek / InternLM / MiniCPM",
      "Neural architecture type(s) ": "LLM",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "33b",
      "Release date": "2025-06-19 00:00:00",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "Symbolic representation(s)": "Taxonomies / hierarchies / thesauri",
      "Symbolic representation(s) (for other) specify here:": "a custom datastructure called schema that represents the different fragments present in a codebase",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Extracted automatically from structured data / logs",
      "Update / learning of symbols": "Periodically updated post‑training (batch updates), Automatically pruned/regularized for consistency",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Post‑hoc verification or logical consistency checking of neural outputs",
      "What are the key findings of the study (1-4 dot points)?": "Programming language translation is particularly difficult because of dependencies on various language specific APIs. Using LLMs to aid the translation and an symbolic verifier yields better result than relying on LLMs alone. The availability of good test code in the source programming language helps a lot in this kind of setup. ",
      "Author‑reported limitations": "The Java based validation system is limiting because it can handle only a limited number of built in and library types. Maps or objects with impure methods for hashing, isomorphism between java and python, etc may not be maintained. It is sometimes not possible to disambiguate target types when casting python objects to java types. fpr",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "AUROC (ROC‑AUC)",
      "Primary task metrics reported (for other) specify here:": "TNEF, ATP, OTF, MTF, TPR",
      "Split / Protocol": "Not reported / unclear",
      "Evaluation assets provided (if yes / partial above) ": "Docker / Conda / container to reproduce metrics",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom curated Github codebases",
      "Link to evaluation dataset used (if other)": "https://zenodo.org/records/15204625",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "two developers to test the speed improvement after using AlphaTrans",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "0.01",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It is a very well maintained and complete codebase capable of full reproduction of their reported numbers. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.01",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Program translation, coding nsai, coding ai, transpilation",
      "nsai_domain": "Program translation",
      "application_area_original": "Programming Language transpilation",
      "application_area": "Programming Language transpilation",
      "task_type_original": "programming tasks, csv parsing, fileupload, graph, cli, etc.",
      "task_type": "programming tasks",
      "symbolic_representation_original": "Taxonomies / hierarchies / thesauri",
      "symbolic_representation": "Taxonomies / hierarchies / thesauri",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Extracted automatically from structured data / logs",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), Instruct, DeepSeek / InternLM / MiniCPM",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": ">10B",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "1",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2025.0",
      "venue_raw": "ACM on Software Engineering Volume 2",
      "venue_canonical": "ACM",
      "venue_group_bin": "ACM conferences/journals",
      "venue_group_plot": "ACM conferences/journals",
      "venue_clean": "acm",
      "venue_norm": "ACM conferences/journals",
      "venue_group": "ACM conferences/journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "242085638",
    "title": "Neuro-symbolic Training for Reasoning over Spatial Language",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 13:12:50.248000",
      "Email Address": "ddubey12@umd.edu",
      "Reviewer Name": "Dhruv",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "242085638",
      "Paper DOI / URL": "https://arxiv.org/abs/2406.13828",
      "Paper Title ": "Neuro-symbolic Training for Reasoning over Spatial Language",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework/Model paper",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "This paper presents SpaRTUNQChain, a neuro-symbolic framework that combines BERT embeddings with spatial logic constraints for question-answering over spatial language. The system uses the DomiKnowS framework to enforce compositional reasoning rules during training, improving accuracy on spatial reasoning benchmarks.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/HLR/SpaRTUNQChain",
      "Primary language / framework": "Python / PyTorch, DomiKnowS",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Notes on reproduction": " Required manual setup: creating output directories (Models/, Results/, logs/), installing spacy language model (en_core_web_sm), and creating symlink for DataSet/ directory. Data downloaded successfully from Google Drive. Preliminary testing (1 epoch, 500 samples) achieved 53.8% dev accuracy, confirming code functionality. Full 8-epoch training requires ~2 hours on A100 GPU. No major reproducibility blockers identified.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "No - Goto Section 8",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Evaluation Datasets (for other) specify here:": "TuningSQA - Spatial reasoning question-answering dataset with compositional spatial relations",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "- BERT baseline (no constraints)\n- Primal-Dual method\n- Sampling Loss method\n- DomiKnowS framework variants\n- Ablations on constraint types (symmetric, reverse, transitive relations)",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "Unable to calculate - full reproduction not completed. Preliminary 1-epoch test: 53.8% dev accuracy (baseline performance established).",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "- Accuracy computed on dev set after each epoch\n- Code uses sklearn metrics (accuracy_score, precision_score, recall_score, f1_score)\n- Constraint satisfaction rate also reported\n- Results written to training.txt file\n- No averaging across multiple runs\n- Single label warnings in sklearn suggest some batches have homogeneous predictions",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper presents SpaRTUNQChain, a neuro-symbolic framework integrating BERT embeddings with DomiKnowS logic constraints for spatial reasoning, with publicly available code and data that successfully executes and demonstrates functional reproducibility of the proposed compositional reasoning approach.",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Code successfully reproduced on Zaratan HPC with A100 GPU. Manual setup required: creating output directories (Models/, Results/, logs/), installing spacy model (en_core_web_sm-3.7.1), and symlinking DataSet/ directory. Preliminary 1-epoch test confirmed functionality (53.8% dev accuracy on 500 samples). Full 8-epoch training requires ~2 hours compute time but was not completed due to time constraints. No fundamental reproducibility blockers identified - all dependencies install correctly, data downloads successfully, and code executes without errors. Documentation could be improved with explicit directory setup instructions and conda environment YAML file. No LICENSE file present in repository.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "unknown",
      "nsai_domain": "unknown",
      "application_area_original": "unknown",
      "application_area": "unknown",
      "task_type_original": "unknown",
      "task_type": "unknown",
      "symbolic_representation_original": "unknown",
      "symbolic_representation": "unknown",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "unknown",
      "integration_strategy": "unknown",
      "knowledge_source_original": "unknown",
      "knowledge_source": "unknown",
      "model_family_original": "unknown",
      "model_family": "unknown",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "publication_year": "2024.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242086150",
    "title": "Neuro-ConceptualArtificialIntelligence:IntegratingOPMwithDeep LearningtoEnhanceQuestionAnsweringQuality",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 16:07:21.831000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242086150",
      "Paper DOI / URL": "https://aclanthology.org/2025.neusymbridge-1.8.pdf",
      "Paper Title ": "Neuro-ConceptualArtificialIntelligence:IntegratingOPMwithDeep LearningtoEnhanceQuestionAnsweringQuality",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACL",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "introduceNeuro-ConceptualArtificial Intelligence(NCAI),aspecializationof the neuro-symbolicAI approach that integrates conceptual modeling usingObject-Process Methodology (OPM) ISO19450:2024with deeplearningtoenhancequestion-answering (QA)quality",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/kangxin/NCAI",
      "Primary language / framework": "Python scripts with OpenAI GPT-4o API for inference and HuggingFace BLEURT for evaluation; standard Python tooling (requirements.txt + shell script).",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "Included in the same GitHub repo: data/qa_pairs.json, data/q.json, data/k_qa_pairs.json, etc",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "knowledge representation, reasoning transparency, question answering",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "systems engineering, conceptual modeling, multi-hop reasoning QA",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "multi-hop question answering, explanation / rationale generation, transparency evaluation",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural architecture type(s) ": "LLM",
      "Neural architecture type(s) (for other) specify here:": "OpenAI GPT",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Uses GPT-4o version o1-preview-2024-09-12; underlying model release date is not explicitly reported in the paper, but version string suggests 2024-09-12",
      "Prompting strategy (if applicable)": "few‑shot, Few‑shot (N‑shot), Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "they perform in-context learning with example QA pairs in the prompt",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "Generated text answers reference OPM elements and are then matched against the symbolic OPM model to compute transparency precision/recall/F1; effectively, the neural model consumes symbolic OPL knowledge and outputs text that is parsed back into symbolic elements for evaluation.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Object-Process Methodology (OPM, ISO 19450) models created with OPCloud.",
      "Link to Existing symbolic project used (if applicable) ": "OPM conceptual modeling and OPCloud tool as referenced in the paper’s related work (e.g. Dori 2002; Dori et al. 2016; Dori et al. 2018).",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Other – OPM conceptual models and their textual Object-Process Language (OPL) representation, including objects, processes, states, and links between them.",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Reasoning / inference engine (for other) specify here:": "the OPL knowledge base is static and consumed by the LLM; reasoning is done by GPT-4o conditioned on the OPM-derived OPL.",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "Example of a rule / triple / formula (copy from paper)": "Heuristic changes from documented & shared to theoretically backed through Testing & Refining, Pattern Emerging & Recognizing, Effectiveness Validating, and Theoretical Backing.",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "PCloud software for OPM modeling; symbolic knowledge is stored as plain-text OPL files (k_opl.txt, opm_elements.txt)",
      "What are the key findings of the study (1-4 dot points)?": "OPM-based QA (OPM-QA) significantly outperforms natural-language QA (NL-QA) on Loose and Strict Accuracy and all ROUGE metrics, with p < 0.001 in each case. \n\nBLEURT and GPT-Judge scores indicate higher semantic fidelity and factual/logical coherence for OPM-QA, though GPT-Judge improvements are not statistically significant at 0.05. \n\nNewly proposed transparency metrics (precision, recall, F1 over OPM elements) show much higher alignment between OPM-QA’s reasoning and the underlying conceptual model than NL-QA, with large, statistically significant gains. \n\nThe study demonstrates that embedding a conceptual OPM backbone into the prompt yields not only better answers but also more interpretable, verifiable reasoning paths.",
      "Author‑reported limitations": "Uses a relatively small, self-constructed dataset of 50 QA pairs; generalizability to larger and more complex real-world scenarios is untested.\n\nOnly evaluates on a QA task; applicability to other tasks (e.g., predictive modeling, real-time decision-making) is not yet demonstrated.\n\nGenerated OPM representations may still suffer from ambiguities and may require manual refinement or more advanced prompting/agentic patterns to ensure full syntactic correctness.\n\nFuture work is needed on larger public benchmarks, richer conceptual domains, improved prompt designs, and standardized benchmarks/metrics for reasoning transparency.",
      "Reviewer‑identified limitations / threats to validity": "No ablations on number/choice of in-context examples or on alternative LLMs; unclear how robust the gains are to prompt or model variations.\n\nTransparency metrics depend on a particular mapping from text back to OPM elements; any errors in that mapping could bias reported transparency scores.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, ROUGE (L / 1 / 2), BERTScore / MOVERScore / BLEURT / COMET, Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "GPT Judge Score (LLM-based rating of factual/logical quality) and Transparency Precision, Transparency Recall, Transparency F1 over OPM elements.",
      "Split / Protocol": "Few‑shot (N‑shot prompting / small labeled set)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Evaluation assets provided (for other) specify here:": "Custom few-shot in-context evaluation on a 50-question dataset with 5 example QA pairs in the prompt.",
      "Datasets used for Evaluation ": "Other (specify below)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "presents a clearly neuro-symbolic QA system that integrates explicit OPM conceptual models with an LLM",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "knowledge representation, reasoning transparency, question answering",
      "nsai_domain": "knowledge representation",
      "application_area_original": "systems engineering, conceptual modeling, multi-hop reasoning QA",
      "application_area": "systems engineering",
      "task_type_original": "multi-hop question answering, explanation / rationale generation, transparency evaluation",
      "task_type": "multi-hop question answering",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "unknown",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2025.0",
      "venue_raw": "ACL",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242086133",
    "title": "LLMMeetsBoundedModelChecking: Neuro-symbolic Loop Invariant Inference",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 17:34:02.004000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242086133",
      "Paper DOI / URL": "https://dl-acm-org.proxy-um.researchport.umd.edu/doi/pdf/10.1145/3691620.3695014",
      "Paper Title ": "LLMMeetsBoundedModelChecking: Neuro-symbolic Loop Invariant Inference",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": " IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "proposes LaM4Inv, a neuro-symbolic framework that combines large language models (Llama-3-8B, GPT-3.5, GPT-4, GPT-4-Turbo) with bounded model checking (ESBMC + SMT solvers) to automatically infer loop invariants for C programs. It evaluates LaM4Inv on an expanded benchmark of 316 loop-invariant problems, showing large gains in the number of verified loops compared to classical invariant generators and recent LLM-based baselines.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/SoftWiser-group/LaM4Inv",
      "Primary language / framework": "SMT, C, Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "composite benchmark released as part of the repo",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "5",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "Original repo was Windows-only and assumed a local Ollama server for Llama-3, and hard-coded Windows paths for the ESBMC binary. To reproduce the LLama results, we had to:\n\nrewrite GPT_chat/Llama3chat.py to use HuggingFace Transformers with locally downloaded Llama-3-8B-Instruct weights.\n\nadd a runtime subprocess patch + wrapper scripts to normalize .\\windows-release\\bin\\esbmc.exe paths to Linux paths and route through the actual ESBMC binary\n\nupdate the environment to PyTorch 2.1+ / CUDA 12.1 instead of legacy PyTorch 1.7.1.\n– After these fixes, all three Llama configurations (baseline prompt, no-BMC full prompt, full BMC) and GPT-4-Turbo results were successfully reproduced with all 316 benchmarks processed and the same #solved counts",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "program verification, software verification, loop invariant inference, neuro-symbolic reasoning, bounded model checking",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "software engineering, program analysis, formal methods, static analysis",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "loop invariant generation, program verification, code reasoning, SMT-based constraint checking",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "Yes",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural model name & family (for other) specify here:": "– Llama-3-8B (Meta LLaMA family, instruct variant) – GPT-3.5-Turbo – GPT-4 – GPT-4-Turbo",
      "Neural architecture type(s) ": "LLM",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "8B for llama, not reported for GPT ",
      "Prompting strategy (if applicable)": "zero‑shot, Iterative / Recursive prompting, Prompt Chaining / Pipelines, Tool‑augmented prompting (with API calls)",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Alignment / Safety Filters Applied (for other) specify here:": "no filters applied for LLama",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable, Hosted API only",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module, Generated text parsed into symbols/rules, Bidirectional exchange (neural ↔ symbolic loop)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "LLMs output candidate loop invariants as C-style assert(...) statements. These are parsed into logical predicates and checked by SMT/BMC. SMT/BMC counterexamples and failure types are then fed back into subsequent prompts to refine the invariants.",
      "Existing symbolic project used (if applicable) ": "SAT/SMT solvers (MiniSAT, Z3, CVC5) used as the symbolic core, Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "ESBMC (an industrial-strength bounded model checker for C/C++), used to filter candidate predicates and check loop invariants; SMT solvers (e.g., Z3, cvc5) are used underneath for satisfiability.",
      "Link to Existing symbolic project used (if applicable) ": "ESBMC: https://esbmc.org/ (not explicitly linked in repo but standard tool) Z3: https://github.com/Z3Prover/z3",
      "Symbolic representation(s)": "First‑order / predicate logic, Constraint satisfaction / SMT formulas, Domain‑specific languages (DSLs) / program sketches, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "C programs are translated into CFGs and SMT-LIB2 formulas encoding preconditions, loop conditions, and postconditions; loop invariants are symbolic assertions over program variables.",
      "Reasoning / inference engine": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "ESBMC orchestrates bounded model checking over the C program + candidate invariants; SMT solvers check the three loop invariant conditions (reachability, inductiveness, provability) and produce counterexamples.",
      "Source of symbolic knowledge": "Extracted automatically from text (IE / OpenIE / pattern mining), Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Automatically pruned/regularized for consistency, Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "The set of candidate predicates is iteratively pruned as incorrect predicates are eliminated by SMT/BMC; verified predicates are reassembled into stronger invariants. No permanent symbolic KB learning beyond each run.",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Integration strategy with neural part (for other) specify here:": "The system implements a “query–filter–reassemble” loop: LLM queries produce candidate invariants; BMC/SMT filter; verified predicates are reassembled and used to prompt the LLM again with counterexamples until a valid invariant or limits are reached.",
      "Example of a rule / triple / formula (copy from paper)": "(hi - lo == 2 * mid) ∧ (mid >= 0)\nor more generally outputs in the format assert(<invariant_expression>);",
      "Tooling / libraries for symbolic side": "Z3 / CVC5 / Boolector (SMT solvers), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "ESBMC as BMC tool; CVC5 used as one of the baseline invariant checkers.",
      "What are the key findings of the study (1-4 dot points)?": "LaM4Inv, combining LLMs with bounded model checking, solves 309/316 loop invariant benchmarks, substantially outperforming classical invariant generators (best baseline ~219/316).\n\nBoth the tailored loop-invariant prompts and the BMC-based predicate filtering are critical: ablations show reduced performance when either is removed.\n\nDifferent LLMs yield different performance, with GPT-4/GPT-4-Turbo and Llama-3-8B all benefiting from the neuro-symbolic pipeline relative to simple baseline prompts.\n\nRobustness experiments across 5 runs show that the BMC predicate filter reduces variance in the number of solved problems relative to No-BMC settings, mitigating LLM randomness.",
      "Author‑reported limitations": "SMT solvers have limited capability with complex arithmetic (multiplication, division, bit-level, power operations), constraining some invariants.\n\nBenchmarks, though expanded to 316, are still relatively small and toy-like compared with real industrial programs.\n\nDataset size and simplicity make LLM fine-tuning difficult and may not fully capture real-world complexities.\n\nDifficulty handling disjunctive normal form (DNF) invariants and more complex logical structures is acknowledged.",
      "Reviewer‑identified limitations / threats to validity": "Codebase was originally Windows-only, with hard-coded Windows paths and assumptions about local GUI/ESBMC setup; cross-platform reproducibility required non-trivial engineering.\n\nLlama3 integration relied on running an Ollama server at localhost:11434, which is incompatible with many HPC environments and was not documented as a reproducibility constraint.\n\nNo formal statistical significance tests; only descriptive comparisons and a single robustness experiment.\n\nReliance on proprietary GPT models (hosted APIs) may affect long-term reproducibility if APIs change or disappear.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "4.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "– Number of solved benchmarks (#problems where a correct loop invariant is found and verified). – Breakdown of solved benchmarks by category (“All”, “None”, “Only”, “Total”). – Average number of LLM proposals per benchmark. – Average runtime per benchmark (seconds). – For robustness experiments: mean and standard deviation of #solved.",
      "Split / Protocol": "Zero‑shot (no task‑specific training), Other (specify below)",
      "Split / Protocol (for other) specify here:": "All 316 benchmarks are treated as test problems; LLMs are not trained, only prompted zero-shot.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "LaM4Inv benchmark”: 316 loop-invariant problems composed of: – 133 programs from the Code2Inv benchmark. – 84 manually crafted problems inspired by 2019 SyGuS competition. – 99 problems from 2024 SV-COMP loops benchmarks. Packaged as C + CFG JSON + SMT-LIB2 and provided in Benchmarks/.",
      "Link to evaluation dataset used (if other)": "ncluded in main repo: https://github.com/SoftWiser-group/LaM4Inv → Benchmarks/",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "– LoopInvGen\n– CVC5\n– Code2Inv\n– LIPUS\n– CLN2INV\n– G-CLN\n– ESBMC\n– LEMUR (LLM-based invariant tool using GPT-4)",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Timeout is 600 seconds per benchmark with a hard cap of 50 proposals per problem; unsolved after timeout or exhausted proposals counts as failure.\n\nLLM temperature and penalties set to 0 to reduce randomness; but GPT-series APIs are still non-deterministic unless seed is enforced (not discussed).\n\nAverage runtime includes LLM calls and symbolic solving.\n\nRobustness metrics (means/stds) are over 5 independent runs with different stochastic outcomes.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "LaM4Inv is a clearly neuro-symbolic loop invariant inference system",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "program verification, software verification, loop invariant inference, neuro-symbolic reasoning, bounded model checking",
      "nsai_domain": "program verification",
      "application_area_original": "software engineering, program analysis, formal methods, static analysis",
      "application_area": "software engineering",
      "task_type_original": "loop invariant generation, program verification, code reasoning, SMT-based constraint checking",
      "task_type": "loop invariant generation",
      "symbolic_representation_original": "First‑order / predicate logic, Constraint satisfaction / SMT formulas, Domain‑specific languages (DSLs) / program sketches, Other (specify below)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "reasoning_engine": "SMT solvers (Z3",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs, Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Extracted automatically from text (IE / OpenIE / pattern mining), Generated synthetically (procedural rule generation)",
      "knowledge_source": "Extracted automatically from text (IE / OpenIE / pattern mining)",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "1-10B",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "4.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": " IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "venue_canonical": "IEEE",
      "venue_group_bin": "IEEE journals/proceedings",
      "venue_group_plot": "IEEE journals/proceedings",
      "venue_clean": "ieee",
      "venue_norm": "IEEE journals/proceedings",
      "venue_group": "IEEE journals/proceedings",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084891",
    "title": "Enhancing SQL Query Generation with Neurosymbolic Reasoning",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 22:05:35.414000",
      "Email Address": "bhuvan9@umd.edu",
      "Reviewer Name": "Bhuvanesh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084891",
      "Paper DOI / URL": "https://arxiv.org/abs/2408.13888",
      "Paper Title ": "Enhancing SQL Query Generation with Neurosymbolic Reasoning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ArXiV",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "New framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Find a way to use language models to generate SQL queries. They introduce a new tool called Xander which helps ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/henrijsprincis/Xander",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "f09547752a6eec77074b5f259a2d36ee08c59ebf",
      "If yes: Provide link": "https://github.com/henrijsprincis/Xander/commit/f09547752a6eec77074b5f259a2d36ee08c59ebf",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logic driven language generation",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "SQL, databases",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "SQL generation",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Generating SQL queries for applications",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Code, T5 / FLAN‑T5 / UL2",
      "Neural architecture type(s) ": "LLM, Simple MLP",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "Depends on model used. ",
      "Release date": "2024-08-24 00:00:00",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "What are the key findings of the study (1-4 dot points)?": "We explore unifying symbolic and neural reasoning ap-\nproaches for SQL query generation. In particular, we use\nLMs to generate SQL queries from natural language de-\nscriptions and examples, but guide the exploration of the\nsolution space using two symbolic modules: (i) a symbolic\nchecker that verifies the correctness of incomplete queries,\nand (ii) a repair module which uses fuzzing to fix proposed-\nbut-incorrect complete queries.\n(2) We investigate the use of normalization in code generation\nby introducing Normalized SQL3, which increases LM’s\naccuracy out of the box via finetuning, and can be easily\nverified during generation.\n(3) We implemented a prototype tool called Xander, and per-\nformed the following experiments:\n(a) Runtime and accuracy evaluation when using the\nneurosymbolic tool Xander with various open-source\nLMs.\n(b) Ablation study on which parts of Xander bring the\ngreatest improvements to accuracy and runtime.\n(c) Runtime and accuracy comparison between a neural\nand symbolic approach for detecting semantic, syntax\nand runtime query errors.",
      "Author‑reported limitations": "* Symbolic reasoning may be less effective at improving Huge LMs that make very few mistakes. \n* Imperfect dataset\n* Examples are not always easy to provide. ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "7.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy",
      "Split / Protocol": "Not reported / unclear",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Partial",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "CodeTF, BART, CodeGen, Microsoft-Phi, ChatGPT 3.5",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "I think the paper is relevant to how NeSy can be used in the place of SQL generation. The study was well documented and mostly reproducible. I think this is a valid entry for our research project. \n",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "0.0",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "logic driven language generation",
      "nsai_domain": "logic driven language generation",
      "application_area_original": "SQL, databases",
      "application_area": "SQL",
      "task_type_original": "SQL generation",
      "task_type": "SQL generation",
      "symbolic_representation_original": "unknown",
      "symbolic_representation": "unknown",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "unknown",
      "integration_strategy": "unknown",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Code, T5 / FLAN‑T5 / UL2",
      "model_family": "Code",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "7.0",
      "publication_year": "2024.0",
      "venue_raw": "ArXiV",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084661",
    "title": "Neuro-symbolic Natural Logic with Introspective Revision for Natural Language Inference",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-25 22:53:44.647000",
      "Email Address": "bhuvan9@umd.edu",
      "Reviewer Name": "Bhuvanesh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084661",
      "Paper DOI / URL": "10.1162/tacl_a_00458",
      "Paper Title ": "Neuro-symbolic Natural Logic with Introspective Revision for Natural Language Inference",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Transactions of the Association for Computational Linguistics, Volume 10",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "New framework ",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Presents a NeSy framework to integrate natural logic with NNs to do natural language inference. They use RL to help guide this natural logic. Overall this improves the intuitive inference understandability of humans. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/feng-yufei/NS-NLI?tab=readme-ov-file",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "b6642232ddfcacebe77cf2720c09daed88ce8ca2",
      "If yes: Provide link": "https://github.com/feng-yufei/NS-NLI/commit/b6642232ddfcacebe77cf2720c09daed88ce8ca2",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "No",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logic driven language",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "natural logic, interpretability ",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural architecture type(s) ": "Simple MLP",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Local Relation Modeling ",
      "Source of symbolic knowledge": "Not reported / unclear",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "The NeSy framework worked in allowing for natural logic inference to be possible. ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "7.0",
      "Primary task metrics reported ": "Accuracy, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Not reported / unclear",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Evaluation Datasets (for other) specify here:": "SNLI, HELP, MonLI, NatLog-2hop",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Partial",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "ESIM, BERT-base, GPT-2, ",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper meets all the criteria for the reproducibility study. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "0.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "logic driven language",
      "nsai_domain": "logic driven language",
      "application_area_original": "natural logic, interpretability",
      "application_area": "natural logic",
      "task_type_original": "unknown",
      "task_type": "unknown",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Not reported / unclear",
      "knowledge_source": "Not reported / unclear",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "7.0",
      "publication_year": "2022.0",
      "venue_raw": "Transactions of the Association for Computational Linguistics, Volume 10",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084532",
    "title": "CORRPUS: Code-based Structured Prompting for Neurosymbolic Story Understanding",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-26 01:03:14.261000",
      "Email Address": "bhuvan9@umd.edu",
      "Reviewer Name": "Bhuvanesh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084532",
      "Paper DOI / URL": "https://doi.org/10.18653/v1/2023.findings-acl.832",
      "Paper Title ": "CORRPUS: Code-based Structured Prompting for Neurosymbolic Story Understanding",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Findings of the Association for Computational Linguistics: ACL 2023",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "New Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "CoRRPUS shows the usefuleness of code-based symbolic representations for enabling LLMs to perofrm better on story reasoning tasks. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/dong-river/CoRRPUS",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "ac9f5e691c0c269fd360aeb61b76b12ee5660dc6",
      "If yes: Provide link": "https://github.com/dong-river/CoRRPUS/commit/ac9f5e691c0c269fd360aeb61b76b12ee5660dc6",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logic driven language",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "code-based, story reasoning tasks, symbolic representations",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "story reasoning tasks",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "Codex, Code-LLM ",
      "Neural architecture type(s) ": "LLM",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Not reported / unclear",
      "Reasoning / inference engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Not discussed / unclear",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "Code-based prompting can leverage symbolic information to perform multi-step logical reasoning, which is better than Natural Language prompting. \n\nCode-based prompting can extract structured information from complicated stories using 1-shot prompting. ",
      "Author‑reported limitations": "Only performed on two tasks. \n\nRobustness to all tasks is questionable. \n\nQuestion is assumed to be same across all storeis. So this may not be accurate assumption. \n\nDue to cost, they couldn't run all of GPT-3 experiments. ",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "LLMs have been trained on a large corpus of data which can be misogynistic, hateful, racist, etc. so be careful. Output of CoRRPUS is not guaranteed to run nor is it guaranteed to be accurate. ",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, AUROC (ROC‑AUC)",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "GPT-3, Codex, COT, SI, DS",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This experiment shows the value of a NeSy framework in reasoning on story-like corpuses. Additionally, it was easily reproducible with the instructions given. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "logic driven language",
      "nsai_domain": "logic driven language",
      "application_area_original": "code-based, story reasoning tasks, symbolic representations",
      "application_area": "code-based",
      "task_type_original": "story reasoning tasks",
      "task_type": "story reasoning tasks",
      "symbolic_representation_original": "Not reported / unclear",
      "symbolic_representation": "Not reported / unclear",
      "reasoning_engine_original": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "reasoning_engine": "No explicit reasoning engine (symbols stored but not reasoned over)",
      "integration_strategy_original": "unknown",
      "integration_strategy": "unknown",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "Findings of the Association for Computational Linguistics: ACL 2023",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084358",
    "title": "MDD-5k: a new diagnostic conversation dataset for mental disorders synthesized via neuro-symbolic LLM agents",
    "year": "2025.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-26 01:32:31.144000",
      "Email Address": "bhuvan9@umd.edu",
      "Reviewer Name": "Bhuvanesh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084358",
      "Paper DOI / URL": "https://doi.org/10.1609/aaai.v39i24.34763",
      "Paper Title ": "MDD-5k: a new diagnostic conversation dataset for mental disorders synthesized via neuro-symbolic LLM agents",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2025",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "AAAI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Dataset, Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Introduces a new framework to generate a dataset of diagnostic conversations between a patient and a doctor. It also provides a dataset with 5k high-quality long conversations with diagnosis results and treatment options. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/lemonsis/MDD-5k",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "e161d2b94ae6a0d4418a78c86a34cbc016e50cd2",
      "If yes: Provide link": "https://github.com/lemonsis/MDD-5k/commit/e161d2b94ae6a0d4418a78c86a34cbc016e50cd2",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/lemonsis/MDD-5k",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "Yes",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logical driven language",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "diagnostic, dataset, conversation dataset, clinical, medical ",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "medical and clinical diagnosis",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Not reported / unclear",
      "Neural architecture type(s) ": "LLM",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "Existing symbolic project used (if applicable) ": "Not reported / unclear",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Dynamic Diagnosis Tree",
      "Reasoning / inference engine": "Not reported / unclear",
      "Source of symbolic knowledge": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "What are the key findings of the study (1-4 dot points)?": "* New dataset with significantly more data on diagnostic conversations. \n* Simple tool to generate more data as needed. ",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Notes that the health data is sensitive and that data masking techniques were used to protect privacy.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Human rating (Likert / pairwise preference)",
      "Split / Protocol": "Not reported / unclear",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "No",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "6 categories. number of human raters is not listed. ",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This is a novel piece of research that was able to be reproduced. I was not able to check the dataset as it is currently under review for ethics. However, I still feel this paper is worth including. ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "3.0",
      "nsai_domain_original": "logical driven language",
      "nsai_domain": "logical driven language",
      "application_area_original": "diagnostic, dataset, conversation dataset, clinical, medical",
      "application_area": "diagnostic",
      "task_type_original": "medical and clinical diagnosis",
      "task_type": "medical and clinical diagnosis",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Not reported / unclear",
      "reasoning_engine": "Not reported / unclear",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Converted from neural outputs (e.g.",
      "model_family_original": "Not reported / unclear",
      "model_family": "Not reported / unclear",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "1",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2025.0",
      "venue_raw": "AAAI",
      "venue_canonical": "AAAI",
      "venue_group_bin": "AAAI family",
      "venue_group_plot": "AAAI family",
      "venue_clean": "aaai",
      "venue_norm": "AAAI family",
      "venue_group": "AAAI family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084050",
    "title": "ImageEye: Batch Image Processing using Program Synthesis",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-26 02:11:43.312000",
      "Email Address": "itamraka@umd.edu",
      "Reviewer Name": "Ishan",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084050",
      "Paper DOI / URL": "https://arxiv.org/pdf/2304.03253",
      "Paper Title ": "ImageEye: Batch Image Processing using Program Synthesis",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "PLDI",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Batch editing of images such as cropping out a desired object/person in a batch of 100+ images has not been an easy task. The paper describes a neuro symbolic approach to generate programs from user demonstrations that perform such tasks. They show the program can automate 96% of these tasks. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/celestebarnaby/ImageEye",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "Yes",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "50 benchmark tasks * 3 datasets * 20 images * 10 rounds = 3000",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      "Train/validation/test split described?": "No",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "MIT license",
      "Notes on reproduction": "attempting to build docker image will fail on first attempt. modify docker file to add apt-get pyparsing. ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "automatic programming, program synthesis, neuro-symbolic synthesis",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "computer vision, batch image editing ",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "batch image editing ",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Possible to batch edit a large number of images if a handful of human demonstrations are provided such as cropping out objects or interest. ",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family (for other) specify here:": "Amazon Rekognition ",
      "Neural architecture type(s) ": "Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Unknown. they mention computer vision primitives used from Amazon Rekognition. It alludes to some object detection model. ",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "unkn",
      "Release date": "2023-06-14 00:00:00",
      "Prompting strategy (if applicable)": "zero‑shot",
      "Prompting strategy (if applicable) (for other) specify here:": "No finetuning. Model is being used off the shelf as-is. ",
      "How neural outputs are used by the symbolic part ": "Text passed to symbolic module",
      "Symbolic representation(s)": "Domain‑specific languages (DSLs) / program sketches, Algebraic specifications / term‑rewriting systems",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Induced via ILP / rule mining / program synthesis, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Static (fixed once authored/imported), Human‑in‑the‑loop edits during experimentation",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "CVC5 was tried but was deemed insufficient",
      "What are the key findings of the study (1-4 dot points)?": "96% automation success with average time of 1.1 seconds across 50 diverse batch image editing tasks. 4 human demonstrations per task needed. neuro-symbolic integration enables selective editing eg. blur faces not playing guitar; which was previously impossible with neural approaches. ",
      "Author‑reported limitations": "The symbolic component is only as good as the accuracy of the neural models. Difficult to diagnose failures as human verification is costly. No 3D reasoning capabilities. Limited to the symbolic rules fixed in DSL. ",
      "Reviewer‑identified limitations / threats to validity": "Evaluation is done on small scale data only 3 domains (wedding: 121 images, receipts: 38 images, and objects 608 images) ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy, Exact Match (EM), Human rating (Likert / pairwise preference), Energy / FLOPs / latency / throughput, Confidence intervals (CI) / standard error bars",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Checkpoints / weights for evaluation, Docker / Conda / container to reproduce metrics",
      "Datasets used for Evaluation ": "Custom dataset (introduced in paper)",
      "Evaluation Datasets (for other) specify here:": "wedding, receipts, and objects. total 767 images. ",
      "Link to evaluation dataset used (if other)": "https://zenodo.org/records/7810841",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "EUSolver, CVC5. No goal inference, no partial evaluation, no equivalence reduction ablations ran. ",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "0",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It demonstrates a novel neuro symbolic approach to solve a real world task and codebase is simple enough to be adapted for future research. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "0.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "automatic programming, program synthesis, neuro-symbolic synthesis",
      "nsai_domain": "automatic programming",
      "application_area_original": "computer vision, batch image editing",
      "application_area": "computer vision",
      "task_type_original": "batch image editing",
      "task_type": "batch image editing",
      "symbolic_representation_original": "Domain‑specific languages (DSLs) / program sketches, Algebraic specifications / term‑rewriting systems",
      "symbolic_representation": "Domain‑specific languages (DSLs) / program sketches",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Induced via ILP / rule mining / program synthesis, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "unknown",
      "model_family": "unknown",
      "param_scale_band": "unknown",
      "licence_category": "MIT",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "PLDI",
      "venue_canonical": "PLDI",
      "venue_group_bin": "PLDI",
      "venue_group_plot": "Other journals (CS)",
      "venue_clean": "pldi",
      "venue_norm": "PLDI",
      "venue_group": "Other journals (CS)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084309",
    "title": "ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-26 02:15:06.146000",
      "Email Address": "bhuvan9@umd.edu",
      "Reviewer Name": "Bhuvanesh",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084309",
      "Paper DOI / URL": "https://arxiv.org/pdf/2210.03849",
      "Paper Title ": "ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "EMNLP",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Dataset",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Introduces a new dataset to study chain of numerical reasoning in question-answering. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/czyssrs/ConvFinQA?tab=readme-ov-file",
      "Primary language / framework": "Python, Json",
      "Commit / tag / release hash used": "cf3eed2d5984960bf06bb8145bcea5e80b0222a6",
      "If yes: Provide link": "https://github.com/czyssrs/ConvFinQA/commit/cf3eed2d5984960bf06bb8145bcea5e80b0222a6",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "https://github.com/czyssrs/ConvFinQA?tab=readme-ov-file",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Unknown",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "logic driven language",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "finance, question-answering, conversation",
      "Real‑world application claimed?": "No",
      "What are the key findings of the study (1-4 dot points)?": "New dataset that enables further training on existing LLMs and NeSy systems. ",
      "Author‑reported limitations": "The two construction methods presented here do not exhaust all possible real-world conversations. \n\nDue to payment constraints, they do not do extensive prompt engineering. ",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Dataset Collection Process and Conditions. IRB (Institutional Review Board) Approval.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "8.0",
      "Primary task metrics reported ": "Accuracy",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "This paper primarily introduces a dataset and mechanism for generating more data. This is available in the repo and relevant to NeSy. ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "logic driven language",
      "nsai_domain": "logic driven language",
      "application_area_original": "finance, question-answering, conversation",
      "application_area": "finance",
      "task_type_original": "unknown",
      "task_type": "unknown",
      "symbolic_representation_original": "unknown",
      "symbolic_representation": "unknown",
      "reasoning_engine_original": "unknown",
      "reasoning_engine": "unknown",
      "integration_strategy_original": "unknown",
      "integration_strategy": "unknown",
      "knowledge_source_original": "unknown",
      "knowledge_source": "unknown",
      "model_family_original": "unknown",
      "model_family": "unknown",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "8.0",
      "publication_year": "2022.0",
      "venue_raw": "EMNLP",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084606",
    "title": "Motion Question Answering via Modular Motion Programs",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-26 12:27:33.272000",
      "Email Address": "itamraka@umd.edu",
      "Reviewer Name": "Ishan",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084606",
      "Paper DOI / URL": "https://arxiv.org/abs/2305.08953",
      "Paper Title ": "Motion Question Answering via Modular Motion Programs",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ICML",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Proposes a neuro symbolic framework to reason about motion sequences in human actions via symbolic reasoning and modular design. They say that it grounds motion through learning motion concepts, attribute neural operators and temporal relations. The task they chose is human motion QA for evaluate their NSPose method. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/markendo/HumanMotionQA/tree/master/NSPose",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3",
      "Variance / error bars shown?": "Yes",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown ",
      "Notes on reproduction": "It took significant effort (half a day) to get the dataset downloaded, organized into expected directory structure, and resolve the environment conflicts before I could finally run the dataset generation script. After that another environment needed to be setup to run the NSPose code. A lot of manual edits needed to be made in order to get this codebase running. ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro symbolic visual reasoning, program synthesis, concept learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "human motion question answering, motion analysis, action recognition, temporal reasoning, video understanding, activity recognition",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "motion question answering, motion classification",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "To build models that can perceive and interact with humans in the real world. ",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "Neural architecture type(s) ": "CNN / ConvNet, RNN, GNN (Graph Neural Network), Simple MLP",
      "Release date": "2023-05-17 00:00:00",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints, Bidirectional exchange (neural ↔ symbolic loop)",
      "Symbolic representation(s)": "Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Extracted automatically from structured data / logs, Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Learned/induced jointly during model training",
      "Integration strategy with neural part": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "Tooling / libraries for symbolic side": "Not reported / unclear",
      "What are the key findings of the study (1-4 dot points)?": "NSPose outperforms all baselines showing need for neuro symbolic formulations for the task. Weak supervision from question-answer pairs alone is sufficient to identify action boundaries and temporal relationships. ",
      "Author‑reported limitations": "requires pre defined motion programs for each question type. Segment based action prediction rather than frame based. Struggles with body part queries in between relations. Long transition periods can disrupt temporal relations. ",
      "Reviewer‑identified limitations / threats to validity": "No computation resources requirements mentioned. Small dataset size (1109 motion sequences/ 2557 questions) ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Full",
      "Primary task metrics reported ": "Accuracy",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Checkpoints / weights for evaluation, Docker / Conda / container to reproduce metrics",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "AMASS + BABEL -> BABEL-QA",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Partial",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "0.09",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Paper reports 0.578 test accuracy but got 0.526",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "It is an interesting neuro-symbolic approach that uses differentiable program execution with modular neural operators to perform complex multi-step reasoning over motion sequences. Can form the basis for further action understanding research. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Need to create account on three different dataset/model providing websites and manually download the sub datasets to run the code. Takes a lot of hours. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.09",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "3.0",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "neuro symbolic visual reasoning, program synthesis, concept learning",
      "nsai_domain": "neuro symbolic visual reasoning",
      "application_area_original": "human motion question answering, motion analysis, action recognition, temporal reasoning, video understanding, activity recognition",
      "application_area": "human motion question answering",
      "task_type_original": "motion question answering, motion classification",
      "task_type": "motion question answering",
      "symbolic_representation_original": "Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Domain‑specific languages (DSLs) / program sketches",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Differentiable logic / differentiable constraints (semantic loss, t‑norms, etc.), Joint / co‑training of neural and symbolic modules",
      "integration_strategy": "Differentiable logic / differentiable constraints (semantic loss",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Extracted automatically from structured data / logs, Generated synthetically (procedural rule generation)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception), Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2023.0",
      "venue_raw": "ICML",
      "venue_canonical": "ICML",
      "venue_group_bin": "ICML",
      "venue_group_plot": "ICML",
      "venue_clean": "icml",
      "venue_norm": "ICML",
      "venue_group": "ICML",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242086137",
    "title": "MILE: Memory-Interactive Learning Engine for Neuro-Symbolic Solutions to Mathematical Problems",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-11-27 00:13:02.409000",
      "Email Address": "martiros@umd.edu",
      "Reviewer Name": "Vladimir",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242086137",
      "Paper DOI / URL": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10680497",
      "Paper Title ": "MILE: Memory-Interactive Learning Engine for Neuro-Symbolic Solutions to Mathematical Problems",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "IEEE Xplore",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "MILE is a neuro-symbolic math word problem solver that predicts formulas using a memory-based decoder instead of tree-structured decoding, letting it handle more complex computation graphs. It beats existing methods on Math23K by learning formulas as rules.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://ieeexplore.ieee.org/abstract/document/10680497",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "3cc9987f505e6dc7541c1b196f99f7357424f16d",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "No",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "unknown",
      "Notes on reproduction": "Code timed out around 85%, with 7 hours in running, but the accuracy plateau-ed at 84.1% which is similar to the results in the paper.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Mathematical reasoning, Formula prediction, Memory-augmented neural networks, Sequence-to-sequence learning",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "Math word problem solving, Educational AI, Automated reasoning, Natural language understanding",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "Sequence generation, Classification, Symbolic regression, Question answering",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA), RNN/LSTM/GRU family, Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), LSTM, GNN (Graph Neural Network), Simple MLP",
      "Release date": "2024-09-16 00:00:00",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Wikipedia / encyclopedic corpora (all language editions), Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "Math23K",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "Symbolic representation(s)": "Domain‑specific languages (DSLs) / program sketches",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Source of symbolic knowledge": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Math23K",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "fs = [(+, 4, 6), (+, R0, 8), (-, R1, 1), (×, R1, R2), (÷, R3, 2)]",
      "Tooling / libraries for symbolic side": "Custom in‑house engine (name below)",
      "Tooling / libraries for symbolic side (for other) specify here:": " Simple arithmetic evaluator in Python that executes formula terms sequentially",
      "What are the key findings of the study (1-4 dot points)?": "The Memory Embedding Pool enables the decoder to treat constants, numbers, and intermediate results uniformly, improving formula prediction.\nMILE with RoBERTa encoder achieves 85.2% accuracy on Math23K, outperforming prior methods.",
      "Author‑reported limitations": "Training difficulty due to complex decoding mechanism and operator-specific parameters, takes a while to run",
      "Reviewer‑identified limitations / threats to validity": "Only evaluated on Math23K, generalization to other datasets unclear. No variance analysis, no checkpoints.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "8.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "6.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "6.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy, Not reported / unclear",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), k‑fold cross‑validation (specify k)",
      "Evaluation assets provided (if yes / partial above) ": "No evaluation assets provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Math23K",
      "Link to evaluation dataset used (if other)": "https://github.com/evan-ak/mile/tree/master/data",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "DNS (Wang et al. 2017)\nT-RNN (Wang 2019)\nTreeDecoder (Liu et al. 2019)\nGTS (Xie & Sun 2019)\nGraph2Tree (Zhang et al. 2020)\nDeductReasoner (Jie et al. 2022)\nAblations: MILE with different encoders (LSTM, Graph, BERT, RoBERTa)\nAblations: With/without formula mutation",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "<0.5%",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Answer accuracy computed by executing predicted formula and comparing numerical result to ground truth. Paper should really specify the computing budget and provide checkpoints.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Paper presents a novel study, is relevant and recent, and can be partially reproduced.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.5",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "1.0",
      "nsai_domain_original": "Mathematical reasoning, Formula prediction, Memory-augmented neural networks, Sequence-to-sequence learning",
      "nsai_domain": "Mathematical reasoning",
      "application_area_original": "Math word problem solving, Educational AI, Automated reasoning, Natural language understanding",
      "application_area": "Math word problem solving",
      "task_type_original": "Sequence generation, Classification, Symbolic regression, Question answering",
      "task_type": "Sequence generation",
      "symbolic_representation_original": "Domain‑specific languages (DSLs) / program sketches",
      "symbolic_representation": "Domain‑specific languages (DSLs) / program sketches",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Imported from existing KBs or ontologies (e.g., WordNet, Wikidata, UMLS), Other (specify below)",
      "knowledge_source": "Imported from existing KBs or ontologies (e.g.",
      "model_family_original": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA), RNN/LSTM/GRU family, Graph Neural Networks (GCN, GAT, GraphSAGE, GraphTransformer)",
      "model_family": "BERT derivatives (BERT",
      "param_scale_band": "unknown",
      "licence_category": "unknown",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "6.0",
      "publication_year": "2024.0",
      "venue_raw": "IEEE Xplore",
      "venue_canonical": "IEEE",
      "venue_group_bin": "IEEE journals/proceedings",
      "venue_group_plot": "IEEE journals/proceedings",
      "venue_clean": "ieee",
      "venue_norm": "IEEE journals/proceedings",
      "venue_group": "IEEE journals/proceedings",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242085281",
    "title": "AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-12-01 12:40:55.194000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242085281",
      "Paper DOI / URL": "https://aclanthology.org/2022.acl-long.494.pdf",
      "Paper Title ": "AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ACL",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "present a neural-symbolic approach which, to predict an answer, passes messages over a graph representing logical relations between text units.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/nju-websoft/AdaLoGN",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "https://whyu.me/reclor/, https://github.com/lgw863/LogiQA-dataset",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache",
      "Notes on reproduction": "The main friction was environment setup (older transformers + tokenizers compatibility).\n\nOnce the conda environment was stabilized, evaluation using the provided checkpoints ran cleanly on both ReClor and LogiQA.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neural-symbolic reasoning, logical reasoning, machine reading comprehension",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "natural language processing, standardized-test QA, logical exam-style reasoning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "multiple-choice question answering, machine reading comprehension, logical reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), GNN (Graph Neural Network)",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "355M parameters",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Fine‑tuning / adaptation details  (for other) specify here:": "ReClor and LogiQA multiple-choice QA labels).",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Bidirectional exchange (neural ↔ symbolic loop)",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Graphene information extraction is used to derive rhetorical relations which are then mapped to logical relations.",
      "Symbolic representation(s)": "Propositional / Boolean logic rules, Logic programs (Horn clauses, Datalog)",
      "Symbolic representation(s) (for other) specify here:": "EDUs are nodes; edges encode logical relations such as implication (impl), negation (neg), conjunction (conj), disjunction (disj), reverse implication (rev), and unknown (unk).",
      "Reasoning / inference engine": "Custom in‑house rule/constraint engines",
      "Reasoning / inference engine (for other) specify here:": "Implements fixed inference rules (e.g., hypothetical syllogism, transposition, plus one custom rule) to extend the TLG.",
      "Source of symbolic knowledge": "Extracted automatically from text (IE / OpenIE / pattern mining)",
      "Source of symbolic knowledge (for other) specify here:": "Rhetorical relations from Graphene are mapped into logical relations; new relations are inferred using logic rules.",
      "Update / learning of symbols": "Learned/induced jointly during model training, Automatically pruned/regularized for consistency",
      "Integration strategy with neural part": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Joint / co‑training of neural and symbolic modules, Post‑hoc verification or logical consistency checking of neural outputs",
      "Example of a rule / triple / formula (copy from paper)": "If (ui → uj) and (uj → uk) hold, then derive (ui → uk)",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom graph reasoning implemented in Python, using graph libraries (e.g., DGL) rather than a standard logic engine.",
      "What are the key findings of the study (1-4 dot points)?": "AdaLoGN combines a RoBERTa-large encoder with a text logic graph over EDUs and iterative symbolic inference to improve logical reasoning in MRC.\n\nThe model achieves higher accuracy than previous graph-based baselines (e.g., DAGN) on ReClor, including on the “hard” subset, and on LogiQA.\n\nA subgraph-to-node message passing mechanism improves context–option interaction by aggregating over the entire context subgraph before updating option nodes.\n\nAblation studies show that both adaptive logical graph extension and subgraph-to-node message passing contribute substantially to performance gains.",
      "Author‑reported limitations": "Limited to reasoning over propositional-style logical relations between EDUs; cannot directly model more complex logical structures or world knowledge.\n\nPerformance is bounded by the quality of EDU segmentation and the Graphene-based mapping from rhetorical relations to logical relations.",
      "Reviewer‑identified limitations / threats to validity": "Heavy reliance on one specific IE pipeline and mapping scheme; robustness to alternative segmentations or noisy EDU extraction is not tested.\n\nEvaluation is limited to two datasets (ReClor and LogiQA) from a similar domain; generalization to other reasoning benchmarks remains untested.\n\nReporting uses best-of-N runs without error bars; reproducibility of training-time metrics beyond point estimates is not quantified.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "8.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "ReClor, LogiQA (public reasoning-based MRC datasets introduced by prior work)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Baselines: BERT-large, RoBERTa-large, XLNet-large, DAGN, Focal Reasoner, LReasoner and others reported in ReClor/LogiQA literature.\n\nAblations: variants without adaptive logical extension, without subgraph-to-node message passing, etc.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "For ReClor they additionally report accuracy on “easy” vs “hard” subsets as defined by the dataset authors.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "AdaLoGN is a neuro-symbolic QA system ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "nsai_domain_original": "neural-symbolic reasoning, logical reasoning, machine reading comprehension",
      "nsai_domain": "neural-symbolic reasoning",
      "application_area_original": "natural language processing, standardized-test QA, logical exam-style reasoning",
      "application_area": "natural language processing",
      "task_type_original": "multiple-choice question answering, machine reading comprehension, logical reasoning",
      "task_type": "multiple-choice question answering",
      "symbolic_representation_original": "Propositional / Boolean logic rules, Logic programs (Horn clauses, Datalog)",
      "symbolic_representation": "Propositional / Boolean logic rules",
      "reasoning_engine_original": "Custom in‑house rule/constraint engines",
      "reasoning_engine": "Custom in‑house rule/constraint engines",
      "integration_strategy_original": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training), Joint / co‑training of neural and symbolic modules, Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: symbolic → neural (symbols/constraints shape neural inputs/training)",
      "knowledge_source_original": "Extracted automatically from text (IE / OpenIE / pattern mining)",
      "knowledge_source": "Extracted automatically from text (IE / OpenIE / pattern mining)",
      "model_family_original": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "model_family": "BERT derivatives (BERT",
      "param_scale_band": "<1B",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "8.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2022.0",
      "venue_raw": "ACL",
      "venue_canonical": "ACL/EMNLP",
      "venue_group_bin": "ACL/EMNLP family",
      "venue_group_plot": "ACL/EMNLP family",
      "venue_clean": "acl/emnlp",
      "venue_norm": "ACL/EMNLP family",
      "venue_group": "ACL/EMNLP family",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242086029",
    "title": "AalphaGeometry - Solving olympiad geometry without human demonstrations",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-12-01 13:01:16.951000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242086029",
      "Paper DOI / URL": "https://www.nature.com/articles/s41586-023-06747-5",
      "Paper Title ": "AalphaGeometry - Solving olympiad geometry without human demonstrations",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "Nature",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/google-deepmind/alphageometry",
      "Primary language / framework": "Python",
      "Commit / tag / release hash used": "e8af054",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "IMO-AG-30 translated geometry benchmark and the 231-problem JGEX-AG set are provided via the paper’s Supplementary Information and GitHub repo",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Apache 2.0",
      "Notes on reproduction": "We successfully reproduced AlphaGeometry’s reported performance but only after resolving several major environment and compatibility issues on our HPC cluster: pinning Meliad to an older commit to fix a decoder_stack import, downgrading SciPy/JAX/Flax to match system GLIBCXX, patching the matplotlib backend for headless Slurm jobs, and working around a check_cyclic bug that caused TypeErrors in some problems. The system is extremely compute-intensive: average ~9.5 hours per AlphaGeometry problem on a single A100 GPU with 16 CPUs and 96 GB RAM, with some problems taking more than 24 hours. Parallelization across 8 GPUs plus a large CPU pool was essential to approach the full IMO-AG-30 and 231-problem benchmarks within reasonable wall-clock time, but the codebase itself is functionally reproducible once the environment is stabilized. Of very important note, you MUST downgrade the meliad code using :\n\nhttps://github.com/google-deepmind/alphageometry/issues/169\n\nto get the current version on Github to run !!! ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic theorem proving, geometry theorem proving, synthetic-data-driven reasoning, hybrid neural-symbolic search",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "automated reasoning, olympiad mathematics, STEM education / training tools, symbolic mathematics, AI for science",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "formal theorem proving, auxiliary construction generation, proof search, symbolic deduction, benchmark evaluation",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Theorem proving ",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "Other (specify below)",
      "Neural model name & family (for other) specify here:": "custom 12-layer transformer language model trained from scratch on synthetic geometry proofs (AlphaGeometry LM)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only), Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "Autoregressive transformer with 12 layers, d_model=1024, 8 attention heads, FFN size 4096, T5-style relative position embeddings, context length 1024.",
      "Parameter count / size (provide as size units, e.g. 406M, 7B, 70B etc.) ": "≈151M transformer parameters (excluding embeddings; total including embeddings ~200M).",
      "Release date": "2024-01-01 00:00:00",
      "Prompting strategy (if applicable)": "Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "Beam-search decoding conditioned on serialized premises and goal; at each step the model generates one auxiliary construction sentence, which is parsed and fed to the symbolic engine.",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Other (specify)",
      "Pre‑training source(s) (for other) specify here:": "all training data consists of structured theorem statements and synthetic proofs within the Euclidean geometry environment.",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, Parameter‑free prompt engineering only (no gradient updates), Other (specify below)",
      "Fine‑tuning / adaptation details  (for other) specify here:": "After pretraining on all proofs (including pure deduction), the LM is fine-tuned on the ~9% of proofs that require auxiliary constructions, to better focus on proposing new points/objects during proof search.",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules",
      "How neural outputs are used by the symbolic part (for other) specify here:": "The LM outputs geometry-language constructions such as “Construct D as midpoint of BC”, which are parsed into new points and relations; these are added to the symbolic database, and the DD+AR engine recomputes its deduction closure to check for goal reachability.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Deductive Database (DD) for geometry plus algebraic reasoning (AR), inspired by JGEX/GeoLogic-style environments but implemented as a custom in-house engine.",
      "Link to Existing symbolic project used (if applicable) ": "Implemented within the AlphaGeometry GitHub repo (custom DD+AR engine); conceptually based on Chou et al.’s deductive database approach.",
      "Symbolic representation(s)": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog)",
      "Symbolic representation(s) (for other) specify here:": "Geometry facts are encoded as predicates over point objects; equalities, collinearity and concyclicity are also represented in graph/hypergraph structures for efficient transitivity reasoning.",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "A structured deductive database that applies ~50+ geometric deduction rules plus a Gaussian-elimination-based algebraic reasoning module (AR) for angle/ratio/distance chasing, iterated to closure.",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Update / learning of symbols (for other) specify here:": "During training/evaluation, the KB contents (per problem) change, but the rule set is fixed; no learning over symbolic rules themselves.",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "Integration strategy with neural part (for other) specify here:": "Proof search loops: DD+AR attempts pure deduction; if it fails, the LM proposes auxiliary constructions, which update the symbolic state; DD+AR is re-run, and this alternates up to a fixed depth/beam size.",
      "Example of a rule / triple / formula (copy from paper)": "Q(x) ← P1(x), P2(x), …, Pk(x) where predicates include things like equal_segment, collinear, perpendicular, cyclic, etc.",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom in-house engine (DD+AR) - Implemented in Python/C++ with custom graph/hypergraph data structures and Gaussian elimination for algebraic closure; no off-the-shelf SAT/SMT/ASP engines are used.",
      "What are the key findings of the study (1-4 dot points)?": "A neuro-symbolic system trained purely on synthetic geometry proofs (no human proof demonstrations) can solve 25/30 translated IMO-style geometry problems, surpassing previous SOTA and approaching average IMO gold-medallist performance.\n\nLarge-scale synthetic theorem/proof generation via a deductive database plus algebraic reasoning (DD+AR) can rediscover known theorems and produce proofs longer and more varied than human olympiad proofs.\n\nAuxiliary construction – exogenous term generation – is effectively handled by a transformer LM guiding the symbolic engine via beam-search over auxiliary point constructions.\n\nThe system exposes both strengths (high success rate, human-readable proofs) and limitations (slow runtime, dependence on a narrow geometry language and missing high-level theorems).",
      "Author‑reported limitations": "Geometry representation is restricted to a specialized synthetic-geometry language; many IMO problems (geometric inequalities, combinatorial geometry) are out of scope.\n\nSynthetic data and the symbolic rule set omit higher-level tools (e.g. Reim’s theorem, homothety), leading to failures on certain hard problems and longer, low-level proofs.\n\nThe approach is focused on Euclidean plane geometry; extending the framework to other math domains will require substantial domain-specific engineering.",
      "Reviewer‑identified limitations / threats to validity": "Reproducibility is fragile: environment pinning (Meliad version, SciPy/JAX/Flax) and backend tweaks are required, none of which are fully documented.\n\nRuntime is extremly slow: solving a single AlphaGeometry instance can take 0.3–28+ hours on a modern GPU; full benchmarks require week long + ( We ran this for 2 weeks) multi-GPU compute, limiting accessibility.\n\nSome persistent bugs (e.g. check_cyclic edge cases) can cause failures on subset of problems unless patched; unit tests do not cover these real-world HPC scenarios.\n\nEvaluation has no statistical variation analysis (single model, no multiple seeds) and focuses on problem-count metrics; robustness under hyperparameter changes is only partially explored.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "10.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "7.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "number and fraction of geometry problems solved (binary success/failure per problem) on IMO-AG-30 and a 231-problem geometry benchmark.",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "fixed benchmark protocol – all suitable IMO geometry problems from 2000 onward translated into the geometry language (IMO-AG-30) plus a 231-problem geometry set; model is trained on separate synthetic data and evaluated once on these test sets with a fixed search budget.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Custom dataset (introduced in paper): IMO-AG-30 (30 translated IMO geometry problems)  Custom dataset (introduced in paper): 231-problem geometry benchmark compiled from textbooks, regional olympiads and classic theorems",
      "Link to evaluation dataset used (if other)": "In Github repo for AlphaGeometry",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Computer algebra: Wu’s method; Gröbner basis approach.\n\nSearch-based / synthetic: Deductive Database (DD); DD + human-designed heuristics; DD + AR (algebraic reasoning, this work); DD + AR + human-designed heuristics; full-angle method.\n\nLLM baselines: GPT-4 prompted directly in natural language; GPT-4 used to propose auxiliary constructions for DD+AR.",
      "Human evaluation details (only if applicable!) (e.g. number of raters, scale used, inter‑rater agreement).": "A single experienced human expert (USA IMO team coach) graded AlphaGeometry’s automatically translated natural-language proofs for IMO 2000 and 2015; they judged the solutions as worthy of full marks on the geometry problems in those years (i.e., model would pass the medal threshold on geometry under official grading standards).",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "Our independent run, using the released checkpoint and benchmarks, matches the reported number of problems solved given comparable search budgets and enough wall-clock time; small discrepancies are attributable to timeouts and resource limits rather than algorithmic differences. ",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Metrics are binary per problem (solved/not solved) and aggregated as counts; for human comparison they convert IMO scores (0–7) into fractional “problems solved,” which is an approximate mapping rather than a statistical test. We observed that reproducing a solved problem sometimes requires long runtime; early timeouts can change the metric, so search budget / wall-clock is an important hidden parameter.",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "AlphaGeometry is a flagship neuro-symbolic system for mathematical theorem proving. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Reproducing AlphaGeometry first required fixing a hard incompatibility with the Meliad library by pinning it to an older commit (e8af054) so that the expected decoder_stack import path still exists, otherwise the LM could not even be instantiated.\n\nWe then had to patch the hard-coded matplotlib.use('TkAgg') backend in numericals.py and force a headless-safe backend (Agg) via wrappers and environment variables, because every run crashed immediately on Slurm nodes without a GUI.\n\nSciPy, JAX, and Flax also had to be manually downgraded and installed with --no-deps to work around GLIBCXX and ICU version mismatches on the cluster; one unit-test path (lm_inference_test.py via t5.data/nltk/sqlite3) remains broken but is not exercised by the main experiments.\n\nWe encountered a persistent check_cyclic bug in numericals.py where passing a single Point object instead of an iterable raises a TypeError, causing dozens of DDAR and AlphaGeometry problems to fail until patched; this really needs a proper upstream fix in the core source rather than wrapper-level hacks. (someone should open a bug / issue on GitHub for this) \n\nAdditional annoyances included noisy duplicate absl.flags definitions that had to be suppressed and the need to write our own wrapper scripts (fix_all_compatibility.sh, run_tests.py, and Slurm launchers) to make the system robust under repeated HPC invocations.\n\nEven after all that, the compute/time requirements are extreme as AlphaGeometry mode averages roughly 9.5 GPU-hours per problem on a single A100 (with some problems taking >24 hours), implying ~98 days of sequential time for the full benchmark or  the roughly12+ days we used even with 8 A100s in parallel, so practical reproduction depends on careful Slurm orchestration, aggressive parallelization, and realistic expectations about the required multi-week GPU budget.",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "neuro-symbolic theorem proving, geometry theorem proving, synthetic-data-driven reasoning, hybrid neural-symbolic search",
      "nsai_domain": "neuro-symbolic theorem proving",
      "application_area_original": "automated reasoning, olympiad mathematics, STEM education / training tools, symbolic mathematics, AI for science",
      "application_area": "automated reasoning",
      "task_type_original": "formal theorem proving, auxiliary construction generation, proof search, symbolic deduction, benchmark evaluation",
      "task_type": "formal theorem proving",
      "symbolic_representation_original": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Post‑hoc verification or logical consistency checking of neural outputs",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Generated synthetically (procedural rule generation)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "Other (specify below)",
      "model_family": "Other (specify below)",
      "param_scale_band": "<1B",
      "licence_category": "Apache",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "1",
      "clarity_score": "7.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "Nature",
      "venue_canonical": "Nature journals",
      "venue_group_bin": "Nature journals",
      "venue_group_plot": "Nature journals",
      "venue_clean": "nature journals",
      "venue_norm": "Nature journals",
      "venue_group": "Nature journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242083828",
    "title": "Composing Neural Learning and Symbolic Reasoning with an Application to Visual Discrimination",
    "year": "2022.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-12-01 20:12:34.046000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242083828",
      "Paper DOI / URL": "https://arxiv.org/pdf/1907.05878",
      "Paper Title ": "Composing Neural Learning and Symbolic Reasoning with an Application to Visual Discrimination",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2022",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "propose a compositional neurosymbolic framework that combines a neural network to detect objects and relationships with a symbolic learner that finds interpretable discriminators.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/muraliadithya/vdp",
      "Primary language / framework": "Jupyter Notebook",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "Yes",
      "Data Link (if applicable) ": "VDP datasets and scripts: linked from the VDP GitHub repo",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Partial",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100)",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "not reported",
      "Notes on reproduction": "We ran the provided test suite / scripts and obtained 29/35 tests passing (83%) overall:\n\nCLEVR puzzles: 15/15 passing.\n\nSolver regression tests: 13/15 passing; devoicing and threepack regressions timed out at 60s but work via the full pipeline.\n\nNatural Scenes pipeline: 1 failure due to a missing / mis-referenced image (0.jpg) under natscene_data/images, indicating a data/path packaging issue rather than algorithmic failure.\n\nBaseline tests: 3 failures due to environment issues – missing deep-ranking Conda env and missing pytorch_lightning for the prototypical network baseline.\n\nOut-of-order (OOO) analysis script failed because it assumes a filename pattern (-fovariant-) that does not match the actual puzzle names.\n\nAdditional practical issues:\n\nZ3 dependency was not clearly documented; we had to manually install appropriate Z3 Python bindings to make the symbolic solver run.\n\nHard-coded filesystem paths (e.g., to datasets and Darknet builds) in parts of the toolchain had to be edited to match the local environment.\n\nDarknet needed recompilation with a GCC version compatible with CUDA 11.2.2.",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic visual reasoning, program synthesis, SAT/SMT-based logical synthesis, visual discrimination puzzles",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "computer vision, visual QA / puzzle solving, explainable AI, concept learning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "visual discrimination (choose candidate matching examples), odd-one-out detection, few-shot classification, logical formula synthesis, scene-graph reasoning",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "Neural model name & family (for other) specify here:": "YOLOv4 / Darknet for Natural Scenes object detection, NS-VQA model (Mask R-CNN + attribute network) for CLEVR objects/attributes and ResNet-18 backbone + MLP for prototypical network baseline.",
      "Neural architecture type(s) ": "CNN / ConvNet",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels",
      "Access level ": "Open weights downloadable",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module, Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "SAT/SMT solvers (MiniSAT, Z3, CVC5) used as the symbolic core",
      "Link to Existing symbolic project used (if applicable) ": "Z3, CVC4SY (standard SMT / SyGuS tools; URLs not given in paper but widely known).",
      "Symbolic representation(s)": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Constraint satisfaction / SMT formulas",
      "Reasoning / inference engine": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "CVC4SY (SyGuS engine) used in ablation; also a custom bottom-up FO solver.",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Hybrid (combination of the above), Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "Hybrid - Hand-crafted concept schemas / intended discriminators for Natural Scenes, CLEVR VDP, ODDONE AND Automatically converted from neural scene graphs (objects/relations from YOLOv4, NS-VQA).",
      "Update / learning of symbols": "Static (fixed once authored/imported), Automatically pruned/regularized for consistency, Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Static base schemas, but discriminators (FO-SL formulas) are synthesized per puzzle via search; symbolic knowledge itself is not updated across tasks.",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "Example of a rule / triple / formula (copy from paper)": "“All teddy bears on a sofa”\n\n∃x.(sofa(x) ∧ ∀y.(teddy_bear(y) ⇒ sitting_on(y, x)))",
      "Tooling / libraries for symbolic side": "Z3 / CVC5 / Boolector (SMT solvers), Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Custom in-house SAT-based FO-SL synthesizer implemented by the authors.",
      "What are the key findings of the study (1-4 dot points)?": "A SAT/SMT-based symbolic synthesizer over FO-SL scene models can solve a large fraction of visual discrimination puzzles while providing explicit logical discriminators. \n\nThe tool solves 68% of 3,864 Natural Scenes puzzles (71% average per concept class), with 17% of solutions being unintended but valid discriminators. \n\nOn GQA VDP, using ground-truth scene graphs, it solves 81% of puzzles (4% unintended), indicating strong generality once vision noise is removed. \n\nOn CLEVR VDP and ODDONE synthetic datasets with unique minimal discriminators, the symbolic solver substantially outperforms neural baselines (random, deep ranking, prototypical networks).",
      "Author‑reported limitations": "Vision model failures (mis-detections, duplicate bounding boxes, poor scene-graph quality) are the primary failure mode in realistic images. \n\nFO-SL expressivity is insufficient for some concepts (e.g., region-based predicates, negation like “a dog that is not white”), limiting solvable puzzle classes. \n\nA more expressive full FOL solver is slower (57% timeouts) and often yields unnatural discriminators, making it impractical as a default. \n\nSyGuS solver CVC4SY does not scale, requiring several minutes per puzzle or failing to terminate.",
      "Reviewer‑identified limitations / threats to validity": "Reproduction required manual fixes:\n\nInstalling Z3 Python bindings and ensuring the correct solver version, despite this not being clearly specified in the documentation.\n\nEditing hard-coded paths in the architecture (e.g., dataset and Darknet locations) to match our cluster environment.\n\nNatural Scenes pipeline depends on external COCO images and packaging; at least one referenced image path (0.jpg) failed, causing a test failure and indicating data/packaging fragility.\n\nBaseline comparisons rely on additional complex environments (deep-ranking Conda env, pytorch_lightning) that are not fully automated; reproducibility of baselines is weaker than that of the main symbolic solver.\n\nNo variance estimates, CIs, or statistical tests; robustness to seed variation is unknown.\n\nPerformance is tightly coupled to specific pretrained vision models (YOLOv4, NS-VQA) whose failure modes directly propagate to symbolic synthesis.",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "10.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "9.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Custom dataset protocol:  Natural Scenes: curated set of 3,864 puzzles, evaluated as a whole with a timeout per puzzle.   GQA VDP: auto-generated from GQA scene graphs; evaluated with FO-SL solver on the full puzzle set.   CLEVR VDP: 825 puzzles across 15 concept schemas with unique discriminators; used both for solver evaluation and neural baselines (with held-out schemas for baseline validation).   ODDONE: 1,872 puzzles derived from CLEVR VDP with unique minimal discriminators.",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "CLEVR, Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Natural Scenes VDP (puzzles over COCO images).   GQA VDP (auto-generated puzzles using GQA scene graphs).   ODDONE puzzles (derived from CLEVR VDP)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "Baselines:\nRandom choice baseline and Deep Ranking similarity baseline (CNN-based metric) and Prototypical network baseline (ResNet-18 + MLP). \n\nAblations:\nAlternative solver using CVC4SY (SyGuS) and Composing Neural Learning and and Full FOL bottom-up solver vs FO-SL solver. ",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Gap between reported and reproduced (%)": "0.17",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Presented a neuro-symbolic system that composes neural scene understanding with symbolic FO-SL synthesis over multiple visual discrimination benchmarks,",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "gap_percent": "0.17",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neuro-symbolic visual reasoning, program synthesis, SAT/SMT-based logical synthesis, visual discrimination puzzles",
      "nsai_domain": "neuro-symbolic visual reasoning",
      "application_area_original": "computer vision, visual QA / puzzle solving, explainable AI, concept learning",
      "application_area": "computer vision",
      "task_type_original": "visual discrimination (choose candidate matching examples), odd-one-out detection, few-shot classification, logical formula synthesis, scene-graph reasoning",
      "task_type": "visual discrimination (choose candidate matching examples)",
      "symbolic_representation_original": "First‑order / predicate logic, Logic programs (Horn clauses, Datalog), Constraint satisfaction / SMT formulas",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "SMT solvers (Z3, CVC5, Boolector), Other (specify below)",
      "reasoning_engine": "SMT solvers (Z3",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Neuro‑symbolic program synthesis (neural proposes programs; symbolic verifies)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Hybrid (combination of the above), Other (specify below)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "CNN families (ResNet, EfficientNet, DenseNet, Inception)",
      "model_family": "CNN families (ResNet",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "1.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2022.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084271",
    "title": "Neuro-symbolic Commonsense Social Reasoning",
    "year": "2023.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-12-02 16:03:47.755000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084271",
      "Paper DOI / URL": "https://arxiv.org/pdf/2303.08264",
      "Paper Title ": "Neuro-symbolic Commonsense Social Reasoning",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2023",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "arXiv",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "present a novel system for taking social rules of thumb (ROTs) in natural language from the Social Chemistry 101 dataset and converting them to first-order logic where reasoning is performed using a neuro-symbolic theorem prover.",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "If arXiv only - check yes": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/chanind/amr-social-chemistry-reasoner",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Partial",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "Yes",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "Yes",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "No",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "Not reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "reproduction passed 2/3 configurations (threshold & merge sweeps). Grid search failed due to a bug in AmrMergeGenerator._contains_existing_merge() (IndexError).",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic theorem proving; AMR-to-logic; semantic unification",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "commonsense social reasoning; ethics/morality norms",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "rule-to-situation applicability (binary inference); ablations over similarity threshold & merge size ",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "Neural architecture type(s) ": "Transformer (encoder–decoder / decoder‑only)",
      "Prompting strategy (if applicable)": "Not reported / unclear",
      "Alignment / Safety Filters Applied (if applicable) ": "No filters applied / not reported",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "How neural outputs are used by the symbolic part ": "Embeddings/vectors passed to symbolic module",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "AMR Logic Converter; Tensor Theorem Prover (custom libraries by authors)",
      "Symbolic representation(s)": "First‑order / predicate logic",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Resolution-based (custom “Tensor Theorem Prover”) with non-binary unification",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Other (specify below)",
      "Source of symbolic knowledge (for other) specify here:": "ROTs from Social Chemistry 101; converted to logic; SSTs likewise --> facts/queries",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Integration strategy with neural part (for other) specify here:": "AMR merge alternatives to improve structural alignment",
      "Example of a rule / triple / formula (copy from paper)": "ROT “hang-up(H) → BAD(H)” after conversion (see subsection 4.3 text and figures).",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "penman; amr-logic-converter; tensor-theorem-prover",
      "What are the key findings of the study (1-4 dot points)?": "Similarity threshold trade-off: Raising the AMR-logic similarity threshold increases precision and decreases recall; F1 peaks mid-range (paper Fig. 12; text explicitly notes the precision–recall trade-off). \n\nMerge size helps recall/F1 up to ~6 nodes: Allowing larger AMR leaf-node merges (≤6) has little effect on precision but substantially boosts recall and F1 (paper Fig. 13 and discussion). \n\nCollapsability correlates with recall: Dataset buckets with higher AMR “collapsability” (fraction of nodes legally mergeable under the algorithm) show large recall gains; at very high collapsability, precision dips slightly due to over-averaging embeddings (paper Fig. 14; formal definition provided). \n\nNeuro-symbolic alignment without exact AMR is feasible: Hybrid reasoning (RoBERTa embeddings + resolution prover) enables ROT↔SST matches even when AMR structures differ, via merged nodes and embedding similarity; method contributions include merge algorithm, hybrid similarity, modified AMR→logic for ROT implications, and Tensor Theorem Prover / AMR Logic Converter.",
      "Author‑reported limitations": "Merge restrictions (no crossing negation or coreference boundaries) limit achievable collapsability and thus recall; future work: relax these constraints. \n\nDoes not address antonyms; multi-sentence/coreference handling left for future work; embeddings could be fine-tuned via differentiable prover.",
      "Reviewer‑identified limitations / threats to validity": "External dependency: IBM Transition AMR Parser is not on PyPI and normally requires manual setup/permissions; repo ships a pre-enhanced subset to avoid this for reproduction. \n\nCurrent HEAD bug observed in our run: Grid-search path fails at AmrMergeGenerator._contains_existing_merge() on malformed predicates (IndexError). (From our reproduction log; not a paper claim.)",
      "Ethics / legal / privacy concerns listed": "Yes",
      "Ethics / legal / privacy concerns listed (if yes, specify) ": "Paper motivates interpretability and harm mitigation for social-norm reasoning; discusses bias concerns in LMs and desirability of editable, transparent rules, though not a standalone formal ethics section.",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "6.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Classification / structured prediction, Precision / Recall, F1 (micro / macro / weighted)",
      "Split / Protocol": "Other (specify below)",
      "Split / Protocol (for other) specify here:": "Not a train/test benchmark; evaluation on paired vs random ROT<--> SST matching (protocol described, no official split). ",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided, Checkpoints / weights for evaluation",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "Social Chemistry 101 (with provided enhanced subset)",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Partial",
      "Baselines / ablations compared against": "Ablations over similarity threshold and merge size; no external baselines reported.",
      "Reproduction outcome ": "Partially reproduced (subset of metrics/tasks)",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Conducted experimentation ( somewhat well documented in the paper) utilising a neuro-symbolic theorem prover",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Authors should Patch AmrMergeGenerator._contains_existing_merge() to handle empty/malformed predicates.",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "partially_reproduced",
      "reproduction_outcome_raw": "Partially reproduced (subset of metrics/tasks)",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "0",
      "partially_reproduced": "1",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "partially_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "nsai_domain_original": "neuro-symbolic theorem proving; AMR-to-logic; semantic unification",
      "nsai_domain": "neuro-symbolic theorem proving",
      "application_area_original": "commonsense social reasoning; ethics/morality norms",
      "application_area": "commonsense social reasoning",
      "task_type_original": "rule-to-situation applicability (binary inference); ablations over similarity threshold & merge size",
      "task_type": "rule-to-situation applicability (binary inference)",
      "symbolic_representation_original": "First‑order / predicate logic",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Other (specify below)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "BERT derivatives (BERT, RoBERTa, DeBERTa, ALBERT, ELECTRA)",
      "model_family": "BERT derivatives (BERT",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "not_reported",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "6.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2023.0",
      "venue_raw": "arXiv",
      "venue_canonical": "arXiv",
      "venue_group_bin": "arXiv",
      "venue_group_plot": "arXiv",
      "venue_clean": "arxiv",
      "venue_norm": "arXiv",
      "venue_group": "arXiv",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "1",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084996",
    "title": "Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-12-03 14:17:51.699000",
      "Email Address": "itamraka@umd.edu",
      "Reviewer Name": "Ishan",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084996",
      "Paper DOI / URL": "https://arxiv.org/pdf/2506.10753",
      "Paper Title ": "Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "WACV",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "The paper discusses a novel approach to do causal and temporal reasoning in video particularly for counterfactual reasoning. They make use of a causal graph and ASP to coordinate between perception and simulation modules. ",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/azreasoners/CRCG",
      "Primary language / framework": "python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Limitations section reported?": "No",
      "Broader‑impact / ethics statement present?": "No",
      "Hyper‑parameter utilised during development and final parameters selected documented/described?": "No",
      "Pre‑processing scripts included?": "Yes",
      "Method used for setting random seeds are described in a way sufficient to allow replication of results (If applicable) ": "Partial",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Yes",
      "Compute/hardware reported ": "GPU  (specify type below e.g., A100, V100), Memory / batch size reported",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "Yes",
      "Number of independent runs (if yes to the above)": "3 * ~10 experiments  = 30",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Train/validation/test split described?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "public repository",
      "Notes on reproduction": "Temperature set to 0 for reproducibility. Need to run conversion script after downloading the artifacts which takes ~ 30 mins. Then it is pretty much running the commands given in the readme(s). ",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "neuro-symbolic reasoning, causal reasoning, counterfactual reasoning, logic programming, ASP",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "video understanding, visual question answering, physical reasoning, temporal reasoning",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "event detection, object tracking, causal inference",
      "Real‑world application claimed?": "No",
      "Model card or equivalent info‑sheet released?": "No",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "Neural model name & family (for other) specify here:": "Mask-RCNN, differentiable physics engine",
      "Neural architecture type(s) ": "LLM, CNN / ConvNet, Other (specify below)",
      "Neural architecture type(s) (for other) specify here:": "physics simulation networks, differentiable physics engines",
      "Release date": "2024-01-08 00:00:00",
      "Prompting strategy (if applicable)": "few‑shot, Other (specify below)",
      "Prompting strategy (if applicable) (for other) specify here:": "CRCG guided prompting",
      "Fine‑tuning / adaptation details": "Supervised fine‑tuning on task‑specific labels, No fine‑tuning (frozen backbone)",
      "Access level ": "Open weights downloadable, Hosted API only",
      "How neural outputs are used by the symbolic part ": "Generated text parsed into symbols/rules, Probabilities/logits converted to logic facts or constraints",
      "Existing symbolic project used (if applicable) ": "ASP tools (clingo, gringo)",
      "Link to Existing symbolic project used (if applicable) ": "Clingo v5.3.0",
      "Symbolic representation(s)": "First‑order / predicate logic, Answer Set Programs (ASP), Temporal / modal logics, Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "Causal graphs with directed edges",
      "Reasoning / inference engine": "ASP solvers (clingo, gringo, clasp)",
      "Source of symbolic knowledge": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "Update / learning of symbols": "Static (fixed once authored/imported)",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Meta‑controller or selector switches between neural and symbolic experts",
      "Example of a rule / triple / formula (copy from paper)": "ancestor(O,T1,O,T2) :- object(O),\ncollision(_,_,T1), collision(_,_,T2), T1<T2\nsim(O,T) :- not removed(O), affected(O,T), T<=T': affected(O,T')",
      "Tooling / libraries for symbolic side": "clingo / gringo (ASP)",
      "What are the key findings of the study (1-4 dot points)?": "The study shows their method beats the state of the art on CLEVRER significantly. Using symbolic causal reasoning to determine when simulation is needed improves accuracy. LLMs can serve as proxy simulators for counterfactual reasoning. ",
      "Author‑reported limitations": "the method requires a simulator. Physics simulator assumes linear trajectory and basic kinematics. ",
      "Reviewer‑identified limitations / threats to validity": "no statistical significance. no real world dataset. ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "9.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "8.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "9.0",
      "Reproducibility confidence (after our attempt)": "Mostly reproducible with minor gaps",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "9.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Accuracy",
      "Split / Protocol": "Official train/validation/test split (as provided by dataset), Few‑shot (N‑shot prompting / small labeled set)",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Results table with baselines & ablations in repo",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "CLEVRER, CRAFT",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "NS-DR, DCL, VRDP, Vanilla GPT-3.5 and GPT-4",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Gap between reported and reproduced (%)": "< 1% ",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Highly reproducible and a novel and creative neuro symbolic framework proposed. ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Need to sting together different artifacts from different sources but ultimately the code runs smoothly. ",
      "has_code": "1",
      "has_data": "0",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "0",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "gap_percent": "1.0",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "exp_reporting_index": "2.0",
      "doc_governance_index": "1.0",
      "nsai_domain_original": "neuro-symbolic reasoning, causal reasoning, counterfactual reasoning, logic programming, ASP",
      "nsai_domain": "neuro-symbolic reasoning",
      "application_area_original": "video understanding, visual question answering, physical reasoning, temporal reasoning",
      "application_area": "video understanding",
      "task_type_original": "event detection, object tracking, causal inference",
      "task_type": "event detection",
      "symbolic_representation_original": "First‑order / predicate logic, Answer Set Programs (ASP), Temporal / modal logics, Other (specify below)",
      "symbolic_representation": "First‑order / predicate logic",
      "reasoning_engine_original": "ASP solvers (clingo, gringo, clasp)",
      "reasoning_engine": "ASP solvers (clingo",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner), Meta‑controller or selector switches between neural and symbolic experts",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Hand‑crafted by authors / domain experts, Converted from neural outputs (e.g., rule extraction, concept induction)",
      "knowledge_source": "Hand‑crafted by authors / domain experts",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.), CNN families (ResNet, EfficientNet, DenseNet, Inception), Other (specify below)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "open_weights",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "9.0",
      "reviewer_confidence_score": "9.0",
      "publication_year": "2024.0",
      "venue_raw": "WACV",
      "venue_canonical": "CVPR/ICCV/ECCV/WACV",
      "venue_group_bin": "CVPR/ICCV/ECCV/WACV (vision)",
      "venue_group_plot": "CVPR/ICCV/ECCV/WACV (vision)",
      "venue_clean": "cvpr/iccv/eccv/wacv",
      "venue_norm": "CVPR/ICCV/ECCV/WACV (vision)",
      "venue_group": "CVPR/ICCV/ECCV/WACV (vision)",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  },
  {
    "article_id": "rayyan-242084302",
    "title": "Neurosymbolic Repair of Test Flakiness",
    "year": "2024.0",
    "author": "",
    "url": "",
    "abstract": "",
    "note": "Extracted from Excel only (no match in include.json)",
    "customizations": [],
    "excel_data": {
      "Timestamp": "2025-12-11 18:14:59.492000",
      "Email Address": "brandcol@umd.edu",
      "Reviewer Name": "Brandon",
      "Paper ID\n(the Rayyan ID from the excel spreadsheet) ": "rayyan-242084302",
      "Paper DOI / URL": "https://doi.org/10.1145/3650212.3680369",
      "Paper Title ": "Neurosymbolic Repair of Test Flakiness",
      "Publication Year\n(e.g. 2025, 2024, 2023 ....) ": "2024",
      "Journal or Conference Name\n(add arXiv if you cannot find journal / conference publication)": "ISSTA / ACM ",
      "Study design / paper type ( dataset paper, framework/demo, etc.)": "Framework",
      "Your Brief Summary on the paper \n(in 1-2 sentences, describe what the paper is presenting) ": "Introduces FlakyDoctor, a neuro-symbolic repair system that couples LLM-based patch synthesis with static analysis, compilation “stitching,” and targeted validation to repair order-dependent (OD) and implementation-dependent (ID) flaky tests. Evaluated on 873 flaky tests from 243 projects, achieving ~57% OD and 59% ID repair success and producing 79 previously un-fixed patches (19 merged PRs)",
      "Is the paper written in English?": "Yes",
      "The paper is Not a Review": "Yes",
      "Does the paper present an original research study?": "Yes",
      "Paper is Peer Reviewed (including arXiv) ": "Yes",
      "The paper has an associated codebase": "Yes",
      "Does the paper include a Quantitative Evaluation": "Yes",
      "Does the paper discuss Neuro-Symbolic AI": "Yes",
      "Is the Full Text available for the paper?": "Yes",
      "Is the study reproducible (is the codebase AND data AND model artifacts required to reproduce publicly available)? ": "Yes",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper)": "Yes",
      "If you answered YES to all of the above OR answered NO to just the final question (were the results reproduced)  - Select continue. \n\n\n\nIf you answered NO to any of the other sections above, this paper will be Excluded - Select SKIP ": "Continue",
      "Repository URL": "https://github.com/Intelligent-CAT-Lab/FlakyDoctor",
      "Primary language / framework": "Python",
      "Documentation / code comments is provided to describe its use (for novel methods introduced in the paper)": "Yes",
      "Build successful on first try?": "No",
      "Is a new dataset released with paper?": "No",
      "Data Link (if applicable) ": "International Dataset of Flaky Tests",
      "Limitations section reported?": "Yes",
      "Broader‑impact / ethics statement present?": "No",
      "Pre‑processing scripts included?": "Yes",
      "Exact run command / environment file provided?  (e.g. Docker/Conda provided?)": "Partial",
      "Compute/hardware reported ": "CPU only",
      "Total compute budget disclosed?": "No",
      "Number of independent runs reported?": "No",
      "Variance / error bars shown?": "No",
      " Statistical significance tests applied?": "No",
      " Rationale for dataset choice clearly stated?": "Yes",
      "Includes a conceptual outline and/or pseudocode de-scription of AI methods introduced?": "Yes",
      "Data / Code Licence type (MIT, Apache‑2.0, GPL‑3, proprietary, unknown).": "Not reported",
      "Notes on reproduction": "Installation took a long time ( there were 455 packages that were installed for this, each of which took a couple minutes each ) + the reproduction took ages and required an API key for GPT",
      "Were the results reproduced? (did the results obtained match (from full to partial) the reported results from the paper).1": "Yes - Continue",
      "Primary NSAI Domain (Provide tags - singular concepts separated by a comma)": "Neuro-symbolic program repair, software testing, LLM-assisted repair",
      "Application area(s) (Provide tags - singular concepts separated by a comma)": "software engineering, test flakiness repair",
      "Task type(s) (Provide tags - singular concepts, separated by a comma)": "repair of tests; OD/ID flakiness localization and patching",
      "Real‑world application claimed?": "Yes",
      "If Yes: Brief description of application": "Submitted repair PRs to public OSS projects; 19 merged at submission.",
      "Neural model name & family ": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "Neural model name & family (for other) specify here:": "GPT-4 Via api",
      "Neural architecture type(s) ": "LLM, Transformer (encoder–decoder / decoder‑only)",
      "Neural architecture type(s) (for other) specify here:": "GPT-4 Via api",
      "Prompting strategy (if applicable)": "chain‑of‑thought",
      "Prompting strategy (if applicable) (for other) specify here:": "Instruction prompting with implicit chain-of-thought, iterative feedback based on concise failure/compilation snippets; targeted context injection (Related Code + Failure Location).",
      "Alignment / Safety Filters Applied (if applicable) ": "OpenAI Moderation API",
      "Pre‑training source(s) ": "Not reported / unclear",
      "Fine‑tuning / adaptation details": "No fine‑tuning (frozen backbone)",
      "Access level ": "Hosted API only",
      "How neural outputs are used by the symbolic part ": "Other (specify)",
      "How neural outputs are used by the symbolic part (for other) specify here:": "LLM generates candidate patches; symbolic pipeline stitches imports/modifiers, then compiles & validates via Surefire/NonDex; feedback loop refines prompts. See Figure 3 pipeline.",
      "Existing symbolic project used (if applicable) ": "Other (specify below)",
      "Existing symbolic project used (if applicable) (for other) specify here:": "Maven Surefire and NonDex",
      "Symbolic representation(s)": "Other (specify below)",
      "Symbolic representation(s) (for other) specify here:": "program analysis artifacts (culprit methods, global vars, assertions, unordered collections)",
      "Reasoning / inference engine": "Other (specify below)",
      "Reasoning / inference engine (for other) specify here:": "Custom static analysis + heuristic Stitching (Algorithm 1) and deterministic validators.",
      "Source of symbolic knowledge": "Extracted automatically from structured data / logs",
      "Source of symbolic knowledge (for other) specify here:": "Extracted from code/tests (stack traces, data-/control-flow, import resolution) + build metadata.",
      "Update / learning of symbols": "Static (fixed once authored/imported), Other (specify below)",
      "Update / learning of symbols (for other) specify here:": "Static per iteration; refined via feedback loop.",
      "Integration strategy with neural part": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "Example of a rule / triple / formula (copy from paper)": "Heuristic: replace HashMap with LinkedHashMap and import it; reconstruct expected order before assertion (see Hadoop ID example).",
      "Tooling / libraries for symbolic side": "Other (specify below)",
      "Tooling / libraries for symbolic side (for other) specify here:": "Maven Surefire; NonDex; Java compiler; project pom.xml edits; import resolution via JDK search (Algorithm 1).",
      "What are the key findings of the study (1-4 dot points)?": "FlakyDoctor repairs ~58% OD and ~57% (GPT-4) / 16% (Magicoder) ID tests; outperforms ODRepair/iFixFlakies/DexFix on overlapping sets. \n\nNeuro-symbolic Stitching contributes 10–41% of correct patches in first iteration; 12–31% overall across iterations. \n\n79 previously un-fixed flaky tests repaired; 19 PRs merged. \n\nConcise context beats long logs; without localization, performance drops sharply (table shows drastic decrease).",
      "Author‑reported limitations": "Does not target general NOD flaky tests; LLM hallucinations; occasional overfitting to context.",
      "Reviewer‑identified limitations / threats to validity": "There was no real reasoning engine. Code was just validated from the compilers. ",
      "Ethics / legal / privacy concerns listed": "No",
      "How relevant is this paper to our research objective?\n(Linear Scale: 1-10, where 1 = Not Relevant, 10 = Highly Relevant)": "7.0",
      "Perceived novelty / contribution level (Linear scale (1–10) where 1 = Incremental, 10 = Highly novel / field‑shaping)": "7.0",
      "Clarity & completeness of reporting  (Linear scale (1–10) where 1 = Poor , 10 = Excellent)": "10.0",
      "Reproducibility confidence (after our attempt)": "Fully reproducible",
      "Reviewer confidence in this extraction ( Linear scale (1–10) where 1 = Low confidence,  10 = Very confident)": "10.0",
      "Raw logs / result tables made available?": "Partial",
      "Primary task metrics reported ": "Other (specify below)",
      "Primary task metrics reported (for other) specify here:": "Repair success rate (%), totals by category; comparative counts vs. baselines; time & cost per attempt.",
      "Split / Protocol": "Not reported / unclear",
      "Evaluation assets provided (if yes / partial above) ": "Evaluation scripts / notebooks released, Preprocessed data & official splits provided",
      "Datasets used for Evaluation ": "Other (specify below)",
      "Evaluation Datasets (for other) specify here:": "DexFix dataset (ID); ODRepair dataset (OD-Victim); IDoFT additional tests.",
      "A motivation is given for why the experiments are conducted on the selected datasets": "Yes",
      "All datasets drawn from the existing literature are publicly available": "Yes",
      "Baselines / ablations compared against": "iFixFlakies, ODRepair, DexFix; plus Magicoder vs GPT-4 variants.",
      "Reproduction outcome ": "Fully reproduced within reported variance",
      "Notes on metric computation quirks (Any non‑standard preprocessing, smoothing, micro/macro averaging, etc.)": "Validation uses nondexRuns=5 for ID and the OD validated by order manipulations (Surefire).",
      "Final Decision to Include / Exclude Study": "Include",
      "If Included, in one sentence, describe why the paper should be included in this review.": "Demonstrates a neuro-symbolic repair pipeline. In my opinion, this is a weakly integrated NSAI pipeline as the LLM generates stuffa nd it is just validated so there is no real reasoning (IMHO) ",
      "Comments on reproduction / Action items / follow‑up needed (if applicable) ": "Required alot to set up due to maven / java dependency and the 355 projects that were installed for testing, BUT, the authors provided bash scripts which made this step alot easier. ",
      "has_code": "1",
      "has_data": "1",
      "has_model_artifacts": "1",
      "reproducible_all_artifacts": "1",
      "reproduction_outcome_cat": "fully_reproduced",
      "reproduction_outcome_raw": "Fully reproduced within reported variance",
      "reproduction_attempted": "1",
      "repro_attempted": "1",
      "repro_positive": "1",
      "repro_negative": "0",
      "fully_reproduced": "1",
      "partially_reproduced": "0",
      "not_reproduced": "0",
      "any_reproduced": "1",
      "not_reproduced_overall": "0",
      "failed_due_to_missing_artifacts": "0",
      "failed_with_artifacts": "0",
      "repro_status_overall": "fully_reproduced",
      "included_final": "1",
      "exclusion_reason": "Continue",
      "doc_governance_index": "2.0",
      "nsai_domain_original": "Neuro-symbolic program repair, software testing, LLM-assisted repair",
      "nsai_domain": "Neuro-symbolic program repair",
      "application_area_original": "software engineering, test flakiness repair",
      "application_area": "software engineering",
      "task_type_original": "repair of tests; OD/ID flakiness localization and patching",
      "task_type": "repair of tests",
      "symbolic_representation_original": "Other (specify below)",
      "symbolic_representation": "Other (specify below)",
      "reasoning_engine_original": "Other (specify below)",
      "reasoning_engine": "Other (specify below)",
      "integration_strategy_original": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "integration_strategy": "Pipeline: neural → symbolic (neural generates facts/rules fed to a reasoner)",
      "knowledge_source_original": "Extracted automatically from structured data / logs",
      "knowledge_source": "Extracted automatically from structured data / logs",
      "model_family_original": "GPT / LLaMA family (GPT‑x, LLaMA‑x, Vicuna, WizardLM, etc.)",
      "model_family": "GPT / LLaMA family (GPT‑x",
      "param_scale_band": "unknown",
      "licence_category": "other",
      "access_level_cat": "API_only",
      "all_eval_data_public": "1",
      "new_dataset_released": "0.0",
      "human_eval_present": "0",
      "clarity_score": "10.0",
      "reviewer_confidence_score": "10.0",
      "publication_year": "2024.0",
      "venue_raw": "ISSTA / ACM ",
      "venue_canonical": "ACM",
      "venue_group_bin": "ACM conferences/journals",
      "venue_group_plot": "ACM conferences/journals",
      "venue_clean": "acm",
      "venue_norm": "ACM conferences/journals",
      "venue_group": "ACM conferences/journals",
      "positive_reproduced_all": "1",
      "negative_reproduced_all": "0",
      "partially_reproduced_above": "0",
      "partially_reproduced_below": "0"
    },
    "repository_url": null
  }
]