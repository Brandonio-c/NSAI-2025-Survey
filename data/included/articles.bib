@article{rayyan-242083763,
  title={Neuro-symbolic video search},
  year={2024},
  author={Choi, M. and Goel, H. and Omama, M. and Yang, Y. and Shah, S.},
  url={https://ui.adsabs.harvard.edu/abs/2024arXiv240311021C/abstract},
  abstract={The unprecedented surge in video data production in recent years necessitates efficient tools to extract meaningful frames from videos for downstream tasks. Long-term temporal …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["Github: {https://github.com/UTAustin-SwarmLab/Neuro-Symbolic-Video-SearchTemporal-Logic}"]}}
}

@article{rayyan-242083766,
  title={UnRavL: A Neuro-Symbolic Framework for Answering Graph Pattern Queries in Knowledge Graphs},
  year={2024},
  author={Cucumides, T. and Daza, D. and Barcelo, P.},
  url={https://openreview.net/forum?id=183XrFqaHN},
  abstract={The challenge of answering graph queries over incomplete knowledge graphs is gaining significant attention in the machine learning community. Neuro-symbolic models have …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Email sent to author requesting access to codebase.", "Github: [https://github.com/TamaraCucumides/UnRavL]"]}}
}

@article{rayyan-242083778,
  title={A Hybrid Neuro-Symbolic Approach for Complex Event Processing},
  year={2020},
  author={Vilamala, Marc Roig and Taylor, Harrison and Xing, Tianwei and Garcia, Luis and Srivastava, Mani and Kaplan, Lance and Preece, Alun and Kimmig, Angelika and Federico, Cerutti},
  abstract={Training a model to detect patterns of interrelated events that form situations of interest can be a complex problem: such situations tend to be uncommon, and only sparse data is available. We propose a hybrid neuro-symbolic architecture based on Event Calculus that can perform Complex Event Processing (CEP). It leverages both a neural network to interpret inputs and logical rules that express the pattern of the complex event. Our approach is capable of training with much fewer labelled data than a pure neural network approach, and to learn to classify individual events even when training in an end-to-end manner. We demonstrate this comparing our approach against a pure neural network approach on a dataset based on Urban Sounds 8K.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["Github: https://github.com/MarcRoigVilamala/DeepProbCEP"]}}
}

@article{rayyan-242083784,
  title={PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World},
  year={2021},
  author={Zellers, Rowan and Holtzman, Ari and Peters, Matthew and Mottaghi, Roozbeh and Kembhavi, Aniruddha and Farhadi, Ali and Yejin, Choi},
  abstract={We propose PIGLeT: a model that learns physical commonsense knowledge through interaction, and then uses this knowledge to ground language. We factorize PIGLeT into a physical dynamics model, and a separate language model. Our dynamics model learns not just what objects are but also what they do: glass cups break when thrown, plastic ones don't. We then use it as the interface to our language model, giving us a unified model of linguistic form and grounded meaning. PIGLeT can read a sentence, simulate neurally what might happen next, and then communicate that result through a literal symbolic representation, or natural language. Experimental results show that our model effectively learns world dynamics, along with how to communicate them. It is able to correctly forecast what happens next given an English sentence over 80% of the time, outperforming a 100x larger, text-to-text approach by over 10%. Likewise, its natural language summaries of physical interactions are also judged by humans as more accurate than LM alternatives. We present comprehensive analysis showing room for future work.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["Github: https://github.com/rowanz/piglet"]}}
}

@article{rayyan-242083800,
  title={Dolphin: A Programmable Framework for Scalable Neurosymbolic Learning},
  year={2024},
  author={Naik, Aaditya and Liu, Jason and Wang, Claire and Sethi, Amish and Dutta, Saikat and Naik, Mayur and Eric, Wong},
  abstract={Neurosymbolic learning enables the integration of symbolic reasoning with deep learning but faces significant challenges in scaling to complex symbolic programs, large datasets, or both. We introduce Dolphin, a framework that tackles these challenges by supporting neurosymbolic programs in Python, executing complex symbolic reasoning on the CPU while vectorizing probabilistic computations and gradient propagation on the GPU. Across 13 benchmarks spanning tasks over text, image, and video data, with symbolic reasoning features like recursion and black-box functions, Dolphin converges to state-of-the-art accuracies on the more complex benchmarks while existing frameworks such as Scallop, ISED, and IndeCateR+ fail to converge within the time limit. On simpler benchmarks, Dolphin matches their performance, while achieving these results 1.71x to 62x faster than the baselines. Overall, Dolphin advances the scalability of neurosymbolic frameworks, achieving state-of-the-art efficiency and convergence on difficult benchmarks where existing frameworks struggle.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["Github: https://github.com/PasaLab/dolphin"]}}
}

@article{rayyan-242083805,
  title={NESTER: An Adaptive Neurosymbolic Method for Causal Effect Estimation},
  year={2022},
  author={Reddy, Abbavaram Gowtham and Vineeth, N. Balasubramanian},
  abstract={Causal effect estimation from observational data is a central problem in causal inference. Methods based on potential outcomes framework solve this problem by exploiting inductive biases and heuristics from causal inference. Each of these methods addresses a specific aspect of causal effect estimation, such as controlling propensity score, enforcing randomization, etc., by designing neural network (NN) architectures and regularizers. In this paper, we propose an adaptive method called Neurosymbolic Causal Effect Estimator (NESTER), a generalized method for causal effect estimation. NESTER integrates the ideas used in existing methods based on multi-head NNs for causal effect estimation into one framework. We design a Domain Specific Language (DSL) tailored for causal effect estimation based on causal inductive biases used in literature. We conduct a theoretical analysis to investigate NESTER's efficacy in estimating causal effects. Our comprehensive empirical results show that NESTER performs better than state-of-the-art methods on benchmark datasets.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["GitHub: [https://github.com/gautam0707/NESTER]", "The github link was obtained upon email request. The original paper mentions that the code has been released in the supplemental material but none was found. "]}}
}

@article{rayyan-242083810,
  title={Neuro-symbolic visual dialog},
  year={2022},
  author={Abdessaied, A. and Bâce, M. and Bulling, A.},
  abstract={We propose Neuro-Symbolic Visual Dialog (NSVD) -the first method to combine deep learning and symbolic program execution for multi-round visually-grounded reasoning. NSVD …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Email request for source code access sent.", "Github: [https://github.com/adnenabdessaied/NSVD]"]}}
}

@article{rayyan-242083811,
  title={DeepInfusion: A dynamic infusion based-neuro-symbolic AI model for segmentation of intracranial aneurysms},
  year={2023},
  author={Abdullah, I. and Javed, A. and Malik, K. M. and Malik, G.},
  url={https://www.sciencedirect.com/science/article/pii/S0925231223006331?casa_token=_hGnZM1JgmUAAAAA:FD7Xv9VE4VrQDQdEypmfiql6VhwvnFmht3fXNJUl9r0YDltt9t7m8LtW0sDzw53L9ZQiWYfD},
  abstract={… This study aims to develop a neuro-symbolic AI approach that incorporates domain professionals’ expertise into a DL model for detecting and segmenting cerebral aneurysms from DSA …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/smileslab/deep-infusion/blob/main/deepinfusion.ipynb]"]}}
}

@article{rayyan-242083812,
  title={Autoformalizing Natural Language to First-Order Logic: A Case Study in Logical Fallacy Detection},
  year={2024},
  author={Lalwani, Abhinav and Kim, Tasha and Chopra, Lovish and Hahn, Christopher and Jin, Zhijing and Mrinmaya, Sachan},
  abstract={Translating natural language into formal language such as First-Order Logic (FOL) is a foundational challenge in NLP with wide-ranging applications in automated reasoning, misinformation tracking, and knowledge validation. In this paper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework to autoformalize natural language to FOL step by step using Large Language Models (LLMs). Our approach addresses key challenges in this translation process, including the integration of implicit background knowledge. By leveraging structured representations generated by NL2FOL, we use Satisfiability Modulo Theory (SMT) solvers to reason about the logical validity of natural language statements. We present logical fallacy detection as a case study to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach also provides interpretable insights into the reasoning process and demonstrates robustness without requiring model fine-tuning or labeled training data. Our framework achieves strong performance on multiple datasets. On the LOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing effectively to the LOGICCLIMATE dataset with an F1-score of 80%.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["link: [https://www.semanticscholar.org/reader/99829812c2e5b2ee2669c839020addd2921dc673], github: [https://github.com/lovishchopra/NL2FOL], Not Peer Reviewed"]}}
}

@article{rayyan-242083815,
  title={CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments},
  year={2024},
  author={Abraham, Savitha Sam and Alirezaie, Marjan and De Raedt, Luc},
  abstract={The integration of learning and reasoning is high on the research agenda in AI. Nevertheless, there is only a little attention to use existing background knowledge for reasoning about partially observed scenes to answer questions about the scene. Yet, we as humans use such knowledge frequently to infer plausible answers to visual questions (by eliminating all inconsistent ones). Such knowledge often comes in the form of constraints about objects and it tends to be highly domain or environment-specific. We contribute a novel benchmark called CLEVR-POC for reasoning-intensive visual question answering (VQA) in partially observable environments under constraints. In CLEVR-POC, knowledge in the form of logical constraints needs to be leveraged to generate plausible answers to questions about a hidden object in a given partial scene. For instance, if one has the knowledge that all cups are colored either red, green or blue and that there is only one green cup, it becomes possible to deduce the color of an occluded cup as either red or blue, provided that all other cups, including the green one, are observed. Through experiments, we observe that the low performance of pre-trained vision language models like CLIP ( 22%) and a large language model (LLM) like GPT-4 ( 46%) on CLEVR-POC ascertains the necessity for frameworks that can handle reasoning-intensive tasks where environment-specific background knowledge is available and crucial. Furthermore, our demonstration illustrates that a neuro-symbolic model, which integrates an LLM like GPT-4 with a visual perception network and a formal logical reasoner, exhibits exceptional performance on CLEVR-POC.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["paper: [https://arxiv.org/abs/2403.03203], github: [https://github.com/savithasam88/CLEVR-POC/tree/master]"]}}
}

@article{rayyan-242083818,
  title={Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks},
  year={2025},
  author={Acharya, K. and Lad, M. and Sun, L. and Song, H.},
  abstract={… This study introduces a Neurosymbolic Artificial Intelligence (Neurosymbolic AI) framework … By merging symbolic and neural learning paradigms, this Neurosymbolic approach achieves …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["link: [https://www.researchgate.net/publication/388686587_Neurosymbolic_AI_for_Travel_Demand_Prediction_Integrating_Decision_Tree_Rules_into_Neural_Networks], github: [https://github.com/lotussavy/IWCMC-2025], seems like a preprint."]}}
}

@article{rayyan-242083824,
  title={CLEVR-Math: A Dataset for Compositional Language, Visual and Mathematical Reasoning},
  year={2022},
  author={Lindström, Adam Dahlgren and Savitha Sam, Abraham},
  abstract={We introduce CLEVR-Math, a multi-modal math word problems dataset consisting of simple math word problems involving addition/subtraction, represented partly by a textual description and partly by an image illustrating the scenario. The text describes actions performed on the scene that is depicted in the image. Since the question posed may not be about the scene in the image, but about the state of the scene before or after the actions are applied, the solver envision or imagine the state changes due to these actions. Solving these word problems requires a combination of language, visual and mathematical reasoning. We apply state-of-the-art neural and neuro-symbolic models for visual question answering on CLEVR-Math and empirically evaluate their performances. Our results show how neither method generalise to chains of operations. We discuss the limitations of the two in addressing the task of multi-modal word problem solving.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["paper: [https://ceur-ws.org/Vol-3212/paper11.pdf], github: [https://github.com/dali-does/clevr-math]"]}}
}

@article{rayyan-242083826,
  title={Leveraging Large Language Models to Generate Answer Set Programs},
  year={2023},
  author={Ishay, Adam and Yang, Zhun and Joohyung, Lee},
  abstract={Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer set programs. The majority of errors made are relatively simple and can be easily corrected by humans, thus enabling LLMs to effectively assist in the creation of answer set programs.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["paper: [https://openreview.net/forum?id=cq6jL6EUiG&referrer=%5Bthe%20profile%20of%20Zhun%20Yang%5D(%2Fprofile%3Fid%3D~Zhun_Yang1)], github: [https://github.com/azreasoners/gpt-asp-rules]"]}}
}

@article{rayyan-242083828,
  title={Composing Neural Learning and Symbolic Reasoning with an Application to Visual Discrimination},
  year={2019},
  author={Murali, Adithya and Sehgal, Atharva and Krogmeier, Paul and , P. Madhusudan},
  abstract={We consider the problem of combining machine learning models to perform higher-level cognitive tasks with clear specifications. We propose the novel problem of Visual Discrimination Puzzles (VDP) that requires finding interpretable discriminators that classify images according to a logical specification. Humans can solve these puzzles with ease and they give robust, verifiable, and interpretable discriminators as answers. We propose a compositional neurosymbolic framework that combines a neural network to detect objects and relationships with a symbolic learner that finds interpretable discriminators. We create large classes of VDP datasets involving natural and artificial images and show that our neurosymbolic framework performs favorably compared to several purely neural approaches.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["GitHub: [https://github.com/muraliadithya/vdp]"]}}
}

@article{rayyan-242083832,
  title={Principled Transfer Learning for Autonomic Systems: A Neuro-Symbolic Vision},
  year={2024},
  author={Adriano, C. M. and Ghahremani, S.},
  url={https://ieeexplore.ieee.org/abstract/document/10766077/?casa_token=dWHupiH9X1sAAAAA:DKMScV3K8RE2KFAP6NnkahLSG_PRT2L8N-HjFOLiHaVl0zisXs3IFDAiuFgkDCclnBfPzST-Tx5udQ},
  abstract={… We present a workflow of neuro-symbolic models with the joint capability of manipulating both learned and rule-based knowledge. The models comprise a decision tree, a system graph…},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["github: [https://github.com/hpi-sam]"]}}
}

@article{rayyan-242083833,
  title={Greybox XAI: a Neural-Symbolic learning framework to produce interpretable predictions for image classification},
  year={2022},
  author={Bennetot, Adrien and Franchi, Gianni and Ser, Javier Del and Chatila, Raja and Natalia, Diaz-Rodriguez},
  abstract={Although Deep Neural Networks (DNNs) have great generalization and prediction capabilities, their functioning does not allow a detailed explanation of their behavior. Opaque deep learning models are increasingly used to make important predictions in critical environments, and the danger is that they make and use predictions that cannot be justified or legitimized. Several eXplainable Artificial Intelligence (XAI) methods that separate explanations from machine learning models have emerged, but have shortcomings in faithfulness to the model actual functioning and robustness. As a result, there is a widespread agreement on the importance of endowing Deep Learning models with explanatory capabilities so that they can themselves provide an answer to why a particular prediction was made. First, we address the problem of the lack of universal criteria for XAI by formalizing what an explanation is. We also introduced a set of axioms and definitions to clarify XAI from a mathematical perspective. Finally, we present the Greybox XAI, a framework that composes a DNN and a transparent model thanks to the use of a symbolic Knowledge Base (KB). We extract a KB from the dataset and use it to train a transparent model (i.e., a logistic regression). An encoder-decoder architecture is trained on RGB images to produce an output similar to the KB used by the transparent model. Once the two models are trained independently, they are used compositionally to form an explainable predictive model. We show how this new architecture is accurate and explainable in several datasets.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["paper: [https://www.researchgate.net/publication/364090265_Greybox_XAI_A_Neural-Symbolic_learning_framework_to_produce_interpretable_predictions_for_image_classification], github: [https://github.com/AdrienBennetot/Greybox-]"]}}
}

@article{rayyan-242083838,
  title={Fast and scalable learning of neuro-symbolic representations of biomedical knowledge},
  year={2018},
  author={Agibetov, A. and Samwald, M.},
  abstract={In this work we address the problem of fast and scalable learning of neuro-symbolic representations for general biological knowledge. Based on a recently published comprehensive …},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["GitHub: [https://github.com/matthias-samwald/Fast-and-scalable-neural-embedding-models-for-biomedical-sentence-classification/]"]}}
}

@article{rayyan-242083847,
  title={Semantic probabilistic layers for neuro-symbolic learning},
  year={2022},
  author={Ahmed, K. and Teso, S. and Chang, K. W.},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/c182ec594f38926b7fcb827635b9a8f4-Abstract-Conference.html},
  abstract={… Summarizing, we: (i) Identify six desiderata that neuro-symbolic … neuro-symbolic SOP tasks, such as HMLC and pathfinding, where it outperforms state-of-the-art neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/KareemYousrii/SPL]"]}}
}

@article{rayyan-242083849,
  title={Neuro-symbolic entropy regularization},
  year={2022},
  author={Ahmed, K. and Wang, E. and Chang, K. W.},
  url={https://proceedings.mlr.press/v180/ahmed22a.html},
  abstract={… “Full Entropy” and “NeSy Entropy", with “NeSy Entropy" leading to the best performing predictive models. Remarkably, we also observe that “NeSy Entropy” leads to predictive models …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/UCLA-StarAI/NeSyEntropy]"]}}
}

@article{rayyan-242083850,
  title={Pylon: A PyTorch Framework for Learning with Constraints},
  year={2021},
  volume={176},
  author={Ahmed, Kareem and Tao, Li and Thy, Ton and Quan, Guo and Kai-Wei, Chang and Parisa, Kordjamshidi and Vivek, Srikumar and den Broeck Guy, Van and Sameer, Singh},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={Deep learning excels at learning low-level task information from large amounts of data, but struggles with learning high-level domain knowledge, which can often be directly and succinctly expressed. In this work, we introduce Pylon, a neuro-symbolic training framework that builds on PyTorch to augment procedurally trained neural networks with declaratively specified knowledge. Pylon allows users to programmatically specify constraints as PyTorch functions, and compiles them into a differentiable loss, thus training predictive models that fit the data whilst satisfying the specified constraints. Pylon includes both exact as well as approximate compilers to efficiently compute the loss, employing fuzzy logic, sampling methods, and circuits, ensuring scalability even to complex models and constraints. A guiding principle in designing Pylon has been the ease with which any existing deep learning codebase can be extended to learn from constraints using only a few lines: a function expressing the constraint and a single line of code to compile it into a loss. We include case studies from natural language processing, computer vision, logical games, and knowledge graphs, that can be interactively trained, and highlights Pylon's usage.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | RAYYAN-EXCLUSION-REASONS: no-eval,not-research | USER-NOTES: {"Bhuvanesh"=>["No quantitative evaluation present and introduces a framework. ", "Paper: [https://proceedings.mlr.press/v176/ahmed22a.html], Website: [https://pylon-lib.github.io/], GitHub: [https://github.com/pylon-lib/pylon]"]}}
}

@article{rayyan-242083852,
  title={A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints},
  year={2024},
  author={Ahmed, Kareem and Kai-Wei, Chang and Van den Broeck, Guy},
  abstract={Neuro-symbolic AI bridges the gap between purely symbolic and neural approaches to learning. This often requires maximizing the likelihood of a symbolic constraint w.r.t the neural network's output distribution. Such output distributions are typically assumed to be fully-factorized. This limits the applicability of neuro-symbolic learning to the more expressive autoregressive distributions, e.g., transformers. Under such distributions, computing the likelihood of even simple constraints is #P-hard. Instead of attempting to enforce the constraint on the entire output distribution, we propose to do so on a random, local approximation thereof. More precisely, we optimize the likelihood of the constraint under a pseudolikelihood-based approximation centered around a model sample. Our approximation is factorized, allowing the reuse of solutions to sub-problems, a main tenet for efficiently computing neuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of the likelihood, exhibiting low entropy and KL-divergence around the model sample. We evaluate our approach on Sudoku and shortest-path prediction cast as autoregressive generation, and observe that we greatly improve upon the base model's ability to predict logically-consistent outputs. We also evaluate on the task of detoxifying large language models. Using a simple constraint disallowing a list of toxic words, we are able to steer the model's outputs away from toxic generations, achieving SoTA detoxification compared to previous approaches.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code is not currently available, but they share a GitHub link that we may be able to request to be populated. ", "PR Link: [https://proceedings.neurips.cc/paper_files/paper/2023/hash/3accfe8332366a6f740d8740cd4cd653-Abstract-Conference.html], GitHub: [https://github.com/UCLA-StarAI/PseudoSL]"]}}
}

@article{rayyan-242083853,
  title={Twist and Snap: A Neuro-Symbolic System for Affordance Learning of Opening Jars and Bottles},
  year={2024},
  author={Aina, J. A. and Hedblom, M. M.},
  url={https://ieeexplore.ieee.org/abstract/document/10797390/?casa_token=jvmUDB1ZDGMAAAAA:UD8iBUy9m1S3TNZ9YpqD4_Dm6ixh2WtZeoRVCWUYYxls9qC-K54ywBR2iOpsuD9K_duoci3p5jvObg},
  abstract={… Focusing on affordance learning, we introduce a neuro-symbolic AI system with a robot simulation capable of inferring appropriate action. The system's core is a visuo-lingual attribute …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/Joagai23/robot-neuro-symbolic-system]"]}}
}

@article{rayyan-242083855,
  title={Neuro-symbolic representations for video captioning: A case for leveraging inductive biases for vision and language},
  year={2020},
  author={Akbari, H. and Palangi, H. and Yang, J. and Rao, S.},
  abstract={Neuro-symbolic representations have proved effective in learning structure information in vision and language. In this paper, we propose a new model architecture for learning multi-…},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/hassanhub/R3Transformer]"]}}
}

@article{rayyan-242083861,
  title={Psychic: A neuro-symbolic framework for knowledge graph question-answering grounding},
  year={2023},
  author={Akl, H. A.},
  abstract={… We answer the KGQA over DBLP (DBLP-QUAD) task by proposing a neurosymbolic (NS) framework based on PSYCHIC 2, an extractive QA model capable of identifying the query and …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Hugging Face: [https://huggingface.co/HannaAbiAkl/psychic]", "The abstract claims that they create something based off Psychic. So we can reach out to the authors for the codebase"]}}
}

@article{rayyan-242083862,
  title={NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification},
  year={2024},
  author={Akl, H. A.},
  abstract={… This section describes our NeSy methodology combining a LLM agent and a symbolic … to prompt ChatGPT and create a neuro-symbolic workflow that teaches the LLM the proper syntax …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/HannaAbiAkl/NeSy-Code-Generation-Workflow]"]}}
}

@article{rayyan-242083872,
  title={Towards generalization in subitizing with neuro-symbolic loss using holographic reduced representations},
  year={2023},
  author={Alam, M. M. and Raff, E. and Oates, T.},
  abstract={… We investigate how this neuro-symbolic approach to learning affects the subitizing capability of CNNs and ViTs, and so we focus on specially crafted problems that isolate …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/MahmudulAlam/Subitizing]"]}}
}

@article{rayyan-242083874,
  title={Recasting Self-Attention with Holographic Reduced Representations},
  year={2023},
  volume={202},
  author={Alam, Mohammad Mahmudul and Edward, Raff and Stella, Biderman and Tim, Oates and James, Holt},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={In recent years, self-attention has become the dominant paradigm for sequence modeling in a variety of domains. However, in domains with very long sequence lengths the O(T-2) memory and O((TH)-H-2) compute costs can make using transformers infeasible. Motivated by problems in malware detection, where sequence lengths of T >= 100, 000 are a roadblock to deep learning, we re-cast self-attention using the neuro-symbolic approach of Holographic Reduced Representations (HRR). In doing so we perform the same high-level strategy of the standard self-attention: a set of queries matching against a set of keys, and returning a weighted response of the values for each key. Implemented as a ``Hrrformer '' we obtain several benefits including O(TH logH) time complexity, O(TH) space complexity, and convergence in 10x fewer epochs. Nevertheless, the Hrrformer achieves near state-of-the-art accuracy on LRA benchmarks and we are able to learn with just a single layer. Combined, these benefits make our Hrrformer the first viable Transformer for such long malware classification sequences and up to 280x faster to train on the Long Range Arena benchmark. Code is available at https: //github. com/NeuromorphicComputa tionResearchProgram/Hrrformer},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/NeuromorphicComputationResearchProgram/Hrrformer]"]}}
}

@article{rayyan-242083875,
  title={A Walsh Hadamard Derived Linear Vector Symbolic Architecture},
  year={2024},
  author={Alam, Mohammad Mahmudul and Oberle, Alexander and Raff, Edward and Biderman, Stella and Oates, Tim and Holt, James},
  abstract={Vector Symbolic Architectures (VSAs) are one approach to developing Neuro-symbolic AI, where two vectors in \({ℝ}{ᵈ}{\)} are `bound' together to produce a new vector in the same space. VSAs support the commutativity and associativity of this binding operation, along with an inverse operation, allowing one to construct symbolic-style manipulations over real-valued vectors. Most VSAs were developed before deep learning and automatic differentiation became popular and instead focused on efficacy in hand-designed systems. In this work, we introduce the Hadamard-derived linear Binding (HLB), which is designed to have favorable computational efficiency, and efficacy in classic VSA tasks, and perform well in differentiable systems. Code is available at https://github.com/FutureComputing4AI/Hadamard-derived-Linear-Binding},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/FutureComputing4AI/Hadamard-derived-Linear-Binding]"]}}
}

@article{rayyan-242083877,
  title={Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation},
  year={2025},
  author={Alcedo, K. and Lima, P. U. and Alami, R.},
  abstract={… Inspired by Theory of Mind and Epistemic Planning, we propose (1) a neuro-symbolic model-based reinforcement learning architecture for social navigation, addressing the challenge …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/alcedok/SocialNav_paper]"]}}
}

@article{rayyan-242083883,
  title={Noise to the Rescue: Escaping Local Minima in Neurosymbolic Local Search},
  year={2025},
  author={Daniele, Alessandro and Emile van, Krieken},
  abstract={Deep learning has achieved remarkable success across various domains, largely thanks to the efficiency of backpropagation (BP). However, BP's reliance on differentiability poses challenges in neurosymbolic learning, where discrete computation is combined with neural models. We show that applying BP to Godel logic, which represents conjunction and disjunction as min and max, is equivalent to a local search algorithm for SAT solving, enabling the optimisation of discrete Boolean formulas without sacrificing differentiability. However, deterministic local search algorithms get stuck in local optima. Therefore, we propose the Godel Trick, which adds noise to the model's logits to escape local optima. We evaluate the Godel Trick on SATLIB, and demonstrate its ability to solve a broad range of SAT problems. Additionally, we apply it to neurosymbolic models and achieve state-of-the-art performance on Visual Sudoku, all while avoiding expensive probabilistic reasoning. These results highlight the Godel Trick's potential as a robust, scalable approach for integrating symbolic reasoning with neural architectures.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/DanieleAlessandro/Godel-Trick.git]"]}}
}

@article{rayyan-242083885,
  title={Knowledge Enhanced Neural Networks for relational domains},
  year={2022},
  author={Daniele, Alessandro and Luciano, Serafini},
  abstract={In the recent past, there has been a growing interest in Neural-Symbolic Integration frameworks, i.e., hybrid systems that integrate connectionist and symbolic approaches to obtain the best of both worlds. In this work we focus on a specific method, KENN (Knowledge Enhanced Neural Networks), a Neural-Symbolic architecture that injects prior logical knowledge into a neural network by adding on its top a residual layer that modifies the initial predictions accordingly to the knowledge. Among the advantages of this strategy, there is the inclusion of clause weights, learnable parameters that represent the strength of the clauses, meaning that the model can learn the impact of each rule on the final predictions. As a special case, if the training data contradicts a constraint, KENN learns to ignore it, making the system robust to the presence of wrong knowledge. In this paper, we propose an extension of KENN for relational data. One of the main advantages of KENN resides in its scalability, thanks to a flexible treatment of dependencies between the rules obtained by stacking multiple logical layers. We show experimentally the efficacy of this strategy. The results show that KENN is capable of increasing the performances of the underlying neural network, obtaining better or comparable accuracies in respect to other two related methods that combine learning with logic, requiring significantly less time for learning.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/DanieleAlessandro/KENN2"]}}
}

@article{rayyan-242083891,
  title={L-TReiD: Logic Tensor Transformer for Re-identification},
  year={2023},
  volume={14362},
  author={Alessandro, Russo and Manigrasso, Francesco and Lamberti, Fabrizio and Morra, Lia},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={This article proposes a Neuro-Symbolic (NeSy) machine learning approach to Object Re-identification. NeSy is an emerging branch of artificial intelligence which combines symbolic reasoning and logic-based knowledge representation with the learning capabilities of neural networks. Since object re-identification involves assigning the identity of the same object across different images and different conditions, such a task could benefit greatly from leveraging the logic capabilities of a NeSy framework to inject prior knowledge about invariant properties of the objects. To test this assertion, we combined the Logic Tensor Networks (LTNs) NeSy framework with a state-of-the-art Transformer-based Re-Identification and Damage Detection Network (TransRe3ID). The LTN incorporates prior knowledge about the properties that two instances of the same object have in common. Experimental results on the Bent&Broken Bicycle re-identification dataset demonstrate the potential of LTNs to improve re-identification systems and provide novel opportunities to identify pitfalls during training.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/damo-cv/TransReID"]}}
}

@article{rayyan-242083892,
  title={A Framework for Neurosymbolic Robot Action Planning using Large Language Models},
  year={2023},
  author={Capitanelli, Alessio and Fulvio, Mastrogiovanni},
  abstract={Symbolic task planning is a widely used approach to enforce robot autonomy due to its ease of understanding and deployment in robot architectures. However, techniques for symbolic task planning are difficult to scale in real-world, human-robot collaboration scenarios because of the poor performance in complex planning domains or when frequent re-planning is needed. We present a framework, Teriyaki, specifically aimed at bridging the gap between symbolic task planning and machine learning approaches. The rationale is training Large Language Models (LLMs), namely GPT-3, into a neurosymbolic task planner compatible with the Planning Domain Definition Language (PDDL), and then leveraging its generative capabilities to overcome a number of limitations inherent to symbolic task planners. Potential benefits include (i) a better scalability in so far as the planning domain complexity increases, since LLMs' response time linearly scales with the combined length of the input and the output, and (ii) the ability to synthesize a plan action-by-action instead of end-to-end, making each action available for execution as soon as it is generated instead of waiting for the whole plan to be available, which in turn enables concurrent planning and execution. Recently, significant efforts have been devoted by the research community to evaluate the cognitive capabilities of LLMs, with alternate successes. Instead, with Teriyaki we aim to provide an overall planning performance comparable to traditional planners in specific planning domains, while leveraging LLMs capabilities to build a look-ahead predictive planning model. Preliminary results in selected domains show that our method can: (i) solve 95.5% of problems in a test data set of 1,000 samples; (ii) produce plans up to 13.5% shorter than a traditional symbolic planner; (iii) reduce average overall waiting times for a plan availability by up to 61.4%},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/alessiocpt/teriyaki"]}}
}

@article{rayyan-242083903,
  title={AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation},
  year={2024},
  author={Ibrahimzada, Ali Reza and Ke, Kaiyao and Pawagi, Mrigank and Abid, Muhammad Salman and Pan, Rangeet and Sinha, Saurabh and Reyhaneh, Jabbarvand},
  abstract={Code translation transforms programs from one programming language (PL) to another. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc. We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of <836, 8575, 2719> classes, methods, and tests. AlphaTrans breaks down these projects into 17874 fragments and translates the entire repository. 96.40% of the translated fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 27.03% and 25.14% of fragments. On average, the integrated translation and validation take 34 hours to translate a project, showing its scalability in practice. For the incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They were able to fix the issues in 20.1 hours on average and achieve all passing tests.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/Intelligent-CAT-Lab/AlphaTrans"]}}
}

@article{rayyan-242083907,
  title={Semantic referee: A neural-symbolic framework for enhancing geospatial semantic segmentation},
  year={2019},
  author={Alirezaie, M. and Längkvist, M. and Sioutis, M. and Loutfi, A.},
  url={https://content.iospress.com/articles/semantic-web/sw190362},
  abstract={… Our contribution differentiates from the neural-symbolic systems explained in Section 2 in three regards. Firstly, our method plays the role of a semantic referee for the imagery data …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/rezacsedu/SemanticRobot"]}}
}

@article{rayyan-242083917,
  title={Neuro-symbolic language modeling with automaton-augmented retrieval},
  year={2022},
  author={Alon, U. and Xu, F. and He, J. and Sengupta, S.},
  url={http://proceedings.mlr.press/v162/alon22a.html},
  abstract={… We believe that these results suggest a promising direction for the neuro-symbolic synergy … These results suggest a promising direction for the neurosymbolic synergy of neural models …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/neulab/retomaton]"]}}
}

@article{rayyan-242083918,
  title={Synthesizing a Progression of Subtasks for Block-Based Visual Programming Tasks},
  year={2023},
  author={Tercan, Alperen and Ghosh, Ahana and Eniser, Hasan Ferit and Christakis, Maria and Adish, Singla},
  abstract={Block-based visual programming environments play an increasingly important role in introducing computing concepts to K-12 students. In recent years, they have also gained popularity in neuro-symbolic AI, serving as a benchmark to evaluate general problem-solving and logical reasoning skills. The open-ended and conceptual nature of these visual programming tasks make them challenging, both for state-of-the-art AI agents as well as for novice programmers. A natural approach to providing assistance for problem-solving is breaking down a complex task into a progression of simpler subtasks; however, this is not trivial given that the solution codes are typically nested and have non-linear execution behavior. In this paper, we formalize the problem of synthesizing such a progression for a given reference block-based visual programming task. We propose a novel synthesis algorithm that generates a progression of subtasks that are high-quality, well-spaced in terms of their complexity, and solving this progression leads to solving the reference task. We show the utility of our synthesis algorithm in improving the efficacy of AI agents (in this case, neural program synthesizers) for solving tasks in the Karel programming environment. Then, we conduct a user study to demonstrate that our synthesized progression of subtasks can assist a novice programmer in solving tasks in the Hour of Code: Maze Challenge by Code-dot-org.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/machine-teaching-group/ProgresSyn]"]}}
}

@article{rayyan-242083919,
  title={Neuro-symbolic representation learning on biological knowledge graphs},
  year={2017},
  author={Alshahrani, M. and Khan, M. A. and Maddouri, O. and Kinjo, A. R.},
  url={https://academic.oup.com/bioinformatics/article-abstract/33/17/2723/3760100},
  abstract={Motivation Biological data and knowledge bases increasingly rely on Semantic Web technologies and the use of knowledge graphs for data integration, retrieval and federated queries. …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/bio-ontology-research-group/walking-rdf-and-owl]"]}}
}

@article{rayyan-242083921,
  title={Prioritizing genomic variants through neuro-symbolic, knowledge-enhanced learning},
  year={2024},
  volume={40},
  number={5},
  author={Althagafi, A. and Zhapa-Camacho, F. and Hoehndorf, R.},
  abstract={MOTIVATION: Whole-exome and genome sequencing have become common tools in diagnosing patients with rare diseases. Despite their success, this approach leaves many patients undiagnosed. A common argument is that more disease variants still await discovery, or the novelty of disease phenotypes results from a combination of variants in multiple disease-related genes. Interpreting the phenotypic consequences of genomic variants relies on information about gene functions, gene expression, physiology, and other genomic features. Phenotype-based methods to identify variants involved in genetic diseases combine molecular features with prior knowledge about the phenotypic consequences of altering gene functions. While phenotype-based methods have been successfully applied to prioritizing variants, such methods are based on known gene-disease or gene-phenotype associations as training data and are applicable to genes that have phenotypes associated, thereby limiting their scope. In addition, phenotypes are not assigned uniformly by different clinicians, and phenotype-based methods need to account for this variability. RESULTS: We developed an Embedding-based Phenotype Variant Predictor (EmbedPVP), a computational method to prioritize variants involved in genetic diseases by combining genomic information and clinical phenotypes. EmbedPVP leverages a large amount of background knowledge from human and model organisms about molecular mechanisms through which abnormal phenotypes may arise. Specifically, EmbedPVP incorporates phenotypes linked to genes, functions of gene products, and the anatomical site of gene expression, and systematically relates them to their phenotypic effects through neuro-symbolic, knowledge-enhanced machine learning. We demonstrate EmbedPVP's efficacy on a large set of synthetic genomes and genomes matched with clinical information. AVAILABILITY AND IMPLEMENTATION: EmbedPVP and all evaluation experiments are freely available at https://github.com/bio-ontology-research-group/EmbedPVP.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/bio-ontology-research-group/EmbedPVP]"]}}
}

@article{rayyan-242083933,
  title={Neuro-symbolic visual reasoning: Disentangling},
  year={2020},
  author={Amizadeh, S. and Palangi, H. and Polozov, A.},
  url={http://proceedings.mlr.press/v119/amizadeh20a.html},
  abstract={… As we show in Section 4, a neurosymbolic VQA model that has access to ground-truth scene graphs achieves 96% accuracy on GQA. Moreover, language interpretation (ie semantic …},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"}}
}

@article{rayyan-242083934,
  title={Neuro-Symbolic Visual Reasoning: Disentangling ``Visual '' from ``Reasoning ''},
  year={2020},
  volume={119},
  author={Amizadeh, Saeed and Hamid, Palangi and Oleksandr, Polozov and Yichen, Huang and Kazuhito, Koishida},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={Visual reasoning tasks such as visual question answering (VQA) require an interplay of visual perception with reasoning about the question semantics grounded in perception. However, recent advances in this area are still primarily driven by perception improvements (e.g. scene graph generation) rather than reasoning. Neuro-symbolic models such as Neural Module Networks bring the benefits of compositional reasoning to VQA, but they are still entangled with visual representation learning, and thus neural reasoning is hard to improve and assess on its own. To address this, we propose (1) a framework to isolate and evaluate the reasoning aspect of VQA separately from its perception, and (2) a novel top-down calibration technique that allows the model to answer reasoning questions even with imperfect perception. To this end, we introduce a differentiable first-order logic formalism for VQA that explicitly decouples question answering from visual perception. On the challenging GQA dataset, this framework is used to perform in-depth, disentangled comparisons between well-known VQA models leading to informative insights regarding the participating models as well as the task.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/microsoft/DFOL-VQA"]}}
}

@article{rayyan-242083941,
  title={Neurosymbolic reinforcement learning with formally verified exploration},
  year={2020},
  author={Anderson, G. and Verma, A. and Dillig, I.},
  url={https://proceedings.neurips.cc/paper_files/paper/2020/hash/448d5eda79895153938a8431919f4c9f-Abstract.html},
  abstract={We present REVEL, a partially neural reinforcement learning (RL) framework for provably safe exploration in continuous state and action spaces. A key challenge for provably safe deep …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/gavlegoat/safe-learning"], "Anh"=>["GitHub: [https://github.com/dair-iitd/NS-KGC-AUG]"]}}
}

@article{rayyan-242083963,
  title={A neuro-symbolic approach for real-world event recognition from weak supervision},
  year={2022},
  author={Apriceno, G. and Passerini, A. and Serafini, L.},
  url={https://cris.fbk.eu/handle/11582/336001},
  abstract={… On the other hand, neuro-symbolic approaches have shown their capability to constrain the … In this paper, we propose a neuro-symbolic approach for TED in a real world scenario …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/Gianlu94/A-neuro-symbolic-approach-for-real-world-event-recognition-from-weak-supervision]"]}}
}

@article{rayyan-242083964,
  title={Conversational neuro-symbolic commonsense reasoning},
  year={2021},
  author={Arabshahi, F. and Lee, J. and Gawarecki, M. and Mazaitis, K.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/16623},
  abstract={… We present a neuro-symbolic theorem prover that extracts multi-hop reasoning chains, and … conversational framework built on our neuro-symbolic system, that conversationally evokes …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ForoughA/CORGI]"]}}
}

@article{rayyan-242083966,
  title={NS3: Neuro-symbolic semantic code search},
  year={2022},
  author={Arakelyan, S. and Hakhverdyan, A.},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/43f5f6c5cb333115914c8448b8506411-Abstract-Conference.html},
  abstract={Semantic code search is the task of retrieving a code snippet given a textual description of its functionality. Recent work has been focused on using similarity metrics between neural …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ShushanArakelyan/modular_code_search]"]}}
}

@article{rayyan-242083967,
  title={A Neuro-Symbolic Approach for Fault Diagnosis in Smart Power Grids},
  year={2022},
  author={Aravanis, T. and Kabouris, I.},
  abstract={… Against this background, we present, in this work, a novel neurosymbolic approach for the diagnosis (ie, detection and classification) of the common faults encountered in modern power …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent to the author requesting code access", "Github: [https://github.com/faravanis/PCI_2022]"]}}
}

@article{rayyan-242083969,
  title={Identifying Logical Patterns in Text for Reasoning},
  year={2024},
  author={Armary, Pauline and Cheikh-Brahim, El-Vaigh and Antoine, Spicher and Labbani, Narsis Ouassila and Christophe, Nicolle},
  publisher={IEEE COMPUTER SOC},
  abstract={Translating unstructured text into logical format is a key challenge for building ontologies automatically and addressing deductive inference. Most of the approaches have tackled the identification of concepts and relations in text, but few of them have addressed the most complex axioms like class expression subsumption. This work proposes DeLIR, a neurosymbolic approach to identify complex logical patterns in text by combining a grammatical translation of dependency parsing trees and a fine-tuned Large language Model (LLM). DeLIR combines the strength of the parsing accuracy provided by a grammatical approach and pattern flexibility provided by a fine-tuned LLM. We evaluated our approach on FOLIO dataset for both translation capacity and inference capability. Our grammatical approach has a perfect parsing accuracy and combining the grammatical approach with LLMs improves the LLMS translation capacity: tinyLlama, T5-small-text2logic, Llama-7B and Mistral-7B. We also evaluate the inference capacity of the different LLMs. Mistral-7B, while being smaller than the state-of-the-art approach using GPT-4, presents similar results to predict the correct inference labels.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent to author asking for code access", "Github: [https://gitlab.com/anabasis-public/delir]"]}}
}

@article{rayyan-242083977,
  title={Answer Set Networks: Casting Answer Set Programming into Deep Learning},
  year={2024},
  author={Skryagin, Arseny and Ochs, Daniel and Deibert, Phillip and Kohaut, Simon and Dhami, Devendra Singh and Kristian, Kersting},
  abstract={Although Answer Set Programming (ASP) allows constraining neural-symbolic (NeSy) systems, its employment is hindered by the prohibitive costs of computing stable models and the CPU-bound nature of state-of-the-art solvers. To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep Probabilistic Logic Programming (DPPL). Specifically, we show how to translate ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded problem by leveraging GPU's batching and parallelization capabilities. Our experimental evaluations demonstrate that ASNs outperform state-of-the-art CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following two contributions based on the strengths of ASNs. Namely, we are the first to show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs to guide the training with logic. Further, we show the constitutional navigation of drones, i.e., encoding public aviation laws in an ASN for routing Unmanned Aerial Vehicles in uncertain environments.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [ https://github.com/ml-research/answersetnetworks/]"]}}
}

@article{rayyan-242083978,
  title={SLASH: Embracing Probabilistic Circuits into Neural Answer Set Programming},
  year={2021},
  author={Skryagin, Arseny and Stammer, Wolfgang and Ochs, Daniel and Dhami, Devendra Singh and Kristian, Kersting},
  abstract={The goal of combining the robustness of neural networks and the expressivity of symbolic methods has rekindled the interest in neuro-symbolic AI. Recent advancements in neuro-symbolic AI often consider specifically-tailored architectures consisting of disjoint neural and symbolic components, and thus do not exhibit desired gains that can be achieved by integrating them into a unifying framework. We introduce SLASH - a novel deep probabilistic programming language (DPPL). At its core, SLASH consists of Neural-Probabilistic Predicates (NPPs) and logical programs which are united via answer set programming. The probability estimates resulting from NPPs act as the binding element between the logical program and raw input data, thereby allowing SLASH to answer task-dependent logical queries. This allows SLASH to elegantly integrate the symbolic and neural components in a unified framework. We evaluate SLASH on the benchmark data of MNIST addition as well as novel tasks for DPPLs such as missing data prediction and set prediction with state-of-the-art performance, thereby showing the effectiveness and generality of our method.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/askrix/SLASH?tab=readme-ov-file]"]}}
}

@article{rayyan-242083985,
  title={Neural-Symbolic Descriptive Action Model from Images: The Search for STRIPS},
  year={2019},
  author={Asai, M.},
  abstract={Recent work on Neural-Symbolic systems that learn the discrete planning model from images has opened a promising direction for expanding the scope of Automated Planning and …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/guicho271828/latplan/"]}}
}

@article{rayyan-242083986,
  title={Learning neural-symbolic descriptive planning models via cube-space priors: The voyage home (to STRIPS)},
  year={2020},
  author={Asai, M. and Muise, C.},
  abstract={We achieved a new milestone in the difficult task of enabling agents to learn about their environment autonomously. Our neuro-symbolic architecture is trained end-to-end to produce a …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/guicho271828/latplan/"]}}
}

@article{rayyan-242083992,
  title={Learning with Holographic Reduced Representations},
  year={2021},
  author={Ganesan, Ashwinkumar and Gao, Hang and Gandhi, Sunil and Raff, Edward and Oates, Tim and Holt, James and Mark, McLean},
  abstract={Holographic Reduced Representations (HRR) are a method for performing symbolic AI on top of real-valued vectors by associating each vector with an abstract concept, and providing mathematical operations to manipulate vectors as if they were classic symbolic objects. This method has seen little use outside of older symbolic AI work and cognitive science. Our goal is to revisit this approach to understand if it is viable for enabling a hybrid neural-symbolic approach to learning as a differentiable component of a deep learning architecture. HRRs today are not effective in a differentiable solution due to numerical instability, a problem we solve by introducing a projection step that forces the vectors to exist in a well behaved point in space. In doing so we improve the concept retrieval efficacy of HRRs by over 100×. Using multi-label classification we demonstrate how to leverage the symbolic HRR properties to develop an output layer and loss function that is able to learn effectively, and allows us to investigate some of the pros and cons of an HRR neuro-symbolic learning approach. Our code can be found at https://github.com/NeuromorphicComputationResearchProgram/Learning-with-Holographic-Reduced-Representations},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/FutureComputing4AI/Learning-with-Holographic-Reduced-Representations"]}}
}

@article{rayyan-242083994,
  title={Embed2sym-scalable neuro-symbolic reasoning via clustered embeddings},
  year={2022},
  author={Aspis, Y. and Broda, K. and Lobo, J. and Russo, A.},
  url={https://scholar.archive.org/work/r3ff2msdz5gbdgatkevgg3dmem/access/wayback/https://proceedings.kr.org/2022/44/kr2022-0044-aspis-et-al.pdf},
  abstract={… Neuro-symbolic methods are seen as a method of … These systems see neuro-symbolic reasoning on raw data as a … In this paper we refer to these systems as “neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/YanivAspis/Embed2Sym"]}}
}

@article{rayyan-242083995,
  title={Neurosymbolic Grounding for Compositional World Models},
  year={2023},
  author={Sehgal, Atharva and Grayeli, Arya and Jennifer, J. Sun and Chaudhuri, Swarat},
  abstract={We introduce Cosmos, a framework for object-centric world modeling that is designed for compositional generalization (CompGen), i.e., high performance on unseen input scenes obtained through the composition of known visual atoms. The central insight behind Cosmos is the use of a novel form of neurosymbolic grounding. Specifically, the framework introduces two new tools: (i) neurosymbolic scene encodings, which represent each entity in a scene using a real vector computed using a neural encoder, as well as a vector of composable symbols describing attributes of the entity, and (ii) a neurosymbolic attention mechanism that binds these entities to learned rules of interaction. Cosmos is end-to-end differentiable; also, unlike traditional neurosymbolic methods that require representations to be manually mapped to symbols, it computes an entity's symbolic attributes using vision-language foundation models. Through an evaluation that considers two different forms of CompGen on an established blocks-pushing domain, we show that the framework establishes a new state-of-the-art for CompGen in world modeling. Artifacts are available at: https://trishullab.github.io/cosmos-web/},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/trishullab/cosmos"]}}
}

@article{rayyan-242084010,
  title={-NeSy: A Possibilistic Neuro-Symbolic Approach},
  year={2025},
  author={Baaj, I. and Marquis, P.},
  abstract={… Π-NeSy requires explicit background knowledge to perform the high-level reasoning task. … Π-NeSy joint inference The structure of our neuro-symbolic approach Π-NeSy, which enables …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ibaaj/pi-nesy]"]}}
}

@article{rayyan-242084020,
  title={Logic Tensor Networks},
  year={2022},
  volume={303},
  author={Badreddine, Samy and d'Avila, Garcez Artur and Luciano, Serafini and Michael, Spranger},
  abstract={Attempts at combining logic and neural networks into neurosymbolic approaches have been on the increase in recent years. In a neurosymbolic system, symbolic knowledge assists deep learning, which typically uses a sub-symbolic distributed representation, to learn and reason at a higher level of abstraction. We present Logic Tensor Networks (LTN), a neurosymbolic framework that supports querying, learning and reasoning with both rich data and abstract knowledge about the world. LTN introduces a fully differentiable logical language, called Real Logic, whereby the elements of a first-order logic signature are grounded onto data using neural computational graphs and first-order fuzzy logic semantics. We show that LTN provides a uniform language to represent and compute efficiently many of the most important AI tasks such as multi-label classification, relational learning, data clustering, semi-supervised learning, regression, embedding learning and query answering. We implement and illustrate each of the above tasks with several simple explanatory examples using TensorFlow 2. The results indicate that LTN can be a general and powerful framework for neurosymbolic AI. (c) 2021 Elsevier B.V. All rights reserved. (C) 2021 Elsevier B.V. All rights reserved.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/logictensornetworks/logictensornetworks"]}}
}

@article{rayyan-242084021,
  title={Interval Logic Tensor Networks},
  year={2023},
  author={Badreddine, Samy and Apriceno, Gianluca and Passerini, Andrea and Serafini, Luciano},
  abstract={In this paper, we introduce Interval Real Logic (IRL), a two-sorted logic that interprets knowledge such as sequential properties (traces) and event properties using sequences of real-featured data. We interpret connectives using fuzzy logic, event durations using trapezoidal fuzzy intervals, and fuzzy temporal relations using relationships between the intervals' areas. We propose Interval Logic Tensor Networks (ILTN), a neuro-symbolic system that learns by propagating gradients through IRL. In order to support effective learning, ILTN defines smoothened versions of the fuzzy intervals and temporal relations of IRL using softplus activations. We show that ILTN can successfully leverage knowledge expressed in IRL in synthetic tasks that require reasoning about events to predict their fuzzy durations. Our results show that the system is capable of making events compliant with background temporal knowledge.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github:https://github.com/sbadredd/interval-ltn"]}}
}

@article{rayyan-242084027,
  title={A Practical Three-phase Approach To Fully Automated Programming Using System Decomposition And Coding Copilots},
  year={2023},
  author={Bai, Hao},
  publisher={Association for Computing Machinery},
  abstract={Very large-scale (VLS) deep learning models are capable of generating meaningful code snippets, yet the performance drops dramatically when the coding task becomes more complex. Although fully neural approaches have been proposed to solve this problem, the value of the application is still limited. In our work, we propose a neuro-symbolic approach that integrates the symbolic natures of programming and the existing neural language models. We divide a programming task into three phases: forming a hierarchical task composed of functions, completing each function, and fulfilling the corner cases. Because each phase can be completed by language models, the coding process can be fully automated. Our contribution is three-fold. Firstly, we show that with little help from humans, VLS language models are capable of completing non-trivial programming tasks. Secondly, we provide a number of empirical insights to create prompt templates that help the language models generate better code. Thirdly, compared to the existing approaches, our work provides a much more practical approach for programmers and researchers to follow. The generated programming project using our fully automated programming approach and part of the ablation study code are available at https://github.com/BiEchi/FAP.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/BiEchi/FAP]"], "Haowei"=>["github: https://github.com/BiEchi/FAP"]}}
}

@article{rayyan-242084028,
  title={Argument Identification for Neuro-Symbolic Dispute Resolution in Scientific Peer Review},
  year={2025},
  author={Baimuratov, Ildar and Alexandr, Karpovich and Elena, Lisanyuk and Dmitry, Prokudin},
  publisher={Association for Computing Machinery},
  abstract={Peer review is a cornerstone of the academic editorial decision-making process, yet it faces significant challenges. Artificial intelligence can help address these challenges, but its use raises concerns about reliability and the potential for reproducing existing biases. In this research, we employ a formal argumentation-theoretic framework that allows for explicit analysis of arguments and their interrelations, combined with argument mining techniques to streamline the formalization of peer reviews, and resulting in a neuro-symbolic approach to dispute resolution. Our method involves identifying parties' arguments in peer reviews and representing them as abstract argumentation frameworks, which facilitate dispute resolution through logical inference. We annotate these frameworks within a corpus of scientific peer reviews, achieving a high Krippendorff's alpha of 0.81. Having the annotated corpus, we implement an argument mining pipeline that integrates BERT sentence embeddings with an LSTM model, classifying sentences into three categories: authors' arguments, reviewers' arguments, and non-arguments. We achieved an accuracy of 0.634 and an F1 score of 0.631, which are comparable to models trained on other datasets. However, our approach stands out by enabling the processing of the extracted argumentation with logical inference.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Karpovich-alex/mdpi_argumentations]"], "Haowei"=>["github: https://github.com/Karpovich-alex/mdpi_argumentations"]}}
}

@article{rayyan-242084029,
  title={CodePlan: Repository-Level Coding using LLMs and Planning},
  year={2024},
  volume={1},
  author={Bairi, Ramakrishna and Atharv, Sonwane and Aditya, Kanade and C. Vageesh, D. and Arun, Iyer and Suresh, Parthasarathy and Sriram, Rajamani and Ashok, B. and Shashank, Shet},
  abstract={Software engineering activities such as package migration, fixing error reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code. We formulate these activities as repository-level coding tasks. Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems. Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt. We frame repository-level coding as a planning problem and present a task-agnostic, neuro-symbolic framework called CodePlan to solve it. CodePlan synthesizes a multi-step chain-of-edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions. CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm (symbolic components) with the neural LLMs. We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2-97 files). Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines. CodePlan is able to get 5/7 repositories to pass the validity checks (i.e., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them. We provide our (non-proprietary) data, evaluation scripts and supplementary material at https://github.com/microsoft/codeplan.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/microsoft/codeplan"]}}
}

@article{rayyan-242084032,
  title={xLP: Explainable Link Prediction for Master Data Management},
  year={2024},
  author={Ganesan, Balaji and Pasha, Matheen Ahmed and Parkala, Srinivasa and Neeraj, R. Singh and Mishra, Gayatri and Bhatia, Sumit and Patel, Hima and Naganna, Somashekar and Mehta, Sameep},
  abstract={Explaining neural model predictions to users requires creativity. Especially in enterprise applications, where there are costs associated with users' time, and their trust in the model predictions is critical for adoption. For link prediction in master data management, we have built a number of explainability solutions drawing from research in interpretability, fact verification, path ranking, neuro-symbolic reasoning and self-explaining AI. In this demo, we present explanations for link prediction in a creative way, to allow users to choose explanations they are more comfortable with.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Asked for codebase, 06/15"], "Haowei"=>["github: https://github.com/kingsaint/InductiveExplainableLinkPrediction"]}}
}

@article{rayyan-242084033,
  title={Ready Player One! Eliciting Diverse Knowledge Using A Configurable Game},
  year={2022},
  author={Balayn, Agathe and Gaole, He and Andrea, Hu and Jie, Yang and Ujwal, Gadiraju},
  publisher={ASSOC COMPUTING MACHINERY},
  abstract={Access to commonsense knowledge is receiving renewed interest for developing neuro-symbolic AI systems, or debugging deep learning models. Little is currently understood about the types of knowledge that can be gathered using existing knowledge elicitation methods. Moreover, these methods fall short of meeting the evolving requirements of several downstream AI tasks. To this end, collecting broad and tacit knowledge, in addition to negative or discriminative knowledge can be highly useful. Addressing this research gap, we developed a novel game with a purpose, `FindItOut', to elicit different types of knowledge from human players through easily configurable game mechanics. We recruited 125 players from a crowdsourcing platform, who played 2430 rounds, resulting in the creation of more than 150k tuples of knowledge. Through an extensive evaluation of these tuples, we show that FindItOut can successfully result in the creation of plural knowledge with a good player experience. We evaluate the efficiency of the game (over 10x higher than a reference baseline) and the usefulness of the resulting knowledge, through the lens of two downstream tasks - commonsense question answering and the identification of discriminative attributes. Finally, we present a rigorous qualitative analysis of the tuples' characteristics, that informs the future use of FindItOut across various researcher and practitioner communities.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/delftcrowd/FindItOut]"]}}
}

@article{rayyan-242084034,
  title={Fine-Tuning Large Enterprise Language Models via Ontological Reasoning},
  year={2023},
  volume={14244},
  author={Baldazzi, Teodoro and Luigi, Bellomarini and Stefano, Ceri and Andrea, Colombo and Andrea, Gentili and Emanuel, Sallinger},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Large Language Models (LLMs) exploit fine-tuning as a technique to adapt to diverse goals, thanks to task-specific training data. Task specificity should go hand in hand with domain orientation, that is, the specialization of an LLM to accurately address the tasks of a given realm of interest. However, models are usually fine-tuned over publicly available data or, at most, over ground data from databases, ignoring business-level definitions and domain experience. On the other hand, Enterprise Knowledge Graphs (EKGs) are able to capture and augment such domain knowledge via ontological reasoning. With the goal of combining LLM flexibility with the domain orientation of EKGs, we propose a novel neurosymbolic architecture that leverages the power of ontological reasoning to build task- and domain-specific corpora for LLM fine-tuning.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Asked for codebase, 06/15"]}}
}

@article{rayyan-242084037,
  title={Neural-Symbolic Recommendation with Graph-Enhanced Information},
  year={2023},
  author={Chen, Bang and Peng, Wei and Wu, Maonian and Zheng, Bo and Shaojun, Zhu},
  abstract={The recommendation system is not only a problem of inductive statistics from data but also a cognitive task that requires reasoning ability. The most advanced graph neural networks have been widely used in recommendation systems because they can capture implicit structured information from graph-structured data. However, like most neural network algorithms, they only learn matching patterns from a perception perspective. Some researchers use user behavior for logic reasoning to achieve recommendation prediction from the perspective of cognitive reasoning, but this kind of reasoning is a local one and ignores implicit information on a global scale. In this work, we combine the advantages of graph neural networks and propositional logic operations to construct a neuro-symbolic recommendation model with both global implicit reasoning ability and local explicit logic reasoning ability. We first build an item-item graph based on the principle of adjacent interaction and use graph neural networks to capture implicit information in global data. Then we transform user behavior into propositional logic expressions to achieve recommendations from the perspective of cognitive reasoning. Extensive experiments on five public datasets show that our proposed model outperforms several state-of-the-art methods, source code is avaliable at [https://github.com/hanzo2020/GNNLR].},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/hanzo2020/GNNLR]"]}}
}

@article{rayyan-242084040,
  title={Neuro-symbolic AI for compliance checking of electrical control panels},
  year={2023},
  author={Barbara, V. and Guarascio, M. and Leone, N. and Manco, G.},
  url={https://www.cambridge.org/core/journals/theory-and-practice-of-logic-programming/article/neurosymbolic-ai-for-compliance-checking-of-electrical-control-panels/11D166DB93715AD996EC98B7ADF4278B},
  abstract={… In particular, we define a Neuro-Symbolic approach for automating the compliance … This paper describes a Neuro-symbolic approach to checking the compliance of electrical control …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["emailed for codebase, 06/15", "Github: [https://github.com/aleqrt/mask-rcnn-api]", "Comment from authors: \"Please note that some sections of the code are in Italian, as it was originally developed for internal use as part of a larger industrial application project. However, since that application is proprietary, we were not able to include that part in the public repository.  That said, the available code is sufficient for research purposes and allows you to train the models and reproduce the results.    Regarding the ASP component, I recommend referring directly to the explanations and examples provided in the paper.    Let me know if you have any further questions. We’d be happy to see your work and would appreciate your citation.\""]}}
}

@article{rayyan-242084041,
  title={Interpretable neural-symbolic concept reasoning},
  year={2023},
  author={Barbiero, P. and Ciravegna, G. and Giannini, F.},
  url={http://proceedings.mlr.press/v202/barbiero23a.html},
  abstract={… of neural-symbolic systems trained using human rules (Table 1) Our experiments show that DCR generates rules that, when applied, obtain accuracy levels close to neural-symbolic …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/pietrobarbiero/pytorch_explain]"]}}
}

@article{rayyan-242084050,
  title={ImageEye: Batch Image Processing using Program Synthesis},
  year={2023},
  volume={7},
  author={Barnaby, Celeste and Qiaochu, Chen and Roopsha, Samanta and c il, Dillig I.},
  abstract={This paper presents a new synthesis-based approach for batch image processing. Unlike existing tools that can only apply global edits to the entire image, our method can apply fine-grained edits to individual objects within the image. For example, our method can selectively blur or crop specific objects that have a certain property. To facilitate such fine-grained image editing tasks, we propose a neuro-symbolic domain-specific language (DSL) that combines pre-trained neural networks for image classification with other language constructs that enable symbolic reasoning. Our method can automatically learn programs in this DSL from user demonstrations by utilizing a novel synthesis algorithm. We have implemented the proposed technique in a tool called ImageEye and evaluated it on 50 image editing tasks. Our evaluation shows that ImageEye is able to automate 96% of these tasks.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/celestebarnaby/ImageEye]"], "Haowei"=>["github: https://github.com/celestebarnaby/ImageEye"]}}
}

@article{rayyan-242084063,
  title={EXPLORER: Exploration-guided Reasoning for Textual Reinforcement Learning},
  year={2024},
  author={Basu, Kinjal and Keerthiram, Murugesan and Subhajit, Chaudhury and Murray, Campbell and Kartik, Talamadupula and Tim, Klinger},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Text-based games (TBGs) have emerged as an important collection of NLP tasks, requiring reinforcement learning (RL) agents to combine natural language understanding with reasoning. A key challenge for agents attempting to solve such tasks is to generalize across multiple games and demonstrate good performance on both seen and unseen objects. Purely deep-RL-based approaches may perform well on seen objects; however, they fail to showcase the same performance on unseen objects. Commonsense-infused deep-RL agents may work better on unseen data; unfortunately, their policies are often not interpretable or easily transferable. To tackle these issues, in this paper, we present EXPLORER1 which is an exploration-guided reasoning agent for textual reinforcement learning. EXPLORER is neuro-symbolic in nature, as it relies on a neural module for exploration and a symbolic module for exploitation. It can also learn generalized symbolic policies and perform well over unseen data. Our experiments show that EXPLORER outperforms the baseline agents on Text-World cooking (TW-Cooking) and Text-World Commonsense (TWC) games.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/kinjalbasu/explorer]"]}}
}

@article{rayyan-242084064,
  title={NSA: Neuro-symbolic ARC Challenge},
  year={2025},
  author={Batorski, P. and Brinkmann, J. and Swoboda, P.},
  abstract={The Abstraction and Reasoning Corpus (ARC) evaluates general reasoning capabilities that are difficult for both machine learning models and combinatorial search methods. We …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Batorskq/NSA]"]}}
}

@article{rayyan-242084065,
  title={Neuro-symbolic visual graph question answering with LLMs for language parsing},
  year={2023},
  author={Bauer, J. J. and Eiter, T. and Ruiz, N. H.},
  url={https://repositum.tuwien.at/bitstream/20.500.12708/193865/1/Bauer-2023-Neuro-Symbolic%20Visual%20Graph%20Question%20Answering%20with%20LLMs%20for%20L...-vor.pdf},
  abstract={Images containing graph-based structures are an ubiquitous and popular form of data representation that, to the best of our knowledge, have not yet been considered in the domain of …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/pudumagico/NSGRAPH]"]}}
}

@article{rayyan-242084066,
  title={Neuro-symbolic rule learning in real-world classification tasks},
  year={2023},
  author={Baugh, K. G. and Cingillioglu, N. and Russo, A.},
  abstract={Neuro-symbolic rule learning has attracted lots of attention as it offers better interpretability than pure neural models and scales better than symbolic rule learning. A recent approach …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/kittykg/neural-dnf-cub]", "Github: [https://github.com/kittykg/neural-dnf-tmc]", "They have split the codebase into two for two separate experiments"], "Haowei"=>["github:https://github.com/kittykg/neural-dnf-cub"]}}
}

@article{rayyan-242084067,
  title={Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies},
  year={2025},
  author={Baugh, K. G. and Dickens, L. and Russo, A.},
  abstract={Although deep reinforcement learning has been shown to be effective, the model's black-box nature presents barriers to direct policy interpretation. To address this problem, we propose …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/kittykg/neural-dnf-mt-policy-learning]"], "Haowei"=>["github: https://github.com/kittykg/neural-dnf-mt-policy-learning"]}}
}

@article{rayyan-242084082,
  title={Temporal Reasoning on Implicit Events from Distant Supervision},
  year={2020},
  author={Zhou, Ben and Richardson, Kyle and Ning, Qiang and Khot, Tushar and Sabharwal, Ashish and Dan, Roth},
  abstract={We propose TRACIE, a novel temporal reasoning dataset that evaluates the degree to which systems understand implicit events - events that are not mentioned explicitly in natural language text but can be inferred from it. This introduces a new challenge in temporal reasoning research, where prior work has focused on explicitly mentioned events. Human readers can infer implicit events via commonsense reasoning, resulting in a more comprehensive understanding of the situation and, consequently, better reasoning about time. We find, however, that state-of-the-art models struggle when predicting temporal relationships between implicit and explicit events. To address this, we propose a neuro-symbolic temporal reasoning model, SYMTIME, which exploits distant supervision signals from large-scale text and uses temporal rules to combine start times and durations to infer end times. SYMTIME outperforms strong baseline systems on TRACIE by 5%, and by 11% in a zero prior knowledge training setting. Our approach also generalizes to other temporal reasoning tasks, as evidenced by a gain of 1%-9% on MATRES, an explicit event benchmark.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/allenai/tracie"]}}
}

@article{rayyan-242084084,
  title={Controllable neural symbolic regression},
  year={2023},
  author={Bendinelli, T. and Biggio, L.},
  url={http://proceedings.mlr.press/v202/bendinelli23a.html},
  abstract={In symbolic regression, the objective is to find an analytical expression that accurately fits experimental data with the minimal use of mathematical symbols such as operators, variables, …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/SymposiumOrganization/ControllableNeuralSymbolicRegression"]}}
}

@article{rayyan-242084089,
  title={Preliminary Results on a State-Driven Method for Rule Construction in Neural-Symbolic Reinforcement Learning},
  year={2023},
  author={Beretta, D. and Monica, S. and Bergenti, F.},
  url={https://www.cs.ox.ac.uk/isg/conferences/tmp-proceedings/NeSy2023/paper10.pdf},
  abstract={… these limitations, neural-symbolic methods for reinforcement learning have been recently proposed. This paper presents preliminary results on a new neural-symbolic method for …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["mostly a previous paper's code to do some hyperparameter tuning", "Github: [github.com/ZhengyaoJiang/NLRL]"]}}
}

@article{rayyan-242084095,
  title={Jointly Learning Truth-Conditional Denotations and Groundings using Parallel Attention},
  year={2021},
  author={Bergen, Leon and Bahdanau, Dzmitry and O'Donnell, Timothy J.},
  abstract={We present a model that jointly learns the denotations of words together with their groundings using a truth-conditional semantics. Our model builds on the neurosymbolic approach of Mao et al. (2019), learning to ground objects in the CLEVR dataset (Johnson et al., 2017) using a novel parallel attention mechanism. The model achieves state of the art performance on visual question answering, learning to detect and ground objects with question performance as the only training signal. We also show that the model is able to learn flexible non-canonical groundings just by adjusting answers to questions in the training set.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent", "Github: [https://github.com/bergen/learning-groundings]"]}}
}

@article{rayyan-242084107,
  title={Let Me Help You! Neuro-Symbolic Short-Context Action Anticipation},
  year={2024},
  author={Bhagat, S. and Li, S. and Campbell, J. and Xie, Y.},
  url={https://ieeexplore.ieee.org/abstract/document/10582423/?casa_token=hTeNd2UASrcAAAAA:DjMPab_aQ32aBfXcSHJEzJ7fXfh5gkxeuX8a4GZ8IZ6Y9mqOGzmPl6Gxdy72itdQYTWak3Uo7mgFog},
  abstract={In an era where robots become available to the general public, the applicability of assistive robotics extends across numerous aspects of daily life, including in-home robotics. This work …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/sarthak268/nesca-pytorch]"]}}
}

@article{rayyan-242084108,
  title={Sample- Efficient Learning of Novel Visual Concepts},
  year={2023},
  volume={232},
  author={Bhagat, Sarthak and Simon, Stepputtis and Joseph, Campbell and Katia, Sycara},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={Despite the advances made in visual object recognition, state-of-the-art deep learning models struggle to effectively recognize novel objects in a few-shot setting where only a limited number of examples are provided. Unlike humans who excel at such tasks, these models often fail to leverage known relationships between entities in order to draw conclusions about such objects. In this work, we show that incorporating a symbolic knowledge graph into a state-of-the-art recognition model enables a new approach for effective few-shot classification. In our proposed neuro-symbolic architecture and training methodology, the knowledge graph is augmented with additional relationships extracted from a small set of examples, improving its ability to recognize novel objects by considering the presence of interconnected entities. Unlike existing few-shot classifiers, we show that this enables our model to incorporate not only objects but also abstract concepts and affordances. The existence of the knowledge graph also makes this approach amenable to interpretability through analysis of the relationships contained within it. We empirically show that our approach outperforms current state-of-the-art few-shot multi-label classification methods on the COCO dataset and evaluate the addition of abstract concepts and affordances on the Visual Genome dataset.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/sarthak268/sample-efficient-visual-concept-learning]"]}}
}

@article{rayyan-242084110,
  title={Language Independent Neuro-Symbolic Semantic Parsing for Form Understanding},
  year={2023},
  author={Voutharoja, Bhanu Prakash and Qu, Lizhen and Fatemeh, Shiri},
  abstract={Recent works on form understanding mostly employ multimodal transformers or large-scale pre-trained language models. These models need ample data for pre-training. In contrast, humans can usually identify key-value pairings from a form only by looking at layouts, even if they don't comprehend the language used. No prior research has been conducted to investigate how helpful layout information alone is for form understanding. Hence, we propose a unique entity-relation graph parsing method for scanned forms called LAGNN, a language-independent Graph Neural Network model. Our model parses a form into a word-relation graph in order to identify entities and relations jointly and reduce the time complexity of inference. This graph is then transformed by deterministic rules into a fully connected entity-relation graph. Our model simply takes into account relative spacing between bounding boxes from layout information to facilitate easy transfer across languages. To further improve the performance of LAGNN, and achieve isomorphism between entity-relation graphs and word-relation graphs, we use integer linear programming (ILP) based inference. Code is publicly available at https://github.com/Bhanu068/LAGNN},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/Bhanu068/LAGNN]"]}}
}

@article{rayyan-242084128,
  title={Complementing Logical Reasoning with Sub-symbolic Commonsense},
  year={2019},
  volume={11784},
  author={Bianchi, Federico and Matteo, Palmonari and Pascal, Hitzler and Luciano, Serafini},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Neuro-symbolic integration is a current field of investigation in which symbolic approaches are combined with deep learning ones. In this work we start from simple non-relational knowledge that can be extracted from text by considering the co-occurrence of entities inside textual corpora; we show that we can easily integrate this knowledge with Logic Tensor Networks (LTNs), a neuro-symbolic model. Using LTNs it is possible to integrate axioms and facts with commonsense knowledge represented in a sub-symbolic form in one single model performing well in reasoning tasks. In spite of some current limitations, we show that results are promising.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/vinid/logical_commonsense]"]}}
}

@article{rayyan-242084132,
  title={Neural symbolic regression that scales},
  year={2021},
  author={Biggio, L. and Bendinelli, T. and Neitz, A.},
  url={https://proceedings.mlr.press/v139/biggio21a.html},
  abstract={Symbolic equations are at the core of scientific discovery. The task of discovering the underlying equation from a set of input-output pairs is called symbolic regression. Traditionally, …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/SymposiumOrganization/NeuralSymbolicRegressionThatScales]"]}}
}

@article{rayyan-242084143,
  title={Deep Node Ranking for Neuro-symbolic Structural Node Embedding and Classification},
  year={2019},
  author={Škrlj, Blaž and Kralj, Jan and Konc, Janez and Robnik-Šikonja, Marko and Nada, Lavrač},
  abstract={Network node embedding is an active research subfield of complex network analysis. This paper contributes a novel approach to learning network node embeddings and direct node classification using a node ranking scheme coupled with an autoencoder-based neural network architecture. The main advantages of the proposed Deep Node Ranking (DNR) algorithm are competitive or better classification performance, significantly higher learning speed and lower space requirements when compared to state-of-the-art approaches on 15 real-life node classification benchmarks. Furthermore, it enables exploration of the relationship between symbolic and the derived sub-symbolic node representations, offering insights into the learned node space structure. To avoid the space complexity bottleneck in a direct node classification setting, DNR computes stationary distributions of personalized random walks from given nodes in mini-batches, scaling seamlessly to larger networks. The scaling laws associated with DNR were also investigated on 1488 synthetic Erdő s-Rényi networks, demonstrating its scalability to tens of millions of links.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/benedekrozemberczki/GraphWaveMachine]"]}}
}

@article{rayyan-242084152,
  title={Neural networks for abstraction and reasoning: Towards broad generalization in machines},
  year={2024},
  author={Bober-Irizar, Mikel and Banerjee, Soumya},
  abstract={For half a century, artificial intelligence research has attempted to reproduce the human qualities of abstraction and reasoning - creating computer systems that can learn new concepts from a minimal set of examples, in settings where humans find this easy. While specific neural networks are able to solve an impressive range of problems, broad generalisation to situations outside their training data has proved elusive.In this work, we look at several novel approaches for solving the Abstraction & Reasoning Corpus (ARC), a dataset of abstract visual reasoning tasks introduced to test algorithms on broad generalization. Despite three international competitions with 100,000 in prizes, the best algorithms still fail to solve a majority of ARC tasks and rely on complex hand-crafted rules, without using machine learning at all. We revisit whether recent advances in neural networks allow progress on this task. First, we adapt the DreamCoder neurosymbolic reasoning solver to ARC. DreamCoder automatically writes programs in a bespoke domain-specific language to perform reasoning, using a neural network to mimic human intuition. We present the Perceptual Abstraction and Reasoning Language (PeARL) language, which allows DreamCoder to solve ARC tasks, and propose a new recognition model that allows us to significantly improve on the previous best implementation.We also propose a new encoding and augmentation scheme that allows large language models (LLMs) to solve ARC tasks, and find that the largest models can solve some ARC tasks. LLMs are able to solve a different group of problems to state-of-the-art solvers, and provide an interesting way to complement other approaches. We perform an ensemble analysis, combining models to achieve better results than any system alone. Finally, we publish the arckit Python library to make future research on ARC easier.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/mxbi/arckit]"]}}
}

@article{rayyan-242084168,
  title={In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications},
  year={2021},
  author={Borja, G. León and Shanahan, Murray and Belardinelli, Francesco},
  abstract={We address the problem of building agents whose goal is to learn to execute out-of distribution (OOD) multi-task instructions expressed in temporal logic (TL) by using deep reinforcement learning (DRL). Recent works provided evidence that the agent's neural architecture is a key feature when DRL agents are learning to solve OOD tasks in TL. Yet, the studies on this topic are still in their infancy. In this work, we propose a new deep learning configuration with inductive biases that lead agents to generate latent representations of their current goal, yielding a stronger generalization performance. We use these latent-goal networks within a neuro-symbolic framework that executes multi-task formally-defined instructions and contrast the performance of the proposed neural networks against employing different state-of-the-art (SOTA) architectures when generalizing to unseen instructions in OOD environments.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/bgLeon/Latent-Goal-Architectures]"]}}
}

@article{rayyan-242084181,
  title={LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation},
  year={2024},
  author={Li, Bowen and Li, Zhaoyu and Du, Qiwei and Luo, Jinqi and Wang, Wenshan and Xie, Yaqi and Stepputtis, Simon and Wang, Chen and Katia, P. Sycara and Ravikumar, Pradeep Kumar and Gray, Alexander G. and Si, Xujie and Scherer, Sebastian},
  abstract={Recent years have witnessed the rapid development of Neuro-Symbolic (NeSy) AI systems, which integrate symbolic reasoning into deep neural networks. However, most of the existing benchmarks for NeSy AI fail to provide long-horizon reasoning tasks with complex multi-agent interactions. Furthermore, they are usually constrained by fixed and simplistic logical rules over limited entities, making them far from real-world complexities. To address these crucial gaps, we introduce LogiCity, the first simulator based on customizable first-order logic (FOL) for an urban-like environment with multiple dynamic agents. LogiCity models diverse urban elements using semantic and spatial concepts, such as IsAmbulance(X) and IsClose(X, Y). These concepts are used to define FOL rules that govern the behavior of various agents. Since the concepts and rules are abstractions, they can be universally applied to cities with any agent compositions, facilitating the instantiation of diverse scenarios. Besides, a key feature of LogiCity is its support for user-configurable abstractions, enabling customizable simulation complexities for logical reasoning. To explore various aspects of NeSy AI, LogiCity introduces two tasks, one features long-horizon sequential decision-making, and the other focuses on one-step visual reasoning, varying in difficulty and agent behaviors. Our extensive evaluation reveals the advantage of NeSy frameworks in abstract reasoning. Moreover, we highlight the significant challenges of handling more complex abstractions in long-horizon multi-agent scenarios or under high-dimensional, imbalanced data. With its flexible design, various features, and newly raised challenges, we believe LogiCity represents a pivotal step forward in advancing the next generation of NeSy AI. All the code and data are open-sourced at our website: https://jaraxxus-me.github.io/LogiCity/},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Jaraxxus-Me/LogiCity]"]}}
}

@article{rayyan-242084182,
  title={Neural Symbolic Logical Rule Learner for Interpretable Learning},
  year={2024},
  author={Wei, Bowen and Ziwei, Zhu},
  abstract={Rule-based neural networks stand out for enabling interpretable classification by learning logical rules for both prediction and interpretation. However, existing models often lack flexibility due to the fixed model structure. Addressing this, we introduce the Normal Form Rule Learner (NFRL) algorithm, leveraging a selective discrete neural network, that treat weight parameters as hard selectors, to learn rules in both Conjunctive Normal Form (CNF) and Disjunctive Normal Form (DNF) for enhanced accuracy and interpretability. Instead of adopting a deep, complex structure, the NFRL incorporates two specialized Normal Form Layers (NFLs) with adaptable AND/OR neurons, a Negation Layer for input negations, and a Normal Form Constraint (NFC) to streamline neuron connections. We also show the novel network architecture can be optimized using adaptive gradient update together with Straight-Through Estimator to overcome the gradient vanishing challenge. Through extensive experiments on 11 datasets, NFRL demonstrates superior classification performance, quality of learned rules, efficiency and interpretability compared to 12 state-of-the-art alternatives. Code and data are available at \url https://anonymous.4open.science/r/NFRL-27B4/ .},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Codebase expired, requested access, 06/17", "Github: [https://github.com/tdurieux/anonymous_github/], 4open.science: [https://anonymous.4open.science/r/NFRL-9DE5/README.md]"]}}
}

@article{rayyan-242084183,
  title={Rule-Based Error Detection and Correction to Operationalize Movement Trajectory Classification},
  year={2023},
  author={Xi, Bowen and Scaria, Kevin and Bavikadi, Divyagna and Paulo, Shakarian},
  abstract={Classification of movement trajectories has many applications in transportation and is a key component for large-scale movement trajectory generation and anomaly detection which has key safety applications in the aftermath of a disaster or other external shock. However, the current state-of-the-art (SOTA) are based on supervised deep learning - which leads to challenges when the distribution of trajectories changes due to such a shock. We provide a neuro-symbolic rule-based framework to conduct error correction and detection of these models to integrate into our movement trajectory platform. We provide a suite of experiments on several recent SOTA models where we show highly accurate error detection, the ability to improve accuracy with a changing test distribution, and accuracy improvement for the base use case in addition to a suite of theoretical properties that informed algorithm development. Specifically, we show an F1 scores for predicting errors of up to 0.984, significant performance increase for out-of distribution accuracy (8.51% improvement over SOTA for zero-shot accuracy), and accuracy improvement over the SOTA model.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/lab-v2/Error-Detection-and-Correction]"]}}
}

@article{rayyan-242084188,
  title={Commonsense Reasoning: how do Neuro-Symbolic and Neuro-only approaches compare?},
  year={2021},
  author={Branco, R. and Branco, A. and Silva, J. M. and Rodrigues, J.},
  url={https://ceur-ws.org/Vol-3052/short22.pdf},
  abstract={… In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only … Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior. …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/nlx-group/Commonsense-Reasoning-Neuro-only-vs-Neuro-Symbolic-Methods]"]}}
}

@article{rayyan-242084219,
  title={CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay},
  year={2024},
  volume={235},
  author={Butt, Natasha and Blazej, Manczak and Auke, Wiggers and Corrado, Rainone and Zhang David, W. and Michael, Defferrard and Taco, Cohen},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={Large language models are increasingly solving tasks that are commonly believed to require human-level reasoning ability. However, these models still perform very poorly on benchmarks of general intelligence such as the Abstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a programming-by-examples problem, and introduce a novel and scalable method for language model self-improvement called Code Iteration (CodeIt). Our method iterates between 1) program sampling and hindsight relabeling, and 2) learning from prioritized experience replay. By relabeling the goal of an episode (i.e., the target program output given input) to the realized output produced by the sampled program, our method effectively deals with the extreme sparsity of rewards in program synthesis. Applying CodeIt to the ARC dataset, we demonstrate that prioritized hindsight replay, along with pre-training and data-augmentation, leads to successful inter-task generalization. CodeIt is the first neuro-symbolic approach that scales to the full ARC evaluation dataset. Our method solves 15% of ARC evaluation tasks, achieving state-of-the-art performance and outperforming existing neural and symbolic baselines. Our code is available at https://github.com/Qualcomm-AI-research/codeit.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Qualcomm-AI-research/codeit]"]}}
}

@article{rayyan-242084222,
  title={NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning},
  year={2025},
  author={Cai, Z. and Ke, F. and Jahangard, S. and de la Banda, M. G.},
  abstract={Visual Grounding (VG) tasks, such as referring expression detection and segmentation tasks are important for linking visual entities to context, especially in complex reasoning tasks that …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ControlNet/NAVER]"], "Vladimir"=>["Github: [https://github.com/ControlNet/NAVER]"]}}
}

@article{rayyan-242084223,
  title={Logically consistent language models via neuro-symbolic integration},
  year={2024},
  author={Calanzone, D. and Teso, S. and Vergari, A.},
  abstract={Large language models (LLMs) are a promising venue for natural language understanding and generation. However, current LLMs are far from reliable: they are prone to generating …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ddidacus/loco-llm]"]}}
}

@article{rayyan-242084226,
  title={SenticNet 7: A Commonsense-based Neurosymbolic AI Framework for Explainable Sentiment Analysis},
  year={2022},
  author={Cambria, Erik and Qian, Liu and Sergio, Decherchi and Frank, Xing and Kenneth, Kwok},
  publisher={EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA},
  abstract={In recent years, AI research has demonstrated enormous potential for the benefit of humanity and society. While often better than its human counterparts in classification and pattern recognition tasks, however, AI still struggles with complex tasks that require commonsense reasoning such as natural language understanding. In this context, the key limitations of current AI models are: dependency, reproducibility, trustworthiness, interpretability, and explainability. In this work, we propose a commonsense-based neurosymbolic framework that aims to overcome these issues in the context of sentiment analysis. In particular, we employ unsupervised and reproducible subsymbolic techniques such as auto-regressive language models and kernel methods to build trustworthy symbolic representations that convert natural language to a sort of protolanguage and, hence, extract polarity from text in a completely interpretable and explainable manner.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/senticnet]"]}}
}

@article{rayyan-242084241,
  title={NeSIG: A Neuro-Symbolic Method for Learning to Generate Planning Problems},
  year={2023},
  author={Núñez-Molina, Carlos and Mesejo, Pablo and Juan, Fernández-Olivares},
  abstract={In the field of Automated Planning there is often the need for a set of planning problems from a particular domain, e.g., to be used as training data for Machine Learning or as benchmarks in planning competitions. In most cases, these problems are created either by hand or by a domain-specific generator, putting a burden on the human designers. In this paper we propose NeSIG, to the best of our knowledge the first domain-independent method for automatically generating planning problems that are valid, diverse and difficult to solve. We formulate problem generation as a Markov Decision Process and train two generative policies with Deep Reinforcement Learning to generate problems with the desired properties. We conduct experiments on three classical domains, comparing our approach against handcrafted, domain-specific instance generators and various ablations. Results show NeSIG is able to automatically generate valid and diverse problems of much greater difficulty (15.5 times more on geometric average) than domain-specific generators, while simultaneously reducing human effort when compared to them. Additionally, it can generalize to larger problems than those seen during training.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ari-dasci/S-PlanningProblemGeneration]"]}}
}

@article{rayyan-242084246,
  title={Mitigating data sparsity via neuro-symbolic knowledge transfer},
  year={2024},
  author={Carraro, T. and Daniele, A. and Aiolli, F. and Serafini, L.},
  abstract={… Following this idea, we propose a novel approach based on Neuro-Symbolic computing designed for the knowledge transfer task in recommender systems. In particular, we use a Logic …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/tommasocarraro/NESYKnowledgeTransfer"]}}
}

@article{rayyan-242084262,
  title={Learning to reason over scene graphs: a case study of finetuning GPT-2 into a robot language model for grounded task planning},
  year={2023},
  volume={10},
  author={Chalvatzaki, G. and Younes, A. and Nandha, D. and Le, A. T. and Ribeiro, L. F. R. and Gurevych, I.},
  abstract={Long-horizon task planning is essential for the development of intelligent assistive and service robots. In this work, we investigate the applicability of a smaller class of large language models (LLMs), specifically GPT-2, in robotic task planning by learning to decompose tasks into subgoal specifications for a planner to execute sequentially. Our method grounds the input of the LLM on the domain that is represented as a scene graph, enabling it to translate human requests into executable robot plans, thereby learning to reason over long-horizon tasks, as encountered in the ALFRED benchmark. We compare our approach with classical planning and baseline methods to examine the applicability and generalizability of LLM-based planners. Our findings suggest that the knowledge stored in an LLM can be effectively grounded to perform long-horizon task planning, demonstrating the promising potential for the future application of neuro-symbolic planning methods in robotics.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/dnandha/RobLM]"]}}
}

@article{rayyan-242084271,
  title={Neuro-symbolic commonsense social reasoning},
  year={2023},
  author={Chanin, D. and Hunter, A.},
  abstract={Social norms underlie all human social interactions, yet formalizing and reasoning with them remains a major challenge for AI systems. We present a novel system for taking social rules …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/chanind/amr-social-chemistry-reasoner]"]}}
}

@article{rayyan-242084274,
  title={Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning},
  year={2024},
  author={Dickens, Charles and Gao, Changyu and Pryor, Connor and Wright, Stephen and Lise, Getoor},
  abstract={We leverage convex and bilevel optimization techniques to develop a general gradient-based parameter learning framework for neural-symbolic (NeSy) systems. We demonstrate our framework with NeuPSL, a state-of-the-art NeSy architecture. To achieve this, we propose a smooth primal and dual formulation of NeuPSL inference and show learning gradients are functions of the optimal dual variables. Additionally, we develop a dual block coordinate descent algorithm for the new formulation that naturally exploits warm-starts. This leads to over 100x learning runtime improvements over the current best NeuPSL inference method. Finally, we provide extensive empirical evaluations across 8 datasets covering a range of tasks and demonstrate our learning framework achieves up to a 16% point prediction performance improvement over alternative learning methods.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/linqs/dickens-icml24]"]}}
}

@article{rayyan-242084275,
  title={A Mathematical Framework, a Taxonomy of Modeling Paradigms, and a Suite of Learning Techniques for Neural-Symbolic Systems},
  year={2024},
  author={Dickens, Charles and Pryor, Connor and Gao, Changyu and Albalak, Alon and Augustine, Eriq and Wang, William and Wright, Stephen and Lise, Getoor},
  abstract={The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed approaches show great promise in achieving symbiotic unions of neural and symbolic methods. However, each NeSy system differs in fundamental ways. There is a pressing need for a unifying theory to illuminate the commonalities and differences in approaches and enable further progress. In this paper, we introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying mathematical framework for discriminative and generative modeling with probabilistic and non-probabilistic NeSy approaches. We utilize NeSy-EBMs to develop a taxonomy of modeling paradigms focusing on a system's neural-symbolic interface and reasoning capabilities. Additionally, we introduce a suite of learning techniques for NeSy-EBMs. Importantly, NeSy-EBMs allow the derivation of general expressions for gradients of prominent learning losses, and we provide four learning approaches that leverage methods from multiple domains, including bilevel and stochastic policy optimization. Finally, we present Neural Probabilistic Soft Logic (NeuPSL), an open-source NeSy-EBM library designed for scalability and expressivity, facilitating real-world application of NeSy systems. Through extensive empirical analysis across multiple datasets, we demonstrate the practical advantages of NeSy-EBMs in various tasks, including image classification, graph node labeling, autonomous vehicle situation awareness, and question answering.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/linqs/dickens-arxiv24]"]}}
}

@article{rayyan-242084277,
  title={SmartPilot: A Multiagent CoPilot for Adaptive and Intelligent Manufacturing},
  year={2025},
  author={Shyalika, Chathurangi and Prasad, Renjith and Ghazo, Alaa Al and Eswaramoorthi, Darssan and Kaur, Harleen and Muthuselvam, Sara Shree and Amit, Sheth},
  abstract={In the dynamic landscape of Industry 4.0, achieving efficiency, precision, and adaptability is essential to optimize manufacturing operations. Industries suffer due to supply chain disruptions caused by anomalies, which are being detected by current AI models but leaving domain experts uncertain without deeper insights into these anomalies. Additionally, operational inefficiencies persist due to inaccurate production forecasts and the limited effectiveness of traditional AI models for processing complex sensor data. Despite these advancements, existing systems lack the seamless integration of these capabilities needed to create a truly unified solution for enhancing production and decision-making. We propose SmartPilot, a neurosymbolic, multiagent CoPilot designed for advanced reasoning and contextual decision-making to address these challenges. SmartPilot processes multimodal sensor data and is compact to deploy on edge devices. It focuses on three key tasks: anomaly prediction, production forecasting, and domain-specific question answering. By bridging the gap between AI capabilities and real-world industrial needs, SmartPilot empowers industries with intelligent decision-making and drives transformative innovation in manufacturing. The demonstration video, datasets, and supplementary materials are available at https://github.com/ChathurangiShyalika/SmartPilot.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ChathurangiShyalika/SmartPilot]"]}}
}

@article{rayyan-242084278,
  title={NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines},
  year={2025},
  author={Shyalika, Chathurangi and Prasad, Renjith and Kalach, Fadi El and Venkataramanan, Revathy and Zand, Ramtin and Harik, Ramy and Amit, Sheth},
  abstract={In modern assembly pipelines, identifying anomalies is crucial in ensuring product quality and operational efficiency. Conventional single-modality methods fail to capture the intricate relationships required for precise anomaly prediction in complex predictive environments with abundant data and multiple modalities. This paper proposes a neurosymbolic AI and fusion-based approach for multimodal anomaly prediction in assembly pipelines. We introduce a time series and image-based fusion model that leverages decision-level fusion techniques. Our research builds upon three primary novel approaches in multimodal learning: time series and image-based decision-level fusion modeling, transfer learning for fusion, and knowledge-infused learning. We evaluate the novel method using our derived and publicly available multimodal dataset and conduct comprehensive ablation studies to assess the impact of our preprocessing techniques and fusion model compared to traditional baselines. The results demonstrate that a neurosymbolic AI-based fusion approach that uses transfer learning can effectively harness the complementary strengths of time series and image data, offering a robust and interpretable approach for anomaly prediction in assembly pipelines with enhanced performance. \noindent The datasets, codes to reproduce the results, supplementary materials, and demo are available at https://github.com/ChathurangiShyalika/NSF-MAP.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ChathurangiShyalika/NSF-MAP]"]}}
}

@article{rayyan-242084285,
  title={Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision},
  year={2016},
  author={Liang, Chen and Berant, Jonathan and Le, Quoc and Kenneth, D. Forbus and Lao, Ni},
  abstract={Harnessing the statistical power of neural networks to perform language understanding and symbolic reasoning is difficult, when it requires executing efficient discrete operations against a large knowledge-base. In this work, we introduce a Neural Symbolic Machine, which contains (a) a neural programmer , i.e., a sequence-to-sequence model that maps language utterances to programs and utilizes a key-variable memory to handle compositionality (b) a symbolic computer , i.e., a Lisp interpreter that performs program execution, and helps find good programs by pruning the search space. We apply REINFORCE to directly optimize the task reward of this structured prediction problem. To train with weak supervision and improve the stability of REINFORCE, we augment it with an iterative maximum-likelihood training process. NSM outperforms the state-of-the-art on the WebQuestionsSP dataset when trained from question-answer pairs only, without requiring any feature engineering or domain-specific knowledge.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github:https://github.com/crazydonkey200/neural-symbolic-machines"]}}
}

@article{rayyan-242084295,
  title={Web question answering with neurosymbolic program synthesis},
  year={2021},
  author={Chen, Q. and Lamoreaux, A. and Wang, X. and Durrett, G.},
  abstract={… • Neurosymbolic DSL: To combine the relative strengths of wrapper induction techniques with the flexibility of language models, we design a new neurosymbolic domainspecific …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/utopia-group/WebQA"]}}
}

@article{rayyan-242084302,
  title={Neurosymbolic Repair of Test Flakiness},
  year={2024},
  author={Chen, Y. and Jabbarvand, R.},
  abstract={… To bridge the gap, we propose FlakyDoctor, a neuro-symbolic technique that combines the power of LLMs- generalizability-and program analysis-soundness-to fix different types …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/Intelligent-CAT-Lab/FlakyDoctor]"], "Haowei"=>["zenodo: https://zenodo.org/records/12670050"]}}
}

@article{rayyan-242084304,
  title={Genome: generative neuro-symbolic visual reasoning by growing and reusing modules},
  year={2023},
  author={Chen, Z. and Sun, R. and Liu, W. and Hong, Y. and Gan, C.},
  abstract={Recent works have shown that Large Language Models (LLMs) could empower traditional neuro-symbolic models via programming capabilities to translate language into module …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included", "Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/UMass-Embodied-AGI/genome]"], "Haowei"=>["github: https://github.com/UMass-Embodied-AGI/genome"]}}
}

@article{rayyan-242084305,
  title={Forecasting of nonlinear dynamics based on symbolic invariance},
  year={2022},
  volume={277},
  author={Chen, Zhao and Yang, Liu and Hao, Sun},
  abstract={Forecasting unknown dynamics is of great interest across many physics-related disciplines. However, data-driven machine learning methods are bothered by the poor generalization issue. To this end, a forecasting model based on symbolic invariance (i.e., symbolic expressions/equations that represent intrinsic system mechanisms) is proposed. By training and pruning a symbolic neural network wrapped in a numerical integrator, we develop an invariant symbolic structure that represents the evolution function and thus can generalize well to unseen data. To counter noise effect, an algorithmic framework for probabilistic forecasting has also been developed by leveraging a non-parametric Bayesian inference method. Additionally, to account for univariate forecasting that is partially observed from a system with multiple state variables, we further leverage the delay coordinate embedding to find symbolic invariance of the partially observed system in a more self-contained embedding. The performance of the proposed framework has been demonstrated on both synthetic and real-world nonlinear dynamics and shown better generalization over popular deep learning models in short/medium forecasting horizons. Moreover, comparison with dictionary-based symbolic regression methods suggests better-behaved and more efficient optimization of the proposed framework when the function search space is enormous. (c) 2022 Elsevier B.V. All rights reserved.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ZhaoChenCivilSciML/Forecasting-of-nonlinear-dynamics-based-on-symbolic-invariance]"]}}
}

@article{rayyan-242084306,
  title={Symbolic Deep Learning for Structural System Identification},
  year={2022},
  volume={148},
  number={9},
  author={Chen, Zhao and Yang, Liu and Hao, Sun},
  abstract={Closed-form model expression is commonly required for parametric data assimilation (e.g., model updating, damage quantification, and so on). However, episternic bias due to fixing the model class is a challenging issue for structural identification. Furthermore, it is sometimes hard to derive explicit expressions for structural mechanisms such as damping and nonlinear restoring forces. Although existing model class selection methods are beneficial to reduce the model uncertainty, the primary issue lies in their limitation to a small number of predefined model choices. We propose a symbolic deep learning framework that alleviates the constraint of fixed model classes and lets the data more flexibly determine the model type and discover the symbolic invariance of the structural system. A design principle for symbolic neural networks has been developed to leverage domain knowledge and translate data to flexibly symbolic equations of motion with a good predictive capacity for new data. A two-stage model selection strategy is proposed to conduct adaptive pruning on network and equation levels by balancing the model sparsity and the goodness of fit. The proposed method's expressive strengths and weaknesses have been analyzed in several numerical case studies, including systems with nonlinear damping, restoring force, and chaotic behavior. Results from an experimental case study revealed the potential of the proposed method for flexibly interpreting hidden mechanisms for real-world applications. Finally, we discuss necessary improvements to transfer this computational method for practical applications. (C) 2022 American Society of Civil Engineers.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent", "Github: [https://github.com/ZhaoChenCivilSciML/Symbolic-Neural-Net-for-Structural-Identification]"]}}
}

@article{rayyan-242084308,
  title={ComPhy: Compositional Physical Reasoning of Objects and Events from Videos},
  year={2022},
  author={Chen, Zhenfang and Yi, Kexin and Li, Yunzhu and Ding, Mingyu and Torralba, Antonio and Tenenbaum, Joshua B. and Chuang, Gan},
  abstract={Objects' motions in nature are governed by complex interactions and their properties. While some properties, such as shape and material, can be identified via the object's visual appearances, others like mass and electric charge are not directly visible. The compositionality between the visible and hidden properties poses unique challenges for AI models to reason from the physical world, whereas humans can effortlessly infer them with limited observations. Existing studies on video reasoning mainly focus on visually observable elements such as object appearance, movement, and contact interaction. In this paper, we take an initial step to highlight the importance of inferring the hidden physical properties not directly observable from visual appearances, by introducing the Compositional Physical Reasoning (ComPhy) dataset. For a given set of objects, ComPhy includes few videos of them moving and interacting under different initial conditions. The model is evaluated based on its capability to unravel the compositional hidden properties, such as mass and charge, and use this knowledge to answer a set of questions posted on one of the videos. Evaluation results of several state-of-the-art video reasoning models on ComPhy show unsatisfactory performance as they fail to capture these hidden properties. We further propose an oracle neural-symbolic framework named Compositional Physics Learner (CPL), combining visual perception, physical property learning, dynamic prediction, and symbolic execution into a unified framework. CPL can effectively identify objects' physical properties from their interactions and predict their dynamics to answer questions.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/zfchenUnique/compositional_physics_learner]"], "Vladimir"=>["Github: [https://github.com/zfchenUnique/compositional_physics_learner]"]}}
}

@article{rayyan-242084309,
  title={ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering},
  year={2022},
  author={Chen, Zhiyu and Li, Shiyang and Smiley, Charese and Ma, Zhiqiang and Shah, Sameena and William Yang, Wang},
  abstract={With the recent advance in large pre-trained language models, researchers have achieved record performances in NLP tasks that mostly focus on language pattern matching. The community is experiencing the shift of the challenge from how to model language to the imitation of complex reasoning abilities like human beings. In this work, we investigate the application domain of finance that involves real-world, complex numerical reasoning. We propose a new large-scale dataset, ConvFinQA, aiming to study the chain of numerical reasoning in conversational question answering. Our dataset poses great challenge in modeling long-range, complex numerical reasoning paths in real-world conversations. We conduct comprehensive experiments and analyses with both the neural symbolic methods and the prompting-based methods, to provide insights into the reasoning mechanisms of these two divisions. We believe our new dataset should serve as a valuable resource to push forward the exploration of real-world, complex reasoning tasks as the next research focus. Our dataset and code is publicly available at https://github.com/czyssrs/ConvFinQA.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/czyssrs/ConvFinQA]"], "Ishan"=>["Github: [https://github.com/czyssrs/ConvFinQA]"]}}
}

@article{rayyan-242084310,
  title={Image Translation as Diffusion Visual Programmers},
  year={2024},
  author={Han, Cheng and James, C. Liang and Wang, Qifan and Rabbani, Majid and Dianat, Sohail and Rao, Raghuveer and Wu, Ying Nian and Liu, Dongfang},
  abstract={We introduce the novel Diffusion Visual Programmer (DVP), a neuro-symbolic image translation framework. Our proposed DVP seamlessly embeds a condition-flexible diffusion model within the GPT architecture, orchestrating a coherent sequence of visual programs (i.e., computer vision models) for various pro-symbolic steps, which span RoI identification, style transfer, and position manipulation, facilitating transparent and controllable image translation processes. Extensive experiments demonstrate DVP's remarkable performance, surpassing concurrent arts. This success can be attributed to several key features of DVP: First, DVP achieves condition-flexible translation via instance normalization, enabling the model to eliminate sensitivity caused by the manual guidance and optimally focus on textual descriptions for high-quality content generation. Second, the framework enhances in-context reasoning by deciphering intricate high-dimensional concepts in feature spaces into more accessible low-dimensional symbols (e.g., [Prompt], [RoI object]), allowing for localized, context-free editing while maintaining overall coherence. Last but not least, DVP improves systemic controllability and explainability by offering explicit symbolic representations at each programming stage, empowering users to intuitively interpret and modify results. Our research marks a substantial step towards harmonizing artificial image translation processes with cognitive intelligence, promising broader applications.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included", "Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/DVPmain/DVP/blob/main/image_editing.ipynb]"], "Ishan"=>["email sent.", "Github: [https://github.com/DVPmain/DVP]"]}}
}

@article{rayyan-242084314,
  title={Binding Language Models in Symbolic Languages},
  year={2023},
  author={Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A. and Yu, Tao},
  abstract={Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of language model (LM) functionalities to a programming language (e.g., SQL, Python) to extend its grammar coverage and thus tackle more diverse questions, (2) adopts an LM as both the program parser and the underlying model called by the API during execution, and (3) requires only a few in-context exemplar annotations. Specifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only a few in-context exemplars, Codex is able to identify the part of the task input that cannot be answerable by the original programming language, correctly generate API calls to prompt Codex to solve the unanswerable part, and identify where to place the API calls while being compatible with the original grammar. In the execution stage, Codex can perform versatile functionalities (e.g., commonsense QA, information extraction) given proper prompts in the API calls. Binder achieves state-of-the-art results on WikiTableQuestions and TabFact datasets, with explicit output programs that benefit human debugging. Note that previous best systems are all finetuned on tens of thousands of task-specific samples, while Binder only uses dozens of annotations as in-context exemplars without any training. Our code is available at https://github.com/HKUNLP/Binder .},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/xlang-ai/Binder]"]}}
}

@article{rayyan-242084315,
  title={Transformer Embeddings of Irregularly Spaced Events and Their Participants},
  year={2021},
  author={Yang, Chenghao and Mei, Hongyuan and Jason, Eisner},
  abstract={The neural Hawkes process (Mei & Eisner, 2017) is a generative model of irregularly spaced sequences of discrete events. To handle complex domains with many event types, Mei et al. (2020a) further consider a setting in which each event in the sequence updates a deductive database of facts (via domain-specific pattern-matching rules); future events are then conditioned on the database contents. They show how to convert such a symbolic system into a neuro-symbolic continuous-time generative model, in which each database fact and the possible event has a time-varying embedding that is derived from its symbolic provenance. In this paper, we modify both models, replacing their recurrent LSTM-based architectures with flatter attention-based architectures (Vaswani et al., 2017), which are simpler and more parallelizable. This does not appear to hurt our accuracy, which is comparable to or better than that of the original models as well as (where applicable) previous attention-based methods (Zuo et al., 2020; Zhang et al., 2020a).},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/yangalan123/anhp-andtt]"]}}
}

@article{rayyan-242084317,
  title={Safe Neurosymbolic Learning with Differentiable Symbolic Execution},
  year={2022},
  author={Yang, Chenxi and Swarat, Chaudhuri},
  abstract={We study the problem of learning worst-case-safe parameters for programs that use neural networks as well as symbolic, human-written code. Such neurosymbolic programs arise in many safety-critical domains. However, because they can use nondifferentiable operations, it is hard to learn their parameters using existing gradient-based approaches to safe learning. Our approach to this problem, Differentiable Symbolic Execution (DSE), samples control flow paths in a program, symbolically constructs worst-case safety losses along these paths, and backpropagates the gradients of these losses through program operations using a generalization of the REINFORCE estimator. We evaluate the method on a mix of synthetic tasks and real-world benchmarks. Our experiments show that DSE significantly outperforms the state-of-the-art DiffAI method on these tasks.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/chenxi-yang/DSE]"]}}
}

@article{rayyan-242084318,
  title={Formally Verified Neurosymbolic Trajectory Learning via Tensor-based Linear Temporal Logic on Finite Traces},
  year={2025},
  author={Chevallier, M. and Smola, F. and Schmoetten, R.},
  abstract={We present a novel formalisation of tensor semantics for linear temporal logic on finite traces (LTLf), with formal proofs of correctness carried out in the theorem prover Isabelle/HOL. We …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/hasktorch/hasktorch/]"]}}
}

@article{rayyan-242084319,
  title={ACRE: Abstract Causal REasoning Beyond Covariation},
  year={2021},
  author={Zhang, Chi and Jia, Baoxiong and Edmonds, Mark and Zhu, Song-Chun and Yixin, Zhu},
  abstract={Causal induction, i.e., identifying unobservable mechanisms that lead to the observable relations among variables, has played a pivotal role in modern scientific discovery, especially in scenarios with only sparse and limited data. Humans, even young toddlers, can induce causal relationships surprisingly well in various settings despite its notorious difficulty. However, in contrast to the commonplace trait of human cognition is the lack of a diagnostic benchmark to measure causal induction for modern Artificial Intelligence (AI) systems. Therefore, in this work, we introduce the Abstract Causal REasoning (ACRE) dataset for systematic evaluation of current vision systems in causal induction. Motivated by the stream of research on causal discovery in Blicket experiments, we query a visual reasoning system with the following four types of questions in either an independent scenario or an interventional scenario: direct, indirect, screening-off, and backward-blocking, intentionally going beyond the simple strategy of inducing causal relationships by covariation. By analyzing visual reasoning architectures on this testbed, we notice that pure neural models tend towards an associative strategy under their chance-level performance, whereas neuro-symbolic combinations struggle in backward-blocking reasoning. These deficiencies call for future research in models with a more comprehensive capability of causal induction.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/WellyZhang/ACRE]"]}}
}

@article{rayyan-242084320,
  title={Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution},
  year={2021},
  author={Zhang, Chi and Jia, Baoxiong and Zhu, Song-Chun and Yixin, Zhu},
  abstract={Spatial-temporal reasoning is a challenging task in Artificial Intelligence (AI) due to its demanding but unique nature: a theoretic requirement on representing and reasoning based on spatial-temporal knowledge in mind, and an applied requirement on a high-level cognitive system capable of navigating and acting in space and time. Recent works have focused on an abstract reasoning task of this kind - Raven's Progressive Matrices (RPM). Despite the encouraging progress on RPM that achieves human-level performance in terms of accuracy, modern approaches have neither a treatment of human-like reasoning on generalization, nor a potential to generate answers. To fill in this gap, we propose a neuro-symbolic Probabilistic Abduction and Execution (PrAE) learner; central to the PrAE learner is the process of probabilistic abduction and execution on a probabilistic scene representation, akin to the mental manipulation of objects. Specifically, we disentangle perception and reasoning from a monolithic model. The neural visual perception frontend predicts objects' attributes, later aggregated by a scene inference engine to produce a probabilistic scene representation. In the symbolic logical reasoning backend, the PrAE learner uses the representation to abduce the hidden rules. An answer is predicted by executing the rules on the probabilistic representation. The entire system is trained end-to-end in an analysis-by-synthesis manner without any visual attribute annotations. Extensive experiments demonstrate that the PrAE learner improves cross-configuration generalization and is capable of rendering an answer, in contrast to prior works that merely make a categorical choice from candidates.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/WellyZhang/PrAE]"]}}
}

@article{rayyan-242084325,
  title={Learning neuro-symbolic relational transition models for bilevel planning},
  year={2022},
  author={Chitnis, R. and Silver, T. and Tenenbaum, J. B.},
  url={https://ieeexplore.ieee.org/abstract/document/9981440/?casa_token=CQMlkinikywAAAAA:g68mnGpoeVP5JLpWRxQvDAPWZFfpNfJXEwWR1GL76xR73bxJIN7AvuV9lkKNB6yxx-b87zwWXj_trw},
  abstract={In robotic domains, learning and planning are complicated by continuous state spaces, continuous action spaces, and long task horizons. In this work, we address these challenges with …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Learning-and-Intelligent-Systems/predicators/releases/tag/skill-learning-june-2022]"]}}
}

@article{rayyan-242084328,
  title={CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning},
  year={2025},
  author={Choi, S. and Solko-Breslin, A. and Alur, R. and Wong, E.},
  abstract={… neurosymbolic learning, Next, we introduce CTSketch, a scalable algorithm for learning such neurosymbolic … using state-of-the-art neurosymbolic frameworks against a diverse set of …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/alaiasolkobreslin/CTSketch]"]}}
}

@article{rayyan-242084334,
  title={Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning},
  year={2022},
  author={Raymond, Christian and Chen, Qi and Xue, Bing and Mengjie, Zhang},
  abstract={In this paper, we develop upon the emerging topic of loss function learning, which aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for learning model-agnostic loss functions via a hybrid neuro-symbolic search approach. The framework first uses evolution-based methods to search the space of primitive mathematical operations to find a set of symbolic loss functions. Second, the set of learned loss functions are subsequently parameterized and optimized via an end-to-end gradient-based training procedure. The versatility of the proposed framework is empirically validated on a diverse set of supervised learning tasks. Results show that the meta-learned loss functions discovered by the newly proposed method outperform both the cross-entropy loss and state-of-the-art loss function learning methods on a diverse range of neural network architectures and datasets.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Decadz/Evolved-Model-Agnostic-Loss]"]}}
}

@article{rayyan-242084341,
  title={Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners},
  year={2024},
  author={Feng, Chun and Hsu, Joy and Liu, Weiyu and Jiajun, Wu},
  abstract={3D visual grounding is a challenging task that often requires direct and dense supervision, notably the semantic label for each object in the scene. In this paper, we instead study the naturally supervised setting that learns from only 3D scene and QA pairs, where prior works underperform. We propose the Language-Regularized Concept Learner (LARC), which uses constraints from language as regularization to significantly improve the accuracy of neuro-symbolic concept learners in the naturally supervised setting. Our approach is based on two core insights: the first is that language constraints (e.g., a word's relation to another) can serve as effective regularization for structured representations in neuro-symbolic models; the second is that we can query large language models to distill such constraints from language properties. We show that LARC improves performance of prior works in naturally supervised 3D visual grounding, and demonstrates a wide range of 3D visual reasoning capabilities-from zero-shot composition, to data efficiency and transferability. Our method represents a promising step towards regularizing structured visual reasoning frameworks with language-based priors, for learning in settings without dense supervision.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/chunfeng3364/LARC]"]}}
}

@article{rayyan-242084343,
  title={pix2rule: End-to-end Neuro-symbolic Rule Learning},
  year={2021},
  author={Cingillioglu, N. and Russo, A.},
  abstract={… Neuro-symbolic systems aim to bring a unifying approach to connectionist and logic-based … This paper presents a complete neuro-symbolic method for processing images into objects, …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/nuric/pix2rule]"]}}
}

@article{rayyan-242084344,
  title={Neuro-Symbolic Hierarchical Rule Induction},
  year={2021},
  author={Glanois, Claire and Feng, Xuening and Jiang, Zhaohui and Weng, Paul and Zimmer, Matthieu and Li, Dong and Wulong, Liu},
  abstract={We propose an efficient interpretable neuro-symbolic model to solve Inductive Logic Programming (ILP) problems. In this model, which is built from a set of meta-rules organised in a hierarchical structure, first-order rules are invented by learning embeddings to match facts and body predicates of a meta-rule. To instantiate it, we specifically design an expressive set of generic meta-rules, and demonstrate they generate a consequent fragment of Horn clauses. During training, we inject a controlled \pw Gumbel noise to avoid local optima and employ interpretability-regularization term to further guide the convergence to interpretable rules. We empirically validate our model on various tasks (ILP, visual genome, reinforcement learning) against several state-of-the-art methods.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/claireaoi/hierarchical-rule-induction]"]}}
}

@article{rayyan-242084351,
  title={Leveraging Neurosymbolic AI for Slice Discovery},
  year={2024},
  volume={14979},
  author={Collevati, Michele and Thomas, Eiter and Nelson, Higuera},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={While remarkable recent developments in deep neural networks have significantly contributed to advancing the state-of-the-art in Computer Vision (CV), several studies have also shown their limitations and defects. In particular, CV models often make systematic errors on important subsets of data called slices, which are groups of data sharing a set of attributes. The slice discovery problem involves detecting semantically meaningful slices on which the model performs poorly, called rare slices. We propose a modular Neurosymbolic AI approach whose distinct advantage is the extraction of human-readable logical rules that describe rare slices, and thus enhances explainability of CV models. To this end, we present a methodology to induce rare slice occurrences in a model. Experiments on datasets from our data generator leveraging on Super-CLEVR show that the approach can correctly identify rare slices and produce logical rules describing them. The rules can be fruitfully used to generate new training data to mend model behavior or may be integrated into the model to enhance its inference capabilities. (The code for reproducing our experiments is available as an online repository: https://gitlab.tuwien.ac.at/kbs/nesy- ai/ilp4sd).},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://gitlab.tuwien.ac.at/kbs/nesy-ai/ilp4sd]"]}}
}

@article{rayyan-242084355,
  title={Neuro-Symbolic Fusion of Wi-Fi Sensing Data for Passive Radar with Inter-Modal Knowledge Transfer},
  year={2024},
  author={Cominelli, Marco and Francesco, Gringoli and Kaplantzis Lance, M. and Srivastava Mani, B. and Trevor, Bihl and Blasch Erik, P. and Nandini, Iyer and Federico, Cerutti},
  publisher={IEEE},
  abstract={Wi-Fi devices, akin to passive radars, can discern human activities within indoor settings due to the human body's interaction with electromagnetic signals. Current Wi-Fi sensing applications predominantly employ data-driven learning techniques to associate the fluctuations in the physical properties of the communication channel with the human activity causing them. However, these techniques often lack the desired flexibility and transparency. This paper introduces DeepProbHAR, a neuro-symbolic architecture for Wi-Fi sensing, providing initial evidence that Wi-Fi signals can differentiate between simple movements, such as leg or arm movements, which are integral to human activities like running or walking. The neuro-symbolic approach affords gathering such evidence without needing additional specialised data collection or labelling. The training of DeepProbHAR is facilitated by declarative domain knowledge obtained from a camera feed and by fusing signals from various antennas of the Wi-Fi receivers. DeepProbHAR achieves results comparable to the state-of-the-art in human activity recognition. Moreover, as a by-product of the learning process, DeepProbHAR generates specialised classifiers for simple movements that match the accuracy of models trained on finely labelled datasets, which would be particularly costly.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/marcocominelli/csi-vae/tree/fusion2024]"]}}
}

@article{rayyan-242084358,
  title={MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents},
  year={2024},
  author={Yin, Congchi and Li, Feng and Zhang, Shu and Wang, Zike and Shao, Jun and Li, Piji and Chen, Jianhua and Xun, Jiang},
  abstract={The clinical diagnosis of most mental disorders primarily relies on the conversations between psychiatrist and patient. The creation of such diagnostic conversation datasets is promising to boost the AI mental healthcare community. However, directly collecting the conversations in real diagnosis scenarios is near impossible due to stringent privacy and ethical considerations. To address this issue, we seek to synthesize diagnostic conversation by exploiting anonymized patient cases that are easier to access. Specifically, we design a neuro-symbolic multi-agent framework for synthesizing the diagnostic conversation of mental disorders with large language models. It takes patient case as input and is capable of generating multiple diverse conversations with one single patient case. The framework basically involves the interaction between a doctor agent and a patient agent, and generates conversations under symbolic control via a dynamic diagnosis tree. By applying the proposed framework, we develop the largest Chinese mental disorders diagnosis dataset MDD-5k. This dataset is built upon 1000 real, anonymized patient cases by cooperating with Shanghai Mental Health Center and comprises 5000 high-quality long conversations with diagnosis results and treatment opinions as labels. To the best of our knowledge, it's also the first labeled dataset for Chinese mental disorders diagnosis. Human evaluation demonstrates the proposed MDD-5k dataset successfully simulates human-like diagnostic process of mental disorders.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/lemonsis/MDD-5k]"]}}
}

@article{rayyan-242084360,
  title={NeuPSL: Neural Probabilistic Soft Logic},
  year={2022},
  author={Pryor, Connor and Dickens, Charles and Augustine, Eriq and Albalak, Alon and Wang, William and Lise, Getoor},
  abstract={In this paper, we introduce Neural Probabilistic Soft Logic (NeuPSL), a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To model the boundary between neural and symbolic representations, we propose a family of energy-based models, NeSy Energy-Based Models, and show that they are general enough to include NeuPSL and many other NeSy approaches. Using this framework, we show how to seamlessly integrate neural and symbolic parameter learning and inference in NeuPSL. Through an extensive empirical evaluation, we demonstrate the benefits of using NeSy methods, achieving upwards of 30% improvement over independent neural network models. On a well-established NeSy task, MNIST-Addition, NeuPSL demonstrates its joint reasoning capabilities by outperforming existing NeSy approaches by up to 10% in low-data settings. Furthermore, NeuPSL achieves a 5% boost in performance over state-of-the-art NeSy methods in a canonical citation network task with up to a 40 times speed up.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/linqs/neupsl-ijcai23]"]}}
}

@article{rayyan-242084370,
  title={Neurosynt: A neuro-symbolic portfolio solver for reactive synthesis},
  year={2024},
  author={Cosler, M. and Hahn, C. and Omar, A. and Schmitt, F.},
  abstract={We introduce NeuroSynt , a neuro-symbolic portfolio solver framework for reactive synthesis. At the core of the solver lies a seamless integration of neural and symbolic approaches to …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/reactive-systems/neurosynt]"]}}
}

@article{rayyan-242084372,
  title={Enforcement Heuristics for Argumentation with Deep Reinforcement Learning},
  year={2022},
  author={Craandijk, Dennis and Floris, Bex},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={In this paper, we present a learning-based approach to the symbolic reasoning problem of dynamic argumentation, where the knowledge about attacks between arguments is incomplete or evolving. Specifically, we employ deep reinforcement learning to learn which attack relations between arguments should be added or deleted in order to enforce the acceptability of (a set of) arguments. We show that our Graph Neural Network (GNN) architecture EGNN can learn a near optimal enforcement heuristic for all common argument-fixed enforcement problems, including problems for which no other (symbolic) solvers exist. We demonstrate that EGNN outperforms other GNN baselines and on enforcement problems with high computational complexity performs better than state-of-the-art symbolic solvers with respect to efficiency. Thus, we show our neuro-symbolic approach is able to learn heuristics without the expert knowledge of a human designer and offers a valid alternative to symbolic solvers. We publish our code at https://github.com/DennisCraandijk/DL-Abstract- Argumentation.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/DennisCraandijk/DL-Abstract-Argumentation]"]}}
}

@article{rayyan-242084373,
  title={Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification},
  year={2025},
  author={Cornelio, Cristina and Petruzzellis, Flavio and Pietro, Lio},
  abstract={Large Language Models (LLMs) have shown promise as robotic planners but often struggle with long-horizon and complex tasks, especially in specialized environments requiring external knowledge. While hierarchical planning and Retrieval-Augmented Generation (RAG) address some of these challenges, they remain insufficient on their own and a deeper integration is required for achieving more reliable systems. To this end, we propose a neuro-symbolic approach that enhances LLMs-based planners with Knowledge Graph-based RAG for hierarchical plan generation. This method decomposes complex tasks into manageable subtasks, further expanded into executable atomic action sequences. To ensure formal correctness and proper decomposition, we integrate a Symbolic Validator, which also functions as a failure detector by aligning expected and observed world states. Our evaluation against baseline methods demonstrates the consistent significant advantages of integrating hierarchical planning, symbolic verification, and RAG across tasks of varying complexity and different LLMs. Additionally, our experimental setup and novel metrics not only validate our approach for complex planning but also serve as a tool for assessing LLMs' reasoning and compositional capabilities.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent to cristina", "Github: [https://github.com/corneliocristina/HVR]"]}}
}

@article{rayyan-242084378,
  title={Neuro-symbolic learning of answer set programs from raw data},
  year={2022},
  author={Cunnington, D. and Law, M. and Lobo, J. and Russo, A.},
  abstract={One of the ultimate goals of Artificial Intelligence is to assist humans in complex decision making. A promising direction for achieving this goal is Neuro-Symbolic AI, which aims to …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/DanCunnington/NSIL]"]}}
}

@article{rayyan-242084386,
  title={Neuro-symbolic interpretable AI for automatic COVID-19 patient-stratification based on standardised lung ultrasound data},
  year={2022},
  author={Custode, L. L. and Mento, F. and Afrakhteh, S. and Tursi, F.},
  url={https://pubs.aip.org/asa/poma/article-abstract/46/1/020002/2842422},
  abstract={… In this work, we present a novel neuro-symbolic approach able to provide video-level predictions by aggregating results from frame-level analysis made by deep-networks. Specifically, …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent to leonardo", "email address bounced. so sent the same email to giovanni", "Gitlab: [https://gitlab.com/leocus/neurosymbolic-covid19-scoring]"]}}
}

@article{rayyan-242084397,
  title={Dynamic Planning with a LLM},
  year={2023},
  author={Dagan, Gautier and Keller, Frank and Lascarides, Alex},
  abstract={While Large Language Models (LLMs) can solve many NLP tasks in zero-shot settings, applications involving embodied agents remain problematic. In particular, complex plans that require multi-step reasoning become difficult and too costly as the context window grows. Planning requires understanding the likely effects of one's actions and identifying whether the current environment satisfies the goal state. While symbolic planners find optimal solutions quickly, they require a complete and accurate representation of the planning problem, severely limiting their use in practical scenarios. In contrast, modern LLMs cope with noisy observations and high levels of uncertainty when reasoning about a task. Our work presents LLM Dynamic Planner (LLM-DP): a neuro-symbolic framework where an LLM works hand-in-hand with a traditional planner to solve an embodied task. Given action-descriptions, LLM-DP solves Alfworld faster and more efficiently than a naive LLM ReAct baseline.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/itl-ed/llm-dp]"]}}
}

@article{rayyan-242084398,
  title={Vehicle: Bridging the embedding gap in the verification of neuro-symbolic programs},
  year={2024},
  author={Daggitt, M. L. and Kokke, W. and Atkey, R. and Slusarz, N.},
  abstract={… the correctness of neuro-symbolic programs by linking … a neuro-symbolic car controller. We believe this to be the first ever modular proof of the complete verification of a neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/vehicle-lang/vehicle]"]}}
}

@article{rayyan-242084408,
  title={Plans: Neuro-symbolic program learning from videos},
  year={2020},
  author={Dang-Nhu, R.},
  url={https://proceedings.neurips.cc/paper/2020/hash/fe131d7f5a6b38b23cc967316c13dae2-Abstract.html},
  abstract={Recent years have seen the rise of statistical program learning based on neural models as an alternative to traditional rule-based systems for programming by example. Rule-based …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/rdang-nhu/PLANS"]}}
}

@article{rayyan-242084413,
  title={NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization},
  year={2024},
  author={Kamali, Danial and Elham, J. Barezi and Kordjamshidi, Parisa},
  abstract={Compositional generalization is crucial for artificial intelligence agents to solve complex vision-language reasoning tasks. Neuro-symbolic approaches have demonstrated promise in capturing compositional structures, but they face critical challenges: (a) reliance on predefined predicates for symbolic representations that limit adaptability, (b) difficulty in extracting predicates from raw data, and (c) using non-differentiable operations for combining primitive concepts. To address these issues, we propose NeSyCoCo, a neuro-symbolic framework that leverages large language models (LLMs) to generate symbolic representations and map them to differentiable neural computations. NeSyCoCo introduces three innovations: (a) augmenting natural language inputs with dependency structures to enhance the alignment with symbolic representations, (b) employing distributed word representations to link diverse, linguistically motivated logical predicates to neural modules, and (c) using the soft composition of normalized predicate scores to align symbolic and differentiable reasoning. Our framework achieves state-of-the-art results on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks and demonstrates robust performance with novel concepts in the CLEVR-SYN benchmark.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/hlr/nesycoco"]}}
}

@article{rayyan-242084414,
  title={FF-NSL: Feed-Forward Neural-Symbolic Learner},
  year={2021},
  author={Cunnington, Daniel and Law, Mark and Russo, Alessandra and Jorge, Lobo},
  abstract={Logic-based machine learning aims to learn general, interpretable knowledge in a data-efficient manner. However, labelled data must be specified in a structured logical form. To address this limitation, we propose a neural-symbolic learning framework, called Feed-Forward Neural-Symbolic Learner (FFNSL), that integrates a logic-based machine learning system capable of learning from noisy examples, with neural networks, in order to learn interpretable knowledge from labelled unstructured data. We demonstrate the generality of FFNSL on four neural-symbolic classification problems, where different pre-trained neural network models and logic-based machine learning systems are integrated to learn interpretable knowledge from sequences of images. We evaluate the robustness of our framework by using images subject to distributional shifts, for which the pre-trained neural networks may predict incorrectly and with high confidence. We analyse the impact that these shifts have on the accuracy of the learned knowledge and run-time performance, comparing FFNSL to tree-based and pure neural approaches. Our experimental results show that FFNSL outperforms the baselines by learning more accurate and interpretable knowledge with fewer examples.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/DanCunnington/FFNSL"]}}
}

@article{rayyan-242084419,
  title={Learning Signal Temporal Logic through Neural Network for Interpretable Classification},
  year={2022},
  author={Li, Danyang and Cai, Mingyu and Vasile, Cristian-Ioan and Roberto, Tron},
  abstract={Machine learning techniques using neural networks have achieved promising success for time-series data classification. However, the models that they produce are challenging to verify and interpret. In this paper, we propose an explainable neural-symbolic framework for the classification of time-series behaviors. In particular, we use an expressive formal language, namely Signal Temporal Logic (STL), to constrain the search of the computation graph for a neural network. We design a novel time function and sparse softmax function to improve the soundness and precision of the neural-STL framework. As a result, we can efficiently learn a compact STL formula for the classification of time-series data through off-the-shelf gradient-based tools. We demonstrate the computational efficiency, compactness, and interpretability of the proposed method through driving scenarios and naval surveillance case studies, compared with state-of-the-art baselines.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/danyangl6/nn-tli"]}}
}

@article{rayyan-242084432,
  title={NeSy4VRD: A Multifaceted Resource for Neurosymbolic AI Research using Knowledge Graphs in Visual Relationship Detection},
  year={2023},
  author={Herron, David and Jiménez-Ruiz, Ernesto and Tarroni, Giacomo and Tillman, Weyde},
  abstract={NeSy4VRD is a multifaceted resource designed to support the development of neurosymbolic AI (NeSy) research. NeSy4VRD re-establishes public access to the images of the VRD dataset and couples them with an extensively revised, quality-improved version of the VRD visual relationship annotations. Crucially, NeSy4VRD provides a well-aligned, companion OWL ontology that describes the dataset domain.It comes with open source infrastructure that provides comprehensive support for extensibility of the annotations (which, in turn, facilitates extensibility of the ontology), and open source code for loading the annotations to/from a knowledge graph. We are contributing NeSy4VRD to the computer vision, NeSy and Semantic Web communities to help foster more NeSy research using OWL-based knowledge graphs.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github:https://github.com/djherron/NeSy4VRD"]}}
}

@article{rayyan-242084436,
  title={Tratto: A Neuro-Symbolic Approach to Deriving Axiomatic Test Oracles},
  year={2025},
  author={Molinelli, Davide and Martin-Lopez, Alberto and Zackrone, Elliott and Eken, Beyza and Michael, D. Ernst and Pezzè, Mauro},
  abstract={This paper presents Tratto, a neuro-symbolic approach that generates assertions (boolean expressions) that can serve as axiomatic oracles, from source code and documentation. The symbolic module of Tratto takes advantage of the grammar of the programming language, the unit under test, and the context of the unit (its class and available APIs) to restrict the search space of the tokens that can be successfully used to generate valid oracles. The neural module of Tratto uses transformers fine-tuned for both deciding whether to output an oracle or not and selecting the next lexical token to incrementally build the oracle from the set of tokens returned by the symbolic module. Our experiments show that Tratto outperforms the state-of-the-art axiomatic oracle generation approaches, with 73% accuracy, 72% precision, and 61% F1-score, largely higher than the best results of the symbolic and neural approaches considered in our study (61%, 62%, and 37%, respectively). Tratto can generate three times more axiomatic oracles than current symbolic approaches, while generating 10 times less false positives than GPT4 complemented with few-shot learning and Chain-of-Thought prompting.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/AML14/tratto"]}}
}

@article{rayyan-242084437,
  title={Zero-Shot Conditioning of Score-Based Diffusion Models by Neuro-Symbolic Constraints},
  year={2023},
  author={Scassola, Davide and Saccani, Sebastiano and Carbone, Ginevra and Luca, Bortolussi},
  abstract={Score-based diffusion models have emerged as effective approaches for both conditional and unconditional generation. Still conditional generation is based on either a specific training of a conditional model or classifier guidance, which requires training a noise-dependent classifier, even when a classifier for uncorrupted data is given. We propose a method that, given a pre-trained unconditional score-based generative model, samples from the conditional distribution under arbitrary logical constraints, without requiring additional training. Differently from other zero-shot techniques, that rather aim at generating valid conditional samples, our method is designed for approximating the true conditional distribution. Firstly, we show how to manipulate the learned score in order to sample from an un-normalized distribution conditional on a user-defined constraint. Then, we define a flexible and numerically stable neuro-symbolic framework for encoding soft logical constraints. Combining these two ingredients we obtain a general, but approximate, conditional sampling algorithm. We further developed effective heuristics aimed at improving the approximation. Finally, we show the effectiveness of our approach in approximating conditional distributions for various types of constraints and data: tabular data, images and time series.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/davidescassola/score-based-constrained-generation"]}}
}

@article{rayyan-242084470,
  title={Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification},
  year={2024},
  author={Pandiani, Delfina Sol Martinez and Lazzari, Nicolas and Valentina, Presutti},
  abstract={The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute KG embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual transformer embeddings. Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances. Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification. The posthoc interpretability analyses reveal the visual transformer's proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements. We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual knowledge and deep visual model's sensory-perceptual understanding for AC image classification. This work suggests a strong potential of neuro-symbolic methods for knowledge integration and robust image representation for use in downstream intricate visual comprehension tasks. All the materials and code are available online.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["github: [https://github.com/delfimpandiani/Stitching-Gaps]"]}}
}

@article{rayyan-242084471,
  title={Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction},
  year={2023},
  author={Delfosse, Quentin and Hikaru, Shindo and Singh, Dhami Devendra and Kristian, Kersting},
  publisher={NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)},
  abstract={The limited priors required by neural networks make them the dominating choice to encode and learn policies using reinforcement learning (RL). However, they are also black-boxes, making it hard to understand the agent's behaviour, especially when working on the image level. Therefore, neuro-symbolic RL aims at creating policies that are interpretable in the first place. Unfortunately, interpretability is not explainability. To achieve both, we introduce Neurally gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural network-based agents to guide the search of candidate-weighted logic rules, then uses differentiable logic to train the logic agents. Our experimental evaluation demonstrates that NUDGE agents can induce interpretable and explainable policies while outperforming purely neural ones and showing good flexibility to environments of different initial states and problem sizes.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/k4ntz/NUDGE]"]}}
}

@article{rayyan-242084473,
  title={Mars: A neurosymbolic approach for interpretable drug discovery},
  year={2024},
  author={DeLong, L. N. and Gadiya, Y. and Galdi, P. and Fleuriot, J. D.},
  abstract={… Compared to neural approaches, NeSy methods often … We then develop the MoA Retrieval System (MARS), a NeSy ap… , we find that MARS and other NeSy approaches on KGs are …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/laurendelong21/MARS]"]}}
}

@article{rayyan-242084478,
  title={Encoding and Decoding of Recursive Structures in Neural-Symbolic Systems},
  year={2021},
  volume={30},
  number={1},
  author={Demidovskij, A.},
  abstract={One of the ways to join the connectionist approach and the symbolic paradigm is Tensor Product Variable Binding. It was initially devoted to building distributed representation of recursive structures for neural networks to use it as the input. Structures are an essential part of both formal and natural languages and appear in syntactic trees, grammar, semantic interpretation. A human mind smoothly operates with the appearing problems on the neural level, and it is naturally scalable and robust. The question arises of whether it is possible to translate traditional symbolic algorithms to the sub-symbolic level to reuse performance and computational gain of the neural networks for general tasks. However, several aspects of Tensor Product Variable Binding lack attention in public research, especially in building such a neural architecture that performs computations according to the mathematical model without preliminary training. In this paper, those implementation aspects are addressed. A proposed novel design for the decoding network translates a tensor to a corresponding recursive structure with the arbitrary level of nesting. Also, several complex topics about encoding such structures in the distributed representation or tensor are addressed. Both encoding and decoding neural networks are built with the Keras framework's help and are analyzed from the perspective of applied value. The proposed design continues the series of papers dedicated to building a robust bridge between two computational paradigms: connectionist and symbolic.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/demid5111/ldss-tensor-structures]"]}}
}

@article{rayyan-242084482,
  title={Automatic Construction of Tensor Product Variable Binding Neural Networks for Neural-Symbolic Intelligent Systems},
  year={2020},
  author={Demidovskij, Alexander},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/demid5111/ldss-tensor-structures]"]}}
}

@article{rayyan-242084483,
  title={Exploring Neural Turing Machines Applicability in Neural-Symbolic Decision Support Systems},
  year={2021},
  author={Demidovskij, Alexander},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/demid5111/NeuralTuringMachine]"]}}
}

@article{rayyan-242084485,
  title={Neuro-Symbolic Class Expression Learning},
  year={2023},
  author={Demir, C. and Ngomo, A. C. N.},
  url={https://www.researchgate.net/profile/Caglar-Demir-2/publication/373081746_Neuro-Symbolic_Class_Expression_Learning/links/64ddf2a6177c59041300653e/Neuro-Symbolic-Class-Expression-Learning.pdf},
  abstract={Abstract Models computed using deep learning have been effectively applied to tackle various problems in many disciplines. Yet, the predictions of these models are often at most post-…},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/dice-group/DRILL]"]}}
}

@article{rayyan-242084496,
  title={Semantic code repair using neuro-symbolic transformation networks},
  year={2017},
  author={Devlin, J. and Uesato, J. and Singh, R. and Kohli, P.},
  abstract={We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code. The majority of past work in semantic code repair …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://iclr2018anon.github.io/semantic_code_repair/index.html]", "might need LLM access"]}}
}

@article{rayyan-242084497,
  title={Improving Rule-based Reasoning in LLMs via Neurosymbolic Representations},
  year={2025},
  author={Dhanraj, V. and Eliasmith, C.},
  abstract={… laying the groundwork for more advanced neurosymbolic systems that balance the adapt… neurosymbolic algorithms and decoding hidden state information into structured neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/vdhanraj/Neurosymbolic-LLM]"]}}
}

@article{rayyan-242084500,
  title={Forecasting Traffic Progression in Terms of Semantically Interpretable States by Exploring Multiple Data Representations},
  year={2025},
  author={Dhont, Michiel and Adrian, Munteanu and Elena, Tsiporkova},
  abstract={In the rapidly evolving landscape of mobility modelling, the application of deep learning approaches introduces both opportunities and challenges. Such approaches, while powerful, yield opaque models that lack interpretability and adaptability to diverse traffic contexts. Addressing those challenges, a finite set of humanly-interpretable traffic states is exploited here for the purpose of facilitating the annotation of mobility data with meaningful labels such as congestion, free-flow, traffic build-up, etc. Such annotation unlocks a range of opportunities to integrate multiple complementary approaches for modelling state transition behaviour. Concretely, a novel hybrid modelling framework is introduced in this article leveraging multiple data representations (temporal, time-frequency and symbolic) with the aim to forecast traffic progression in terms of humanly-explicable state transitions. Three distinct modelling paradigms are subsequently explored: neural, neural-to-symbolic, and symbolic-to-neural, by demonstrating their potential to capture and forecast traffic dynamics on real-world mobility data. While the fully neural approach is undoubtedly the most accurate one, the two neuro-symbolic approaches offer a better trade-off between accuracy on one side and interpretability, probability calibration, and computational efficiency, on the other. This work illustrates the importance of tailored data representations in understanding and predicting complex mobility behaviour, highlighting the benefits of hybrid approaches in achieving interpretability and efficiency in traffic data analysis.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/MichielDhont/Forecasting-Traffic-Progression-in-Terms-of-Semantically-Interpretable-States]"]}}
}

@article{rayyan-242084505,
  title={EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: The MonuMAI cultural heritage use case},
  year={2022},
  volume={79},
  author={Diaz-Rodriguez, Natalia and Alberto, Lamas and Jules, Sanchez and Gianni, Franchi and Ivan, Donadello and Siham, Tabik and David, Filliat and Policarpo, Cruz and Rosana, Montes and Francisco, Herrera},
  abstract={The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols - such as knowledge graphs - are easier to explain. However, they present lower generalization and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process so it serves as a sound basis for explainability. In particular, X-NeSyL methodology involves the concrete use of two notions of explanation, both at inference and training time respectively: (1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional convolutional neural network that makes use of symbolic representations, and (2) SHAP-Backprop, an explainable AI-informed training procedure that corrects and guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that with our approach, it is possible to improve explainability at the same time as performance.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ivanDonadello/semantic-PASCAL-Part]"]}}
}

@article{rayyan-242084506,
  title={A Unifying Mathematical Framework for Neural-Symbolic Systems},
  year={2024},
  author={Dickens, C.},
  url={https://search.proquest.com/openview/9cc4f4c12499fa9ce39f4f7890d97608/1?pq-origsite=gscholar\&cbl=18750\&diss=y},
  publisher={search.proquest.com},
  abstract={… the capabilities of existing NeSy systems. Moreover, I identify architectures that support compelling NeSy use cases. Then, I introduce a suite of four NeSy learning techniques: one for …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/linqs/dickens-arxiv24]"]}}
}

@article{rayyan-242084507,
  title={Modeling patterns for neural-symbolic reasoning using energy-based models},
  year={2024},
  author={Dickens, C. and Pryor, C. and Getoor, L.},
  url={https://ojs.aaai.org/index.php/AAAI-SS/article/view/31187},
  abstract={… Neural-symbolic (NeSy) AI strives to empower machine … focusing on the neural-symbolic interface capturing methods … spanning three tasks, we show NeSy approaches reach up to a …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/linqs/aaai-make24]"]}}
}

@article{rayyan-242084513,
  title={Scene graph generation in autonomous driving: a neuro-symbolic approach},
  year={2023},
  author={Dimasi, P. E. I.},
  url={https://webthesis.biblio.polito.it/29354/},
  publisher={webthesis.biblio.polito.it},
  abstract={The 2022 study on traffic fatalities in Italy by the Italian National Institute of Statistics (ISTAT) reports 454 daily fatalities and 561 injuries, primarily due to distractions. Then, the success …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Pamasi/sgg_av]"]}}
}

@article{rayyan-242084517,
  title={Parameter Choice and Neuro-Symbolic Approaches for Deep Domain-Invariant Learning},
  year={2024},
  author={Dinu, M. C.},
  abstract={… Neuro-symbolic (NeSy) AI bridges the gap between symbolic … In contrast, NeSy AI systems use multiple models and … In this work, we analyze common DA and NeSy approaches with the …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Xpitfire/bpda]"]}}
}

@article{rayyan-242084519,
  title={Neurosymbolic Visual Transform Based on Logic Tensor Network for Defect Detection},
  year={2025},
  author={Djenouri, Youcef and Belbachir, Ahmed Nabil and Belhadi, Asma and Michalak, Tomasz},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/YousIA/NSViT-LTN/]"]}}
}

@article{rayyan-242084527,
  title={An energy-based model for neuro-symbolic reasoning on knowledge graphs},
  year={2021},
  author={Dold, D. and Garrido, J. S.},
  url={https://ieeexplore.ieee.org/abstract/document/9680167/?casa_token=CIJmV2IIaDEAAAAA:_IYxzvA2_OpVFFavNqwtakgRfsjlHSxN1nc4L5T_0iofbfbmoiiuMHD7AwSQA04awAvTLiW9qbNSiA},
  abstract={Machine learning on graph-structured data has recently become a major topic in industry and research, finding many exciting applications such as recommender systems and …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/dodo47/cyberML]"]}}
}

@article{rayyan-242084529,
  title={Bringing Back Semantics to Knowledge Graph Embeddings: An Interpretability Approach},
  year={2024},
  volume={14980},
  author={Domingues, Antoine and Nitisha, Jain and Merono, Penuela Albert and Elena, Simperl},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Knowledge Graph Embeddings Models project entities and relations from Knowledge Graphs into a vector space. Despite their widespread application, concerns persist about the ability of these models to capture entity similarity effectively. To address this, we introduce InterpretE, a novel neuro-symbolic approach to derive interpretable vector spaces with human-understandable dimensions in terms of the features of the entities. We demonstrate the efficacy of InterpretE in encapsulating desired semantic features, presenting evaluations both in the vector space as well as in terms of semantic similarity measurements.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/toniodo/InterpretE]"]}}
}

@article{rayyan-242084532,
  title={CORRPUS: Code-based Structured Prompting for Neurosymbolic Story Understanding},
  year={2023},
  author={Done, Yijiang River and Martine Lara, J. and Chris, Callison-Burch},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Story generation and understanding-as with all NLG/NLU tasks-has seen a surge in neurosymbolic work. Researchers have recognized that, while large language models (LLMs) have tremendous utility, they can be augmented with symbolic means to be even better and to make up for many flaws that neural networks have. However, symbolic methods are extremely costly in terms of the amount of time and expertise needed to create them. In this work, we capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use of symbolic methods for tracking the state of stories and aiding in story understanding. We show that our CoRRPUS system and abstracted prompting procedures can beat current state-of-the-art structured LLM techniques on preexisting story understanding tasks (bAbI Task 2 and Re-3) with minimal hand engineering. This work highlights the usefulness of code-based symbolic representations for enabling LLMs to better perform story reasoning tasks.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/dong-river/CoRRPUS]"]}}
}

@article{rayyan-242084533,
  title={Neural Logic Machines},
  year={2019},
  author={Dong, Honghua and Mao, Jiayuan and Lin, Tian and Wang, Chong and Li, Lihong and Zhou, Denny},
  abstract={We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks-as function approximators, and logic programming-as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/google/neural-logic-machines]"]}}
}

@article{rayyan-242084538,
  title={Unveiling implicit deceptive patterns in multi-modal fake news via neuro-symbolic reasoning},
  year={2024},
  author={Dong, Y. and He, D. and Wang, X. and Jin, Y. and Ge, M. and Yang, C.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/28677},
  abstract={… Then, we propose a novel Neuro-Symbolic Latent Model called NSLM, that not only derives accurate judgments on the veracity of news but also uncovers the implicit deceptive patterns …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/hedongxiao-tju/NSLM]"]}}
}

@article{rayyan-242084541,
  title={A Novel Neural-symbolic System under Statistical Relational Learning},
  year={2023},
  author={Yu, Dongran and Liu, Xueyan and Pan, Shirui and Li, Anchen and Bo, Yang},
  abstract={A key objective in the field of artificial intelligence is to develop cognitive models that can exhibit human-like intellectual capabilities. One promising approach to achieving this is through neural-symbolic systems, which combine the strengths of deep learning and symbolic reasoning. However, current methodologies in this area face limitations in integration, generalization, and interpretability. To address these challenges, we propose a neural-symbolic framework based on statistical relational learning, referred to as NSF-SRL. This framework effectively integrates deep learning models with symbolic reasoning in a mutually beneficial manner.In NSF-SRL, the results of symbolic reasoning are utilized to refine and correct the predictions made by deep learning models, while deep learning models enhance the efficiency of the symbolic reasoning process. Through extensive experiments, we demonstrate that our approach achieves high performance and exhibits effective generalization in supervised learning, weakly supervised and zero-shot learning tasks. Furthermore, we introduce a quantitative strategy to evaluate the interpretability of the model's predictions, visualizing the corresponding logic rules that contribute to these predictions and providing insights into the reasoning process. We believe that this approach sets a new standard for neural-symbolic systems and will drive future research in the field of general artificial intelligence.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/Dongranyu/NSF-SRL]"]}}
}

@article{rayyan-242084547,
  title={Neuro-symbolic XAI: Application to drug repurposing for rare diseases},
  year={2022},
  author={Drancé, M.},
  abstract={… and symbolic tools that will constitute the final neuro-symbolic model. For example: (i) how to … The impact of these modifications in the data structure will be tested on our neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"}}
}

@article{rayyan-242084567,
  title={Neuro-symbolic deductive reasoning for cross-knowledge graph entailment},
  year={2021},
  author={Ebrahimi, M. and Sarker, M. K.},
  url={https://corescholar.libraries.wright.edu/cse/656/},
  abstract={… A significant and recent development in neural-symbolic learning … Initial neural-symbolic systems that can deduce the … We propose a neural-symbolic system to address this limitation in …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/Monireh2/kg-deductive-reasoner]"]}}
}

@article{rayyan-242084577,
  title={MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
  year={2022},
  author={Muhlgay, Dor and Rozen, Noam and Schwartz, Erez and Shachaf, Gal and Shalev-Shwartz, Shai and Shashua, Amnon and Moshe, Ehud Karpas, Tenenholtz and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and Leyton-Brown, Kevin},
  abstract={Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced miracle ) system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["LLM: [https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1/]"]}}
}

@article{rayyan-242084578,
  title={A Logic-based Approach to Contrastive Explainability for Neurosymbolic Visual Question Answering},
  year={2023},
  author={Eiter, T. and Geibinger, T. and Higuera, N. and Oetsch, J.},
  url={https://www.ijcai.org/proceedings/2023/0408.pdf},
  abstract={… The Neurosymbolic VQA Framework In this section, we introduce a modular neurosymbolic … 3.1 Architecture of NSVQASP We adopt the modular neurosymbolic architecture of NS-VQA, …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/pudumagico/nsvqasp]"]}}
}

@article{rayyan-242084579,
  title={A neuro-symbolic ASP pipeline for visual question answering},
  year={2022},
  author={Eiter, T. and Higuera, N. and Oetsch, J. and Pritz, M.},
  url={https://www.cambridge.org/core/journals/theory-and-practice-of-logic-programming/article/neurosymbolic-asp-pipeline-for-visual-question-answering/48A54F7B23E9FAC3AD6AB495CA901701},
  abstract={… Neuro-symbolic approaches are useful in this regard as they … We present a neuro-symbolic VQA pipeline for the CLEVR … The architecture of our neuro-symbolic VQA pipeline that builds …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/Macehil/nesy-asp-vqa-pipeline]"]}}
}

@article{rayyan-242084581,
  title={A Modular Neurosymbolic Approach for Visual Graph Question Answering},
  year={2023},
  author={Eiter, Thomas and Higuera, Ruiz Nelson and Johannes, Oetsch},
  publisher={RWTH AACHEN},
  abstract={Images containing graph-based structures are a ubiquitous and popular form of data representation that, to the best of our knowledge, have not yet been considered in the domain of Visual Question Answering (VQA). We use CLEGR, a graph question answering dataset with a generator that synthetically produces vertex-labelled graphs that are inspired by metro networks. Structured information about stations and lines is provided, and the task is to answer natural language questions concerning such graphs. While symbolic methods suffice to solve this dataset, we consider the more challenging problem of taking images of the graphs instead of their symbolic representations as input. Our solution takes the form of a modular neurosymbolic model that combines the use of optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing node labels, and answer-set programming, a popular logic-based approach to declarative problem solving, for reasoning. The implementation of the model achieves an overall average accuracy of 73% on the dataset, providing further evidence of the potential of modular neurosymbolic systems in solving complex VQA tasks, in particular, the use and control of pretrained models in this architecture.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/pudumagico/NSGRAPH]"]}}
}

@article{rayyan-242084582,
  title={Pattern-based engineering of Neurosymbolic AI Systems},
  year={2025},
  author={Ekaputra, F. J.},
  url={https://www.sciencedirect.com/science/article/pii/S1570826824000416},
  abstract={… for combining the paradigms into Neurosymbolic AI (NeSy-AI) … challenge by systematically modelling NeSy-AI systems as … support the engineering process of NeSy-AI systems with tasks …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/michipritz/nesy-asp-vqa-pipeline]"]}}
}

@article{rayyan-242084586,
  title={Neural Reward Machines},
  year={2024},
  author={Umili, Elena and Argenziano, Francesco and Roberto, Capobianco},
  abstract={Non-markovian Reinforcement Learning (RL) tasks are very hard to solve, because agents must consider the entire history of state-action pairs to act rationally in the environment. Most works use symbolic formalisms (as Linear Temporal Logic or automata) to specify the temporally-extended task. These approaches only work in finite and discrete state environments or continuous problems for which a mapping between the raw state and a symbolic interpretation is known as a symbol grounding (SG) function. Here, we define Neural Reward Machines (NRM), an automata-based neurosymbolic framework that can be used for both reasoning and learning in non-symbolic non-markovian RL domains, which is based on the probabilistic relaxation of Moore Machines. We combine RL with semisupervised symbol grounding (SSSG) and we show that NRMs can exploit high-level symbolic knowledge in non-symbolic environments without any knowledge of the SG function, outperforming Deep RL methods which cannot incorporate prior knowledge. Moreover, we advance the research in SSSG, proposing an algorithm for analysing the groundability of temporal specifications, which is more efficient than baseline techniques of a factor 10³.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/KRLGroup/NeuralRewardMachines]"]}}
}

@article{rayyan-242084587,
  title={VAEL: Bridging Variational Autoencoders and Probabilistic Logic Programming},
  year={2022},
  author={Misino, Eleonora and Marra, Giuseppe and Emanuele, Sansone},
  abstract={We present VAEL, a neuro-symbolic generative model integrating variational autoencoders (VAE) with the reasoning capabilities of probabilistic logic (L) programming. Besides standard latent subsymbolic variables, our model exploits a probabilistic logic program to define a further structured representation, which is used for logical reasoning. The entire process is end-to-end differentiable. Once trained, VAEL can solve new unseen generation tasks by (i) leveraging the previously acquired knowledge encoded in the neural component and (ii) exploiting new logical programs on the structured latent space. Our experiments provide support on the benefits of this neuro-symbolic integration both in terms of task generalization and data efficiency. To the best of our knowledge, this work is the first to propose a general-purpose end-to-end framework integrating probabilistic logic programming into a deep generative model.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/EleMisi/VAEL]"]}}
}

@article{rayyan-242084591,
  title={Shadow of the (Hierarchical) Tree: Reconciling Symbolic and Predictive Components of the Neural Code for Syntax},
  year={2024},
  author={Elliot, Murphy},
  abstract={Natural language syntax can serve as a major test for how to integrate two infamously distinct frameworks: symbolic representations and connectionist neural networks. Building on a recent neurocomputational architecture for syntax (ROSE), I discuss the prospects of reconciling the neural code for hierarchical 'vertical' syntax with linear and predictive 'horizontal' processes via a hybrid neurosymbolic model. I argue that the former can be accounted for via the higher levels of ROSE in terms of vertical phrase structure representations, while the latter can explain horizontal forms of linguistic information via the tuning of the lower levels to statistical and perceptual inferences. One prediction of this is that artificial language models will contribute to the cognitive neuroscience of horizontal morphosyntax, but much less so to hierarchically compositional structures. I claim that this perspective helps resolve many current tensions in the literature. Options for integrating these two neural codes are discussed, with particular emphasis on how predictive coding mechanisms can serve as interfaces between symbolic oscillatory phase codes and population codes for the statistics of linearized aspects of syntax. Lastly, I provide a neurosymbolic mathematical model for how to inject symbolic representations into a neural regime encoding lexico-semantic statistical features.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent to Elliot.", "email response: This paper is now being published as follows:  Murphy, E. ROSE: A universal neural grammar. Cognitive Neuroscience https://doi.org/10.1080/17588928.2025.2523875.  This pre-print you mentioned is now transformed into the above paper. This is a Discussion article, with no source code per se. But there is a GitHub page with some simulation scripts that you might use: https://github.com/ElliotMurphy91/ROSE", "Github: [https://github.com/ElliotMurphy91/ROSE]"]}}
}

@article{rayyan-242084593,
  title={Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal},
  year={2023},
  author={Marconato, Emanuele and Bontempo, Gianpaolo and Ficarra, Elisa and Calderara, Simone and Passerini, Andrea and Stefano, Teso},
  abstract={We introduce Neuro-Symbolic Continual Learning, where a model has to solve a sequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to high-level concepts and compute predictions by reasoning consistently with prior knowledge. Our key observation is that neuro-symbolic tasks, although different, often share concepts whose semantics remains stable over time. Traditional approaches fall short: existing continual strategies ignore knowledge altogether, while stock neuro-symbolic architectures suffer from catastrophic forgetting. We show that leveraging prior knowledge by combining neuro-symbolic architectures with continual strategies does help avoid catastrophic forgetting, but also that doing so can yield models affected by reasoning shortcuts. These undermine the semantics of the acquired concepts, even when detailed prior knowledge is provided upfront and inference is exact, and in turn continual performance. To overcome these issues, we introduce COOL, a COncept-level cOntinual Learning strategy tailored for neuro-symbolic continual problems that acquires high-quality concepts and remembers them over time. Our experiments on three novel benchmarks highlights how COOL attains sustained high performance on neuro-symbolic continual learning tasks in which other strategies fail.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ema-marconato/NeSy-CL]"]}}
}

@article{rayyan-242084594,
  title={BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts},
  year={2024},
  author={Marconato, Emanuele and Bortolotti, Samuele and van Krieken, Emile and Vergari, Antonio and Passerini, Andrea and Stefano, Teso},
  abstract={Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge - encoding, e.g., safety constraints - can be affected by Reasoning Shortcuts (RSs): They learn concepts consistent with the symbolic knowledge by exploiting unintended semantics. RSs compromise reliability and generalization and, as we show in this paper, they are linked to NeSy models being overconfident about the predicted concepts. Unfortunately, the only trustworthy mitigation strategy requires collecting costly dense supervision over the concepts. Rather than attempting to avoid RSs altogether, we propose to ensure NeSy models are aware of the semantic ambiguity of the concepts they learn, thus enabling their users to identify and distrust low-quality concepts. Starting from three simple desiderata, we derive bears (BE Aware of Reasoning Shortcuts), an ensembling technique that calibrates the model's concept-level confidence without compromising prediction accuracy, thus encouraging NeSy architectures to be uncertain about concepts affected by RSs. We show empirically that bears improves RS-awareness of several state-of-the-art NeSy models, and also facilitates acquiring informative dense annotations for mitigation purposes.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/samuelebortolotti/bears]"]}}
}

@article{rayyan-242084596,
  title={Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts},
  year={2023},
  author={Marconato, Emanuele and Teso, Stefano and Vergari, Antonio and Andrea, Passerini},
  abstract={Neuro-Symbolic (NeSy) predictive models hold the promise of improved compliance with given constraints, systematic generalization, and interpretability, as they allow to infer labels that are consistent with some prior knowledge by reasoning over high-level concepts extracted from sub-symbolic inputs. It was recently shown that NeSy predictors are affected by reasoning shortcuts: they can attain high accuracy but by leveraging concepts with unintended semantics, thus coming short of their promised advantages. Yet, a systematic characterization of reasoning shortcuts and of potential mitigation strategies is missing. This work fills this gap by characterizing them as unintended optima of the learning objective and identifying four key conditions behind their occurrence. Based on this, we derive several natural mitigation strategies, and analyze their efficacy both theoretically and empirically. Our analysis shows reasoning shortcuts are difficult to deal with, casting doubts on the trustworthiness and interpretability of existing NeSy solutions.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ema-marconato/reasoning-shortcuts]"]}}
}

@article{rayyan-242084600,
  title={Neurosymbolic Diffusion Models},
  year={2025},
  author={van Krieken, Emile and Minervini, Pasquale and Ponti, Edoardo and Antonio, Vergari},
  abstract={Neurosymbolic (NeSy) predictors combine neural perception with symbolic reasoning to solve tasks like visual reasoning. However, standard NeSy predictors assume conditional independence between the symbols they extract, thus limiting their ability to model interactions and uncertainty - often leading to overconfident predictions and poor out-of-distribution generalisation. To overcome the limitations of the independence assumption, we introduce neurosymbolic diffusion models (NeSyDMs), a new class of NeSy predictors that use discrete diffusion to model dependencies between symbols. Our approach reuses the independence assumption from NeSy predictors at each step of the diffusion process, enabling scalable learning while capturing symbol dependencies and uncertainty quantification. Across both synthetic and real-world benchmarks - including high-dimensional visual path planning and rule-based autonomous driving - NeSyDMs achieve state-of-the-art accuracy among NeSy predictors and demonstrate strong calibration.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/HEmile/neurosymbolic-diffusion]"]}}
}

@article{rayyan-242084603,
  title={A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference},
  year={2022},
  author={van Krieken, Emile and Thanapalasingam, Thiviyan and Jakub, M. Tomczak and van Harmelen, Frank and ten Teije, Annette},
  abstract={We study the problem of combining neural networks with symbolic reasoning. Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL), such as DeepProbLog, perform exponential-time exact inference, limiting the scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference (A-NeSI): a new framework for PNL that uses neural networks for scalable approximate inference. A-NeSI 1) performs approximate inference in polynomial time without changing the semantics of probabilistic logics; 2) is trained using data generated by the background knowledge; 3) can generate symbolic explanations of predictions; and 4) can guarantee the satisfaction of logical constraints at test time, which is vital in safety-critical applications. Our experiments show that A-NeSI is the first end-to-end method to solve three neurosymbolic tasks with exponential combinatorial scaling. Finally, our experiments show that A-NeSI achieves explainability and safety without a penalty in performance.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/HEmile/a-nesi]"]}}
}

@article{rayyan-242084604,
  title={Optimisation in Neurosymbolic Learning Systems},
  year={2024},
  author={Emile van, Krieken},
  abstract={Neurosymbolic AI aims to integrate deep learning with symbolic AI. This integration has many promises, such as decreasing the amount of data required to train a neural network, improving the explainability and interpretability of answers given by models and verifying the correctness of trained systems. We study neurosymbolic learning, where we have both data and background knowledge expressed using symbolic languages. How do we connect the symbolic and neural components to communicate this knowledge? One option is fuzzy reasoning, which studies degrees of truth. For example, being tall is not a binary concept. Instead, probabilistic reasoning studies the probability that something is true or will happen. Our first research question studies how different forms of fuzzy reasoning combine with learning. We find surprising results like a connection to the Raven paradox stating we confirm "ravens are black" when we observe a green apple. In this study, we did not use the background knowledge when we deployed our models after training. In our second research question, we studied how to use background knowledge in deployed models. We developed a new neural network layer based on fuzzy reasoning. Probabilistic reasoning is a natural fit for neural networks, which we usually train to be probabilistic. However, they are expensive to compute and do not scale well to large tasks. In our third research question, we study how to connect probabilistic reasoning with neural networks by sampling to estimate averages, while in the final research question, we study scaling probabilistic neurosymbolic learning to much larger problems than before. Our insight is to train a neural network with synthetic data to predict the result of probabilistic reasoning.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/HEmile/differentiable-fuzzy-logics]"]}}
}

@article{rayyan-242084606,
  title={Motion Question Answering via Modular Motion Programs},
  year={2023},
  volume={202},
  author={Endo, Mark and Joy, Hsu and Jiaman, Li and Jiajun, Wu},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={In order to build artificial intelligence systems that can perceive and reason with human behavior in the real world, we must first design models that conduct complex spatio-temporal reasoning over motion sequences. Moving towards this goal, we propose the HumanMotionQA task to evaluate complex, multi-step reasoning abilities of models on long-form human motion sequences. We generate a dataset of question-answer pairs that require detecting motor cues in small portions of motion sequences, reasoning temporally about when events occur, and querying specific motion attributes. In addition, we propose NSPose, a neurosymbolic method for this task that uses symbolic reasoning and a modular design to ground motion through learning motion concepts, attribute neural operators, and temporal relations. We demonstrate the suitability of NSPose for the HumanMotionQA task, outperforming all baseline methods.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/markendo/HumanMotionQA]"]}}
}

@article{rayyan-242084607,
  title={NSP: A Neuro-Symbolic Natural Language Navigational Planner},
  year={2024},
  author={English, W. and Simon, D. and Jha, S. K.},
  url={https://ieeexplore.ieee.org/abstract/document/10903323/?casa_token=nAKWfRiht04AAAAA:x7M80OAGlqfaTO3O5hE-XwFQASOTDCSPGwoxeg97u8W_gszGQU1YgtLiY2Xps9tUhrLJ1_C6fD8CyA},
  abstract={… , we propose a neuro-symbolic frame… neuro-symbolic approach using a benchmark suite with 1500 path-planning problems. The experimental evaluation shows that our neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["email sent to William. ", "Github: [https://github.com/Dubascudes/NSP]"]}}
}

@article{rayyan-242084612,
  title={Unsupervised Learning of Neurosymbolic Encoders},
  year={2021},
  author={Zhan, Eric and Jennifer, J. Sun and Kennedy, Ann and Yue, Yisong and Chaudhuri, Swarat},
  abstract={We present a framework for the unsupervised learning of neurosymbolic encoders, which are encoders obtained by composing neural networks with symbolic programs from a domain-specific language. Our framework naturally incorporates symbolic expert knowledge into the learning process, which leads to more interpretable and factorized latent representations compared to fully neural encoders. We integrate modern program synthesis techniques with the variational autoencoding (VAE) framework, in order to learn a neurosymbolic encoder in conjunction with a standard decoder. The programmatic descriptions from our encoders can benefit many analysis workflows, such as in behavior modeling where interpreting agent actions and movements is important. We evaluate our method on learning latent representations for real-world trajectory data from animal biology and sports analytics. We show that our approach offers significantly better separation of meaningful categories than standard VAEs and leads to practical gains on downstream analysis tasks, such as for behavior classification.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ezhan94/neurosymbolic-encoders]"]}}
}

@article{rayyan-242084614,
  title={Learning Semantic Association Rules from Internet of Things Data},
  year={2024},
  author={Karabulut, Erkan and Groth, Paul and Victoria, Degeler},
  abstract={Association Rule Mining (ARM) is the task of discovering commonalities in data in the form of logical implications. ARM is used in the Internet of Things (IoT) for different tasks including monitoring and decision-making. However, existing methods give limited consideration to IoT-specific requirements such as heterogeneity and volume. Furthermore, they do not utilize important static domain-specific description data about IoT systems, which is increasingly represented as knowledge graphs. In this paper, we propose a novel ARM pipeline for IoT data that utilizes both dynamic sensor data and static IoT system metadata. Furthermore, we propose an Autoencoder-based Neurosymbolic ARM method (Aerial) as part of the pipeline to address the high volume of IoT data and reduce the total number of rules that are resource-intensive to process. Aerial learns a neural representation of a given data and extracts association rules from this representation by exploiting the reconstruction (decoding) mechanism of an autoencoder. Extensive evaluations on 3 IoT datasets from 2 domains show that ARM on both static and dynamic IoT data results in more generically applicable rules while Aerial can learn a more concise set of high-quality association rules than the state-of-the-art with full coverage over the datasets.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/DiTEC-project/semantic-association-rule-learning]"]}}
}

@article{rayyan-242084615,
  title={Neurosymbolic Association Rule Mining from Tabular Data},
  year={2025},
  author={Karabulut, Erkan and Groth, Paul and Victoria, Degeler},
  abstract={Association Rule Mining (ARM) is the task of mining patterns among data features in the form of logical rules, with applications across a myriad of domains. However, high-dimensional datasets often result in an excessive number of rules, increasing execution time and negatively impacting downstream task performance. Managing this rule explosion remains a central challenge in ARM research. To address this, we introduce Aerial+, a novel neurosymbolic ARM method. Aerial+ leverages an under-complete autoencoder to create a neural representation of the data, capturing associations between features. It extracts rules from this neural representation by exploiting the model's reconstruction mechanism. Extensive evaluations on five datasets against seven baselines demonstrate that Aerial+ achieves state-of-the-art results by learning more concise, high-quality rule sets with full data coverage. When integrated into rule-based interpretable machine learning models, Aerial+ significantly reduces execution time while maintaining or improving accuracy.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/DiTEC-project/pyaerial]"]}}
}

@article{rayyan-242084618,
  title={Making sense of raw input},
  year={2021},
  volume={299},
  author={Evans, Richard and Matko, Bosnjak and Lars, Buesing and Kevin, Ellis and David, Pfau and Pushmeet, Kohli and Marek, Sergot},
  abstract={How should a machine intelligence perform unsupervised structure discovery over streams of sensory input? One approach to this problem is to cast it as an apperception task [ 1]. Here, the task is to construct an explicit interpretable theory that both explains the sensory sequence and also satisfies a set of unity conditions, designed to ensure that the constituents of the theory are connected in a relational structure. However, the original formulation of the apperception task had one fundamental limitation: it assumed the raw sensory input had already been parsed using a set of discrete categories, so that all the system had to do was receive this already-digested symbolic input, and make sense of it. But what if we don't have access to pre-parsed input? What if our sensory sequence is raw unprocessed information? The central contribution of this paper is a neuro-symbolic framework for distilling interpretable theories out of streams of raw, unprocessed sensory experience. First, we extend the definition of the apperception task to include ambiguous (but still symbolic) input: sequences of sets of disjunctions. Next, we use a neural network to map raw sensory input to disjunctive input. Our binary neural network is encoded as a logic program, so the weights of the network and the rules of the theory can be solved jointly as a single SAT problem. This way, we are able to jointly learn how to perceive (mapping raw sensory information to concepts) and apperceive (combining concepts into declarative rules). (C) 2021 The Author(s). Published by Elsevier B.V.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/RichardEvans/apperception]"]}}
}

@article{rayyan-242084619,
  title={Plan-SOFAI: A neuro-symbolic planning architecture},
  year={2023},
  author={Fabiano, F. and Pallagani, V. and Ganapini, M. B.},
  url={https://openreview.net/forum?id=ORAhay0H4x},
  abstract={The notion of Artificial Intelligence (AI) has garnered significant attention in recent years and AI-based tools have increasingly become integrated into our daily lives. As this strand of …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ai4society/sofai_tool]"]}}
}

@article{rayyan-242084620,
  title={Bridging Logic and Learning: A Neural-Symbolic Approach for Enhanced Reasoning in Neural Models (ASPER)},
  year={2023},
  author={Fadi Al, Machot},
  abstract={Neural-symbolic learning, an intersection of neural networks and symbolic reasoning, aims to blend neural networks' learning capabilities with symbolic AI's interpretability and reasoning. This paper introduces an approach designed to improve the performance of neural models in learning reasoning tasks. It achieves this by integrating Answer Set Programming (ASP) solvers and domain-specific expertise, which is an approach that diverges from traditional complex neural-symbolic models. In this paper, a shallow artificial neural network (ANN) is specifically trained to solve Sudoku puzzles with minimal training data. The model has a unique loss function that integrates losses calculated using the ASP solver outputs, effectively enhancing its training efficiency. Most notably, the model shows a significant improvement in solving Sudoku puzzles using only 12 puzzles for training and testing without hyperparameter tuning. This advancement indicates that the model's enhanced reasoning capabilities have practical applications, extending well beyond Sudoku puzzles to potentially include a variety of other domains. The code can be found on GitHub: https://github.com/Fadi2200/ASPEN.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/Fadi2200/ASPEN]"]}}
}

@article{rayyan-242084621,
  title={Neural-Symbolic Ensemble Learning for early-stage prediction of critical state of Covid-19 patients},
  year={2022},
  author={Fadja, A. N. and Fraccaroli, M. and Bizzarri, A.},
  abstract={… In this section, a neural-symbolic system that allows easy integration of both symbolic and sub-symbolic models is proposed. It allows to build an efficient, interpretable and explainable …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Webapp: [https://cplint.eu/e/phil/phil_examples.swinb]"]}}
}

@article{rayyan-242084627,
  title={DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs},
  year={2024},
  author={Fang, Haishuo and Xiaodan, Zhu and Iryna, Gurevych},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning autonomous language agents in various real-life applications. To improve the neural-symbolic reasoning capabilities of language agents powered by Large Language Models (LLMs) in KGQA, we propose the Decomposition-Alignment-Reasoning Agent (DARA) framework. DARA effectively parses questions into formal queries through a dual mechanism: highlevel iterative task decomposition and low-level task grounding. Importantly, DARA can be efficiently trained with a small number of highquality reasoning trajectories. Our experimental results demonstrate that DARA fine-tuned on LLMs (e.g. Llama-2-7B, Mistral) outperforms both in-context learning-based agents with GPT-4 and alternative fine-tuned agents, across different benchmarks in zero-shot evaluation. This makes such models more accessible for real-life applications. We also show that DARA attains performance comparable to state-of-the-art enumerating-and-rankingbased methods for KGQA.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/UKPLab/acl2024-DARA]"]}}
}

@article{rayyan-242084628,
  title={Large language models are neurosymbolic reasoners},
  year={2024},
  author={Fang, M. and Deng, S. and Zhang, Y. and Shi, Z. and Chen, L.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/29754},
  abstract={A wide range of real-world applications is characterized by their symbolic nature, necessitating a strong capability for symbolic reasoning. This paper investigates the potential …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/hyintell/LLMSymbolic]"]}}
}

@article{rayyan-242084631,
  title={Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models},
  year={2024},
  author={Xu, Fangzhi and Sun, Qiushi and Cheng, Kanzhi and Liu, Jun and Qiao, Yu and Zhiyong, Wu},
  abstract={One of the primary driving forces contributing to the superior performance of Large Language Models (LLMs) is the extensive availability of human-annotated natural language data, which is used for alignment fine-tuning. This inspired researchers to investigate self-training methods to mitigate the extensive reliance on human annotations. However, the current success of self-training has been primarily observed in natural language scenarios, rather than in the increasingly important neural-symbolic scenarios. To this end, we propose an environment-guided neural-symbolic self-training framework named ENVISIONS. It aims to overcome two main challenges: (1) the scarcity of symbolic data, and (2) the limited proficiency of LLMs in processing symbolic language. Extensive evaluations conducted on three distinct domains demonstrate the effectiveness of our approach. Additionally, we have conducted a comprehensive analysis to uncover the factors contributing to ENVISIONS's success, thereby offering valuable insights for future research in this area. Code will be available at \url https://github.com/xufangzhi/ENVISIONS .},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/xufangzhi/ENVISIONS]"]}}
}

@article{rayyan-242084632,
  title={Privacy-Preserving Federated Learning with Differentially Private Hyperdimensional Computing},
  year={2024},
  author={Piran, Fardin Jalil and Chen, Zhiling and Imani, Mohsen and Farhad, Imani},
  abstract={Federated Learning (FL) has become a key method for preserving data privacy in Internet of Things (IoT) environments, as it trains Machine Learning (ML) models locally while transmitting only model updates. Despite this design, FL remains susceptible to threats such as model inversion and membership inference attacks, which can reveal private training data. Differential Privacy (DP) techniques are often introduced to mitigate these risks, but simply injecting},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/FardinJalilPiran/FedHDPrivacy]"]}}
}

@article{rayyan-242084652,
  title={Learning task-general representations with generative neuro-symbolic modeling},
  year={2020},
  author={Feinman, R. and Lake, B. M.},
  abstract={… We develop a generative neuro-symbolic (GNS) model of handwritten character concepts that uses the control flow of a probabilistic program, coupled with symbolic stroke primitives …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/rfeinman/GNS-Modeling]"]}}
}

@article{rayyan-242084653,
  title={Towards scalable and model-agnostic neuro-symbolic artificial intelligence},
  year={2024},
  author={Feldstein, J.},
  url={https://era.ed.ac.uk/handle/1842/42658},
  publisher={era.ed.ac.uk},
  abstract={… neuro-symbolic AI landscape, identifying direct links between architectural choices and strengths of neuro-symbolic … First, we present Concordia, a neuro-symbolic AI framework building …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["This is a thesis so it has multiple code contributions. ", "Github: [https://github.com/jonathanfeldstein/Concordia]", "Github: [https://github.com/jonathanfeldstein/PRISM]", "Github: [https://github.com/jonathanfeldstein/SPECTRUM]", "Github: [https://github.com/jonathanfeldstein/KnowledgeCompilation]", "Github: [https://github.com/jonathanfeldstein/wfomi]"]}}
}

@article{rayyan-242084655,
  title={Parallel neurosymbolic integration with Concordia},
  year={2023},
  author={Feldstein, J. and Jurčius, M.},
  url={https://proceedings.mlr.press/v202/feldstein23a.html},
  abstract={Parallel neurosymbolic architectures have been applied effectively in NLP by distilling knowledge from a logic theory into a deep model. However, prior art faces several limitations …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/jonathanfeldstein/Concordia]"]}}
}

@article{rayyan-242084656,
  title={Principled and Efficient Motif Finding for Structure Learning of Lifted Graphical Models},
  year={2023},
  author={Feldstein, Jonathan and Dominic, Phillips and Efthymia, Tsamoura},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={Structure learning is a core problem in AI central to the fields of neuro-symbolic AI and statistical relational learning. It consists in automatically learning a logical theory from data. The basis for structure learning is mining repeating patterns in the data, known as structural motifs. Finding these patterns reduces the exponential search space and therefore guides the learning of formulas. Despite the importance of motif learning, it is still not well understood. We present the first principled approach for mining structural motifs in lifted graphical models, languages that blend first-order logic with probabilistic models, which uses a stochastic process to measure the similarity of entities in the data. Our first contribution is an algorithm, which depends on two intuitive hyperparameters: one controlling the uncertainty in the entity similarity measure, and one controlling the softness of the resulting rules. Our second contribution is a preprocessing step where we perform hierarchical clustering on the data to reduce the search space to the most relevant data. Our third contribution is to introduce an O(n ln n) (in the size of the entities in the data) algorithm for clustering structurally-related data. We evaluate our approach using standard benchmarks and show that we outperform state-of-the-art structure learning approaches by up to 6% in terms of accuracy and up to 80% in terms of runtime.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/jonathanfeldstein/PRISM]"]}}
}

@article{rayyan-242084657,
  title={Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules},
  year={2024},
  author={Feldstein, Jonathan and Phillips, Dominic and Tsamoura, Efthymia},
  abstract={Probabilistic logical models are a core component of neurosymbolic AI and are important models in their own right for tasks that require high explainability. Unlike neural networks, logical models are often handcrafted using domain expertise, making their development costly and prone to errors. While there are algorithms that learn logical models from data, they are generally prohibitively expensive, limiting their applicability in real-world settings. In this work, we introduce precision and recall for logical rules and define their composition as rule utility - a cost-effective measure to evaluate the predictive power of logical models. Further, we introduce SPECTRUM, a scalable framework for learning logical models from relational data. Its scalability derives from a linear-time algorithm that mines recurrent structures in the data along with a second algorithm that, using the cheap utility measure, efficiently ranks rules built from these structures. Moreover, we derive theoretical guarantees on the utility of the learnt logical model. As a result, SPECTRUM learns more accurate logical models orders of magnitude faster than previous methods on real-world datasets.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/jonathanfeldstein/SPECTRUM]"]}}
}

@article{rayyan-242084658,
  title={Enhancing Multi-Domain Automatic Short Answer Grading through an Explainable Neuro-Symbolic Pipeline},
  year={2024},
  author={Künnecke, Felix and Filighera, Anna and Leong, Colin and Tim, Steuer},
  abstract={Grading short answer questions automatically with interpretable reasoning behind the grading decision is a challenging goal for current transformer approaches. Justification cue detection, in combination with logical reasoners, has shown a promising direction for neuro-symbolic architectures in ASAG. But, one of the main challenges is the requirement of annotated justification cues in the students' responses, which only exist for a few ASAG datasets. To overcome this challenge, we contribute (1) a weakly supervised annotation procedure for justification cues in ASAG datasets, and (2) a neuro-symbolic model for explainable ASAG based on justification cues. Our approach improves upon the RMSE by 0.24 to 0.3 compared to the state-of-the-art on the Short Answer Feedback dataset in a bilingual, multi-domain, and multi-question training setup. This result shows that our approach provides a promising direction for generating high-quality grades and accompanying explanations for future research in ASAG and educational NLP.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/chefkoch24/neuro-symbolic-asag]"]}}
}

@article{rayyan-242084659,
  title={Transformer-based Machine Learning for Fast SAT Solvers and Logic Synthesis},
  year={2021},
  author={Shi, Feng and Lee, Chonghan and Bashar, Mohammad Khairul and Shukla, Nikhil and Zhu, Song-Chun and Vijaykrishnan, Narayanan},
  abstract={CNF-based SAT and MaxSAT solvers are central to logic synthesis and verification systems. The increasing popularity of these constraint problems in electronic design automation encourages studies on different SAT problems and their properties for further computational efficiency. There has been both theoretical and practical success of modern Conflict-driven clause learning SAT solvers, which allows solving very large industrial instances in a relatively short amount of time. Recently, machine learning approaches provide a new dimension to solving this challenging problem. Neural symbolic models could serve as generic solvers that can be specialized for specific domains based on data without any changes to the structure of the model. In this work, we propose a one-shot model derived from the Transformer architecture to solve the MaxSAT problem, which is the optimization version of SAT where the goal is to satisfy the maximum number of clauses. Our model has a scale-free structure which could process varying size of instances. We use meta-path and self-attention mechanism to capture interactions among homogeneous nodes. We adopt cross-attention mechanisms on the bipartite graph to capture interactions among heterogeneous nodes. We further apply an iterative algorithm to our model to satisfy additional clauses, enabling a solution approaching that of an exact-SAT problem. The attention mechanisms leverage the parallelism for speedup. Our evaluation indicates improved speedup compared to heuristic approaches and improved completion rate compared to machine learning approaches.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"}}
}

@article{rayyan-242084661,
  title={Neuro-symbolic natural logic with introspective revision for natural language inference},
  year={2022},
  author={Feng, Y. and Yang, X. and Zhu, X. and Greenspan, M.},
  abstract={We introduce a neuro-symbolic natural logic framework based on reinforcement learning with introspective revision. The model samples and rewards specific reasoning paths through …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/feng-yufei/NS-NLI]"]}}
}

@article{rayyan-242084669,
  title={Integrating Textual Queries with AI-Based Object Detection: A Compositional Prompt-Guided Approach},
  year={2025},
  volume={25},
  number={7},
  author={Ferreira, S. and Martins, A. and Costa, D. G. and Silva, I.},
  abstract={While object detection and recognition have been extensively adopted by many applications in decision-making, new algorithms and methodologies have emerged to enhance the automatic identification of target objects. In particular, the rise of deep learning and language models has opened many possibilities in this area, although challenges in contextual query analysis and human interactions persist. This article presents a novel neuro-symbolic object detection framework that aligns object proposals with textual prompts using a deep learning module while enabling logical reasoning through a symbolic module. By integrating deep learning with symbolic reasoning, object detection and scene understanding are considerably enhanced, enabling complex, query-driven interactions. Using a synthetic 3D image dataset, the results demonstrate that this framework effectively generalizes to complex queries, combining simple attribute-based descriptions without explicit training on compound prompts. We present the numerical results and comprehensive discussions, highlighting the potential of our approach for emerging smart applications.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Email sent to Silvan. ", "Github: [https://github.com/silvaan/prompt-guided-detection]"]}}
}

@article{rayyan-242084676,
  title={A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming},
  year={2023},
  author={Flach, J. and Lamb, L. C.},
  abstract={… The neurosymbolic models aim to merge the two approaches … , there is not only one form of neurosymbolic AI. In the paper, six … In the present work, we use the Neuro: Symbolic → Neuro …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/jmflach/SymbolicLambda]"]}}
}

@article{rayyan-242084682,
  title={Fast relational learning using bottom clause propositionalization with artificial neural networks},
  year={2014},
  volume={94},
  number={1},
  author={Franca, Manoel V. M. and Gerson, Zaverucha and d'Avila, Garcez Artur S.},
  abstract={Relational learning can be described as the task of learning first-order logic rules from examples. It has enabled a number of new machine learning applications, e.g. graph mining and link analysis. Inductive Logic Programming (ILP) performs relational learning either directly by manipulating first-order rules or through propositionalization, which translates the relational task into an attribute-value learning task by representing subsets of relations as features. In this paper, we introduce a fast method and system for relational learning based on a novel propositionalization called Bottom Clause Propositionalization (BCP). Bottom clauses are boundaries in the hypothesis search space used by ILP systems Progol and Aleph. Bottom clauses carry semantic meaning and can be mapped directly onto numerical vectors, simplifying the feature extraction process. We have integrated BCP with a well-known neural-symbolic system, C-(ILP)-P-2, to perform learning from numerical vectors. C-(ILP)-P-2 uses background knowledge in the form of propositional logic programs to build a neural network. The integrated system, which we call CILP++, handles first-order logic knowledge and is available for download from Sourceforge. We have evaluated CILP++ on seven ILP datasets, comparing results with Aleph and a well-known propositionalization method, RSD. The results show that CILP++ can achieve accuracy comparable to Aleph, while being generally faster, BCP achieved statistically significant improvement in accuracy in comparison with RSD when running with a neural network, but BCP and RSD perform similarly when running with C4.5. We have also extended CILP++ to include a statistical feature selection method, mRMR, with preliminary results indicating that a reduction of more than 90 % of features can be achieved with a small loss of accuracy.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/vakker/CILP/tree/master]"]}}
}

@article{rayyan-242084684,
  title={Fuzzy Logic Visual Network (FLVN): A neuro-symbolic approach for visual features matching},
  year={2023},
  author={Manigrasso, Francesco and Morra, Lia and Fabrizio, Lamberti},
  abstract={Neuro-symbolic integration aims at harnessing the power of symbolic knowledge representation combined with the learning capabilities of deep neural networks. In particular, Logic Tensor Networks (LTNs) allow to incorporate background knowledge in the form of logical axioms by grounding a first order logic language as differentiable operations between real tensors. Yet, few studies have investigated the potential benefits of this approach to improve zero-shot learning (ZSL) classification. In this study, we present the Fuzzy Logic Visual Network (FLVN) that formulates the task of learning a visual-semantic embedding space within a neuro-symbolic LTN framework. FLVN incorporates prior knowledge in the form of class hierarchies (classes and macro-classes) along with robust high-level inductive biases. The latter allow, for instance, to handle exceptions in class-level attributes, and to enforce similarity between images of the same class, preventing premature overfitting to seen classes and improving overall performance. FLVN reaches state of the art performance on the Generalized ZSL (GZSL) benchmarks AWA2 and CUB, improving by 1.3% and 3%, respectively. Overall, it achieves competitive performance to recent ZSL methods with less computational overhead. FLVN is available at https://gitlab.com/grains2/flvn.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Gitlab: [https://gitlab.com/grains2/flvn]"]}}
}

@article{rayyan-242084688,
  title={Structured Event Memory: A neuro-symbolic model of event cognition},
  year={2020},
  author={Franklin, N. T. and Norman, K. A. and Ranganath, C.},
  url={https://psycnet.apa.org/journals/rev/127/3/327/?casa_token=g3JpqGrZj2kAAAAA:FPYXl9Y4UDLN5hz2yUbnua4j3Z6AsFEomaC46Yj1j01z8YpbRVZKYmOf2u_Dh9YAZn40LEwbGHrO5IHj7M1U9yUb},
  abstract={Humans spontaneously organize a continuous experience into discrete events and use the learned structure of these events to generalize and organize memory. We introduce the …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Included"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ProjectSEM/SEM]"]}}
}

@article{rayyan-242084694,
  title={LILO: Learning Interpretable Libraries by Compressing and Documenting Code},
  year={2023},
  author={Grand, Gabriel and Wong, Lionel and Bowers, Maddy and Theo, X. Olausson and Liu, Muxin and Tenenbaum, Joshua B. and Andreas, Jacob},
  abstract={While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce LILO, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. LILO combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal lambda abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping LILO's synthesizer to interpret and deploy learned abstractions. We evaluate LILO on three inductive program synthesis benchmarks for string editing, scene reasoning, and graphics composition. Compared to existing neural and symbolic methods - including the state-of-the-art library learning algorithm DreamCoder - LILO solves more complex tasks and learns richer libraries that are grounded in linguistic knowledge.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"}}
}

@article{rayyan-242084722,
  title={NSSC: a neuro-symbolic AI system for enhancing accuracy of named entity recognition and linking from oncologic clinical notes},
  year={2024},
  author={Garcia-Barragan, Alvaro and Ahmad, Sakor and Maria-Esther, Vidal and Ernestina, Menasalvas and Sanchez, Gonzalez Juan Cristobal and Mariano, Provencio and Victor, Robles},
  abstract={Accurate recognition and linking of oncologic entities in clinical notes is essential for extracting insights across cancer research, patient care, clinical decision-making, and treatment optimization. We present the Neuro-Symbolic System for Cancer (NSSC), a hybrid AI framework that integrates neurosymbolic methods with named entity recognition (NER) and entity linking (EL) to transform unstructured clinical notes into structured terms using medical vocabularies, with the Unified Medical Language System (UMLS) as a case study. NSSC was evaluated on a dataset of clinical notes from breast cancer patients, demonstrating significant improvements in the accuracy of both entity recognition and linking compared to state-of-the-art models. Specifically, NSSC achieved a 33% improvement over BioFalcon and a 58% improvement over scispaCy. By combining large language models (LLMs) with symbolic reasoning, NSSC improves the recognition and interoperability of oncologic entities, enabling seamless integration with existing biomedical knowledge. This approach marks a significant advancement in extracting meaningful information from clinical narratives, offering promising applications in cancer research and personalized patient care.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["github: https://github.com/SDM-TIB/NSSC"]}}
}

@article{rayyan-242084734,
  title={dPASP: a comprehensive differentiable probabilistic answer set programming environment for neurosymbolic learning and reasoning},
  year={2023},
  author={Geh, R. L. and Gonçalves, J. and Silveira, I. C. and Mauá, D. D.},
  abstract={We present dPASP, a novel declarative probabilistic logic programming framework for differentiable neuro-symbolic reasoning. The framework allows for the specification of discrete …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["GitHub: https://github.com/kamel-usp/dpasp"]}}
}

@article{rayyan-242084738,
  title={Enhancing Interpretability and Interactivity in Robot Manipulation: A Neurosymbolic Approach},
  year={2022},
  author={Tziafas, Georgios and Hamidreza, Kasaei},
  abstract={In this paper we present a neurosymbolic architecture for coupling language-guided visual reasoning with robot manipulation. A non-expert human user can prompt the robot using unconstrained natural language, providing a referring expression (REF), a question (VQA), or a grasp action instruction. The system tackles all cases in a task-agnostic fashion through the utilization of a shared library of primitive skills. Each primitive handles an independent sub-task, such as reasoning about visual attributes, spatial relation comprehension, logic and enumeration, as well as arm control. A language parser maps the input query to an executable program composed of such primitives, depending on the context. While some primitives are purely symbolic operations (e.g. counting), others are trainable neural functions (e.g. visual grounding), therefore marrying the interpretability and systematic generalization benefits of discrete symbolic approaches with the scalability and representational power of deep networks. We generate a 3D vision-and-language synthetic dataset of tabletop scenes in a simulation environment to train our approach and perform extensive evaluations in both synthetic and real-world scenes. Results showcase the benefits of our approach in terms of accuracy, sample-efficiency, and robustness to the user's vocabulary, while being transferable to real-world scenes with few-shot visual fine-tuning. Finally, we integrate our method with a robot framework and demonstrate how it can serve as an interpretable solution for an interactive object-picking task, both in simulation and with a real robot. We make our datasets available in https://gtziafas.github.io/neurosymbolic-manipulation.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["GitHub: https://github.com/gtziafas/hots"]}}
}

@article{rayyan-242084739,
  title={Learning Better Representations From Less Data For Propositional Satisfiability},
  year={2024},
  author={Ghanem, Mohamed and Schmitt, Frederik and Siber, Julian and Finkbeiner, Bernd},
  abstract={Training neural networks on NP-complete problems typically demands very large amounts of training data and often needs to be coupled with computationally expensive symbolic verifiers to ensure output correctness. In this paper, we present NeuRes, a neuro-symbolic approach to address both challenges for propositional satisfiability, being the quintessential NP-complete problem. By combining certificate-driven training and expert iteration, our model learns better representations than models trained for classification only, with a much higher data efficiency - requiring orders of magnitude less training data. NeuRes employs propositional resolution as a proof system to generate proofs of unsatisfiability and to accelerate the process of finding satisfying truth assignments, exploring both possibilities in parallel. To realize this, we propose an attention-based architecture that autoregressively selects pairs of clauses from a dynamic formula embedding to derive new clauses. Furthermore, we employ expert iteration whereby model-generated proofs progressively replace longer teacher proofs as the new ground truth. This enables our model to reduce a dataset of proofs generated by an advanced solver by 32% after training on it with no extra guidance. This shows that NeuRes is not limited by the optimality of the teacher algorithm owing to its self-improving workflow. We show that our model achieves far better performance than NeuroSAT in terms of both correctly classified and proven instances.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Included"} | USER-NOTES: {"Haowei"=>["GitHub: https://github.com/oschart/neures"]}}
}

@article{rayyan-242084748,
  title={Structural Ambiguity and its Disambiguation in Language Model Based Parsers: the Case of Dutch Clause Relativization},
  year={2023},
  author={Wijnholds, Gijs and Michael, Moortgat},
  abstract={This paper addresses structural ambiguity in Dutch relative clauses. By investigating the task of disambiguation by grounding, we study how the presence of a prior sentence can resolve relative clause ambiguities. We apply this method to two parsing architectures in an attempt to demystify the parsing and language model components of two present-day neural parsers. Results show that a neurosymbolic parser, based on proof nets, is more open to data bias correction than an approach based on universal dependencies, although both setups suffer from a comparable initial data bias.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper claims that the following links are the code links. Two of them don't seem to work (they may be private repositories) since this is still a preprint. We can follow up with authors. ", "Paper: [https://arxiv.org/pdf/2305.14917]", "GitHub: [https://github.com/gijswijnholds/syntactic_nl2i], GitHub: [https://github.com/gijswijnholds/dynamic-proof-nets-disambiguation], GitHub: [https://github.com/gijswijnholds/udparsing_bert]"]}}
}

@article{rayyan-242084753,
  title={MultiPredGO: Deep Multi-Modal Protein Function Prediction by Amalgamating Protein Structure, Sequence, and Interaction Information},
  year={2021},
  volume={25},
  number={5},
  author={Giri, S. J. and Dutta, P. and Halani, P. and Saha, S.},
  abstract={Protein is an essential macro-nutrient for perceiving a wide range of biochemical activities and biological regulations in living cells. In this work, we have presented a novel multi-modal approach, named MultiPredGO, for predicting protein functions by utilizing two different kinds of information, namely protein sequence and the protein secondary structure. Here, our contributions are threefold; firstly, along with the protein sequence, we learn the feature representation from the protein structure. Secondly, we develop two different deep learning models after considering the characteristics of the underlying data patterns of the protein sequence and protein 3D structures. Finally, along with these two modalities, we have also utilized protein interaction information for expediting the efficiency of the proposed model in predicting the protein functions. For extracting features from different modalities, we have utilized various variations of the convolutional neural network. As the protein function classes are dependent on each other, we have used a neuro-symbolic hierarchical classification model, which resembles the structure of Gene Ontology (GO), for effectively predicting the dependent protein functions. Finally, to validate the goodness of our proposed method (MultiPredGO), we have compared our results with various uni-modal along with two well-known multi-modal protein function prediction approaches, namely, INGA and DeepGO. Results show that the overall performance of the proposed approach in terms of accuracy, F-measure, precision, and recall metrics are better than those by the state-of-the-art methods. MultiPredGO attains an average 13.05% and 30.87% improvements over the best existing comparing approach (DeepGO) for cellular component and molecular functions, respectively.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/SwagarikaGiri/Multi-PredGO]"]}}
}

@article{rayyan-242084755,
  title={CCN plus : A neuro-symbolic framework for deep learning with requirements},
  year={2024},
  volume={171},
  author={Giunchiglia, Eleonora and Alex, Tatomir and Catalina, Stoian Mihaela and Thomas, Lukasiewicz},
  abstract={For their outstanding ability of finding hidden patterns in data, deep learning models have been extensively applied in many different domains. However, recent works have shown that, if a set of requirements expressing inherent knowledge about the problem at hand is given, then neural networks often fail to comply with them. This represents a major drawback for deep learning models, as requirements compliance is normally considered a necessary condition for standard software deployment. In this paper, we propose a novel neuro-symbolic framework able to make any neural network compliant by design to a given set of requirements over the output space expressed in full propositional logic. This framework, called CCN + , integrates the requirements into the output layer of the neural network by applying multiple inference rules that ensure compliance with the requirements and adapts the standard binary cross -entropy loss function to the requirement output layer. As a result, not only the outputted predictions are guaranteed to be compliant with the requirements, but the neural network itself learns how to exploit the domain knowledge expressed by the requirements to get better performance. We conduct an extensive experimental evaluation of CCN + on 19 real -world multi -label classification datasets with propositional logic requirements, including a challenging dataset for autonomous driving. Our experimental analysis confirms that CCN + is able to outperform both its neural counterparts and the state-of-the-art models.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/atatomir/CCN]"]}}
}

@article{rayyan-242084758,
  title={Neural Markov Logic Networks},
  year={2019},
  author={Marra, Giuseppe and Ondřej, Kuželka},
  abstract={We introduce neural Markov logic networks (NMLNs), a statistical relational learning system that borrows ideas from Markov logic. Like Markov logic networks (MLNs), NMLNs are an exponential-family model for modelling distributions over possible worlds, but unlike MLNs, they do not rely on explicitly specified first-order logic rules. Instead, NMLNs learn an implicit representation of such rules as a neural network that acts as a potential function on fragments of the relational structure. Similarly to many neural symbolic methods, NMLNs can exploit embeddings of constants but, unlike them, NMLNs work well also in their absence. This is extremely important for predicting in settings other than the transductive one. We showcase the potential of NMLNs on knowledge-base completion, triple classification and on generation of molecular (graph) data.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/GiuseppeMarra/nmln/tree/uai2021]"]}}
}

@article{rayyan-242084761,
  title={Chebifier: automating semantic classification in ChEBI to accelerate data-driven discovery},
  year={2024},
  volume={3},
  number={5},
  author={Glauer, M. and Neuhaus, F. and Flügel, S. and Wosny, M. and Mossakowski, T. and Memariani, A. and Schwerdt, J. and Hastings, J.},
  abstract={Connecting chemical structural representations with meaningful categories and semantic annotations representing existing knowledge enables data-driven digital discovery from chemistry data. Ontologies are semantic annotation resources that provide definitions and a classification hierarchy for a domain. They are widely used throughout the life sciences. ChEBI is a large-scale ontology for the domain of biologically interesting chemistry that connects representations of chemical structures with meaningful chemical and biological categories. Classifying novel molecular structures into ontologies such as ChEBI has been a longstanding objective for data scientific methods, but the approaches that have been developed to date are limited in several ways: they are not able to expand as the ontology expands without manual intervention, and they are not able to learn from continuously expanding data. We have developed an approach for automated classification of chemicals in the ChEBI ontology based on a neuro-symbolic AI technique that harnesses the ontology itself to create the learning system. We provide this system as a publicly available tool, Chebifier, and as an API, ChEB-AI. We here evaluate our approach and show how it constitutes an advance towards a continuously learning semantic system for chemical knowledge discovery.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/ChEB-AI/], Website: [https://chebifier.hastingslab.org/], Article: [https://pmc.ncbi.nlm.nih.gov/articles/PMC11094693/]"]}}
}

@article{rayyan-242084762,
  title={Ontology Pre-training for Poison Prediction},
  year={2023},
  volume={14236},
  author={Glauer, Martin and Fabian, Neuhaus and Till, Mossakowski and Janna, Hastings},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Integrating human knowledge into neural networks has the potential to improve their robustness and interpretability. We have developed a novel approach to integrate knowledge from ontologies into the structure of a Transformer network which we call ontology pre-training: we train the network to predict membership in ontology classes as a way to embed the structure of the ontology into the network, and subsequently fine-tune the network for the particular prediction task. We apply this approach to a case study in predicting the potential toxicity of a small molecule based on its molecular structure, a challenging task for machine learning in life sciences chemistry. Our approach improves on the state of the art, and moreover has several additional benefits. First, we are able to show that the model learns to focus attention on more meaningful chemical groups when making predictions with ontology pre-training than without, paving a path towards greater robustness and interpretability. Second, the training time is reduced after ontology pre-training, indicating that the model is better placed to learn what matters for toxicity prediction with the ontology pre-training than without. This strategy has general applicability as a neuro-symbolic approach to embed meaningful semantics into neural networks.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/ChEB-AI/python-chebai]", "Paper: [https://arxiv.org/pdf/2301.08577]"]}}
}

@article{rayyan-242084765,
  title={A neurosymbolic cognitive architecture framework for handling novelties in open worlds},
  year={2024},
  author={Goel, S. and Lymperopoulos, P. and Thielstrom, R. and Krause, E.},
  url={https://www.sciencedirect.com/science/article/pii/S000437022400047X?casa_token=-y9ZVPx7i18AAAAA:9TVpqnDvXYYt_yd2wSg4eU0eX9tPeUrbZ-7dIobb6C0Tz0KdI8T5K4H1jJQKEehL_EzVD_3U},
  abstract={“Open world” environments are those in which novel objects, agents, events, and more can appear and contradict previous understandings of the environment. This runs counter to the “…},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Parts of implementation are available. We can ask author for full implementation", "Box: [https://tufts.box.com/s/qeypcyn6xyq60vvm6l0adqu647ltttgw]"]}}
}

@article{rayyan-242084766,
  title={OpenCog NS: A Deeply-Interactive Hybrid Neural-Symbolic Cognitive Architecture Designed for Global/Local Memory Synergy},
  year={2009},
  author={Goertzel, B. and Duong, D.},
  url={https://cdn.aaai.org/ocs/871/871-4244-1-PB.pdf},
  abstract={… It seems plausible that this kind of neural-symbolic … neural-symbolic system interact. Neuroscience speculations aside, however, our key conjecture is that this sort of neural-symbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://cdn.aaai.org/ocs/871/871-4244-1-PB.pdf]", "Code not findable, but seems relevant and interesting. Author may share. "]}}
}

@article{rayyan-242084782,
  title={Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation},
  year={2024},
  author={Gong, Nanxu and Wangyang, Ying and Wang, Dongjie and Fu, Yanjie},
  abstract={Feature selection aims to identify the optimal feature subset for enhancing downstream models. Effective feature selection can remove redundant features, save computational resources, accelerate the model learning process, and improve the model overall performance. However, existing works are often time-intensive to identify the effective feature subset within high-dimensional feature spaces. Meanwhile, these methods mainly utilize a single downstream task performance as the selection criterion, leading to the selected subsets that are not only redundant but also lack generalizability. To bridge these gaps, we reformulate feature selection through a neuro-symbolic lens and introduce a novel generative framework aimed at identifying short and effective feature subsets. More specifically, we found that feature ID tokens of the selected subset can be formulated as symbols to reflect the intricate correlations among features. Thus, in this framework, we first create a data collector to automatically collect numerous feature selection samples consisting of feature ID tokens, model performance, and the measurement of feature subset redundancy. Building on the collected data, an encoder-decoder-evaluator learning paradigm is developed to preserve the intelligence of feature selection into a continuous embedding space for efficient search. Within the learned embedding space, we leverage a multi-gradient search algorithm to find more robust and generalized embeddings with the objective of improving model performance and reducing feature subset redundancy. These embeddings are then utilized to reconstruct the feature ID tokens for executing the final feature selection. Ultimately, comprehensive experiments and case studies are conducted to validate the effectiveness of the proposed framework.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/NanxuGong/feature-selection-via-autoregreesive-generation]", "Paper: [https://dl.acm.org/doi/10.1145/3709011]"]}}
}

@article{rayyan-242084789,
  title={Interpretable end-to-end Neurosymbolic Reinforcement Learning agents},
  year={2024},
  author={Grandien, N. and Delfosse, Q. and Kersting, K.},
  abstract={… By explicitly learning to extract object-centric representations from raw states, object-centric RL, and policy distillation via rule extraction, this work places itself within the neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/nlsgrndn/SCoBots/tree/dev], GitHub: [https://github.com/k4ntz/SCoBots/tree/space_detector], GitHub: [https://github.com/k4ntz/SCoBots]", "Paper: [https://arxiv.org/pdf/2410.14371]"]}}
}

@article{rayyan-242084797,
  title={Type-driven Neural Programming by Example},
  year={2020},
  author={Grouwstra, Kiara},
  abstract={In this thesis we look into programming by example (PBE), which is about finding a program mapping given inputs to given outputs. PBE has traditionally seen a split between formal versus neural approaches, where formal approaches typically involve deductive techniques such as SAT solvers and types, while the neural approaches involve training on sample input-outputs with their corresponding program, typically using sequence-based machine learning techniques such as LSTMs [41]. As a result of this split, programming types had yet to be used in neural program synthesis techniques. We propose a way to incorporate programming types into a neural program synthesis approach for PBE. We introduce the Typed Neuro-Symbolic Program Synthesis (TNSPS) method based on this idea, and test it in the functional programming context to empirically verify type information may help improve generalization in neural synthesizers on limited-size datasets. Our TNSPS model builds upon the existing Neuro-Symbolic Program Synthesis (NSPS), a tree-based neural synthesizer combining info from input-output examples plus the current program, by further exposing information on types of those input-output examples, of the grammar production rules, as well as of the hole that we wish to expand in the program. We further explain how we generated a dataset within our domain, which uses a limited subset of Haskell as the synthesis language. Finally we discuss several topics of interest that may help take these ideas further. For reproducibility, we release our code publicly.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["This is a master's thesis. There are useful links within", "Link: [https://arxiv.org/pdf/2008.12613]", "Code: [https://gitlab.com/KiaraGrouwstra/hasktorch/-/tree/synthesis/synthesis]"]}}
}

@article{rayyan-242084798,
  title={On the use of neurosymbolic AI for defending against cyber attacks},
  year={2024},
  author={Grov, G. and Halvorsen, J. and Eckhoff, M. W. and Hansen, B. J.},
  abstract={… In this paper, we make the case for combining them using neurosymbolic AI. We … of neurosymbolic use cases we believe are both interesting research directions for the neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Mostly an overview article. Has two PoC experiments at end. ", "GitHub: [https://github.com/FFI-no/Paper-NeSy24]", "Paper: [https://arxiv.org/pdf/2408.04996]"]}}
}

@article{rayyan-242084800,
  title={Perform Like an Engine: A Closed-Loop Neural-Symbolic Learning Framework for Knowledge Graph Inference},
  year={2021},
  author={Niu, Guanglin and Li, Bo and Zhang, Yongfei and Shiliang, Pu},
  abstract={Knowledge graph (KG) inference aims to address the natural incompleteness of KGs, including rule learning-based and KG embedding (KGE) models. However, the rule learning-based models suffer from low efficiency and generalization while KGE models lack interpretability. To address these challenges, we propose a novel and effective closed-loop neural-symbolic learning framework EngineKG via incorporating our developed KGE and rule learning modules. KGE module exploits symbolic rules and paths to enhance the semantic association between entities and relations for improving KG embeddings and interpretability. A novel rule pruning mechanism is proposed in the rule learning module by leveraging paths as initial candidate rules and employing KG embeddings together with concepts for extracting more high-quality rules. Experimental results on four real-world datasets show that our model outperforms the relevant baselines on link prediction tasks, demonstrating the superiority of our KG inference model in a neural-symbolic learning fashion.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2112.01040], GitHub: [https://github.com/ngl567/EngineKG]"]}}
}

@article{rayyan-242084808,
  title={GOALNET: Interleaving Neural Goal Predicate Inference with Classical Planning for Generalization in Robot Instruction Following},
  year={2024},
  author={Gupta, Jigyasa and Shreya, Sharma and Shreshth, Tuli and Rohan, Paul and Mausam},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={Our goal is to enable a robot to learn how to sequence its actions to perform high-level tasks specified as natural language instructions, given successful demonstrations from a human partner. Our novel neuro-symbolic solution GOALNET builds an iterative two-step approach that interleaves (i) inferring next subgoal predicate implied by the language instruction, for a given world state, and (ii) synthesizing a feasible subgoal-reaching plan from that state. The agent executes the plan, and the two steps are repeated. GOALNET combines (i) learning, where dense representations are acquired for language instruction and the world state via a neural network prediction model, enabling generalization to novel settings and (ii) planning, where the cause-effect modeling by a classical planner eschews irrelevant predicates, facilitating multi-stage decision making in large domains. GOALNET obtains 78% improvement in the goal reaching rate in comparison to several state-of-the-art approaches on benchmark data with multi-stage instructions. Further, GOALNET can generalize to novel instructions for scenes with unseen objects. Source code available at https://github.com/reail-iitd/goalnet.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/reail-iitd/goalnet]"]}}
}

@article{rayyan-242084809,
  title={Visual Programming: Compositional visual reasoning without training},
  year={2022},
  author={Gupta, Tanmay and Kembhavi, Aniruddha},
  abstract={We present VISPROG, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions. VISPROG avoids the need for any task-specific training. Instead, it uses the in-context learning ability of large language models to generate python-like modular programs, which are then executed to get both the solution and a comprehensive and interpretable rationale. Each line of the generated program may invoke one of several off-the-shelf computer vision models, image processing routines, or python functions to produce intermediate outputs that may be consumed by subsequent parts of the program. We demonstrate the flexibility of VISPROG on 4 diverse tasks - compositional visual question answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image editing. We believe neuro-symbolic approaches like VISPROG are an exciting avenue to easily and effectively expand the scope of AI systems to serve the long tail of complex tasks that people may wish to perform.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Website: [https://prior.allenai.org/projects/visprog]", "GitHub: [https://github.com/allenai/visprog]"]}}
}

@article{rayyan-242084823,
  title={EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with Neural Knowledge Base of Entity States},
  year={2025},
  author={Xu, Hainiu and Qi, Siya and Li, Jiazheng and Zhou, Yuxiang and Du, Jinhua and Catmur, Caroline and Yulan, He},
  abstract={Theory-of-Mind (ToM), the ability to infer others' perceptions and mental states, is fundamental to human interaction but remains a challenging task for Large Language Models (LLMs). While existing ToM reasoning methods show promise with reasoning via perceptual perspective-taking, they often rely excessively on LLMs, reducing their efficiency and limiting their applicability to high-order ToM reasoning, which requires multi-hop reasoning about characters' beliefs. To address these issues, we present EnigmaToM, a novel neuro-symbolic framework that enhances ToM reasoning by integrating a Neural Knowledge Base of entity states (Enigma) for (1) a psychology-inspired iterative masking mechanism that facilitates accurate perspective-taking and (2) knowledge injection that elicits key entity information. Enigma generates structured representations of entity states, which construct spatial scene graphs - leveraging spatial information as an inductive bias - for belief tracking of various ToM orders and enhancing events with fine-grained entity state details. Experimental results on multiple benchmarks, including ToMi, HiToM, and FANToM, show that EnigmaToM significantly improves ToM reasoning across LLMs of varying sizes, particularly excelling in high-order reasoning scenarios.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/seacowx/EnigmaToM], Paper: [https://arxiv.org/pdf/2503.03340]"]}}
}

@article{rayyan-242084825,
  title={ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins},
  year={2025},
  author={Hakim, S. B. and Adil, M. and Velasquez, A. and Song, H. H.},
  abstract={In this paper, we propose an Adaptive Neuro-Symbolic Learning Framework for digital twin technology called ``ANSR-DT." Our approach combines pattern recognition algorithms with …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/sbhakim/ansr-dt]", "Paper: [https://arxiv.org/pdf/2501.08561]"]}}
}

@article{rayyan-242084827,
  title={Learning Neurosymbolic Generative Models via Program Synthesis},
  year={2019},
  author={Young, Halley and Bastani, Osbert and Mayur, Naik},
  abstract={Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can't easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model-e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/HalleyYoung/NeurosymGenModelsProgSyn]"]}}
}

@article{rayyan-242084829,
  title={Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review},
  year={2022},
  author={Hamilton, Kyle and Nayak, Aparna and Božić, Bojan and Longo, Luca},
  abstract={Advocates for Neuro-Symbolic Artificial Intelligence (NeSy) assert that combining deep learning with symbolic reasoning will lead to stronger AI than either paradigm on its own. As successful as deep learning has been, it is generally accepted that even our best deep learning systems are not very good at abstract reasoning. And since reasoning is inextricably linked to language, it makes intuitive sense that Natural Language Processing (NLP), would be a particularly well-suited candidate for NeSy. We conduct a structured review of studies implementing NeSy for NLP, with the aim of answering the question of whether NeSy is indeed meeting its promises: reasoning, out-of-distribution generalization, interpretability, learning and reasoning from small data, and transferability to new domains. We examine the impact of knowledge representation, such as rules and semantic networks, language structure and relational structure, and whether implicit or explicit reasoning contributes to higher promise scores. We find that systems where logic is compiled into the neural network lead to the most NeSy goals being satisfied, while other factors such as knowledge representation, or type of neural architecture do not exhibit a clear correlation with goals being met. We find many discrepancies in how reasoning is defined, specifically in relation to human level reasoning, which impact decisions about model architectures and drive conclusions which are not always consistent across studies. Hence we advocate for a more methodical approach to the application of theories of human reasoning as well as the development of appropriate benchmarks, which we hope can lead to a better understanding of progress in the field. We make our data and code available on github for further analysis.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/kyleiwaniec/neuro-symbolic-ai-systematic-review]"]}}
}

@article{rayyan-242084830,
  title={Adaptive neuro-symbolic network agent},
  year={2019},
  author={Hammer, P.},
  abstract={This paper describes Adaptive Neuro-Symbolic Network Agent, a new design of a sensorimotor agent that adapts to its environment by building concepts based on Sparse Distributed …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/patham9/ANSNA?tab=readme-ov-file]", "Paper: [https://cis.temple.edu/tagit/publications/ANSNA.pdf]"]}}
}

@article{rayyan-242084833,
  title={COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System},
  year={2023},
  author={Han, Jipeng},
  abstract={This paper explores the integration of neural networks with logic programming, addressing the longstanding challenges of combining the generalization and learning capabilities of neural networks with the precision of symbolic logic. Traditional attempts at this integration have been hampered by difficulties in initial data acquisition, the reliability of undertrained networks, and the complexity of reusing and augmenting trained models. To overcome these issues, we introduce the COOL (Constraint Object-Oriented Logic) programming language, an innovative approach that seamlessly combines logical reasoning with neural network technologies. COOL is engineered to autonomously handle data collection, mitigating the need for user-supplied initial data. It incorporates user prompts into the coding process to reduce the risks of undertraining and enhances the interaction among models throughout their lifecycle to promote the reuse and augmentation of networks. Furthermore, the foundational principles and algorithms in COOL's design and its compilation system could provide valuable insights for future developments in programming languages and neural network architectures.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2311.03753], GitHub: [https://github.com/coolang2022/COOLang?search=1]"]}}
}

@article{rayyan-242084834,
  title={An empirical evaluation of neural and neuro-symbolic approaches to real-time multimodal complex event detection},
  year={2024},
  author={Han, L. and Srivastava, M. B.},
  abstract={… of various neural and neurosymbolic architectures. Specifically, … a neuro-symbolic architecture on our synthesized 5-min CE dataset. Our empirical analysis indicates the neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2402.11403], GitHub: [https://github.com/nesl/CED_Methods_Eval]"]}}
}

@article{rayyan-242084841,
  title={LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking},
  year={2021},
  author={Jiang, Hang and Gurajada, Sairam and Lu, Qiuhao and Neelam, Sumit and Popa, Lucian and Sen, Prithviraj and Li, Yunyao and Alexander, Gray},
  abstract={Entity linking (EL), the task of disambiguating mentions in text by linking them to entities in a knowledge graph, is crucial for text understanding, question answering or conversational systems. Entity linking on short text (e.g., single sentence or question) poses particular challenges due to limited context. While prior approaches use either heuristics or black-box neural methods, here we propose LNN-EL, a neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to using rules, LNN-EL performs competitively against SotA black-box neural approaches, with the added benefits of extensibility and transferability. In particular, we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even scores resulting from previous EL methods, thus improving on such methods. For instance, on the LC-QuAD-1.0 dataset, we show more than 4% increase in F1 score over previous SotA. Finally, we show that the inductive bias offered by using logic results in learned rules that transfer well across datasets, even without fine tuning, while maintaining high accuracy.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: [https://github.com/IBM/LNN], Website: [https://ibm.github.io/LNN/], Paper: [https://arxiv.org/pdf/2106.09795]"]}}
}

@article{rayyan-242084842,
  title={Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors},
  year={2023},
  author={Yin, Hang and Wang, Zihao and Yangqiu, Song},
  abstract={Reasoning on knowledge graphs is a challenging task because it utilizes observed information to predict the missing one. Particularly, answering complex queries based on first-order logic is one of the crucial tasks to verify learning to reason abilities for generalization and composition. Recently, the prevailing method is query embedding which learns the embedding of a set of entities and treats logic operations as set operations and has shown great empirical success. Though there has been much research following the same formulation, many of its claims lack a formal and systematic inspection. In this paper, we rethink this formulation and justify many of the previous claims by characterizing the scope of queries investigated previously and precisely identifying the gap between its formulation and its goal, as well as providing complexity analysis for the currently investigated queries. Moreover, we develop a new dataset containing ten new types of queries with features that have never been considered and therefore can provide a thorough investigation of complex queries. Finally, we propose a new neural-symbolic method, Fuzzy Inference with Truth value (FIT), where we equip the neural link predictors with fuzzy logic theory to support end-to-end learning using complex queries with provable reasoning capability. Empirical results show that our method outperforms previous methods significantly in the new dataset and also surpasses previous methods in the existing dataset at the same time.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["PDF: [https://arxiv.org/pdf/2304.07063], GitHub: [https://github.com/HKUST-KnowComp/FIT]"]}}
}

@article{rayyan-242084851,
  title={CoNSoLe: Convex Neural Symbolic Learning},
  year={2022},
  author={Li, Haoran and Weng, Yang and Hanghang, Tong},
  abstract={Learning the underlying equation from data is a fundamental problem in many disciplines. Recent advances rely on Neural Networks (NNs) but do not provide theoretical guarantees in obtaining the exact equations owing to the non-convexity of NNs. In this paper, we propose Convex Neural Symbolic Learning (CoNSoLe) to seek convexity under mild conditions. The main idea is to decompose the recovering process into two steps and convexify each step. In the first step of searching for right symbols, we convexify the deep Q-learning. The key is to maintain double convexity for both the negative Q-function and the negative reward function in each iteration, leading to provable convexity of the negative optimal Q function to learn the true symbol connections. Conditioned on the exact searching result, we construct a Locally Convex equation Learner (LoCaL) neural network to convexify the estimation of symbol coefficients. With such a design, we quantify a large region with strict convexity in the loss surface of LoCaL for commonly used physical functions. Finally, we demonstrate the superior performance of the CoNSoLe framework over the state-of-the-art on a diverse set of datasets.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2206.00257]", "Included in supplement: \"Did you include the code, data, and instructions needed to reproduce the main experi- mental results (either in the supplemental material or as a URL)? [No] We will release the code if the paper is accepted.\" ", "So we can email authors for code. "]}}
}

@article{rayyan-242084853,
  title={Reduced Implication-bias Logic Loss for Neuro-Symbolic Learning},
  year={2022},
  author={He, Haoyuan and Dai, Wangzhou and Ming, Li},
  abstract={Integrating logical reasoning and machine learning by approximating logical inference with differentiable operators is a widely used technique in Neuro-Symbolic systems. However, some differentiable operators could bring a significant bias during backpropagation and degrade the performance of Neuro-Symbolic learning. In this paper, we reveal that this bias, named 𝐼mplication Bias is common in loss functions derived from fuzzy logic operators. Furthermore, we propose a simple yet effective method to transform the biased loss functions into 𝑅educed Implication-bias Logic Loss (RILL) to address the above problem. Empirical study shows that RILL can achieve significant improvements compared with the biased logic loss functions, especially when the knowledge base is incomplete, and keeps more robust than the compared methods when labelled data is insufficient.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code availability. Available at https://git.nju.edu.cn/Alkane/clion.git.", "Git: [ https://git.nju.edu.cn/Alkane/clion.git]"]}}
}

@article{rayyan-242084862,
  title={ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition},
  year={2024},
  author={Riaz, Haris and Dumitru, Razvan-Gabriel and Mihai, Surdeanu},
  abstract={In this work, we revisit the problem of semi-supervised named entity recognition (NER) focusing on extremely light supervision, consisting of a lexicon containing only 10 examples per class. We introduce ELLEN, a simple, fully modular, neuro-symbolic method that blends fine-tuned language models with linguistic rules. These rules include insights such as ''One Sense Per Discourse'', using a Masked Language Model as an unsupervised NER, leveraging part-of-speech tags to identify and eliminate unlabeled entities as false negatives, and other intuitions about classifier confidence scores in local and global context. ELLEN achieves very strong performance on the CoNLL-2003 dataset when using the minimal supervision from the lexicon above. It also outperforms most existing (and considerably more complex) semi-supervised NER methods under the same supervision settings commonly used in the literature (i.e., 5% of the training data). Further, we evaluate our CoNLL-2003 model in a zero-shot scenario on WNUT-17 where we find that it outperforms GPT-3.5 and achieves comparable performance to GPT-4. In a zero-shot setting, ELLEN also achieves over 75% of the performance of a strong, fully supervised model trained on gold data. Our code is available at: https://github.com/hriaz17/ELLEN.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/hriaz17/ELLEN]", "Paper: [https://arxiv.org/pdf/2403.17385]"]}}
}

@article{rayyan-242084864,
  title={A Neuro-Symbolic Framework for Tree Crown Delineation and Tree Species Classification},
  year={2024},
  author={Harmon, I. and Weinstein, B. and Bohlman, S. and White, E. and Wang, D. Z.},
  url={https://www.mdpi.com/2072-4292/16/23/4365},
  abstract={… the neuro-symbolic framework, … neuro-symbolic framework paired with hyperparameter tuning algorithms as one solution to alleviating some of the difficulties in creating neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/ihmn02/forest_ecology_neuro_symbolic_framework?tab=readme-ov-file]"]}}
}

@article{rayyan-242084882,
  title={Deep explainable relational reinforcement learning: a neuro-symbolic approach},
  year={2023},
  author={Hazra, R. and Raedt, L. De},
  abstract={Despite its successes, Deep Reinforcement Learning (DRL) yields non-interpretable policies. Moreover, since DRL does not exploit symbolic relational representations, it has difficulties …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2304.08349]", "Section 12 says: \"the codes will be made available soon\" - so we need to reach out to author"]}}
}

@article{rayyan-242084883,
  title={EgoTV : Egocentric Task Verification from Natural Language Task Descriptions},
  year={2023},
  author={Hazra, Rishi and Brian, Chen and Akshara, Rai and Nitin, Kamra and Ruta, Desai},
  publisher={IEEE COMPUTER SOC},
  abstract={To enable progress towards egocentric agents capable of understanding everyday tasks specified in natural language, we propose a benchmark and a synthetic dataset called Egocentric Task Verification (EgoTV). The goal in EgoTV is to verify the execution of tasks from egocentric videos based on the natural language description of these tasks. EgoTV contains pairs of videos and their task descriptions for multi-step tasks - these tasks contain multiple sub-task decompositions, state changes, object interactions, and subtask ordering constraints. In addition, EgoTV also provides abstracted task descriptions that contain only partial details about ways to accomplish a task. Consequently, EgoTV requires causal, temporal, and compositional reasoning of video and language modalities, which is missing in existing datasets. We also find that existing vision- language models struggle at such all round reasoning needed for task verification in EgoTV. Inspired by the needs of EgoTV, we propose a novel Neuro-Symbolic Grounding (NSG) approach that leverages symbolic representations to capture the compositional and temporal structure of tasks. We demonstrate NSG's capability towards task tracking and verification on our EgoTV dataset and a real-world dataset derived from CrossTask [ 82] (CTV). We open-source the EgoTV and CTV datasets and the NSG model for future research on egocentric assistive agents.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Website: [https://rishihazra.github.io/EgoTV/], Paper: [https://arxiv.org/pdf/2303.16975], GitHub: [https://github.com/facebookresearch/EgoTV]"]}}
}

@article{rayyan-242084886,
  title={NeuroSymAD: A Neuro-Symbolic Framework for Interpretable Alzheimer's Disease Diagnosis},
  year={2025},
  author={He, Y. and Wang, Z. and Zhang, Y. and Dan, T. and Chen, T. and Wu, G.},
  abstract={… To bridge this gap, we propose NeuroSymAD, a neuro-symbolic framework that synergizes neural networks with symbolic reasoning. A neural network percepts brain MRI scans, while …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://www.arxiv.org/pdf/2503.00510]", "UMD students, so we can ask them directly", "Recently published, so code likely not available because of that. "]}}
}

@article{rayyan-242084889,
  title={BlueSky: How to Raise a Robot-A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots},
  year={2024},
  author={Hemken, N. and Jacob, F. and Tërnava, F. and Kartmann, R.},
  abstract={… We discuss the inherent trade-offs of symbolic and neural standard methods, which mark the endpoints of a neuro-symbolic spectrum. We propose neuro-symbolic hybrid methods as …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["They discuss a hybrid approach, but unclear if their paper focuses on actually exploring this. ", "Code: [https://github.com/kit-dsn/how-to-raise-a-robot-beyond-ac]"]}}
}

@article{rayyan-242084891,
  title={Enhancing SQL Query Generation with Neurosymbolic Reasoning},
  year={2024},
  author={Princis, Henrijs and David, Cristina and Alan, Mycroft},
  abstract={Neurosymbolic approaches blend the effectiveness of symbolic reasoning with the flexibility of neural networks. In this work, we propose a neurosymbolic architecture for generating SQL queries that builds and explores a solution tree using Best-First Search, with the possibility of backtracking. For this purpose, it integrates a Language Model (LM) with symbolic modules that help catch and correct errors made by the LM on SQL queries, as well as guiding the exploration of the solution tree. We focus on improving the performance of smaller open-source LMs, and we find that our tool, Xander, increases accuracy by an average of 10.9% and reduces runtime by an average of 28% compared to the},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/henrijsprincis/Xander]"]}}
}

@article{rayyan-242084898,
  title={Towards Learning to Reason: Comparing LLMs with Neuro-Symbolic on Arithmetic Relations in Abstract Reasoning},
  year={2024},
  author={Hersche, M. and Camposampiero, G. and Wattenhofer, R.},
  abstract={This work compares large language models (LLMs) and neuro-symbolic approaches in solving Raven's progressive matrices (RPM), a visual abstract reasoning test that involves the …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/IBM/raven-large-language-models], GitHub: [https://github.com/IBM/abductive-rule-learner-with-context-awareness], Paper: [https://arxiv.org/pdf/2412.05586]"]}}
}

@article{rayyan-242084899,
  title={A neuro-vector-symbolic architecture for solving Raven's progressive matrices},
  year={2023},
  volume={5},
  number={4},
  author={Hersche, Michael and Mustafa, Zeqiri and Luca, Benini and Abu, Sebastian and Abbas, Rahimi},
  abstract={Neither deep neural networks nor symbolic artificial intelligence (AI) alone has approached the kind of intelligence expressed in humans. This is mainly because neural networks are not able to decompose joint representations to obtain distinct objects (the so-called binding problem), while symbolic AI suffers from exhaustive rule searches, among other problems. These two problems are still pronounced in neuro-symbolic AI, which aims to combine the best of the two paradigms. Here we show that the two problems can be addressed with our proposed neuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators on high-dimensional distributed representations that serve as a common language between neural networks and symbolic AI. The efficacy of NVSA is demonstrated by solving Raven's progressive matrices datasets. Compared with state-of-the-art deep neural network and neuro-symbolic approaches, end-to-end training of NVSA achieves a new record of 87.7% average accuracy in RAVEN, and 88.1% in I-RAVEN datasets. Moreover, compared with the symbolic reasoning within the neuro-symbolic approaches, the probabilistic reasoning of NVSA with less expensive operations on the distributed representations is two orders of magnitude faster. Neuro-symbolic artificial intelligence approaches display both perception and reasoning capabilities, but inherit the limitations of their individual deep learning and symbolic artificial intelligence components. By combining neural networks and vector-symbolic architectures, Hersche and colleagues propose a neuro-vector-symbolic framework that can solve Raven's progressive matrices tests faster and more accurately than other state-of-the-art methods.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/IBM/raven-large-language-models", "https://github.com/IBM/neuro-vector-symbolic-architectures"]}}
}

@article{rayyan-242084901,
  title={Learning to learn generative programs with Memoised Wake-Sleep},
  year={2020},
  volume={124},
  author={Hewitt, Luke B. and Anh, Le Tuan and Tenenbaum Joshua, B.},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={We study a class of neuro-symbolic generative models in which neural networks are used both for inference and as priors over symbolic, data-generating programs. As generative models, these programs capture compositional structures in a naturally explainable form. To tackle the challenge of performing program induction as an `inner-loop' to learning, we propose the Memoised Wake-Sleep (MWS) algorithm, which extends Wake Sleep by explicitly storing and reusing the best programs discovered by the inference network throughout training. We use MWS to learn accurate, explainable models in three challenging domains: strokebased character modelling, cellular automata, and few-shot learning in a novel dataset of real-world string concepts.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/tuananhle7/mws]"]}}
}

@article{rayyan-242084902,
  title={Neuro-Symbolic Forward Reasoning},
  year={2021},
  author={Shindo, Hikaru and Dhami, Devendra Singh and Kristian, Kersting},
  abstract={Reasoning is an essential part of human intelligence and thus has been a long-standing goal in artificial intelligence research. With the recent success of deep learning, incorporating reasoning with deep learning systems, i.e., neuro-symbolic AI has become a major field of interest. We propose the Neuro-Symbolic Forward Reasoner (NSFR), a new approach for reasoning tasks taking advantage of differentiable forward-chaining using first-order logic. The key idea is to combine differentiable forward-chaining reasoning with object-centric (deep) learning. Differentiable forward-chaining reasoning computes logical entailments smoothly, i.e., it deduces new facts from given facts and rules in a differentiable manner. The object-centric learning approach factorizes raw inputs into representations in terms of objects. Thus, it allows us to provide a consistent framework to perform the forward-chaining inference from raw inputs. NSFR factorizes the raw inputs into the object-centric representations, converts them into probabilistic ground atoms, and finally performs differentiable forward-chaining inference using weighted rules for inference. Our comprehensive experimental evaluations on object-centric reasoning data sets, 2D Kandinsky patterns and 3D CLEVR-Hans, and a variety of tasks show the effectiveness and advantage of our approach.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ml-research/nsfr."], "Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2110.09383], GitHub: [https://github.com/ml-research/nsfr]"]}}
}

@article{rayyan-242084903,
  title={BlendRL: A Framework for Merging Symbolic and Neural Policy Learning},
  year={2024},
  author={Shindo, Hikaru and Delfosse, Quentin and Dhami, Devendra Singh and Kristian, Kersting},
  abstract={Humans can leverage both symbolic reasoning and intuitive reactions. In contrast, reinforcement learning policies are typically encoded in either opaque systems like neural networks or symbolic systems that rely on predefined symbols and rules. This disjointed approach severely limits the agents' capabilities, as they often lack either the flexible low-level reaction characteristic of neural agents or the interpretable reasoning of symbolic agents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL framework that harmoniously integrates both paradigms within RL agents that use mixtures of both logic and neural policies. We empirically demonstrate that BlendRL agents outperform both neural and symbolic baselines in standard Atari environments, and showcase their robustness to environmental changes. Additionally, we analyze the interaction between neural and symbolic policies, illustrating how their hybrid use helps agents overcome each other's limitations.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ml-research/blendrl"], "Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2410.11689]", "GitHub: [https://github.com/ml-research/blendrl]"]}}
}

@article{rayyan-242084904,
  title={Learning Differentiable Logic Programs for Abstract Visual Reasoning},
  year={2023},
  author={Shindo, Hikaru and Pfanschilling, Viktor and Dhami, Devendra Singh and Kristian, Kersting},
  abstract={Visual reasoning is essential for building intelligent agents that understand the world and perform problem-solving beyond perception. Differentiable forward reasoning has been developed to integrate reasoning with gradient-based machine learning paradigms. However, due to the memory intensity, most existing approaches do not bring the best of the expressivity of first-order logic, excluding a crucial ability to solve abstract visual reasoning, where agents need to perform reasoning by using analogies on abstract concepts in different scenarios. To overcome this problem, we propose NEUro-symbolic Message-pAssiNg reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner, passing messages in a memory-efficient manner and handling structured programs with functors. Moreover, we propose a computationally-efficient structure learning algorithm to perform explanatory program induction on complex visual scenes. To evaluate, in addition to conventional visual reasoning tasks, we propose a new task, visual reasoning behind-the-scenes, where agents need to learn abstract programs and then answer queries by imagining scenes that are not observed. We empirically demonstrate that NEUMANN solves visual reasoning tasks efficiently, outperforming neural, symbolic, and neuro-symbolic baselines.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ml-research/neumann"], "Bhuvanesh"=>["Website: [https://sites.google.com/view/neumann-tuda], Code: [https://github.com/ml-research/neumann/]"]}}
}

@article{rayyan-242084906,
  title={Towards a fully declarative neuro-symbolic language},
  year={2024},
  author={Hinnerichs, T. and Manhaeve, R. and Marra, G.},
  abstract={… This work tackles an open problem within neuro-symbolic systems: How can we make them fully declarative? Focusing on the DeepProblog family of neurosymbolic systems, we outline …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Bhuvanesh"=>["Code: [https://github.com/THinnerichs/Declarative-DeepProblog]"]}}
}

@article{rayyan-242084907,
  title={Optimal quadratic binding for relational reasoning in vector symbolic neural architectures},
  year={2023},
  author={Hiratani, N. and Sompolinsky, H.},
  url={https://direct.mit.edu/neco/article-abstract/35/2/105/114138},
  abstract={Binding operation is fundamental to many cognitive processes, such as cognitive map formation, relational reasoning, and language comprehension. In these processes, two different …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/nhiratani/quadratic_binding"], "Bhuvanesh"=>["GitHub: [https://github.com/nhiratani/quadratic_binding]", "Paper: [https://arxiv.org/pdf/2204.07186]"]}}
}

@article{rayyan-242084922,
  title={SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning},
  year={2024},
  author={Ho Fung, Tsoi and Loncar, Vladimir and Dasu, Sridhara and Harris, Philip},
  abstract={Contrary to genetic programming, the neural network approach to symbolic regression can efficiently handle high-dimensional inputs and leverage gradient methods for faster equation searching. Common ways of constraining expression complexity often involve multistage pruning with fine-tuning, which can result in significant performance loss. In this work, we propose \(\tt{SymbolNet}\), a neural network approach to symbolic regression in a novel framework that allows dynamic pruning of model weights, input features, and mathematical operators in a single training process, where both training loss and expression complexity are optimized simultaneously. We introduce a sparsity regularization term for each pruning type, which can adaptively adjust its strength, leading to convergence at a target sparsity ratio. Unlike most existing symbolic regression methods that struggle with datasets containing more than \(\mathcal{O}(10)\) inputs, we demonstrate the effectiveness of our model on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN (3072 inputs). Our approach enables symbolic regression to achieve fast inference with nanosecond-scale latency on FPGAs for high-dimensional datasets in environments with stringent computational resource constraints, such as the high-energy physics experiments at the LHC.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/hftsoi/SymbolNet"], "Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2401.09949]", "GitHub: [https://github.com/hftsoi/SymbolNet]"]}}
}

@article{rayyan-242084931,
  title={An insect-inspired randomly, weighted neural network with random fourier features for neuro-symbolic relational learning},
  year={2021},
  author={Hong, J. and Pavlic, T. P.},
  abstract={Insects, such as fruit flies and honey bees, can solve simple associative learning tasks and learn abstract concepts such as "sameness" and "difference", which is viewed as a higher-…},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jyhong0304/SII"], "Bhuvanesh"=>["GitHub: https://github.com/jyhong0304/SII, Paper: https://arxiv.org/pdf/2109.06663"]}}
}

@article{rayyan-242084941,
  title={NeSyDPP4-QSAR: A Neuro-Symbolic AI Approach for Potent DPP-4-Inhibitor Discovery in Diabetes Treatment},
  year={2025},
  author={Hossain, D. and Saghapour, E. and Chen, J. Y.},
  abstract={Diabetes Mellitus (DM) is a global epidemic and among the top ten leading causes of mortality (WHO, 2019), projected to rank seventh by 2030. The US National Diabetes Statistics Report (2021) states that 38.4 million Americans have diabetes. Dipeptidyl Peptidase-4 (DPP-4) is an FDA-approved target for type 2 diabetes mellitus (T2DM) treatment. However, current DPP-4 inhibitors are associated with adverse effects, including gastrointestinal issues, severe joint pain (FDA safety warning), nasopharyngitis, hypersensitivity, and nausea. Identifying novel inhibitors is crucial. Direct in vivo DPP-4 inhibition assessment is costly and impractical, making in silico IC50 prediction a viable alternative. Quantitative Structure-Activity Relationship (QSAR) modeling is a widely used computational approach for chemical substance assessment. We employ LTN, a neuro-symbolic approach, alongside DNN and transformers as baselines. DPP-4-related data is sourced from PubChem, ChEMBL, BindingDB, and GTP, comprising 6,563 bioactivity records (SMILES-based compounds with IC50 values) after deduplication and thresholding. A diverse set of features including descriptors (CDK Extended-PaDEL), fingerprints (Morgan), chemical language model embeddings (ChemBERTa2), LLaMa 3.2, and physicochemical properties is used to train the NeSyDPP4-QSAR model. The NeSyDPP4-QSAR model yielded the highest accuracy, incorporating CDKextended and Morgan fingerprints, with an accuracy of 0.9725, an F1-score of 0.9723, an ROC AUC of 0.9719, and an MCC of 0.9446. The performance was benchmarked against two standard baseline models: a deep neural network and a transformer. To ensure fair comparisons, DNN models used the equivalent attributes with the same dimension and network configuration as NeSyDPP4-QSAR. Our findings showed that integrating the Neuro-symbolic strategy (neural network-based learning and symbolic reasoning) holds immense potential for discovering drugs that can inhibit diabetes mellitus and classifying biological activities that inhibit it.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/hossain013/NeSyDPP4-QSAR"]}}
}

@article{rayyan-242084944,
  title={Neurocomparatives: Neuro-symbolic distillation of comparative knowledge},
  year={2023},
  author={Howard, P. and Wang, J. and Lal, V. and Singer, G. and Choi, Y.},
  abstract={Comparative knowledge (eg, steel is stronger and heavier than styrofoam) is an essential component of our world knowledge, yet understudied in prior literature. In this paper, we …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/NeuroComparatives, https://huggingface.co/datasets/Intel/NeuroComparatives"]}}
}

@article{rayyan-242084946,
  title={Ns3d: Neuro-symbolic grounding of 3d objects and relations},
  year={2023},
  author={Hsu, J. and Mao, J. and Wu, J.},
  url={http://openaccess.thecvf.com/content/CVPR2023/html/Hsu_NS3D_Neuro-Symbolic_Grounding_of_3D_Objects_and_Relations_CVPR_2023_paper.html},
  abstract={… To this end, we propose NS3D as a powerful neurosymbolic … the free language form to a neuro-symbolic program form. We … Importantly, NS3D extends prior neuro-symbolic approaches …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/joyhsu0504/NS3D"]}}
}

@article{rayyan-242084952,
  title={A multi-grained self-interpretable symbolic-neural model for single/multi-labeled text classification},
  year={2023},
  author={Hu, X. and Kong, X. and Tu, K.},
  abstract={… We propose a Symbolic-Neural model that can learn to explicitly predict class labels of text spans from a constituency tree without requiring any access to span-level gold labels. As the …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ant-research/StructuredLM_RTDT"]}}
}

@article{rayyan-242084959,
  title={Less is more: Data-efficient complex question answering over knowledge bases},
  year={2020},
  volume={65},
  author={Hua, Yuncheng and Yuan-Fang, Li and Guilin, Qi and Wei, Wu and Jingyao, Zhang and Daiqing, Qi},
  abstract={Question answering is an effective method for obtaining information from knowledge bases (KB). In this paper, we propose the Neural-Symbolic Complex Question Answering (NS-CQA) model, a data efficient reinforcement learning framework for complex question answering by using only a modest number of training samples. Our framework consists of a neural generator and a symbolic executor that, respectively, transforms a natural-language question into a sequence of primitive actions, and executes them over the knowledge base to compute the answer. We carefully formulate a set of primitive symbolic actions that allows us to not only simplify our neural network design but also accelerate model convergence. To reduce search space, we employ the copy and masking mechanisms in our encoder-decoder architecture to drastically reduce the decoder output vocabulary and improve model generalizability. We equip our model with a memory buffer that stores high-reward promising programs. Besides, we propose an adaptive reward function. By comparing the generated trial with the trials stored in the memory buffer, we derive the curriculum-guided reward bonus, i.e., the proximity and the novelty. To mitigate the sparse reward problem, we combine the adaptive reward and the reward bonus, reshaping the sparse reward into dense feedback. Also, we encourage the model to generate new trials to avoid imitating the spurious trials while making the model remember the past high-reward trials to improve data efficiency. Our NS-CQA model is evaluated on two datasets: CQA, a recent large-scale complex question answering dataset, and WebQuestionsSP, a multi-hop question answering dataset. On both datasets, our model outperforms the state-of-the-art models. Notably, on CQA, NS-CQA performs well on questions with higher complexity, while only using approximately 1% of the total training samples. (C) 2020 Published by Elsevier B.V.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/DevinJake/NS-CQA"]}}
}

@article{rayyan-242084961,
  title={Generating Programmatic Referring Expressions via Program Synthesis},
  year={2020},
  volume={119},
  author={Huang, Jiani and Calvin, Smith and Osbert, Bastani and Rishabh, Singh and Aws, Albarghouthi and Mayur, Naik},
  publisher={JMLR-JOURNAL MACHINE LEARNING RESEARCH},
  abstract={Incorporating symbolic reasoning into machine learning algorithms is a promising approach to improve performance on learning tasks that require logical reasoning. We study the problem of generating a programmatic variant of referring expressions that we call referring relational programs. In particular, given a symbolic representation of an image and a target object in that image, the goal is to generate a relational program that uniquely identifies the target object in terms of its attributes and its relations to other objects in the image. We propose a neurosymbolic program synthesis algorithm that combines a policy neural network with enumerative search to generate such relational programs. The policy neural network employs a program interpreter that provides immediate feedback on the consequences of the decisions made by the policy, and also takes into account the uncertainty in the symbolic representation of the image. We evaluate our algorithm on challenging benchmarks based on the CLEVR dataset, and demonstrate that our approach significantly outperforms several baselines.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/moqingyan/object_reference_synthesis"]}}
}

@article{rayyan-242084963,
  title={Multi-agent Cooperative Games Using Belief Map Assisted Training},
  year={2024},
  author={Huang, Qinwei and Chen, Luo and Wu, Alex B. and Khan, Simon and Li, Hai and Qiu, Qinru},
  abstract={In a multi-agent system, agents share their local observations to gain global situational awareness for decision making and collaboration using a message passing system. When to send a message, how to encode a message, and how to leverage the received messages directly affect the effectiveness of the collaboration among agents. When training a multi-agent cooperative game using reinforcement learning (RL), the message passing system needs to be optimized together with the agent policies. This consequently increases the model's complexity and poses significant challenges to the convergence and performance of learning. To address this issue, we propose the Belief-map Assisted Multi-agent System (BAMS), which leverages a neuro-symbolic belief map to enhance training. The belief map decodes the agent's hidden state to provide a symbolic representation of the agent's understanding of the environment and other agent's status. The simplicity of symbolic representation allows the gathering and comparison of the ground truth information with the belief, which provides an additional channel of feedback for the learning. Compared to the sporadic and delayed feedback coming from the reward in RL, the feedback from the belief map is more consistent and reliable. Agents using BAMS can learn a more effective message passing network to better understand each other, resulting in better performance in a cooperative predator and prey game with varying levels of map complexity and compare it to previous multi-agent message passing models. The simulation results showed that BAMS reduced training epochs by 66%, and agents who apply the BAMS model completed the game with 34.62% fewer steps on average.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/qhuang18-97/BAMS"]}}
}

@article{rayyan-242084966,
  title={Fast Abductive Learning by Similarity-based Consistency Optimization},
  year={2021},
  volume={34},
  author={Huang, Yu-Xuan and Wang-Zhou, Dai and Le-Wen, Cai and Stephen, Muggleton and Yuan, Jiang},
  publisher={NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)},
  abstract={To utilize the raw inputs and symbolic knowledge simultaneously, some recent neuro-symbolic learning methods use abduction, i.e., abductive reasoning, to integrate sub-symbolic perception and logical inference. While the perception model, e.g., a neural network, outputs some facts that are inconsistent with the symbolic background knowledge base, abduction can help revise the incorrect perceived facts by minimizing the inconsistency between them and the background knowledge. However, to enable effective abduction, previous approaches need an initialized perception model that discriminates the input raw instances. This limits the application of these methods, as the discrimination ability is usually acquired from a thorough pre-training when the raw inputs are difficult to classify. In this paper, we propose a novel abduction strategy, which leverages the similarity between samples, rather than the output information by the perceptual neural network, to guide the search in abduction. Based on this principle, we further present ABductive Learning with Similarity (ABLSim) and apply it to some difficult neuro-symbolic learning tasks. Experiments show that the efficiency of ABLSim is significantly higher than the state-of-the-art neuro-symbolic methods, allowing it to achieve better performance with less labeled data and weaker domain knowledge.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/AbductiveLearning/ABLSim"]}}
}

@article{rayyan-242084967,
  title={Enabling Knowledge Refinement upon New Concepts in Abductive Learning},
  year={2023},
  author={Huang, Yu-Xuan and Wang-Zhou, Dai and Yuan, Jiang and Zhi-Hua, Zhou},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={Recently there are great efforts on leveraging machine learning and logical reasoning. Many approaches start from a given knowledge base, and then try to utilize the knowledge to help machine learning. In real practice, however, the given knowledge base can often be incomplete or even noisy, and thus, it is crucial to develop the ability of knowledge refinement or enhancement. This paper proposes to enable the Abductive learning (ABL) paradigm to have the ability of knowledge refinement/enhancement. In particular, we focus on the problem that, in contrast to closed-environment tasks where a fixed set of symbols are enough to represent the concepts in the domain, in open-environment tasks new concepts may emerge. Ignoring those new concepts can lead to significant performance decay, whereas it is challenging to identify new concepts and add them to the existing knowledge base with potential conflicts resolved. We propose the ABLnc approach which exploits machine learning in ABL to identify new concepts from data, exploits knowledge graph to match them with entities, and refines existing knowledge base to resolve conflicts. The refined/enhanced knowledge base can then be used in the next loop of ABL and help improve the performance of machine learning. Experiments on three neuro-symbolic learning tasks verified the effectiveness of the proposed approach.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/AbductiveLearning/ABL"]}}
}

@article{rayyan-242084969,
  title={Relation Aware Neural-Symbolic Models for Logical Queries on Knowledge Graphs},
  year={2024},
  author={Huang, Z. and An, G.},
  url={https://ieeexplore.ieee.org/abstract/document/10846507/?casa_token=0rFeGSElzR4AAAAA:jA8zOFpPIwCk2_IbklU8BV9m-6VEp4l2DuoRrzqVYVqQNvxZ-majcn21dZli21mHs38M5Zrvlil1kg},
  abstract={… In this paper, we propose a neural-symbolic integration approach to address the firstorder … 1) We design and implement a neural-symbolic integration model for knowledge graph logical …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/DeepGraphLearning/GNN-QE"]}}
}

@article{rayyan-242084970,
  title={Sequential Recommendation with Probabilistic Logical Reasoning},
  year={2023},
  author={Yuan, Huanhuan and Zhao, Pengpeng and Xian, Xuefeng and Liu, Guanfeng and Victor, S. Sheng and Zhao, Lei},
  abstract={Deep learning and symbolic learning are two frequently employed methods in Sequential Recommendation (SR). Recent neural-symbolic SR models demonstrate their potential to enable SR to be equipped with concurrent perception and cognition capacities. However, neural-symbolic SR remains a challenging problem due to open issues like representing users and items in logical reasoning. In this paper, we combine the Deep Neural Network (DNN) SR models with logical reasoning and propose a general framework named Sequential Recommendation with Probabilistic Logical Reasoning (short for SR-PLR). This framework allows},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Huanhuaneryuan/SR-PLR."]}}
}

@article{rayyan-242084971,
  title={Neural-Symbolic Collaborative Distillation: Advancing Small Language Models for Complex Reasoning Tasks},
  year={2024},
  author={Liao, Huanxuan and He, Shizhu and Xu, Yao and Zhang, Yuanzhe and Liu, Kang and Jun, Zhao},
  abstract={In this paper, we propose 𝐍e ural-𝐒y mbolic 𝐂 ollaborative 𝐃 istillation (𝐍esyCD ), a novel knowledge distillation method for learning the complex reasoning abilities of Large Language Models (LLMs, e.g., > 13B). We argue that complex reasoning tasks are difficult for Small Language Models (SLMs, e.g., ≤ 7B), as these tasks demand not only general cognitive abilities but also specialized knowledge, which is often sparse and difficult for these neural-based SLMs to effectively capture. Therefore, NesyCD distills the general capabilities and specialized knowledge in LLMs using different manners. On the one hand, we distill only general abilities from teacher LLMs into the student SLMs of parameterized neural networks. On the other hand, for the specialized abilities and uncommon knowledge of a complex reasoning task, we employ a symbolic knowledge distillation approach to obtain and store the specialized knowledge within a symbolic knowledge base (KB). By decoupling general and specialized capabilities, the proposed NesyCD can achieve superior performance cost-effectively, utilizing smaller models and blending parameterized neural networks with symbolic KB. Moreover, the specialized KB generalizes well and is comprehended and manipulated by humans. Our experiments show that NesyCD significantly boosts SLMs' complex reasoning performance on in-domain (BBH, GSM8K) and out-of-domain (AGIEval, ARC) datasets. Notably, our approach enabled the LLaMA3-8B and Qwen2-7B to surpass GPT-3.5-turbo in performance and come close to matching LLaMA3-70B, despite the latter having nine times more parameters. Our code will be available at https://github.com/Xnhyacinth/NesyCD.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Xnhyacinth/NesyCD"]}}
}

@article{rayyan-242084976,
  title={Composition Vision-Language Understanding via Segment and Depth Anything Model},
  year={2024},
  author={Huo, Mingxiao and Ji, Pengliang and Lin, Haotian and Liu, Junchen and Wang, Yixiao and Chen, Yijun},
  abstract={We introduce a pioneering unified library that leverages depth anything, segment anything models to augment neural comprehension in language-vision model zero-shot understanding. This library synergizes the capabilities of the Depth Anything Model (DAM), Segment Anything Model (SAM), and GPT-4V, enhancing multimodal tasks such as vision-question-answering (VQA) and composition reasoning. Through the fusion of segmentation and depth analysis at the symbolic instance level, our library provides nuanced inputs for language models, significantly advancing image interpretation. Validated across a spectrum of in-the-wild real-world images, our findings showcase progress in vision-language models through neural-symbolic integration. This novel approach melds visual and language analysis in an unprecedented manner. Overall, our library opens new directions for future research aimed at decoding the complexities of the real world through advanced multimodal technologies and our code is available at \url{https://github.com/AnthonyHuo/SAM-DAM-for-Compositional-Reasoning}.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/AnthonyHuo/SAM-DAM-for-Compositional-Reasoning"]}}
}

@article{rayyan-242084978,
  title={Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning},
  year={2024},
  author={Ryu, Hyun and Kim, Gyeongman and Hyemin, S. Lee and Yang, Eunho},
  abstract={Complex logical reasoning tasks require a long sequence of reasoning, which a large language model (LLM) with chain-of-thought prompting still falls short. To alleviate this issue, neurosymbolic approaches incorporate a symbolic solver. Specifically, an LLM only translates a natural language problem into a satisfiability (SAT) problem that consists of first-order logic formulas, and a sound symbolic solver returns a mathematically correct solution. However, we discover that LLMs have difficulties to capture complex logical semantics hidden in the natural language during translation. To resolve this limitation, we propose a Compositional First-Order Logic Translation. An LLM first parses a natural language sentence into newly defined logical dependency structures that consist of an atomic subsentence and its dependents, then sequentially translate the parsed subsentences. Since multiple logical dependency structures and sequential translations are possible for a single sentence, we also introduce two Verification algorithms to ensure more reliable results. We utilize an SAT solver to rigorously compare semantics of generated first-order logic formulas and select the most probable one. We evaluate the proposed method, dubbed CLOVER, on seven logical reasoning benchmarks and show that it outperforms the previous neurosymbolic approaches and achieves new state-of-the-art results.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Hyun-Ryu/clover"]}}
}

@article{rayyan-242084981,
  title={FB15k-CVT: A Challenging Dataset for Knowledge Graph Embedding Models},
  year={2023},
  author={Iferroudjene, Mouloud and Victor, Charpenay and Antoine, Zimmermann},
  publisher={RWTH AACHEN},
  abstract={Knowledge Graphs (KGs) are an essential component of neuro-symbolic AI. KG Embedding Models (KGEMs) are used to represent elements of a KG (its entities and relations) in a vector space, to enable efficient processing and reasoning over knowledge. Most KGEMs are evaluated against datasets derived from the Freebase KG: FB15k and FB15k-237. In this paper, we identify limitations in these datasets with respect to Compound Value Types (CVTs), which are nodes introduced in Freebase as a substitute for..-ary relations. In FB15k and FB51k-237, CVTs have been removed, thereby eliminating valuable information. To evaluate whether KGEMs can learn semantically accurate representations of entities and relations in Freebase, we introduce here a new dataset named FB15k-CVT, which reintroduces the deleted CVT nodes. In a preliminary evaluation, we assess the limitations of baseline KGEMs (TransE, DistMult) in the presence of CVTs. The evaluation suggests that KGEMs based on tensor decomposition are more promising than translational models but, most of all, it calls for further experiments with KGEMs that can answer conjunctive queries or that preserve logical entailment.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/miferroudjene/FB15k-CVT"]}}
}

@article{rayyan-242084982,
  title={Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge},
  year={2023},
  author={Ikbal, Shajith and Udit, Sharma and Hima, Karanam and Sumit, Neelam and Ronny, Luss and Dheeraj, Sreedhar and Pavan, Kapanipathi and Naweed, Khan and Kyle, Erwin and Ndivhuwo, Makondo and Ibrahim, Abdelaziz and Achille, Fokoue and Alexander, Gray and Maxwell, Crouse and Subhajit, Chaudhury and Subramanian Chitra, K.},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={We present a neuro-symbolic approach to self-learn rules that serve as interpretable knowledge to perform relation linking in knowledge base question answering systems. These rules define natural language text predicates as a weighted mixture of knowledge base paths. The weights learned during training effectively serve the mapping needed to perform relation linking. We use popular masked training strategy to self-learn the rules. A key distinguishing aspect of our work is that the masked training operate over logical forms of the sentence instead of their natural language text form. This offers opportunity to extract extended context information from the structured knowledge source and use that to build robust and human readable rules. We evaluate accuracy and usefulness of such learned rules by utilizing them for prediction of missing kinship relation in CLUTRR dataset and relation linking in a KBQA system using SWQ-WD dataset. Results demonstrate the effectiveness of our approach - its generalizability, interpretability and ability to achieve an average performance gain of 17% on CLUTRR dataset.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/IBM/self-supervised-rule-learning"]}}
}

@article{rayyan-242084987,
  title={Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach},
  year={2023},
  author={Sharifi, Iman and Yildirim, Mustafa and Saber, Fallah},
  abstract={The dynamic nature of driving environments and the presence of diverse road users pose significant challenges for decision-making in autonomous driving. Deep reinforcement learning (DRL) has emerged as a popular approach to tackle this problem. However, the application of existing DRL solutions is mainly confined to simulated environments due to safety concerns, impeding their deployment in real-world. To overcome this limitation, this paper introduces a novel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics (DRLSL) that combines the strengths of DRL (learning from experience) and symbolic first-order logics (knowledge-driven reasoning) to enable safe learning in real-time interactions of autonomous driving within real environments. This innovative approach provides a means to learn autonomous driving policies by actively engaging with the physical environment while ensuring safety. We have implemented the DRLSL framework in autonomous driving using the highD dataset and demonstrated that our method successfully avoids unsafe actions during both the training and testing phases. Furthermore, our results indicate that DRLSL achieves faster convergence during training and exhibits better generalizability to new driving scenarios compared to traditional DRL methods.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/CAV-Research-Lab/Safe-Reinforcement-Learning-using-Symbolic-Logical-Programming-for-Autonomous-Highway-Driving"]}}
}

@article{rayyan-242084989,
  title={Neurosymbolic transformers for multi-agent communication},
  year={2020},
  author={Inala, J. P. and Yang, Y. and Paulos, J. and Pu, Y.},
  url={https://proceedings.neurips.cc/paper/2020/hash/9d740bd0f36aaa312c8d504e28c42163-Abstract.html},
  abstract={We study the problem of inferring communication structures that can solve cooperative multi-agent planning problems while minimizing the amount of communication. We quantify the …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jinala/multi-agent-neurosym-transformers"]}}
}

@article{rayyan-242084992,
  title={Systematic Relational Reasoning With Epistemic Graph Neural Networks},
  year={2024},
  author={Khalid, Irtaza and Steven, Schockaert},
  abstract={Developing models that can learn to reason is a notoriously challenging problem. We focus on reasoning in relational domains, where the use of Graph Neural Networks (GNNs) seems like a natural choice. However, previous work has shown that regular GNNs lack the ability to systematically generalize from training examples on test graphs requiring longer inference chains, which fundamentally limits their reasoning abilities. A common solution relies on neuro-symbolic methods that systematically reason by learning rules, but their scalability is often limited and they tend to make unrealistically strong assumptions, e.g.\ {t}{h}{a}t the answer can always be inferred from a single relational path. We propose the Epistemic GNN (EpiGNN), a novel parameter-efficient and scalable GNN architecture with an epistemic inductive bias for systematic reasoning. Node embeddings in EpiGNNs are treated as epistemic states, and message passing is implemented accordingly. We show that EpiGNNs achieve state-of-the-art results on link prediction tasks that require systematic reasoning. Furthermore, for inductive knowledge graph completion, EpiGNNs rival the performance of state-of-the-art specialized approaches. Finally, we introduce two new benchmarks that go beyond standard relational reasoning by requiring the aggregation of information from multiple paths. Here, existing neuro-symbolic approaches fail, yet EpiGNNs learn to reason accurately. Code and datasets are available at https://github.com/erg0dic/gnn-sg.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/erg0dic/gnn-sg"]}}
}

@article{rayyan-242084995,
  title={NeuSTIP: A Novel Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs},
  year={2023},
  author={Singh, Ishaan and Kaur, Navdeep and Gaur, Garima and , Mausam},
  abstract={While Knowledge Graph Completion (KGC) on static facts is a matured field, Temporal Knowledge Graph Completion (TKGC), that incorporates validity time into static facts is still in its nascent stage. The KGC methods fall into multiple categories including embedding-based, rule-based, GNN-based, pretrained Language Model based approaches. However, such dimensions have not been explored in TKG. To that end, we propose a novel temporal neuro-symbolic model, NeuSTIP, that performs link prediction and time interval prediction in a TKG. NeuSTIP learns temporal rules in the presence of the Allen predicates that ensure the temporal consistency between neighboring predicates in a given rule. We further design a unique scoring function that evaluates the confidence of the candidate answers while performing link prediction and time interval prediction by utilizing the learned rules. Our empirical evaluation on two time interval based TKGC datasets suggests that our model outperforms state-of-the-art models for both link prediction and the time interval prediction task.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/dair-iitd/NeuSTIP/"]}}
}

@article{rayyan-242084996,
  title={Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering},
  year={2024},
  author={Ishay, Adam and Zhun, Yang and Joohyung, Lee and Ilgu, Kang and Dongjae, Lim},
  publisher={IEEE COMPUTER SOC},
  abstract={Causal and temporal reasoning about video dynamics is a challenging problem. While neuro-symbolic models that combine symbolic reasoning with neural-based perception and prediction have shown promise, they exhibit limitations, especially in answering counterfactual questions. This paper introduces a method to enhance a neuro-symbolic model for counterfactual reasoning, leveraging symbolic reasoning about causal relations among events. We define the notion of a causal graph to represent such relations and use Answer Set Programming (ASP), a declarative logic programming method, to find how to coordinate perception and simulation modules. We validate the effectiveness of our approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves state-of-the-art performance on the CLEVRER challenge, significantly outperforming existing models. In the case of the CRAFT benchmark, we leverage a large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a dynamics simulator. Our findings show that this method can further improve its performance on counterfactual questions by providing alternative prompts instructed by symbolic causal reasoning.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/azreasoners/crcg, https://github.com/potassco/guide/releases/tag/v2.2.0"]}}
}

@article{rayyan-242084998,
  title={Contrastive Learning in Neural Tensor Networks using Asymmetric Examples},
  year={2021},
  author={Islam, Mohammad Maminur and Somdeb, Sarkhel and Deepak, Venugopal},
  publisher={IEEE},
  abstract={Neuro-Symbolic models combine the best of two worlds, knowledge representation capabilities of symbolic models and representation learning power of deep networks. In this paper, we develop a Neuro-Symbolic approach to infer unknown facts from relational data. A well-known approach is to use statistical relational models such as Markov Logic Networks (MLNs) to perform probabilistic inference. However, these approaches are known to be non-scalable and inaccurate for large, real-world problems. Therefore, given symbolic knowledge, we train a Neural Tensor Network (NTN) to learn representations for symmetries implied by the symbolic knowledge. Further, since the data is interconnected, predicting one fact can positively or negatively impact the prediction of other facts. Therefore, we train the NTN using open-world semantics over multiple possible worlds, learning to represent symmetries in each world. We evaluate our approach in several real-world benchmarks comparing with state-of-the-art relational learning methods, Neuro-Symbolic methods and purely symbolic methods clearly illustrating the generality, accuracy and scalability of our proposed approach.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/tushancse04/MNTN"]}}
}

@article{rayyan-242085009,
  title={Causal Neuro-Symbolic AI for Root Cause Analysis in Smart Manufacturing},
  year={2024},
  author={Jaimini, U. and Henson, C. and Sheth, A.},
  url={https://scholarcommons.sc.edu/aii_fac_pub/614/},
  abstract={… Causal Neuro-Symbolic AI (NSAI) is a hybrid framework that blends the strengths of causal and NSAI representations and techniques [4]. Our Causal NSAI-enhanced RCA approach …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: https://github.com/boschresearch/causalAssembly"], "brandon"=>["https://www.kaggle.com/datasets/ramyharik/ff-2023-12-12-analog-dataset, https://github.com/boschresearch/causalAssembly"]}}
}

@article{rayyan-242085013,
  title={ReOnto: A neuro-symbolic approach for biomedical relation extraction},
  year={2023},
  author={Jain, M. and Singh, K. and Mutharaju, R.},
  abstract={… To address these issues, we present a novel technique called ReOnto, that makes use of neuro symbolic knowledge for the RE task. ReOnto employs a graph neural network to acquire …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/kracr/reonto-relation-extraction"]}}
}

@article{rayyan-242085015,
  title={Visual Graph Question Answering with ASP and LLMs for Language Parsing},
  year={2025},
  author={Bauer, Jakob Johannes and Eiter, Thomas and Ruiz, Nelson Higuera and Johannes, Oetsch},
  abstract={Visual Question Answering (VQA) is a challenging problem that requires to process multimodal input. Answer-Set Programming (ASP) has shown great potential in this regard to add interpretability and explainability to modular VQA architectures. In this work, we address the problem of how to integrate ASP with modules for vision and natural language processing to solve a new and demanding VQA variant that is concerned with images of graphs (not graphs in symbolic form). Images containing graph-based structures are an ubiquitous and popular form of visualisation. Here, we deal with the particular problem of graphs inspired by transit networks, and we introduce a novel dataset that amends an existing one by adding images of graphs that resemble metro lines. Our modular neuro-symbolic approach combines optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing labels, Large Language Models (LLMs) for language processing, and ASP for reasoning. This method serves as a first baseline and achieves an overall average accuracy of 73% on the dataset. Our evaluation provides further evidence of the potential of modular neuro-symbolic systems, in particular with pretrained models that do not involve any further training and logic programming for reasoning, to solve complex VQA tasks.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/pudumagico/NSGRAPH"]}}
}

@article{rayyan-242085016,
  title={Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling},
  year={2021},
  author={Prange, Jakob and Schneider, Nathan and Lingpeng, Kong},
  abstract={We examine the extent to which, in principle, linguistic graph representations can complement and improve neural language modeling. With an ensemble setup consisting of a pretrained Transformer and ground-truth graphs from one of 7 different formalisms, we find that, overall, semantic constituency structures are most useful to language modeling performance - outpacing syntactic constituency structures as well as syntactic and semantic dependency structures. Further, effects vary greatly depending on part-of-speech class. In sum, our findings point to promising tendencies in neuro-symbolic language modeling and invite future research quantifying the design choices made by different formalisms.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jakpra/LinguisticStructureLM"]}}
}

@article{rayyan-242085027,
  title={The Gradient of Algebraic Model Counting},
  year={2025},
  author={Maene, Jaron and Luc De, Raedt},
  abstract={Algebraic model counting unifies many inference tasks on logic formulas by exploiting semirings. Rather than focusing on inference, we consider learning, especially in statistical-relational and neurosymbolic AI, which combine logical, probabilistic and neural representations. Concretely, we show that the very same semiring perspective of algebraic model counting also applies to learning. This allows us to unify various learning algorithms by generalizing gradients and backpropagation to different semirings. Furthermore, we show how cancellation and ordering properties of a semiring can be exploited for more memory-efficient backpropagation. This allows us to obtain some interesting variations of state-of-the-art gradient-based optimisation methods for probabilistic logical models. We also discuss why algebraic model counting on tractable circuits does not lead to more efficient second-order optimization. Empirically, our algebraic backpropagation exhibits considerable speed-ups as compared to existing approaches.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ML-KULeuven/amc-grad"]}}
}

@article{rayyan-242085028,
  title={On the Hardness of Probabilistic Neurosymbolic Learning},
  year={2024},
  author={Maene, Jaron and Derkinderen, Vincent and Luc De, Raedt},
  abstract={The limitations of purely neural learning have sparked an interest in probabilistic neurosymbolic models, which combine neural networks with probabilistic logical reasoning. As these neurosymbolic models are trained with gradient descent, we study the complexity of differentiating probabilistic reasoning. We prove that although approximating these gradients is intractable in general, it becomes tractable during training. Furthermore, we introduce WeightME, an unbiased gradient estimator based on model sampling. Under mild assumptions, WeightME approximates the gradient with probabilistic guarantees using a logarithmic number of calls to a SAT solver. Lastly, we evaluate the necessity of these guarantees on the gradient. Our experiments indicate that the existing biased approximations indeed struggle to optimize even when exact solving is still feasible.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jjcmoon/hardness-nesy"]}}
}

@article{rayyan-242085029,
  title={KLay: Accelerating Arithmetic Circuits for Neurosymbolic AI},
  year={2024},
  author={Maene, Jaron and Derkinderen, Vincent and Pedro Zuidberg Dos, Martires},
  abstract={A popular approach to neurosymbolic AI involves mapping logic formulas to arithmetic circuits (computation graphs consisting of sums and products) and passing the outputs of a neural network through these circuits. This approach enforces symbolic constraints onto a neural network in a principled and end-to-end differentiable way. Unfortunately, arithmetic circuits are challenging to run on modern AI accelerators as they exhibit a high degree of irregular sparsity. To address this limitation, we introduce knowledge layers (KLay), a new data structure to represent arithmetic circuits that can be efficiently parallelized on GPUs. Moreover, we contribute two algorithms used in the translation of traditional circuit representations to KLay and a further algorithm that exploits parallelization opportunities during circuit evaluations. We empirically show that KLay achieves speedups of multiple orders of magnitude over the state of the art, thereby paving the way towards scaling neurosymbolic AI to larger real-world applications.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ML-KULeuven/klay"]}}
}

@article{rayyan-242085032,
  title={AnyTOD: A Programmable Task-Oriented Dialog System},
  year={2022},
  author={Zhao, Jeffrey and Cao, Yuan and Gupta, Raghav and Lee, Harrison and Rastogi, Abhinav and Wang, Mingqiu and Soltau, Hagen and Shafran, Izhak and Yonghui, Wu},
  abstract={We propose AnyTOD, an end-to-end, zero-shot task-oriented dialog (TOD) system capable of handling unseen tasks without task-specific training. We view TOD as a program executed by a language model (LM), where program logic and ontology is provided by a designer as a schema. To enable generalization to unseen schemas and programs without prior training, AnyTOD adopts a neuro-symbolic approach. A neural LM keeps track of events occurring during a conversation and a symbolic program implementing the dialog policy is executed to recommend next actions AnyTOD should take. This approach drastically reduces data annotation and model training requirements, addressing the enduring challenge of rapidly adapting a TOD system to unseen tasks and domains. We demonstrate state-of-the-art results on STAR, ABCD and SGD benchmarks. We also demonstrate strong zero-shot transfer ability in low-resource settings, such as zero-shot on MultiWOZ. In addition, we release STARv2, an updated version of the STAR dataset with richer annotations, for benchmarking zero-shot end-to-end TOD models.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/google-research/task-oriented-dialogue"]}}
}

@article{rayyan-242085042,
  title={FGeo-DRL: Deductive Reasoning for Geometric Problems through Deep Reinforcement Learning},
  year={2024},
  author={Zou, Jia and Zhang, Xiaokai and He, Yiming and Zhu, Na and Tuo, Leng},
  abstract={The human-like automatic deductive reasoning has always been one of the most challenging open problems in the interdiscipline of mathematics and artificial intelligence. This paper is the third in a series of our works. We built a neural-symbolic system, called FGeoDRL, to automatically perform human-like geometric deductive reasoning. The neural part is an AI agent based on reinforcement learning, capable of autonomously learning problem-solving methods from the feedback of a formalized environment, without the need for human supervision. It leverages a pre-trained natural language model to establish a policy network for theorem selection and employ Monte Carlo Tree Search for heuristic exploration. The symbolic part is a reinforcement learning environment based on geometry formalization theory and FormalGeo, which models GPS as a Markov Decision Process. In this formal symbolic system, the known conditions and objectives of the problem form the state space, while the set of theorems forms the action space. Leveraging FGeoDRL, we have achieved readable and verifiable automated solutions to geometric problems. Experiments conducted on the formalgeo7k dataset have achieved a problem-solving success rate of 86.40%. The project is available at https://github.com/PersonNoName/FGeoDRL.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/PersonNoName/FGeoDRL"]}}
}

@article{rayyan-242085043,
  title={Verification Learning: Make Unsupervised Neuro-Symbolic System Feasible},
  year={2025},
  author={Jia, L. H. and Hu, W. C. and Shao, J. J. and Guo, L. Z. and Li, Y. F.},
  abstract={The current Neuro-Symbolic (NeSy) Learning paradigm suffers from an over-reliance on labeled data. If we completely disregard labels, it leads to less symbol information, a larger …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/VerificationLearning/VerificationLearning."]}}
}

@article{rayyan-242085047,
  title={Generative neurosymbolic machines},
  year={2020},
  author={Jiang, J. and Ahn, S.},
  url={https://proceedings.neurips.cc/paper/2020/hash/94c28dcfc97557df0df6d1f7222fc384-Abstract.html},
  abstract={Reconciling symbolic and distributed representations is a crucial challenge that can potentially resolve the limitations of current deep learning. Remarkable advances in this direction …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/JindongJiang/GNM"]}}
}

@article{rayyan-242085059,
  title={ReTool: Reinforcement Learning for Strategic Tool Use in LLMs},
  year={2025},
  author={Feng, Jiazhan and Huang, Shijue and Qu, Xingwei and Zhang, Ge and Qin, Yujia and Zhong, Baoquan and Jiang, Chengquan and Chi, Jinxin and Wanjun, Zhong},
  abstract={While reasoning models (e.g., DeepSeek R1) trained with reinforcement learning (RL), excel in textual reasoning, they struggle in scenarios requiring structured problem-solving, such as geometric reasoning, concise computation, or complex equation solving-areas where computational tools like code interpreters (CI) demonstrate distinct advantages. To bridge this gap, we propose ReTool, which enhances long-form reasoning with tool-integrated learning, including two key features: (1) dynamic interleaving of real-time code execution within natural language reasoning processes, and (2) an automated RL paradigm that allows policy rollouts with multi-turn real-time code execution and teaches the model in learning when and how to invoke tools based on outcome feedback. ReTool employs a systematic training framework, beginning with synthetic cold-start data generation to produce code-augmented long-form reasoning traces for fine-tuning base models. Subsequent RL training leverages task outcomes as rewards to iteratively refine the model's tool use strategy, enabling autonomous discovery of optimal tool invocation patterns without human priors. Experiments on the challenging MATH Olympiad benchmark AIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with 400 training steps, outperforming text-based RL baseline (40% accuracy, 1080 steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5% accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Further analysis reveals emergent behaviors such as code self-correction, signaling an ''aha moment'' in which the model autonomously masters adaptive tool use. These findings highlight the promise of outcome-driven tool integration for advancing complex mathematical reasoning and offer new insights into hybrid neuro-symbolic systems.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://retool-rl.github.io/"]}}
}

@article{rayyan-242085060,
  title={A Neural Symbolic Model for Space Physics},
  year={2025},
  author={Ying, Jie and Lin, Haowei and Yue, Chao and Chen, Yajie and Xiao, Chao and Shi, Quanqi and Liang, Yitao and Yau, Shing-Tung and Zhou, Yuan and Jianzhu, Ma},
  abstract={In this study, we unveil a new AI model, termed PhyE2E, to discover physical formulas through symbolic regression. PhyE2E simplifies symbolic regression by decomposing it into sub-problems using the second-order derivatives of an oracle neural network, and employs a transformer model to translate data into symbolic formulas in an end-to-end manner. The resulting formulas are refined through Monte-Carlo Tree Search and Genetic Programming. We leverage a large language model to synthesize extensive symbolic expressions resembling real physics, and train the model to recover these formulas directly from data. A comprehensive evaluation reveals that PhyE2E outperforms existing state-of-the-art approaches, delivering superior symbolic accuracy, precision in data fitting, and consistency in physical units. We deployed PhyE2E to five applications in space physics, including the prediction of sunspot numbers, solar rotational angular velocity, emission line contribution functions, near-Earth plasma pressure, and lunar-tide plasma signals. The physical formulas generated by AI demonstrate a high degree of accuracy in fitting the experimental data from satellites and astronomical telescopes. We have successfully upgraded the formula proposed by NASA in 1993 regarding solar activity, and for the first time, provided the explanations for the long cycle of solar activity in an explicit form. We also found that the decay of near-Earth plasma pressure is proportional to r² to Earth, where subsequent mathematical derivations are consistent with satellite data from another independent study. Moreover, we found physical formulas that can describe the relationships between emission lines in the extreme ultraviolet spectrum of the Sun, temperatures, electron densities, and magnetic fields. The formula obtained is consistent with the properties that physicists had previously hypothesized it should possess.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Jie0618/PhysicsRegression"]}}
}

@article{rayyan-242085061,
  title={Learning for Long-Horizon Planning via Neuro-Symbolic Abductive Imitation},
  year={2024},
  author={Shao, Jie-Jing and Hao, Hao-Ran and Yang, Xiao-Wen and Yu-Feng, Li},
  abstract={Recent learning-to-imitation methods have shown promising results in planning via imitating within the observation-action space. However, their ability in open environments remains constrained, particularly in long-horizon tasks. In contrast, traditional symbolic planning excels in long-horizon tasks through logical reasoning over human-defined symbolic spaces but struggles to handle observations beyond symbolic states, such as high-dimensional visual inputs encountered in real-world scenarios. In this work, we draw inspiration from abductive learning and introduce a novel framework 𝐀B ductive 𝐈 mitation 𝐋 earning (ABIL) that integrates the benefits of data-driven learning and symbolic-based reasoning, enabling long-horizon planning. Specifically, we employ abductive reasoning to understand the demonstrations in symbolic space and design the principles of sequential consistency to resolve the conflicts between perception and reasoning. ABIL generates predicate candidates to facilitate the perception from raw observations to symbolic space without laborious predicate annotations, providing a groundwork for symbolic planning. With the symbolic understanding, we further develop a policy ensemble whose base policies are built with different logical objectives and managed through symbolic reasoning. Experiments show that our proposal successfully understands the observations with the task-relevant symbolics to assist the imitation learning. Importantly, ABIL demonstrates significantly improved data efficiency and generalization across various long-horizon tasks, highlighting it as a promising solution for long-horizon planning. Project website: \url https://www.lamda.nju.edu.cn/shaojj/KDD25\_{A}{B}{I}L/ .},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Hoar012/ABIL-KDD-2025"]}}
}

@article{rayyan-242085064,
  title={Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks},
  year={2021},
  author={Qin, Jinghui and Liang, Xiaodan and Hong, Yining and Tang, Jianheng and Liang, Lin},
  abstract={Previous math word problem solvers following the encoder-decoder paradigm fail to explicitly incorporate essential math symbolic constraints, leading to unexplainable and unreasonable predictions. Herein, we propose Neural-Symbolic Solver (NS-Solver) to explicitly and seamlessly incorporate different levels of symbolic constraints by auxiliary tasks. Our NS-Solver consists of a problem reader to encode problems, a programmer to generate symbolic equations, and a symbolic executor to obtain answers. Along with target expression supervision, our solver is also optimized via 4 new auxiliary objectives to enforce different symbolic reasoning: a) self-supervised number prediction task predicting both number quantity and number locations; b) commonsense constant prediction task predicting what prior knowledge (e.g. how many legs a chicken has) is required; c) program consistency checker computing the semantic loss between predicted equation and target equation to ensure reasonable equation mapping; d) duality exploiting task exploiting the quasi duality between symbolic equation generation and problem's part-of-speech generation to enhance the understanding ability of a solver. Besides, to provide a more realistic and challenging benchmark for developing a universal and scalable solver, we also construct a new large-scale MWP benchmark CM17K consisting of 4 kinds of MWPs (arithmetic, one-unknown linear, one-unknown non-linear, equation set) with more than 17K samples. Extensive experiments on Math23K and our CM17k demonstrate the superiority of our NS-Solver compared to state-of-the-art methods.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/QinJinghui/NS-Solver."]}}
}

@article{rayyan-242085077,
  title={A Pipeline For Discourse Circuits From CCG},
  year={2023},
  author={Liu, Jonathon and Razin, A. Shaikh and Rodatz, Benjamin and Yeung, Richie and Coecke, Bob},
  abstract={There is a significant disconnect between linguistic theory and modern NLP practice, which relies heavily on inscrutable black-box architectures. DisCoCirc is a newly proposed model for meaning that aims to bridge this divide, by providing neuro-symbolic models that incorporate linguistic structure. DisCoCirc represents natural language text as a `circuit' that captures the core semantic information of the text. These circuits can then be interpreted as modular machine learning models. Additionally, DisCoCirc fulfils another major aim of providing an NLP model that can be implemented on near-term quantum computers. In this paper we describe a software pipeline that converts English text to its DisCoCirc representation. The pipeline achieves coverage over a large fragment of the English language. It relies on Combinatory Categorial Grammar (CCG) parses of the input text as well as coreference resolution information. This semantic and syntactic information is used in several steps to convert the text into a simply-typed λ-calculus term, and then into a circuit diagram. This pipeline will enable the application of the DisCoCirc framework to NLP tasks, using both classical and quantum approaches.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/CQCL/text_to_discocirc"]}}
}

@article{rayyan-242085078,
  title={Invariants for neural automata},
  year={2023},
  author={Uria-Albizuri, Jone and Carmantini, Giovanni Sirio and beim Graben, Peter and Serafim, Rodrigues},
  abstract={Computational modeling of neurodynamical systems often deploys neural networks and symbolic dynamics. A particular way for combining these approaches within a framework called vector symbolic architectures leads to neural automata. An interesting research direction we have pursued under this framework has been to consider mapping symbolic dynamics onto neurodynamics, represented as neural automata. This representation theory, enables us to ask questions, such as, how does the brain implement Turing computations. Specifically, in this representation theory, neural automata result from the assignment of symbols and symbol strings to numbers, known as G\ {o}{d}{e}l encoding. Under this assignment symbolic computation becomes represented by trajectories of state vectors in a real phase space, that allows for statistical correlation analyses with real-world measurements and experimental data. However, these assignments are usually completely arbitrary. Hence, it makes sense to address the problem question of, which aspects of the dynamics observed under such a representation is intrinsic to the dynamics and which are not. In this study, we develop a formally rigorous mathematical framework for the investigation of symmetries and invariants of neural automata under different encodings. As a central concept we define patterns of equality for such systems. We consider different macroscopic observables, such as the mean activation level of the neural network, and ask for their invariance properties. Our main result shows that only step functions that are defined over those patterns of equality are invariant under recodings, while the mean activation is not. Our work could be of substantial importance for related regression studies of real-world measurements with neurosymbolic processors for avoiding confounding results that are dependant on a particular encoding and not intrinsic to the dynamics.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/TuringMachinegun/Turing_Neural_Networks"]}}
}

@article{rayyan-242085081,
  title={Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge},
  year={2024},
  author={Kricheli, Joshua Shay and Vo, Khoa and Datta, Aniruddha and Ozgur, Spencer and Paulo, Shakarian},
  abstract={Recent advances in Hierarchical Multi-label Classification (HMC), particularly neurosymbolic-based approaches, have demonstrated improved consistency and accuracy by enforcing constraints on a neural model during training. However, such work assumes the existence of such constraints a-priori. In this paper, we relax this strong assumption and present an approach based on Error Detection Rules (EDR) that allow for learning explainable rules about the failure modes of machine learning models. We show that these rules are not only effective in detecting when a machine learning classifier has made an error but also can be leveraged as constraints for HMC, thereby allowing the recovery of explainable constraints even if they are not provided. We show that our approach is effective in detecting machine learning errors and recovering constraints, is noise tolerant, and can function as a source of knowledge for neurosymbolic models on multiple datasets, including a newly introduced military vehicle recognition dataset.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/lab-v2/PyEDCR"]}}
}

@article{rayyan-242085088,
  title={CombiBench: Benchmarking LLM Capability for Combinatorial Mathematics},
  year={2025},
  author={Yang and Zhang, Jujian and Zhi, Lihong and Li, Jia and Zhengying, Junqi Liu, Liu and Lin, Xiaohan and Bayer, Jonas and Dillies, Yael and Jiang, Weijie and Liang, Xiaodan and Soletskyi, Roman and Wang, Haiming and Xie, Yunzhou and Xiong, Beibei and Zhengfeng},
  abstract={Neurosymbolic approaches integrating large language models with formal reasoning have recently achieved human-level performance on mathematics competition problems in algebra, geometry and number theory. In comparison, combinatorics remains a challenging domain, characterized by a lack of appropriate benchmarks and theorem libraries. To address this gap, we introduce CombiBench, a comprehensive benchmark comprising 100 combinatorial problems, each formalized in Lean 4 and paired with its corresponding informal statement. The problem set covers a wide spectrum of difficulty levels, ranging from middle school to IMO and university level, and span over ten combinatorial topics. CombiBench is suitable for testing IMO solving capabilities since it includes all IMO combinatorial problems since 2000 (except IMO 2004 P3 as its statement contain an images). Furthermore, we provide a comprehensive and standardized evaluation framework, dubbed Fine-Eval (for 𝐅 ill-in-the-blank 𝐢n L𝐞 an Evaluation), for formal mathematics. It accommodates not only proof-based problems but also, for the first time, the evaluation of fill-in-the-blank questions. Using Fine-Eval as the evaluation method and Kimina Lean Server as the backend, we benchmark several LLMs on CombiBench and observe that their capabilities for formally solving combinatorial problems remain limited. Among all models tested (none of which has been trained for this particular task), Kimina-Prover attains the best results, solving 7 problems (out of 100) under both ``with solution'' and ``without solution'' scenarios. We open source the benchmark dataset alongside with the code of the proposed evaluation method at https://github.com/MoonshotAI/CombiBench/.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/MoonshotAI/CombiBench/]"]}}
}

@article{rayyan-242085093,
  title={Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering},
  year={2020},
  author={Ma, Kaixin and Ilievski, Filip and Francis, Jonathan and Bisk, Yonatan and Nyberg, Eric and Alessandro, Oltramari},
  abstract={Recent developments in pre-trained neural language modeling have led to leaps in accuracy on commonsense question-answering benchmarks. However, there is increasing concern that models overfit to specific tasks, without learning to utilize external knowledge or perform general semantic reasoning. In contrast, zero-shot evaluations have shown promise as a more robust measure of a model's general reasoning abilities. In this paper, we propose a novel neuro-symbolic framework for zero-shot question answering across commonsense tasks. Guided by a set of hypotheses, the framework studies how to transform various pre-existing knowledge resources into a form that is most effective for pre-training models. We vary the set of language models, training regimes, knowledge sources, and data generation strategies, and measure their impact across tasks. Extending on prior work, we devise and compare four constrained distractor-sampling strategies. We provide empirical results across five commonsense question-answering tasks with data generated from five external knowledge resources. We show that, while an individual knowledge graph is better suited for specific tasks, a global knowledge graph brings consistent gains across different tasks. In addition, both preserving the structure of the task as well as generating fair and informative questions help language models learn more effectively.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Mayer123/HyKAS-CSKG"]}}
}

@article{rayyan-242085116,
  title={TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning},
  year={2024},
  author={Sanders, Kate and Weir, Nathaniel and Benjamin Van, Durme},
  abstract={It is challenging for models to understand complex, multimodal content such as television clips, and this is in part because video-language models often rely on single-modality reasoning and lack interpretability. To combat these issues we propose TV-TREES, the first multimodal entailment tree generator.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: [https://github.com/katesanders9/tv-trees]", "Paper: https://arxiv.org/pdf/2402.19467", "GitHub exists, but it is empty - so we need to ask author for more info", "The paper has mostly qualitative analysis. Brief quantitative analysis. "]}}
}

@article{rayyan-242085117,
  title={Tunable Neural Encoding of a Symbolic Robotic Manipulation Algorithm},
  year={2021},
  volume={15},
  author={Katz, G. E. and Akshay and Davis, G. P. and Gentili, R. J. and Reggia, J. A.},
  abstract={We present a neurocomputational controller for robotic manipulation based on the recently developed "neural virtual machine" (NVM). The NVM is a purely neural recurrent architecture that emulates a Turing-complete, purely symbolic virtual machine. We program the NVM with a symbolic algorithm that solves blocks-world restacking problems, and execute it in a robotic simulation environment. Our results show that the NVM-based controller can faithfully replicate the execution traces and performance levels of a traditional non-neural program executing the same restacking procedure. Moreover, after programming the NVM, the neurocomputational encodings of symbolic block stacking knowledge can be fine-tuned to further improve performance, by applying reinforcement learning to the underlying neural architecture.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC8712426/", "Some code has been released. One of the authors is from UMD", "Code: https://github.com/garrettkatz/poppy-muffin/tree/master/pybullet/tasks/pick_and_place"]}}
}

@article{rayyan-242085121,
  title={Guaranteed Conformance of Neurosymbolic Models to Natural Constraints},
  year={2022},
  author={Sridhar, Kaustubh and Dutta, Souradeep and Weimer, James and Insup, Lee},
  abstract={Deep neural networks have emerged as the workhorse for a large section of robotics and control applications, especially as models for dynamical systems. Such data-driven models are in turn used for designing and verifying autonomous systems. They are particularly useful in modeling medical systems where data can be leveraged to individualize treatment. In safety-critical applications, it is important that the data-driven model is conformant to established knowledge from the natural sciences. Such knowledge is often available or can often be distilled into a (possibly black-box) model. For instance, an F1 racing car should conform to Newton's laws (which are encoded within a unicycle model). In this light, we consider the following problem - given a model M and a state transition dataset, we wish to best approximate the system model while being a bounded distance away from M. We propose a method to guarantee this conformance. Our first step is to distill the dataset into a few representative samples called memories, using the idea of a growing neural gas. Next, using these memories we partition the state space into disjoint subsets and compute bounds that should be respected by the neural network in each subset. This serves as a symbolic wrapper for guaranteed conformance. We argue theoretically that this only leads to a bounded increase in approximation error; which can be controlled by increasing the number of memories. We experimentally show that on three case studies (Car Model, Drones, and Artificial Pancreas), our constrained neurosymbolic models conform to specified models (each encoding various constraints) with order-of-magnitude improvements compared to the augmented Lagrangian and vanilla training methods. Our code can be found at: https://github.com/kaustubhsridhar/Constrained\_{M}{o}{d}els},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2212.01346", "Code: https://github.com/kaustubhsridhar/Constrained_Models"]}}
}

@article{rayyan-242085128,
  title={Neuro-Symbolic Imitation Learning: Discovering Symbolic Abstractions for Skill Learning},
  year={2025},
  author={Keller, L. and Tanneberg, D. and Peters, J.},
  abstract={… To execute a neuro-symbolic policy, … neuro-symbolic framework by comparing it to baselines in three simulated robotic environments. Experimental results show that our neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2503.21406", "Paper Website available: https://hri-eu.github.io/NeuroSymbolicImitationLearning/", "No code link, but we can probably reach out and ask .", "Paper Website GH: https://github.com/HRI-EU/NeuroSymbolicImitationLearning"]}}
}

@article{rayyan-242085129,
  title={There and back again: extracting formal domains for controllable neurosymbolic story authoring},
  year={2023},
  author={Kelly, J. and Calderwood, A. and Wardrip-Fruin, N.},
  url={https://ojs.aaai.org/index.php/AIIDE/article/view/27502},
  abstract={Story generators using language models offer the automatic production of highly fluent narrative content, but they are hard to control and understand, seizing creative tasks that many …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: https://github.com/alex-calderwood/there-and-back/blob/main/README.md"]}}
}

@article{rayyan-242085131,
  title={LambdaBeam: Neural Program Search with Higher-Order Functions and Lambdas},
  year={2023},
  author={Shi, Kensen and Dai, Hanjun and Li, Wen-Ding and Ellis, Kevin and Charles, Sutton},
  abstract={Search is an important technique in program synthesis that allows for adaptive strategies such as focusing on particular search directions based on execution results. Several prior works have demonstrated that neural models are effective at guiding program synthesis searches. However, a common drawback of those approaches is the inability to handle iterative loops, higher-order functions, or lambda functions, thus limiting prior neural searches from synthesizing longer and more general programs. We address this gap by designing a search algorithm called LambdaBeam that can construct arbitrary lambda functions that compose operations within a given DSL. We create semantic vector representations of the execution behavior of the lambda functions and train a neural policy network to choose which lambdas to construct during search, and pass them as arguments to higher-order functions to perform looping computations. Our experiments show that LambdaBeam outperforms neural, symbolic, and LLM-based techniques in an integer list manipulation domain.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ellisk42/LambdaBeam"]}}
}

@article{rayyan-242085134,
  title={Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding},
  year={2018},
  author={Yi, Kexin and Wu, Jiajun and Gan, Chuang and Torralba, Antonio and Kohli, Pushmeet and Joshua, B. Tenenbaum},
  abstract={We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering (NS-VQA) system first recovers a structural scene representation from the image and a program trace from the question. It then executes the program on the scene representation to obtain an answer. Incorporating symbolic structure as prior knowledge offers three unique advantages. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model is more data- and memory-efficient: it performs well after learning on a small number of training data; it can also encode an image into a compact representation, requiring less storage than existing methods for offline question answering. Third, symbolic program execution offers full transparency to the reasoning process; we are thus able to interpret and diagnose each execution step.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/kexinyi/ns-vqa"]}}
}

@article{rayyan-242085140,
  title={NeuSyRE: Neuro-symbolic visual understanding and reasoning framework based on scene graph enrichment},
  year={2024},
  author={Khan, M. J. and Breslin, J. G. and Curry, E.},
  abstract={Exploring the potential of neuro-symbolic hybrid approaches offers promising avenues for … We present a loosely-coupled neuro-symbolic visual understanding and reasoning framework …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>[" jaleedkhan/neusire"]}}
}

@article{rayyan-242085143,
  title={KnowZRel: Common Sense Knowledge-based Zero-Shot Relationship Retrieval for Generalised Scene Graph Generation},
  year={2025},
  author={Khan, M. Jaleed and Breslin, John G. and Curry, Edward},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jaleedkhan/zsrr-sgg"]}}
}

@article{rayyan-242085145,
  title={A domain-agnostic neurosymbolic approach for big social data analysis: Evaluating mental health sentiment on social media during covid-19},
  year={2024},
  author={Khandelwal, V. and Gaur, M. and Kursuncu, U.},
  url={https://ieeexplore.ieee.org/abstract/document/10825174/?casa_token=HYFOGNJNAN8AAAAA:YXpZwiQ_yuK4M_P5xKB5ChvbTXiiMmdUPXkcUbaHo46ZUhAfm-2yxTi0uD3nPL8zJQ89puIWGPYw4Q},
  abstract={… We introduce a neurosymbolic method that integrates neural networks with symbolic knowledge … This study demonstrates the benefit of neurosymbolic methods in interpreting text in a …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://arxiv.org/pdf/2411.07163, Link: https://ieeexplore.ieee.org/document/10825174, ", "GitHub: https://github.com/khvedant02/Neurosymbolic-Mental-Health-Monitoring-COVID19"]}}
}

@article{rayyan-242085146,
  title={A Neurosymbolic Fast and Slow Architecture for Graph Coloring},
  year={2024},
  author={Khandelwal, V. and Pallagani, V. and Srivastava, B.},
  abstract={Constraint Satisfaction Problems (CSPs) present significant challenges to artificial intelligence due to their intricate constraints and the necessity for precise solutions. Existing symbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://arxiv.org/abs/2412.01752", "Code: https://github.com/khvedant02/CSP-SOFAI-Instance"]}}
}

@article{rayyan-242085147,
  title={NeuroLit Navigator: A Neurosymbolic Approach to Scholarly Article Searches for Systematic Reviews},
  year={2025},
  author={Khandelwal, V. and Roy, K. and Lookingbill, V.},
  abstract={The introduction of Large Language Models (LLMs) has significantly impacted various fields, including education, for example, by enabling the creation of personalized learning …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/tdurieux/anonymous_github/]"]}}
}

@article{rayyan-242085153,
  title={Out-of-Distribution Detection with Logical Reasoning (Extended Abstract)},
  year={2024},
  volume={14992},
  author={Kirchheim, Konstantin and Tim, Gonschorek and Frank, Ortmeier},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Machine learning models often only generalize reliably to samples from their training distribution which motivates out-of-distribution (OOD) detection in safety-critical applications. Current OOD detection methods, however, tend to be domain agnostic and are incapable of incorporating prior knowledge about the structure of the training distribution. To address this limitation, we introduce a novel, neuro-symbolic OOD detection algorithm that combines a deep learning-based perception system with a first-order logic-based knowledge representation. A reasoning system uses this knowledge base at run-time to infer whether inputs are consistent with prior knowledge about the training distribution. This not only enhances performance but also fosters a level of explainability that is particularly beneficial in safety-critical contexts.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: https://github.com/kkirchheim/logic-ood", "Paper: https://openaccess.thecvf.com/content/WACV2024/papers/Kirchheim_Out-of-Distribution_Detection_With_Logical_Reasoning_WACV_2024_paper.pdf", "Link: https://ieeexplore.ieee.org/document/10483945", "Link: https://dl.acm.org/doi/10.1007/978-3-031-70893-0_29"]}}
}

@article{rayyan-242085155,
  title={What Do Hebbian Learners Learn? Reduction Axioms for Iterated Hebbian Learning},
  year={2024},
  author={Kisby, Caleb Schultz and Blanco Saul, A. and Moss Lawrence, S.},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={This paper is a contribution to neural network semantics, a foundational framework for neuro-symbolic AI. The key insight of this theory is that logical operators can be mapped to operators on neural network states. In this paper, we do this for a neural network learning operator. We map a dynamic operator [ phi] to iterated Hebbian learning, a simple learning policy that updates a neural network by repeatedly applying Hebb's learning rule until the net reaches a fixed-point. Our main result is that we can ``translate away '' [ f]-formulas via reduction axioms. This means that completeness for the logic of iterated Hebbian learning follows from completeness of the base logic. These reduction axioms also provide (1) a human-interpretable description of iterated Hebbian learning as a kind of plausibility upgrade, and (2) an approach to building neural networks with guarantees on what they can learn.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ais-climber/AAAI2024"]}}
}

@article{rayyan-242085157,
  title={A neural-symbolic architecture for inverse graphics improved by lifelong meta-learning},
  year={2019},
  author={Kissner, M. and Mayer, H.},
  abstract={We follow the idea of formulating vision as inverse graphics and propose a new type of element for this task, a neural-symbolic capsule. It is capable of de-rendering a scene into …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Kayzaks/VividNet"]}}
}

@article{rayyan-242085161,
  title={Compositional Program Generation for Few-Shot Systematic Generalization},
  year={2024},
  author={Klinger, Tim and Liu, Luke and Soham, Dan and Crouse, Maxwell and Ram, Parikshit and Gray, Alexander},
  abstract={Compositional generalization is a key ability of humans that enables us to learn new concepts from only a handful examples. Neural machine learning models, including the now ubiquitous Transformers, struggle to generalize in this way, and typically require thousands of examples of a concept during training in order to generalize meaningfully. This difference in ability between humans and artificial neural architectures, motivates this study on a neuro-symbolic architecture called the Compositional Program Generator (CPG). CPG has three key features: 𝑚𝑜𝑑𝑢𝑙𝑎𝑟𝑖𝑡𝑦, 𝑐𝑜𝑚𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛, and 𝑎𝑏𝑠𝑡𝑟𝑎𝑐𝑡𝑖𝑜𝑛, in the form of grammar rules, that enable it to generalize both systematically to new concepts in a few-shot manner, as well as productively by length on various sequence-to-sequence language tasks. For each input, CPG uses a grammar of the input language and a parser to generate a parse in which each grammar rule is assigned its own unique semantic module, a probabilistic copy or substitution program. Instances with the same parse are always processed with the same composed modules, while those with different parses may be processed with different modules. CPG learns parameters for the modules and is able to learn the semantics for new rules and types incrementally, without forgetting or retraining on rules it's already seen. It achieves perfect generalization on both the SCAN and COGS benchmarks using just 14 examples for SCAN and 22 examples for COGS - state-of-the-art accuracy with a 1000x improvement in sample efficiency.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/IBM/cpg, also need https://github.com/lark-parser/lark"]}}
}

@article{rayyan-242085165,
  title={Neural Proof Nets},
  year={2020},
  author={Kogkalidis, Konstantinos and Moortgat, Michael and Moot, Richard},
  abstract={Linear logic and the linear λ-calculus have a long standing tradition in the study of natural language form and meaning. Among the proof calculi of linear logic, proof nets are of particular interest, offering an attractive geometric representation of derivations that is unburdened by the bureaucratic complications of conventional prooftheoretic formats. Building on recent advances in set-theoretic learning, we propose a neural variant of proof nets based on Sinkhorn networks, which allows us to translate parsing as the problem of extracting syntactic primitives and permuting them into alignment. Our methodology induces a batch-efficient, end-to-end differentiable architecture that actualizes a formally grounded yet highly efficient neuro-symbolic parser. We test our approach on ÆThel, a dataset of type-logical derivations for written Dutch, where it manages to correctly transcribe raw text sentences into proofs and terms of the linear λ-calculus with an accuracy of as high as 70%.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["github.com/konstantinosKokos/neural-proof-nets"]}}
}

@article{rayyan-242085166,
  title={Probabilistic Mission Design in Neuro-Symbolic Systems},
  year={2024},
  author={Kohaut, S. and Flade, B. and Ochs, D. and Dhami, D. S. and Eggert, J.},
  abstract={… To tackle these challenges, we present a probabilistic and neuro-symbolic architecture to encode legal frameworks and expert knowledge over uncertain spatial relations and noisy …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/HRI-EU/ProMis"]}}
}

@article{rayyan-242085167,
  title={The Constitutional Filter},
  year={2024},
  author={Kohaut, Simon and Divo, Felix and Flade, Benedict and Devendra Singh, Dhami and Eggert, Julian and Kersting, Kristian},
  abstract={Predictions in environments where a mix of legal policies, physical limitations, and operational preferences impacts an agent's motion are inherently difficult. Since Neuro-Symbolic systems allow for differentiable information flow between deep learning and symbolic building blocks, they present a promising avenue for expressing such high-level constraints. While prior work has demonstrated how to establish novel planning setups, e.g., in advanced aerial mobility tasks, their application in prediction tasks has been underdeveloped. We present the Constitutional Filter (CoFi), a novel filter architecture leveraging a Neuro-Symbolic representation of an agent's rules, i.e., its constitution, to (i) improve filter accuracy, (ii) leverage expert knowledge, (iii) incorporate deep learning architectures, and (iv) account for uncertainties in the environments through probabilistic spatial relations. CoFi follows a general, recursive Bayesian estimation setting, making it compatible with a vast landscape of estimation techniques such as Particle Filters. To underpin the advantages of CoFi, we validate its performance on real-world marine data from the Automatic Identification System and official Electronic Navigational Charts.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://www.github.com/HRI-EU/ProMis/tree/cofi"]}}
}

@article{rayyan-242085185,
  title={Formal verification of parameterised neural-symbolic multi-agent systems},
  year={2024},
  author={Kouvaros, P. and Botoeva, E.},
  url={https://ceur-ws.org/Vol-3819/short1.pdf},
  abstract={We study the problem of verifying multi-agent systems composed of arbitrarily many neural-symbolic agents. We introduce a novel parameterised model, where the parameter denotes …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://www.ijcai.org/proceedings/2024/0012.pdf", "Paper: https://ceur-ws.org/Vol-3819/short1.pdf", "Code: https://github.com/NeuralMAS/venmas"]}}
}

@article{rayyan-242085192,
  title={Affordance embeddings for situated language understanding},
  year={2022},
  volume={5},
  author={Krishnaswamy, N. and Pustejovsky, J.},
  abstract={Much progress in AI over the last decade has been driven by advances in natural language processing technology, in turn facilitated by large datasets and increased computation power used to train large neural language models. These systems demonstrate apparently sophisticated linguistic understanding or generation capabilities, but often fail to transfer their skills to situations they have not encountered before. We argue that computational situated grounding of linguistic information to real or simulated scenarios provide a solution to some of these learning challenges by creating situational representations that both serve as a formal model of the salient phenomena, and contain rich amounts of exploitable, task-appropriate data for training new, flexible computational models. We approach this problem from a neurosymbolic perspective, using multimodal contextual modeling of interactive situations, events, and object properties, particularly afforded behaviors, and habitats, the situations that condition them. These properties are tightly coupled to processes of situated grounding, and herein we discuss we combine neural and symbolic methods with multimodal simulations to create a platform, VoxWorld, for modeling communication in context, and we demonstrate how neural embedding vectors of symbolically-encoded object affordances facilitate transferring knowledge of objects and situations to novel entities, and learning how to recognize and generate linguistic and gestural denotations.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/VoxML/VoxSim"]}}
}

@article{rayyan-242085197,
  title={AutoSNAP: Automatically Learning Neural Architectures for Instrument Pose Estimation},
  year={2020},
  author={Kügler, David and Uecker, Marc and Kuijper, Arjan and Mukhopadhyay, Anirban},
  abstract={Despite recent successes, the advances in Deep Learning have not yet been fully translated to Computer Assisted Intervention (CAI) problems such as pose estimation of surgical instruments. Currently, neural architectures for classification and segmentation tasks are adopted ignoring significant discrepancies between CAI and these tasks. We propose an automatic framework (AutoSNAP) for instrument pose estimation problems, which discovers and learns the architectures for neural networks. We introduce 1) an efficient testing environment for pose estimation, 2) a powerful architecture representation based on novel Symbolic Neural Architecture Patterns (SNAPs), and 3) an optimization of the architecture using an efficient search scheme. Using AutoSNAP, we discover an improved architecture (SNAPNet) which outperforms both the hand-engineered i3PosNet and the state-of-the-art architecture search method DARTS.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/MECLabTUDA/AutoSNAP"]}}
}

@article{rayyan-242085203,
  title={Semantic similarity and machine learning with ontologies},
  year={2021},
  volume={22},
  number={4},
  author={Kulmanov, M. and Smaili, F. Z. and Gao, X. and Hoehndorf, R.},
  abstract={Ontologies have long been employed in the life sciences to formally represent and reason over domain knowledge and they are employed in almost every major biological database. Recently, ontologies are increasingly being used to provide background knowledge in similarity-based analysis and machine learning models. The methods employed to combine ontologies and machine learning are still novel and actively being developed. We provide an overview over the methods that use ontologies to compute similarity and incorporate them in machine learning methods; in particular, we outline how semantic similarity measures and ontology embeddings can exploit the background knowledge in ontologies and how ontologies can provide constraints that improve machine learning models. The methods and experiments we describe are available as a set of executable notebooks, and we also provide a set of slides and additional resources at https://github.com/bio-ontology-research-group/machine-learning-with-ontologies.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/bio-ontology-research-group/machine-learning-with-ontologies"]}}
}

@article{rayyan-242085204,
  title={Protein function prediction as approximate semantic entailment},
  year={2024},
  volume={6},
  number={2},
  author={Kulmanov, Maxat and Guzman-Vega Francisco, J. and Duek, Roggli Paula and Lydie, Lane and Arold Stefan, T. and Robert, Hoehndorf},
  abstract={The Gene Ontology (GO) is a formal, axiomatic theory with over 100,000 axioms that describe the molecular functions, biological processes and cellular locations of proteins in three subontologies. Predicting the functions of proteins using the GO requires both learning and reasoning capabilities in order to maintain consistency and exploit the background knowledge in the GO. Many methods have been developed to automatically predict protein functions, but effectively exploiting all the axioms in the GO for knowledge-enhanced learning has remained a challenge. We have developed DeepGO-SE, a method that predicts GO functions from protein sequences using a pretrained large language model. DeepGO-SE generates multiple approximate models of GO, and a neural network predicts the truth values of statements about protein functions in these approximate models. We aggregate the truth values over multiple models so that DeepGO-SE approximates semantic entailment when predicting protein functions. We show, using several benchmarks, that the approach effectively exploits background knowledge in the GO and improves protein function prediction compared to state-of-the-art methods. Deep learning language models have proved useful for both natural language and protein modelling. Similar to semantics in natural language, protein functions are complex and depend on the context of their environment, rather than on the similarity of sequences. Kulmanov and colleagues present an approach to frame function prediction as semantic entailment using a neuro-symbolic model to augment a large protein language model.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/bio-ontology-research-group/deepgo2"]}}
}

@article{rayyan-242085213,
  title={A Probabilistic Neuro-symbolic Layer for Algebraic Constraint Satisfaction},
  year={2025},
  author={Kurscheidt, L. and Morettin, P. and Sebastiani, R.},
  abstract={In safety-critical applications, guaranteeing the satisfaction of constraints over continuous environments is crucial, eg, an autonomous agent should never crash into obstacles or go off-…},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/april-tools/pal"]}}
}

@article{rayyan-242085236,
  title={Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment},
  year={2024},
  author={Okamoto, Lauren and Paritosh, Parmar},
  abstract={Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers. Annotated training data and code: https://github.com/laurenok24/NSAQA.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: https://github.com/laurenok24/NSAQA", "Link: https://arxiv.org/pdf/2403.13798"]}}
}

@article{rayyan-242085239,
  title={HOUDINI: Lifelong Learning as Program Synthesis},
  year={2018},
  author={Valkov, Lazar and Chaudhari, Dipak and Srivastava, Akash and Sutton, Charles and Swarat, Chaudhuri},
  abstract={We present a neurosymbolic framework for the lifelong learning of algorithmic tasks that mix perception and procedural reasoning. Reusing high-level concepts across domains and learning complex procedures are key challenges in lifelong learning. We show that a program synthesis approach that combines gradient descent with combinatorial search over programs can be a more effective response to these challenges than purely neural methods. Our framework, called HOUDINI, represents neural networks as strongly typed, differentiable functional programs that use symbolic higher-order combinators to compose a library of neural functions. Our learning algorithm consists of: (1) a symbolic program synthesizer that performs a type-directed search over parameterized programs, and decides on the library functions to reuse, and the architectures to combine them, while learning a sequence of tasks; and (2) a neural module that trains these programs using stochastic gradient descent. We evaluate HOUDINI on three benchmarks that combine perception with the algorithmic tasks of counting, summing, and shortest-path computation. Our experiments show that HOUDINI transfers high-level concepts more effectively than traditional transfer learning and progressive neural networks, and that the typed representation of networks significantly accelerates the search.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/1804.00218", "Code: https://github.com/trishullab/houdini"]}}
}

@article{rayyan-242085252,
  title={Diakop: Dialogue-based knowledge-oriented programming for neural-symbolic knowledge base question answering},
  year={2024},
  author={Lee, Z. and Huang, Z. and Yao, Z. and Liu, J. and Xin, A. and Hou, L.},
  abstract={We present Dialogue-based Knowledge-oriented Programming system (DiaKoP), a system with a chat interface designed for multi-turn knowledge base question answering (KBQA). …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/THU-KEG/DiaKoP"]}}
}

@article{rayyan-242085255,
  title={A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic},
  year={2024},
  author={Smet, Lennert De and Pedro Zuidberg Dos, Martires},
  abstract={As illustrated by the success of integer linear programming, linear integer arithmetic is a powerful tool for modelling combinatorial problems. Furthermore, the probabilistic extension of linear programming has been used to formulate problems in neurosymbolic AI. However, two key problems persist that prevent the adoption of neurosymbolic techniques beyond toy problems. First, probabilistic inference is inherently hard, #P-hard to be precise. Second, the discrete nature of integers renders the construction of meaningful gradients challenging, which is problematic for learning. In order to mitigate these issues, we formulate linear arithmetic over integer-valued random variables as tensor manipulations that can be implemented in a straightforward fashion using modern deep learning libraries. At the core of our formulation lies the observation that the addition of two integer-valued random variables can be performed by adapting the fast Fourier transform to probabilities in the log-domain. By relying on tensor operations we obtain a differentiable data structure, which unlocks, virtually for free, gradient-based learning. In our experimental validation we show that tensorising probabilistic linear integer arithmetic and leveraging the fast Fourier transform allows us to push the state of the art by several orders of magnitude in terms of inference and learning times.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ML-KULeuven/probabilistic-arithmetic"]}}
}

@article{rayyan-242085266,
  title={Closed loop neural-symbolic learning via integrating neural perception, grammar parsing, and symbolic reasoning},
  year={2020},
  author={Li, Q. and Huang, S. and Hong, Y. and Chen, Y.},
  url={https://proceedings.mlr.press/v119/li20f.html},
  abstract={… Prior methods learn the neural-symbolic models using … these issues and close the loop of neural-symbolic learning by (1) … conducted on two weakly-supervised neuralsymbolic tasks: (1) …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://liqing-ustc.github.io/NGS."]}}
}

@article{rayyan-242085267,
  title={Leveraging LLMs for Hypothetical Deduction in Logical Inference: A Neuro-Symbolic Approach},
  year={2024},
  author={Li, Q. and Li, J. and Liu, T. and Zeng, Y. and Cheng, M. and Huang, W.},
  abstract={… To mitigate these issues, we introduce LINA, a LLM-driven neuro-symbolic approach for faithful logical reasoning. By enabling an LLM to autonomously perform the transition from …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/wufeiwuwoshihua/nshy"]}}
}

@article{rayyan-242085275,
  title={A Competence-aware Curriculum for Visual Concepts Learning via Question Answering},
  year={2020},
  author={Li, Qing and Huang, Siyuan and Hong, Yining and Song-Chun, Zhu},
  abstract={Humans can progressively learn visual concepts from easy to hard questions. To mimic this efficient learning ability, we propose a competence-aware curriculum for visual concept learning in a question-answering manner. Specifically, we design a neural-symbolic concept learner for learning the visual concepts and a multi-dimensional Item Response Theory (mIRT) model for guiding the learning process with an adaptive curriculum. The mIRT effectively estimates the concept difficulty and the model competence at each learning step from accumulated model responses. The estimated concept difficulty and model competence are further utilized to select the most profitable training samples. Experimental results on CLEVR show that with a competence-aware curriculum, the proposed method achieves state-of-the-art performances with superior data efficiency and convergence speed. Specifically, the proposed model only uses 40% of training data and converges three times faster compared with other state-of-the-art methods.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2007.01499", "Website: https://liqing.io/CL-mIRT/", "Code: https://github.com/liqing-ustc/CL-mIRT", "Code was available looks like it has been removed - we can contact author for access. "]}}
}

@article{rayyan-242085276,
  title={NEURAL-SYMBOLIC RECURSIVE MACHINE FOR SYSTEMATIC GENERALIZATION},
  year={2024},
  author={Li, Qing and Zhu, Yixin and Liang, Yitao and Wu, Ying Nian and Zhu, Song-Chun and Huang, Siyuan},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200541381&partnerID=40&md5=4f4bf37abc81e23e0b387336b1bab906},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://par.nsf.gov/servlets/purl/10561839 , Paper: https://arxiv.org/pdf/2210.01603", "Code: https://github.com/liqing-ustc/nsr", "Website: https://liqing.io/NSR/"]}}
}

@article{rayyan-242085278,
  title={Combining Formal and Informal Information in Bayesian Program Analysis via Soft Evidences},
  year={2025},
  volume={9},
  author={Li, Tianchi and Xin, Zhang},
  abstract={We propose a neural-symbolic style of program analysis that systematically incorporates informal information in a Datalog program analysis. The analysis is converted into a probabilistic analysis by attaching probabilities to its rules. And its output becomes a ranking of possible alarms based on their probabilities. We apply a neural network to judge how likely an analysis fact holds based on informal information such as variable names and String constants. This information is encoded as a soft evidence in the probabilistic analysis, which is a “noisy sensor” of the fact. With this information, the probabilistic analysis produces a better ranking of the alarms. We have demonstrated the effectiveness of our approach by improving a pointer analysis based on variable names on eight Java benchmarks, and a taint analysis that considers inter-component communication on eight Android applications. On average, our approach has improved the inversion count between true alarms and false alarms, mean rank of true alarms, and median rank of true alarms by 55.4%, 44.9%, and 58% on the pointer analysis, and 67.2%, 44.7%, and 37.6% on the taint analysis respectively. We also demonstrated the generality of our soft evidence mechanism by improving a taint analysis and an interval analysis for C programs using dynamic information from program executions.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://dl.acm.org/doi/pdf/10.1145/3720508", "This is currently accepted to \"OOPSLA 2025:\" - so we may need to ask authors for code. "]}}
}

@article{rayyan-242085280,
  title={Symbolic Neural Ordinary Differential Equations},
  year={2025},
  author={Li, X. and Zhao, C. and Zhang, X. and Duan, X.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/34037},
  abstract={Differential equations are widely used to describe complex dynamical systems with evolving parameters in nature and engineering. Effectively learning a family of maps from the …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2503.08059 ", "Link; https://ojs.aaai.org/index.php/AAAI/article/view/34037", "No code, but was published recently april 2025", "So we should ask authors. "]}}
}

@article{rayyan-242085281,
  title={AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension},
  year={2022},
  author={Li, Xiao and Gong, Cheng and Ziheng, Chen and Yawei, Sun and Yuzhong, Qu},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Recent machine reading comprehension datasets such as ReClor and LogiQA require performing logical reasoning over text. Conventional neural models are insufficient for logical reasoning, while symbolic reasoners cannot directly apply to text. To meet the challenge, we present a neural-symbolic approach which, to predict an answer, passes messages over a graph representing logical relations between text units. It incorporates an adaptive logic graph network (AdaLoGN) which adaptively infers logical relations to extend the graph and, essentially, realizes mutual and iterative reinforcement between neural and symbolic reasoning. We also implement a novel subgraph-to-node message passing mechanism to enhance context-option interaction for answering multiple-choice questions. Our approach shows promising results on ReClor and LogiQA.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://aclanthology.org/2022.acl-long.494/", "Code: https://github.com/nju-websoft/AdaLoGN/blob/main/README.md", "Paper: https://arxiv.org/abs/2203.08992"]}}
}

@article{rayyan-242085282,
  title={Perspective Plane Program Induction from a Single Image},
  year={2020},
  author={Li, Yikai and Jiayuan, Mao and Xiuming, Zhang and Freeman William, T. and Tenenbaum Joshua, B. and Jiajun, Wu},
  publisher={IEEE COMPUTER SOC},
  abstract={We study the inverse graphics problem of inferring a holistic representation for natural images. Given an input image, our goal is to induce a neuro-symbolic, program-like representation that jointly models camera poses, object locations, and global scene structures. Such high-level, holistic scene representations further facilitate low-level image manipulation tasks such as inpainting. We formulate this problem as jointly finding the camera pose and scene structure that best describe the input image. The benefits of such joint inference are two-fold: scene regularity serves as a new cue for perspective correction, and in turn, correct perspective correction leads to a simplified scene structure, similar to how the correct shape leads to the most regular texture in shape from texture. Our proposed framework, Perspective Plane Program Induction (P31), combines search-based and gradient-based algorithms to efficiently solve the problem. P31 outperforms a set of baselines on a collection of Internet images, across tasks including camera pose estimation, global structure inference, and down-stream image manipulation tasks.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2006.14708", "Website: http://p3i.csail.mit.edu/", "Code: https://github.com/42x00/p3i/"]}}
}

@article{rayyan-242085283,
  title={R2G: Reasoning to Ground in 3D Scenes},
  year={2024},
  author={Li, Yixuan and Wang, Zan and Liang, Wei},
  abstract={We propose Reasoning to Ground (R2G), a neural symbolic model that grounds the target objects within 3D scenes in a reasoning manner. In contrast to prior works, R2G explicitly models the 3D scene with a semantic concept-based scene graph; recurrently simulates the attention transferring across object entities; thus makes the process of grounding the target objects with the highest probability interpretable. Specifically, we respectively embed multiple object properties within the graph nodes and spatial relations among entities within the edges, utilizing a predefined semantic vocabulary. To guide attention transferring, we employ learning or prompting-based methods to analyze the referential utterance and convert it into reasoning instructions within the same semantic space. In each reasoning round, R2G either (1) merges current attention distribution with the similarity between the instruction and embedded entity properties or (2) shifts the attention across the scene graph based on the similarity between the instruction and embedded spatial relations. The experiments on Sr3D/Nr3D benchmarks show that R2G achieves a comparable result with the prior works while maintaining improved interpretability, breaking a new path for 3D language grounding.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2408.13499", "Website: https://sites.google.com/view/reasoning-to-ground ", "Code: https://github.com/yixxuan-li/R2G"]}}
}

@article{rayyan-242085284,
  title={A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text},
  year={2023},
  author={Li, Yunxin and Baotian, Hu and Yuxin, Ding and Lin, Ma and Min, Zhang},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Pretrained Vision-Language Models (VLMs) have achieved remarkable performance in image retrieval from text. However, their performance drops drastically when confronted with linguistically complex texts that they struggle to comprehend. Inspired by the Divide-and-Conquer (Smith, 1985) algorithm and dualprocess theory (Groves and Thompson, 1970), in this paper, we regard linguistically complex texts as compound proposition texts composed of multiple simple proposition sentences and propose an end-to-end Neural Divide-and-Conquer Reasoning framework, dubbed NDCR. It contains three main components: 1) Divide: a proposition generator divides the compound proposition text into simple proposition sentences and produces their corresponding representations, 2) Conquer: a pretrained VLMsbased visual-linguistic interactor achieves the interaction between decomposed proposition sentences and images, 3) Combine: a neural-symbolic reasoner combines the above reasoning states to obtain the final solution via a neural logic reasoning approach. According to the dual-process theory, the visual-linguistic interactor and neural-symbolic reasoner could be regarded as analogical reasoning System 1 and logical reasoning System 2. We conduct extensive experiments on a challenging image retrieval from contextual descriptions data set. Experimental results and analyses indicate NDCR significantly improves performance in the complex image-text reasoning problem. Code link: https://github.com/YunxinLi/NDCR.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://aclanthology.org/2023.acl-long.909/", "Paper: https://aclanthology.org/2023.acl-long.909.pdf", "Code: https://github.com/YunxinLi/NDCR"]}}
}

@article{rayyan-242085286,
  title={Scallop: A language for neurosymbolic programming},
  year={2023},
  author={Li, Z. and Huang, J. and Naik, M.},
  abstract={We present Scallop, a language which combines the benefits of deep learning and logical reasoning. Scallop enables users to write a wide range of neurosymbolic applications and …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2304.04812", "GitHub: https://github.com/scallop-lang/scallop"]}}
}

@article{rayyan-242085291,
  title={Learning with Logical Constraints but without Shortcut Satisfaction},
  year={2024},
  author={Li, Zenan and Liu, Zehua and Yao, Yuan and Xu, Jingwei and Chen, Taolue and Ma, Xiaoxing and Lü, Jian},
  abstract={Recent studies in neuro-symbolic learning have explored the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In this paper, we present a new framework for learning with logical constraints. Specifically, we address the shortcut satisfaction issue by introducing dual variables for logical connectives, encoding how the constraint is satisfied. We further propose a variational framework where the encoded logical constraint is expressed as a distributional loss that is compatible with the model's original training loss. The theoretical analysis shows that the proposed approach bears salient properties, and the experimental evaluations demonstrate its superior performance in both model generalizability and constraint satisfaction.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2403.00329", "Code: https://github.com/SoftWiser-group/NeSy-without-Shortcuts"]}}
}

@article{rayyan-242085292,
  title={SOFTENED SYMBOL GROUNDING FOR NEUROSYMBOLIC SYSTEMS},
  year={2023},
  author={Li, Zenan and Yao, Yuan and Chen, Taolue and Xu, Jingwei and Cao, Chun and Ma, Xiaoxing and Lü, Jian},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165135133&partnerID=40&md5=35001553676e23c6536a56b9dacb057b},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/abs/2403.00323", "Code: https://github.com/SoftWiser-group/Soften-NeSy-learning"]}}
}

@article{rayyan-242085295,
  title={PST: Improving Quantitative Trading via Program Sketch-based Tuning},
  year={2024},
  author={Li, Zhiming and Jiang, Junzhe and Cao, Yushi and Cui, Aixin and Wu, Bozhi and Li, Bo and Liu, Yang and Sun, Dongning},
  abstract={Deep reinforcement learning (DRL) has revolutionized quantitative finance by achieving decent performance without significant human expert knowledge. Despite its achievements, we observe that the current state-of-the-art DRL models are still ineffective in identifying the market trend, causing them to miss good trading opportunities or suffer from large drawdowns when encountering market crashes. To tackle this limitation, a natural idea is to embed human expert knowledge regarding the market trend. Whereas, such knowledge is abstract and hard to be quantified. In this paper, we propose a universal neuro-symbolic tuning framework, called program sketch-based tuning (PST). Particularly, PST first proposes using a novel symbolic program sketch to embed the abstract human expert knowledge of market trends. Then we utilize the program sketch to tune a trained DRL policy according to the different market trend of the moment. Finally, in order to optimize this neural-symbolic framework, we propose a novel hybrid optimization method. Extensive evaluations on two popular quantitative trading tasks demonstrate that PST can significantly enhance the performance of previous state-of-the-art DRL strategies while being extremely lightweight.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2310.05551v2", "The implementation is available at: https://sites.google.com/view/pst-kdd24", "Code: https://github.com/unclebob7/PST-KDD24"]}}
}

@article{rayyan-242085296,
  title={Calibrating Concepts and Operations: Towards Symbolic Reasoning on Real Images},
  year={2021},
  author={Li, Zhuowan and Elias, Stengel-Eskin and Yixiao, Zhang and Cihang, Xie and Quan, Tran and Benjamin, Van Durme and Alan, Yuille},
  publisher={IEEE},
  abstract={While neural symbolic methods demonstrate impressive performance in visual question answering on synthetic images, their performance suffers on real images. We identify that the long-tail distribution of visual concepts and unequal importance of reasoning steps in real data are the two key obstacles that limit the models' real-world potentials. To address these challenges, we propose a new paradigm, Calibrating Concepts and Operations (CCO), which enables neural symbolic models to capture underlying data characteristics and to reason with hierarchical importance. Specifically, we introduce an executor with learnable concept embedding magnitudes for handling distribution imbalance, and an operation calibrator for highlighting important operations and suppressing redundant ones. Our experiments show CCO substantially boosts the performance of neural symbolic methods on real images. By evaluating models on the real world dataset GQA, CCO helps the neural symbolic method NSCL outperforms its vanilla counterpart by 9.1% (from 47.0% to 56.1%); this result also largely reduces the performance gap between symbolic and non-symbolic methods. Additionally, we create a perturbed test set for better understanding and analyzing model performance on real images. Code is available at https://lizw14.github.io/project/ccosr.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Lizw14/CaliCO.git"]}}
}

@article{rayyan-242085297,
  title={Relational Programming with Foundation Models},
  year={2024},
  author={Li, Ziyang and Jiani, Huang and Jason, Liu and Felix, Zhu and Eric, Zhao and William, Dodds and Neelay, Velingker and Rajeev, Alur and Mayur, Naik},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={Foundation models have vast potential to enable diverse AI applications. The powerful yet incomplete nature of these models has spurred a wide range of mechanisms to augment them with capabilities such as in-context learning, information retrieval, and code interpreting. We propose VIEIRA, a declarative framework that unifies these mechanisms in a general solution for programming with foundation models. VIEIRA follows a probabilistic relational paradigm and treats foundation models as stateless functions with relational inputs and outputs. It supports neuro-symbolic applications by enabling the seamless combination of such models with logic programs, as well as complex, multi-modal applications by streamlining the composition of diverse sub-models. We implement VIEIRA by extending the SCALLOP compiler with a foreign interface that supports foundation models as plugins. We implement plugins for 12 foundation models including GPT, CLIP, and SAM. We evaluate VIEIRA on 9 challenging tasks that span language, vision, and structured and vector databases. Our evaluation shows that programs in VIEIRA are concise, can incorporate modern foundation models, and have comparable or better accuracy than competitive baselines.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/scalloplang/scallop."]}}
}

@article{rayyan-242085298,
  title={LLM-Assisted Static Analysis for Detecting Security Vulnerabilities},
  year={2024},
  author={Li, Ziyang and Dutta, Saikat and Naik, Mayur},
  abstract={Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or LLMs) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose IRIS, a neuro-symbolic approach that systematically combines LLMs with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, IRIS leverages LLMs to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, CWE-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool CodeQL detects only 27 of these vulnerabilities whereas IRIS with GPT-4 detects 55 (+28) and improves upon CodeQL's average false discovery rate by 5% points. Furthermore, IRIS identifies 6 previously unknown vulnerabilities which cannot be found by existing tools.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/iris-sast/iris"]}}
}

@article{rayyan-242085320,
  title={Towards collaborative neural-symbolic graph semantic parsing via uncertainty},
  year={2022},
  author={Lin, Z. and Liu, J. Z. and Shang, J.},
  url={https://par.nsf.gov/servlets/purl/10345521},
  abstract={… In this work, we aim to develop a simple yet principled neural-symbolic approach for graph semantic parsing to address long-tail generalization, which leverages the information from an …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/google/uncertainty-baselines/tree/main/baselines/t5"]}}
}

@article{rayyan-242085321,
  title={Neural-symbolic inference for robust autoregressive graph parsing via compositional uncertainty quantification},
  year={2023},
  author={Lin, Z. and Liu, J. and Shang, J.},
  abstract={… the compositionality aspects of neural-symbolic inference helps the … principled framework for neural-symbolic graph parsing that … weakness of previous neuralsymbolic methods in OOD …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/google/uncertainty-baselines/tree/main/baselines/t5/data/deepbank"]}}
}

@article{rayyan-242085324,
  title={End-to-End Neuro-Symbolic Reinforcement Learning with Textual Explanations},
  year={2024},
  author={Luo, Lirui and Zhang, Guoxi and Xu, Hongming and Yang, Yaodong and Fang, Cong and Qing, Li},
  abstract={Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. NS-RL entails structured state representations for tasks with visual observations, but previous methods cannot refine the structured states with rewards due to a lack of efficiency. Accessibility also remains an issue, as extensive domain knowledge is required to interpret symbolic policies. In this paper, we present a neuro-symbolic framework for jointly learning structured states and symbolic policies, whose key idea is to distill the vision foundation model into an efficient perception module and refine it during policy learning. Moreover, we design a pipeline to prompt GPT-4 to generate textual explanations for the learned policies and decisions, significantly reducing users' cognitive load to understand the symbolic policies. We verify the efficacy of our approach on nine Atari tasks and present GPT-generated explanations for policies and decisions.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ins-rl/insight"]}}
}

@article{rayyan-242085325,
  title={Out-of-distribution generalization by neural-symbolic joint training},
  year={2023},
  author={Liu, A. and Xu, H. and den Broeck, G. Van and Liang, Y.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/26444},
  abstract={… ), we propose NTOC , a neural-symbolic joint training method that learns invariant features in … Furthermore, we demonstrate that our NTOC out-performs NNs and neuralsymbolic models …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/sbx126/NToC"]}}
}

@article{rayyan-242085326,
  title={Interpretable Multimodal Misinformation Detection with Logic Reasoning},
  year={2023},
  author={Liu, Hui and Wenya, Wang and Haoliang, Li},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Multimodal misinformation on online social platforms is becoming a critical concern due to increasing credibility and easier dissemination brought by multimedia content, compared to traditional text-only information. While existing multimodal detection approaches have achieved high performance, the lack of interpretability hinders these systems' reliability and practical deployment. Inspired by Neural-Symbolic AI which combines the learning ability of neural networks with the explainability of symbolic learning, we propose a novel logic-based neural model for multimodal misinformation detection which integrates interpretable logic clauses to express the reasoning process of the target task. To make learning effective, we parameterize symbolic logical elements using neural representations, which facilitate the automatic generation and evaluation of meaningful logic clauses. Additionally, to make our framework generalizable across diverse misinformation sources, we introduce five meta-predicates that can be instantiated with different correlations. Results on three public datasets (Twitter, Weibo, and Sarcasm) demonstrate the feasibility and versatility of our model. The implementation of our work can be found in this link (1).},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/less-and-less-bugs/LogicMD"]}}
}

@article{rayyan-242085333,
  title={Physics-guided symbolic neural network reveals optimal functional forms describing ground motions},
  year={2025},
  author={Liu, X. and Chen, S. and Fu, L. and Li, X. and Cotton, F.},
  url={https://www.sciencedirect.com/science/article/pii/S0267726124006523?casa_token=a4xENAXn-IgAAAAA:ZF70leNCadQ3-YduOIibFmaxaT9m82NHV9pMzawPgowr4_pf21AbBnYqSuTBkfA7fNHrgRya},
  abstract={This study presents a novel framework for ground motion modelling utilizing Physics-Guided Symbolic Neural Networks (PGSNN). Symbolic neural networks offer a new method for …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Xianwei-Liu/PGSNN"]}}
}

@article{rayyan-242085338,
  title={A neural-symbolic approach to natural language understanding},
  year={2022},
  author={Liu, Z. and Wang, Z. and Lin, Y. and Li, H.},
  abstract={… Inspired by the theory, we present a novel framework for NLU called Neural-Symbolic Processor (NSP), which performs analogical reasoning based on neural processing and logical …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/chadlzx/NSP_QA, https://github.com/zihao-wang/Number-NLI"]}}
}

@article{rayyan-242085341,
  title={Autoformalizing Euclidean Geometry},
  year={2024},
  author={Murphy, Logan and Yang, Kaiyu and Sun, Jialiang and Li, Zhaoyu and Anandkumar, Anima and Xujie, Si},
  abstract={Autoformalization involves automatically translating informal math into formal theorems and proofs that are machine-verifiable. Euclidean geometry provides an interesting and controllable domain for studying autoformalization. In this paper, we introduce a neuro-symbolic framework for autoformalizing Euclidean geometry, which combines domain knowledge, SMT solvers, and large language models (LLMs). One challenge in Euclidean geometry is that informal proofs rely on diagrams, leaving gaps in texts that are hard to formalize. To address this issue, we use theorem provers to fill in such diagrammatic information automatically, so that the LLM only needs to autoformalize the explicit textual steps, making it easier for the model. We also provide automatic semantic evaluation for autoformalized theorem statements. We construct LeanEuclid, an autoformalization benchmark consisting of problems from Euclid's Elements and the UniGeo dataset formalized in the Lean proof assistant. Experiments with GPT-4 and GPT-4V show the capability and limitations of state-of-the-art LLMs on autoformalizing geometry problems. The data and code are available at https://github.com/loganrjmurphy/LeanEuclid.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/loganrjmurphy/LeanEuclid"]}}
}

@article{rayyan-242085344,
  title={PerceptSent - Exploring Subjectivity in a Novel Dataset for Visual Sentiment Analysis},
  year={2023},
  volume={14},
  number={3},
  author={Lopes, Cesar Rafael and Rodrigo, Minetto and Regattieri, Delgado Myriam and Silva Thiago, H.},
  abstract={Visual sentiment analysis is a challenging problem. Many datasets and approaches have been designed to foster breakthroughs in this trending research topic. However, most works scrutinize only subsymbolic models through visual attributes of the evaluated images, paying less attention to the subjectivity of viewers' perceptions as a basis for neuro-symbolic systems. Aiming to fill this gap, we present PerceptSent, a novel dataset for visual sentiment analysis that spans 5,000 images shared by users on social networks. Besides the sentiment opinion (positive, slightly positive, neutral, slightly negative, negative) expressed by every evaluator about each image analyzed, the dataset contains evaluator's metadata (age, gender, socioeconomic status, education, and psychological hints) as well as perceptions observed by the evaluator about the image - such as the presence of nature, violence, lack of maintenance, etc. Deep architectures and different problem formulations are explored using our dataset to combine visual and extra attributes (external knowledge) for automatic sentiment analysis. We show evidence that evaluator's perceptionss, when correctly employed, are crucial in visual sentiment analysis, improving the F-score performance from 61% to an impressive rate above 97%. Although, at this point, we do not have automatic approaches to capture these perceptions, our results open up new investigation avenues.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ceslop84/perceptsent"]}}
}

@article{rayyan-242085346,
  title={The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns},
  year={2024},
  author={Lorello, L. S. and Lippi, M. and Melacci, S.},
  abstract={Artificial intelligence is continuously seeking novel challenges and benchmarks to effectively measure performance and to advance the state-of-the-art. In this paper we introduce …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ continual-nesy/KANDYBenchmark"]}}
}

@article{rayyan-242085347,
  title={A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge},
  year={2025},
  author={Lorello, L. S. and Lippi, M. and Melacci, S.},
  abstract={… neurosymbolic architectures. Building on top of a neural net processing the raw data, our neuro-symbolic … , conversely, relational neuro-symbolic methods present training instabilities …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/continual-nesy/LTLZinc"]}}
}

@article{rayyan-242085359,
  title={Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees},
  year={2023},
  author={Tao, Lue and Huang, Yu-Xuan and Dai, Wang-Zhou and Yuan, Jiang},
  abstract={Neuro-symbolic hybrid systems are promising for integrating machine learning and symbolic reasoning, where perception models are facilitated with information inferred from a symbolic knowledge base through logical reasoning. Despite empirical evidence showing the ability of hybrid systems to learn accurate perception models, the theoretical understanding of learnability is still lacking. Hence, it remains unclear why a hybrid system succeeds for a specific task and when it may fail given a different knowledge base. In this paper, we introduce a novel way of characterising supervision signals from a knowledge base, and establish a criterion for determining the knowledge's efficacy in facilitating successful learning. This, for the first time, allows us to address the two questions above by inspecting the knowledge base under investigation. Our analysis suggests that many knowledge bases satisfy the criterion, thus enabling effective learning, while some fail to satisfy it, indicating potential failures. Comprehensive experiments confirm the utility of our criterion on benchmark tasks.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/AbductiveLearning/ABL-TL"]}}
}

@article{rayyan-242085367,
  title={DANA: Domain-Aware Neurosymbolic Agents for Consistency and Accuracy},
  year={2024},
  author={Luong, V. and Dinh, S. and Raghavan, S. and Nguyen, W.},
  abstract={… propose DANA (Domain-Aware Neurosymbolic Agent), an … neurosymbolic lens, identifying their strengths and limitations. Section 3 introduces the DANA (Domain-Aware Neurosymbolic …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/aitomatic/openssa/blob/main/openssa/core/agent/dana.py"]}}
}

@article{rayyan-242085377,
  title={Soft-Unification in Deep Probabilistic Logic},
  year={2023},
  author={Maene, Jaron and Luc, De Raedt},
  publisher={NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)},
  abstract={A fundamental challenge in neuro-symbolic AI is to devise primitives that fuse the logical and neural concepts. The Neural Theorem Prover has proposed the notion of soft-unification to turn the symbolic comparison between terms (i.e. unification) into a comparison in embedding space. It has been shown that soft-unification is a powerful mechanism that can be used to learn logic rules in an end-to-end differentiable manner. We study soft-unification from a conceptual point and outline several desirable properties of this operation. These include non-redundancy in the proof, well-defined proof scores, and non-sparse gradients. Unfortunately, these properties are not satisfied by previous systems such as the Neural Theorem Prover. Therefore, we introduce a more principled framework called DeepSoftLog based on probabilistic rather than fuzzy semantics. Our experiments demonstrate that DeepSoftLog can outperform the state-of-the-art on neuro-symbolic benchmarks, highlighting the benefits of these properties.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jjcmoon/DeepSoftLog"]}}
}

@article{rayyan-242085387,
  title={NeSyA: Neurosymbolic Automata},
  year={2024},
  author={Manginas, Nikolaos and Paliouras, George and De Raedt, Luc},
  abstract={Neurosymbolic Artificial Intelligence (NeSy) has emerged as a promising direction to integrate low level perception with high level reasoning. Unfortunately, little attention has been given to developing NeSy systems tailored to temporal/sequential problems. This entails reasoning symbolically over sequences of subsymbolic observations towards a target prediction. We show that using a probabilistic semantics symbolic automata, which combine the power of automata for temporal structure specification with that of propositional logic, can be used to reason efficiently and differentiably over subsymbolic sequences. The proposed system, which we call NeSyA (Neuro Symbolic Automata), is shown to either scale or perform better than existing NeSy approaches when applied to problems with a temporal component.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/nmanginas/nesya"]}}
}

@article{rayyan-242085393,
  title={Neuro-Symbolic Recommendation Model based on Logic Query},
  year={2023},
  author={Wu, Maonian and Chen, Bang and Zhu, Shaojun and Zheng, Bo and Peng, Wei and Mingyi, Zhang},
  abstract={A recommendation system assists users in finding items that are relevant to them. Existing recommendation models are primarily based on predicting relationships between users and items and use complex matching models or incorporate extensive external information to capture association patterns in data. However, recommendation is not only a problem of inductive statistics using data; it is also a cognitive task of reasoning decisions based on knowledge extracted from information. Hence, a logic system could naturally be incorporated for the reasoning in a recommendation task. However, although hard-rule approaches based on logic systems can provide powerful reasoning ability, they struggle to cope with inconsistent and incomplete knowledge in real-world tasks, especially for complex tasks such as recommendation. Therefore, in this paper, we propose a neuro-symbolic recommendation model, which transforms the user history interactions into a logic expression and then transforms the recommendation prediction into a query task based on this logic expression. The logic expressions are then computed based on the modular logic operations of the neural network. We also construct an implicit logic encoder to reasonably reduce the complexity of the logic computation. Finally, a user's interest items can be queried in the vector space based on the computation results. Experiments on three well-known datasets verified that our method performs better compared to state of the art shallow, deep, session, and reasoning models.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/hanzo2020/NLQ"]}}
}

@article{rayyan-242085396,
  title={GlanceNets: Interpretable, Leak-proof Concept-based Models},
  year={2023},
  author={Marconato, Emanuele and Andrea, Passerini and Stefano, Teso},
  publisher={RWTH AACHEN},
  abstract={In this extended abstract, we briefly outline GlanceNets [ 1], a new class of deep learning classifiers that acquire high-level concepts from data and use them for both computing predictions and generating ante-hoc explanations of those predictions. In contrast with other concept-based networks, GlanceNets ensure the learned concepts, and the explanations built on them, are human interpretable, even in out-of-distribution scenarios. The core ideas at the heart of GlanceNets extend naturally to other Neuro-Symbolic architectures involving reasoning during inference.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ema-marconato/glancenet"]}}
}

@article{rayyan-242085404,
  title={Satyrn: A Platform for Analytics Augmented Generation},
  year={2024},
  author={Sterbentz, Marko and Barrie, Cameron and Shahi, Shubham and Dutta, Abhratanu and Hooshmand, Donna and Pack, Harper and Kristian, J. Hammond},
  abstract={Large language models (LLMs) are capable of producing documents, and retrieval augmented generation (RAG) has shown itself to be a powerful method for improving accuracy without sacrificing fluency. However, not all information can be retrieved from text. We propose an approach that uses the analysis of structured data to generate fact sets that are used to guide generation in much the same way that retrieved documents are used in RAG. This analytics augmented generation (AAG) approach supports the ability to utilize standard analytic techniques to generate facts that are then converted to text and passed to an LLM. We present a neurosymbolic platform, Satyrn, that leverages AAG to produce accurate, fluent, and coherent reports grounded in large scale databases. In our experiments, we find that Satyrn generates reports in which over 86% of claims are accurate while maintaining high levels of fluency and coherence, even when using smaller language models such as Mistral-7B, as compared to GPT-4 Code Interpreter in which just 57% of claims are accurate.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/nu-c3lab/satyrn"]}}
}

@article{rayyan-242085410,
  title={Relational reasoning networks},
  year={2025},
  volume={310},
  author={Marra, Giuseppe and Michelangelo, Diligenti and Francesco, Giannini},
  abstract={Neural-symbolic methods integrate neural architectures, knowledge representation and reasoning. However, they have struggled with both the intrinsic uncertainty of the observations and scaling to real-world applications. This paper presents Relational Reasoning Networks (R2N), a novel end-to-end model that performs relational reasoning in the latent space of a deep learner architecture, where the representations of constants, ground atoms and their manipulations are learned in an integrated fashion. Unlike flat architectures such as Knowledge Graph Embedders, which can only represent relations between entities, R2Ns define an additional computational structure, accounting for higher-level relations among the ground atoms. The considered relations can be explicitly known, like the ones defined by logic formulas, or defined as unconstrained correlations among groups of ground atoms. R2Ns can be applied to purely symbolic tasks or as a neural- symbolic platform to integrate learning and reasoning in heterogeneous problems with entities represented both symbolically and feature-based. The proposed model overtakes the limitations of previous neural-symbolic methods that have been either limited in terms of scalability or expressivity. The proposed methodology is shown to achieve state-of-the-art results indifferent experimental settings.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/diligmic/R2N_KBS2024"]}}
}

@article{rayyan-242085414,
  title={PROTOtypical Logic Tensor Networks (PROTO-LTN) for Zero Shot Learning},
  year={2022},
  author={Martone, Simone and Francesco, Manigrasso and Fabrizio, Lamberti and Lia, Morra},
  publisher={IEEE},
  abstract={Semantic image interpretation can vastly benefit from approaches that combine sub-symbolic distributed representation learning with the capability to reason at a higher level of abstraction. Logic Tensor Networks (LTNs) are a class of neuro-symbolic systems based on a differentiable, first-order logic grounded into a deep neural network. LTNs replace the classical concept of training set with a knowledge base of fuzzy logical axioms. By defining a set of differentiable operators to approximate the role of connectives, predicates, functions and quantifiers, a loss function is automatically specified so that LTNs can learn to satisfy the knowledge base. We focus here on the subsumption or isOfClass predicate, which is fundamental to encode most semantic image interpretation tasks. Unlike conventional LTNs, which rely on a separate predicate for each class (e.g., dog, cat), each with its own set of learnable weights, we propose a common isOfClass predicate, whose level of truth is a function of the distance between an object embedding and the corresponding class prototype. The PROTOtypical Logic Tensor Networks (PROTO-LTN) extend the current formulation by grounding abstract concepts as parametrized class prototypes in a high-dimensional embedding space, while reducing the number of parameters required to ground the knowledge base. We show how this architecture can be effectively trained in the few and zero-shot learning scenarios. Experiments on Generalized Zero Shot Learning benchmarks validate the proposed implementation as a competitive alternative to traditional embedding-based approaches. The proposed formulation opens up new opportunities in zero shot learning settings, as the LTN formalism allows to integrate background knowledge in the form of logical axioms to compensate for the lack of labelled examples. PROTO-LTN was implemented in Tensorflow and is available at https://github.com/FrancescoManigrass/PROTO-LTN.git},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/FrancescoManigrass/PROTO-LTN.git"]}}
}

@article{rayyan-242085420,
  title={Learning Compositional Rules via Neural Program Synthesis},
  year={2020},
  author={Maxwell, I. Nye and Solar-Lezama, Armando and Tenenbaum, Joshua B. and Lake, Brenden M.},
  abstract={Many aspects of human reasoning, including language, require learning rules from very little data. Humans can do this, often learning systematic rules from very few examples, and combining these rules to form compositional rule-based systems. Current neural architectures, on the other hand, often fail to generalize in a compositional manner, especially when evaluated in ways that vary systematically from training. In this work, we present a neuro-symbolic model which learns entire rule systems from a small set of examples. Instead of directly predicting outputs from inputs, we train our model to induce the explicit system of rules governing a set of previously seen examples, drawing upon techniques from the neural program synthesis literature. Our rule-synthesis approach outperforms neural meta-learning techniques in three domains: an artificial instruction-learning domain used to evaluate human learning, the SCAN challenge datasets, and learning rule-based translations of number words into integers for a wide range of human languages.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/mtensor/rulesynthesis"]}}
}

@article{rayyan-242085427,
  title={LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract Rules},
  year={2024},
  author={Mejri, Mohamed and Chandramouli, Amarnath and Chatterjee, Abhijit},
  abstract={Human cognition excels at symbolic reasoning, deducing abstract rules from limited samples. This has been explained using symbolic and connectionist approaches, inspiring the development of a neuro-symbolic architecture that combines both paradigms. In parallel, recent studies have proposed the use of a "relational bottleneck" that separates object-level features from abstract rules, allowing learning from limited amounts of data . While powerful, it is vulnerable to the curse of compositionality meaning that object representations with similar features tend to interfere with each other. In this paper, we leverage hyperdimensional computing, which is inherently robust to such interference to build a compositional architecture. We adapt the "relational bottleneck" strategy to a high-dimensional space, incorporating explicit vector binding operations between symbols and relational representations. Additionally, we design a novel high-dimensional attention mechanism that leverages this relational representation. Our system benefits from the low overhead of operations in hyperdimensional space, making it significantly more efficient than the state of the art when evaluated on a variety of test datasets, while maintaining higher or equal accuracy.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/mmejri3/LARS-VSA"]}}
}

@article{rayyan-242085432,
  title={A neuro-symbolic approach for enhanced human motion prediction},
  year={2023},
  author={Mghames, S. and Castri, L. and Hanheide, M.},
  url={https://ieeexplore.ieee.org/abstract/document/10191970/?casa_token=V-FaSNPscVgAAAAA:Iim7edWtMODvv4M0u8O89DQ4rZHN57bKnJxFvIOU-aRl09rbchfdY572NC633zAY72BzMRzz3gd35Q},
  abstract={Reasoning on the context of human beings is crucial for many real-world applications especially for those deploying autonomous systems (eg robots). In this paper, we present a new …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/sariahmghames/NeuroSyM-prediction"]}}
}

@article{rayyan-242085433,
  title={neuROSym: Deployment and Evaluation of a ROS-based Neuro-Symbolic Model for Human Motion Prediction},
  year={2024},
  author={Mghames, S. and Castri, L. and Hanheide, M.},
  url={https://ieeexplore.ieee.org/abstract/document/10672815/?casa_token=uFxeg71OHZIAAAAA:bzTx2Ul6voWAHQYTqKXw3uG1Tsj5Hn-dCEzALnE0p2Q-IuXfCiuIC9VbopoEXLE_pVwwYjuiPMPRVw},
  abstract={… In particular, a recent neuro-symbolic architecture (NeuroSyM… neural-only and neuro-symbolic models for motion prediction … improvement in case our neuro-symbolic architecture is used…},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/sariahmghames/neuROSym"]}}
}

@article{rayyan-242085446,
  title={Learning Reasoning Strategies in End-to-End Differentiable Proving},
  year={2020},
  author={Minervini, Pasquale and Riedel, Sebastian and Stenetorp, Pontus and Grefenstette, Edward and Rocktäschel, Tim},
  abstract={Attempts to render deep learning models interpretable, data-efficient, and robust have seen some success through hybridisation with rule-based systems, for example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions. However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. We present Conditional Theorem Provers (CTPs), an extension to NTPs that learns an optimal rule selection strategy via gradient-based optimisation. We show that CTPs are scalable and yield state-of-the-art results on the CLUTRR dataset, which tests systematic generalisation of neural models by learning to reason over smaller graphs and evaluating on larger ones. Finally, CTPs show better link prediction results on standard benchmarks in comparison with other neural-symbolic models, while being explainable. All source code and datasets are available online, at https://github.com/uclnlp/ctp.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/uclnlp/ctp]"]}}
}

@article{rayyan-242085456,
  title={JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities},
  year={2023},
  volume={493},
  author={Mistani, Pouria A. and Samira, Pakravan and Rajesh, Ilango and Frederic, Gibou},
  abstract={We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models of partial differential equations by (i) leveraging the accuracy and convergence properties of advanced numerical methods, solvers, and preconditioners, as well as (ii) better scalability to higher order PDEs by strictly limiting optimization to first order automatic differentiation. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. Importantly, the conservation laws and symmetries present in the bootstrapped finite discretization equations inform the neural network about solution regularities within local neighborhoods of training points. We apply NBM to the important class of elliptic problems with jump conditions across irregular interfaces in three spatial dimensions. We show the method is convergent such that model accuracy improves by increasing number of collocation points in the domain and preconditioning the residuals. We show NBM is competitive in terms of memory and training speed with other PINN-type frameworks. The algorithms presented here are implemented using JAX in a software package named JAX-DIPS (https://github .com /JAXDIPS /JAX-DIPS), standing for differentiable interfacial PDE solver. We open sourced JAXDIPS to facilitate research into use of differentiable algorithms for developing hybrid PDE solvers. (c) 2023 Elsevier Inc. All rights reserved.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/JAX-DIPS/JAX-DIPS"]}}
}

@article{rayyan-242085467,
  title={A Differentiable Integer Linear Programming Solver for Explanation-Based Natural Language Inference},
  year={2024},
  author={Thayaparan, Mokanarangan and Valentino, Marco and André, Freitas},
  abstract={Integer Linear Programming (ILP) has been proposed as a formalism for encoding precise structural and semantic constraints for Natural Language Inference (NLI). However, traditional ILP frameworks are non-differentiable, posing critical challenges for the integration of continuous language representations based on deep learning. In this paper, we introduce a novel approach, named Diff-Comb Explainer, a neuro-symbolic architecture for explanation-based NLI based on Differentiable BlackBox Combinatorial Solvers (DBCS). Differently from existing neuro-symbolic solvers, Diff-Comb Explainer does not necessitate a continuous relaxation of the semantic constraints, enabling a direct, more precise, and efficient incorporation of neural representations into the ILP formulation. Our experiments demonstrate that Diff-Comb Explainer achieves superior performance when compared to conventional ILP solvers, neuro-symbolic black-box solvers, and Transformer-based encoders. Moreover, a deeper analysis reveals that Diff-Comb Explainer can significantly improve the precision, consistency, and faithfulness of the constructed explanations, opening new opportunities for research on neuro-symbolic architectures for explainable and transparent NLI in complex domains.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/neuro-symbolic-ai/diff_comb_explainer"]}}
}

@article{rayyan-242085482,
  title={Designing Logic Tensor Networks for Visual Sudoku puzzle classification},
  year={2023},
  author={Morra, Lia and Alberto, Azzari and Letizia, Bergamasco and Marco, Braga and Luigi, Capogrosso and Federico, Delrio and Giuseppe, Di Giacomo and Simone, Eiraudo and Giorgia, Ghione and Rocco, Giudice and Alkis, Koudounas and Luca, Piano and Rege, Cambrin Daniele and Matteo, Risso and Marco, Rondina and Sebastien, Russo Alessandro and Marco, Russo and Francesco, Taioli and Lorenzo, Vaiani and Chiara, Vercellino},
  publisher={RWTH AACHEN},
  abstract={Given the increasing importance of the neurosymbolic (NeSy) approach in artificial intelligence, there is a growing interest in studying benchmarks specifically designed to emphasize the ability of AI systems to combine low-level representation learning with high-level symbolic reasoning. One such recent benchmark is Visual Sudoku Puzzle Classification, that combines visual perception with relational constraints. In this work, we investigate the application of Logic Tensork Networks (LTNs) to the Visual Sudoku Classification task and discuss various alternatives in terms of logical constraint formulation, integration with the perceptual module and training procedure.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/MalumaDev/SymbolicSudoku"]}}
}

@article{rayyan-242085484,
  title={Modular design patterns for neural-symbolic integration: refinement and combination},
  year={2022},
  author={Mossakowski, T.},
  abstract={… We have formalised neural-symbolic design patterns using simple graphs over some ontology of neural-symbolic elements. We deliberately have not used OWL2 ABoxes or RDF for …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/spechub/Hets"]}}
}

@article{rayyan-242085490,
  title={Neural Program Generation Modulo Static Analysis},
  year={2021},
  volume={34},
  author={Mukherjee, Rohan and Yeming, Wen and Dipak, Chaudhari and Reps Thomas, W. and Swarat, Chaudhuri and Chris, Jermaine},
  publisher={NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)},
  abstract={State-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon tasks such as the generation of entire method bodies. We propose to address this deficiency using weak supervision from a static program analyzer. Our neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static-analysis tool, long-distance semantic relationships in the code that it has already generated. During training, the model observes these relationships and learns to generate programs conditioned on them. We apply our approach to the problem of generating entire Java methods given the remainder of the class that contains the method. Our experiments show that the approach substantially outperforms state-of-the-art transformers and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic semantic errors and in terms of syntactically matching the ground truth.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/rohanmukh/nsg"]}}
}

@article{rayyan-242085494,
  title={Understanding Narratives through Dimensions of Analogy},
  year={2022},
  author={Nagarajah, Thiloshon and Ilievski, Filip and Pujara, Jay},
  abstract={Analogical reasoning is a powerful qualitative reasoning tool that enables humans to connect two situations, and to generalize their knowledge from familiar to novel situations. Cognitive Science research provides valuable insights into the richness and complexity of analogical reasoning, together with implementations of expressive analogical reasoners with limited scalability. Modern scalable AI techniques with the potential to reason by analogy have been only applied to the special case of proportional analogy, and not to understanding higher-order analogies. In this paper, we aim to bridge the gap by: 1) formalizing six dimensions of analogy based on mature insights from Cognitive Science research, 2) annotating a corpus of fables with each of these dimensions, and 3) defining four tasks with increasing complexity that enable scalable evaluation of AI techniques. Experiments with language models and neuro-symbolic AI reasoners on these tasks reveal that state-of-the-art methods can be applied to reason by analogy with a limited success, motivating the need for further research towards comprehensive and scalable analogical reasoning by AI. We make all our code and data available.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/usc-isi-i2/analogical-transfer-learning"]}}
}

@article{rayyan-242085497,
  title={Learning Neuro-symbolic Programs for Language Guided Robot Manipulation},
  year={2022},
  author={Kalithasan, Namasivayam and Singh, Himanshu and Bindal, Vishal and Tuli, Arnav and Agrawal, Vishwajeet and Jain, Rahul and Singla, Parag and Rohan, Paul},
  abstract={Given a natural language instruction and an input scene, our goal is to train a model to output a manipulation program that can be executed by the robot. Prior approaches for this task possess one of the following limitations: (i) rely on hand-coded symbols for concepts limiting generalization beyond those seen during training [1] (ii) infer action sequences from instructions but require dense sub-goal supervision [2] or (iii) lack semantics required for deeper object-centric reasoning inherent in interpreting complex instructions [3]. In contrast, our approach can handle linguistic as well as perceptual variations, end-to-end trainable and requires no intermediate supervision. The proposed model uses symbolic reasoning constructs that operate on a latent neural object-centric representation, allowing for deeper reasoning over the input scene. Central to our approach is a modular structure consisting of a hierarchical instruction parser and an action simulator to learn disentangled action representations. Our experiments on a simulated environment with a 7-DOF manipulator, consisting of instructions with varying number of steps and scenes with different number of objects, demonstrate that our model is robust to such variations and significantly outperforms baselines, particularly in the generalization settings. The code, dataset and experiment videos are available at https://nsrmp.github.io},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Anh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/dair-iitd/nsrmp"], "Anh"=>["[GitHub] https://nsrmp.github.io/"]}}
}

@article{rayyan-242085505,
  title={Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic},
  year={2024},
  author={Benjamin Van, Nathaniel Weir, Durme and Sanders, Kate and Weller, Orion and Sharma, Shreya and Jiang, Dongwei and Jiang, Zhengping and Mishra, Bhavana Dalvi and Tafjord, Oyvind and Jansen, Peter and Clark, Peter},
  abstract={Recent language models enable new opportunities for structured reasoning with text, such as the construction of intuitive, proof-like textual entailment trees without relying on brittle formal logic. However, progress in this direction has been hampered by a long-standing lack of a clear protocol for determining what valid compositional entailment is. This absence causes noisy datasets and limited performance gains by modern neuro-symbolic engines. To address these problems, we formulate a consistent and theoretically grounded approach to annotating decompositional entailment and evaluate its impact on LLM-based textual inference. We find that our new dataset, RDTE (Recognizing Decompositional Textual Entailment), has a substantially higher internal consistency (+9%) than prior decompositional entailment datasets. We also find that training an RDTE-oriented entailment classifier via knowledge distillation and employing it in an entailment tree reasoning engine significantly improves both accuracy and proof quality, illustrating the practical benefit of this advance for textual inference.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/JHU-CLSP/treewise"]}}
}

@article{rayyan-242085506,
  title={NELLIE: A Neuro-Symbolic Inference Engine for Grounded, Compositional, and Explainable Reasoning},
  year={2022},
  author={Weir, Nathaniel and Clark, Peter and Benjamin Van, Durme},
  abstract={Our goal is a modern approach to answering questions via systematic reasoning where answers are supported by human interpretable proof trees grounded in an},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/JHU-CLSP/NELLIE"]}}
}

@article{rayyan-242085511,
  title={Symbolic processing in neural networks},
  year={2003},
  author={Neto, J. P. and Siegelmann, H. T. and Costa, J. F.},
  url={https://www.scielo.br/j/jbcos/a/RxDn9b9yfftD9zWFTrDJxjD/?lang=en},
  abstract={In this paper we show that programming languages can be translated into recurrent (analog, rational weighted) neural nets. Implementation of programming languages in neural nets …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://www.di.fc.ul.pt/~jpn/netdef/netdef.htm"]}}
}

@article{rayyan-242085516,
  title={Neuro Symbolic Knowledge Reasoning for Procedural Video Question Answering},
  year={2025},
  author={Nguyen, T. S. and Yang, H. and Neoh, T. Y. and Zhang, H.},
  abstract={This paper introduces a new video question-answering (VQA) dataset that challenges models to leverage procedural knowledge for complex reasoning. It requires recognizing visual …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/LUNAProject22/KML"]}}
}

@article{rayyan-242085518,
  title={NeuroQL: A Neuro-Symbolic Language and Dataset for Inter-Subjective Reasoning},
  year={2023},
  author={Nick, Papoulias},
  abstract={We present a new AI task and baseline solution for Inter-Subjective Reasoning. We define inter-subjective information, to be a mixture of objective and subjective information possibly shared by different parties. Examples may include commodities and their objective properties as reported by IR (Information Retrieval) systems, that need to be cross-referenced with subjective user reviews from an online forum. For an AI system to successfully reason about both, it needs to be able to combine symbolic reasoning of objective facts with the shared consensus found on subjective user reviews. To this end we introduce the NeuroQL dataset and DSL (Domain-specific Language) as a baseline solution for this problem. NeuroQL is a neuro-symbolic language that extends logical unification with neural primitives for extraction and retrieval. It can function as a target for automatic translation of inter-subjective questions (posed in natural language) into the neuro-symbolic code that can answer them.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Anh"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/orgdlabs/neuroQL]"], "brandon"=>["https://github.com/orgdlabs/neuroQL"]}}
}

@article{rayyan-242085521,
  title={OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System},
  year={2024},
  author={Zhang and Zhu, Xiaowei and Zhou, Jun and Huajun, Ningyu Zhang, Chen and Xi, Zekun and Luo, Yujie and Wang, Peng and Tian, Bozhong and Yao, Yunzhi and Zhang, Jintian and Deng, Shumin and Sun, Mengshu and Liang, Lei and Zhiqiang},
  abstract={Knowledge representation has been a central aim of AI since its inception. Symbolic Knowledge Graphs (KGs) and neural Large Language Models (LLMs) can both represent knowledge. KGs provide highly accurate and explicit knowledge representation, but face scalability issue; while LLMs offer expansive coverage of knowledge, but incur significant training costs and struggle with precise and reliable knowledge manipulation. To this end, we introduce OneEdit, a neural-symbolic prototype system for collaborative knowledge editing using natural language, which facilitates easy-to-use knowledge management with KG and LLM. OneEdit consists of three modules: 1) The Interpreter serves for user interaction with natural language; 2) The Controller manages editing requests from various users, leveraging the KG with rollbacks to handle knowledge conflicts and prevent toxic knowledge attacks; 3) The Editor utilizes the knowledge from the Controller to edit KG and LLM. We conduct experiments on two new datasets with KGs which demonstrate that OneEdit can achieve superior performance.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Anh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/zjunlp/OneEdit"], "Anh"=>["[GitHub] https://github.com/zjunlp/OneEdit"]}}
}

@article{rayyan-242085522,
  title={C2SaferRust: Transforming C Projects into Safer Rust with NeuroSymbolic Techniques},
  year={2025},
  author={Nitin, V. and Krishna, R. and Valle, L. L. and Ray, B.},
  abstract={In recent years, there has been a lot of interest in converting C code to Rust, to benefit from the memory and thread safety guarantees of Rust. C2Rust is a rule-based system that can …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Anh"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/vikramnitin9/c2saferrust"], "Anh"=>["[GitHub] https://github.com/vikramnitin9/c2saferrust"]}}
}

@article{rayyan-242085536,
  title={Neuro-Symbolic AI for Analytical Solutions of Differential Equations},
  year={2025},
  author={Oikonomou, O. and Lingsch, L. and Grund, D. and Mishra, S.},
  abstract={… We combine these ingredients into a neuro-symbolic AI … Thus, we propose a new paradigm of neuro-symbolic AI for … Summary We propose SIGS, a neuro-symbolic AI algorithmic …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/camlab-ethz/LoDE"]}}
}

@article{rayyan-242085538,
  title={(sic) LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers},
  year={2023},
  author={Olausson, Theo X. and Alex, Gu and Benjamin, Lipkin and Zhang Cedegao, E. and Armando, Solar-Lezama and Tenenbaum Joshua, B. and Roger, Levy},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Logical reasoning, i.e., deductively inferring the truth value of a conclusion from a set of premises, is an important task for artificial intelligence with wide potential impacts on science, mathematics, and society. While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways. In this work, we investigate the validity of instead reformulating such tasks as modular neurosymbolic programming, which we call LINC: Logical Inference via Neurosymbolic Computation. In LINC, the LLM acts as a semantic parser, translating premises and conclusions from natural language to expressions in first-order logic. These expressions are then offloaded to an external theorem prover, which symbolically performs deductive inference. Leveraging this approach, we observe significant performance gains on FOLIO and a balanced subset of ProofWriter for three different models in nearly all experimental conditions we evaluate. On ProofWriter, augmenting the comparatively small open-source StarCoder+ (15.5B parameters) with LINC even outperforms GPT-3.5 and GPT-4 with Chain-of-Thought (CoT) prompting by an absolute 38% and 10%, respectively. When used with GPT-4, LINC scores 26% higher than CoT on ProofWriter while performing comparatively on FOLIO. Further analysis reveals that although both methods on average succeed roughly equally often on this dataset, they exhibit distinct and complementary failure modes. We thus provide promising evidence for how logical reasoning over natural language can be tackled through jointly leveraging LLMs alongside symbolic provers. All corresponding code is publicly available.(1)},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/benlipkin/linc"]}}
}

@article{rayyan-242085546,
  title={Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach},
  year={2025},
  author={Sultan, Oren and Stern, Eitan and Dafna, Shahaf},
  abstract={Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2505.14479", "Website: https://www.orensultan.com/llm_proof_generator/", "Code: https://github.com/orensul/LLMs_proof_generation"]}}
}

@article{rayyan-242085549,
  title={NESSY3L: a neurosymbolic system with 3 levels},
  year={1995},
  author={Orsier, B. and Labbi, A.},
  url={https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=b9cd8b8fca0959076c8cdf99b4b5399137a2186c},
  abstract={This paper presents an hybrid neurosymbolic system composed of three levels, contrary to the majority of other hybrid systems which only consists of two levels, one symbolic and one …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: https://github.com/eXascaleInfolab/Nessy_RE", "Paper: https://ieeexplore.ieee.org/document/9860090/media#media", "Paper: https://pure.tudelft.nl/ws/portalfiles/portal/155838874/Nessy_A_Neuro_Symbolic_System_for_Label_Noise_Reduction.pdf"]}}
}

@article{rayyan-242085560,
  title={Hands-On Interactive Neuro-Symbolic NLP with DRaiL},
  year={2022},
  author={Pacheco, Maria Leonor and Roy, Shamik and Goldwasser, Dan},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: https://gitlab.com/purdueNlp/DRaiL", "Website: https://aclanthology.org/2022.emnlp-demos.37/", "Lab Website: https://blast-cu.github.io/publications/"]}}
}

@article{rayyan-242085566,
  title={NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification},
  year={2023},
  author={Padalkar, Parth and Wang, Huaduo and Gupta, Gopal},
  abstract={Deep learning models such as CNNs have surpassed human performance in computer vision tasks such as image classification. However, despite their sophistication, these models lack interpretability which can lead to biased outcomes reflecting existing prejudices in the data. We aim to make predictions made by a CNN interpretable. Hence, we present a novel framework called NeSyFOLD to create a neurosymbolic (NeSy) model for image classification tasks. The model is a CNN with all layers following the last convolutional layer replaced by a stratified answer set program (ASP). A rule-based machine learning algorithm called FOLD-SE-M is used to derive the stratified answer set program from binarized filter activations of the last convolutional layer. The answer set program can be viewed as a rule-set, wherein the truth value of each predicate depends on the activation of the corresponding kernel in the CNN. The rule-set serves as a global explanation for the model and is interpretable. A justification for the predictions made by the NeSy model can be obtained using an ASP interpreter. We also use our NeSyFOLD framework with a CNN that is trained using a sparse kernel learning technique called Elite BackProp (EBP). This leads to a significant reduction in rule-set size without compromising accuracy or fidelity thus improving scalability of the NeSy model and interpretability of its rule-set. Evaluation is done on datasets with varied complexity and sizes. To make the rule-set more intuitive to understand, we propose a novel algorithm for labelling each kernel's corresponding predicate in the rule-set with the semantic concept(s) it learns. We evaluate the performance of our "semantic labelling algorithm" to quantify the efficacy of the semantic labelling for both the NeSy model and the NeSy-EBP model.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/petrichor1998/nesyfold_codebase"]}}
}

@article{rayyan-242085571,
  title={Neurosymbolic Narrative Generation for Cultural Heritage},
  year={2023},
  volume={368},
  author={Palma, Cosimo},
  publisher={IOS PRESS},
  abstract={Aim of my research is to exploit Linguistic Linked Open Data (LLOD) as base for advanced Cultural Heritage (CH) fruition by means of Automatic Story Generation (ASG). Following the rationale that discovering and reviving already existing (yet latent) narratives is worthier than automatically generating them from anew in eliciting the user's interest, the input-2-graph and the graph-2-sequence ASG-pipeline phases, heavily relying on LLOD, will be given a deeper focus, whereby the final Natural Language Generation (NLG) module will be constrained by the entities and relations established in the Knowledge Graph (KG) generation modules (a configuration typical of the neurosymbolic approach). In order to enhance possibilities of implementation in real-life contexts, the elaborated pipeline will be modular, i.e. self-sufficient in its constituent parts. Beyond the countless possible application scenarios ranging from education to entertainment, this solution detangles the user from his role of mere consumer, and empowers him not only to control the creation process [ 3.1], but also to find already within it, and not necessarily in the final outcome, a valuable source for intellectual growth. This work intends the addressing of a specific societal need as an avalanche to simultaneously fill knowledge gaps identified in and among the related scientific domains.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Glottocrisio/IKG4CH"]}}
}

@article{rayyan-242085573,
  title={Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration},
  year={2025},
  author={Pan, Y. and Zhang, Z. and Hu, P. and Ma, J. and Du, J. and Zhang, J.},
  abstract={Recent advances in Multimodal Large Language Models (MLLMs) have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ycpNotFound/GeoGen"]}}
}

@article{rayyan-242085579,
  title={Discrete Dictionary-based Decomposition Layer for Structured Representation Learning},
  year={2024},
  author={Park, Taewon and Kim, Hyun-Chul and Lee, Minho},
  abstract={Neuro-symbolic neural networks have been extensively studied to integrate symbolic operations with neural networks, thereby improving systematic generalization. Specifically, Tensor Product Representation (TPR) framework enables neural networks to perform differentiable symbolic operations by encoding the symbolic structure of data within vector spaces. However, TPR-based neural networks often struggle to decompose unseen data into structured TPR representations, undermining their symbolic operations. To address this decomposition problem, we propose a Discrete Dictionary-based Decomposition (D3) layer designed to enhance the decomposition capabilities of TPR-based models. D3 employs discrete, learnable key-value dictionaries trained to capture symbolic features essential for decomposition operations. It leverages the prior knowledge acquired during training to generate structured TPR representations by mapping input data to pre-learned symbolic features within these dictionaries. D3 is a straightforward drop-in layer that can be seamlessly integrated into any TPR-based model without modifications. Our experimental results demonstrate that D3 significantly improves the systematic generalization of various TPR-based models while requiring fewer additional parameters. Notably, D3 outperforms baseline models on the synthetic task that demands the systematic decomposition of unseen combinatorial data.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["Discrete Dictionary-based Decomposition Layer for Structured Representation Learning"]}}
}

@article{rayyan-242085581,
  title={NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering},
  year={2024},
  author={Zamil, Parvez and Rabby, Gollam and Rahman, Md. Sadekur and Sören, Auer},
  abstract={The growing volume of biomedical scholarly document abstracts presents an increasing challenge in efficiently retrieving accurate and relevant information. To address this, we introduce a novel approach that integrates an optimized topic modelling framework, OVB-LDA, with the BI-POP CMA-ES optimization technique for enhanced scholarly document abstract categorization. Complementing this, we employ the distilled MiniLM model, fine-tuned on domain-specific data, for high-precision answer extraction. Our approach is evaluated across three configurations: scholarly document abstract retrieval, gold-standard scholarly documents abstract, and gold-standard snippets, consistently outperforming established methods such as RYGH and bio-answer finder. Notably, we demonstrate that extracting answers from scholarly documents abstracts alone can yield high accuracy, underscoring the sufficiency of abstracts for many biomedical queries. Despite its compact size, MiniLM exhibits competitive performance, challenging the prevailing notion that only large, resource-intensive models can handle such complex tasks. Our results, validated across various question types and evaluation batches, highlight the robustness and adaptability of our method in real-world biomedical applications. While our approach shows promise, we identify challenges in handling complex list-type questions and inconsistencies in evaluation metrics. Future work will focus on refining the topic model with more extensive domain-specific datasets, further optimizing MiniLM and utilizing large language models (LLM) to improve both precision and efficiency in biomedical question answering.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/zparvez2z/NeuroSym-BioCAT"]}}
}

@article{rayyan-242085583,
  title={Pauk at semeval-2024 task 4: A neuro-symbolic method for consistent classification of propaganda techniques in memes},
  year={2024},
  author={Pauk, M. and Pacheco, M. L.},
  url={https://aclanthology.org/2024.semeval-1.204/},
  abstract={Memes play a key role in most modern informa-tion campaigns, particularly propaganda cam-paigns. Identifying the persuasive techniquespresent in memes is an important step in de-…},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/mappauk/Neuro-Symbolic-Final-Project"]}}
}

@article{rayyan-242085584,
  title={Compositional Generalization Across Distributional Shifts with Sparse Tree Operations},
  year={2024},
  author={Soulos, Paul and Conklin, Henry and Opper, Mattia and Smolensky, Paul and Gao, Jianfeng and Roland, Fernandez},
  abstract={Neural networks continue to struggle with compositional generalization, and this issue is exacerbated by a lack of massive pre-training. One successful approach for developing neural systems which exhibit human-like compositional generalization is ℎybrid neurosymbolic techniques. However, these techniques run into the core issues that plague symbolic approaches to AI: scalability and flexibility. The reason for this failure is that at their core, hybrid neurosymbolic models perform symbolic computation and relegate the scalable and flexible neural computation to parameterizing a symbolic system. We investigate a 𝑢nified neurosymbolic system where transformations in the network can be interpreted simultaneously as both symbolic and neural computation. We extend a unified neurosymbolic architecture called the Differentiable Tree Machine in two central ways. First, we significantly increase the model's efficiency through the use of sparse vector representations of symbolic structures. Second, we enable its application beyond the restricted set of tree2tree problems to the more general class of seq2seq problems. The improved model retains its prior generalization capabilities and, since there is a fully neural path through the network, avoids the pitfalls of other neurosymbolic techniques that elevate symbolic computation over neural computation.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/psoulos/sdtm"]}}
}

@article{rayyan-242085588,
  title={Natlog: Embedding Logic Programming into the Python Deep-Learning Ecosystem},
  year={2023},
  author={Paul, Tarau},
  abstract={Driven by expressiveness commonalities of Python and our Python-based embedded logic-based language Natlog, we design high-level interaction patterns between equivalent language constructs and data types on the two sides. By directly connecting generators and backtracking, nested tuples and terms, coroutines and first-class logic engines, reflection and meta-interpretation, we enable logic-based language constructs to access the full power of the Python ecosystem. We show the effectiveness of our design via Natlog apps working as orchestrators for JAX and Pytorch pipelines and as DCG-driven GPT3 and DALL.E prompt generators. Keyphrases: embedding of logic programming in the Python ecosystem, high-level inter-paradigm data exchanges, coroutining with logic engines, logic-based neuro-symbolic computing, logic grammars as prompt-generators for Large Language Models, logic-based neural network configuration and training.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["paper: [https://arxiv.org/pdf/2308.15890], github: [https://github.com/ptarau/natlog]"]}}
}

@article{rayyan-242085595,
  title={Generating by Understanding: Neural Visual Generation with Logical Symbol Groundings},
  year={2024},
  author={Peng, Yifei and Yu, Jin and Luo, Zhexu and Yao-Xiang, Ding and Wang-Zhou, Dai and Ren, Zhong and Zhou, Kun},
  abstract={Despite the great success of neural visual generative models in recent years, integrating them with strong symbolic reasoning systems remains a challenging task. There are two levels of symbol grounding problems among the core challenges: the first is symbol assignment, i.e. mapping latent factors of neural visual generators to semantic-meaningful symbolic factors from the reasoning systems by learning from limited labeled data. The second is rule learning, i.e. learning new rules that govern the generative process to enhance the symbolic reasoning systems. To deal with these two problems, we propose a neurosymbolic learning approach, Abductive visual Generation (AbdGen), for integrating logic programming systems with neural visual generative models based on the abductive learning framework. To achieve reliable and efficient symbol grounding, the quantized abduction method is introduced for generating abduction proposals by the nearest-neighbor lookup within semantic codebooks. To achieve precise rule learning, the contrastive meta-abduction method is proposed to eliminate wrong rules with positive cases and avoid less informative rules with negative cases simultaneously. Experimental results show that compared to the baseline approaches, AbdGen requires significantly less labeled data for symbol assignment. Furthermore, AbdGen can effectively learn underlying logical generative rules from data, which is out of the capability of existing approaches. The code is released at this link: https://github.com/candytalking/AbdGen.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/future-item/AbdGen"]}}
}

@article{rayyan-242085607,
  title={Knowledge-Based Dataset for Training PE Malware Detection Models},
  year={2022},
  author={Švec, Peter and Balogh, Štefan and Homola, Martin and Ján, Kľuka},
  abstract={Ontologies are a standard for semantic schemata in many knowledge-intensive domains of human interest. They are now becoming increasingly important also in areas until very recently dominated by subsymbolic representations and machine-learning-based data processing. One such area is information security, and more specifically malware detection. We propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE, Windows binary format) malware files. The ontology was inspired by the structure of the data in the EMBER dataset and it currently covers the data intended for static malware analysis. With this proposal, we hope to achieve: a) a unified semantic representation for PE malware datasets that are available or will be published in the future; (b) applicability of symbolic, neural-symbolic, or otherwise explainable approaches in the PE Malware domain that may lead to improved interpretability of results which may now be characterized by the terms defined in the ontology; and (c)by joint publishing of semantically treated EMBER data, including fractional datasets, also improved reproducibility of experiments.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2301.00153", "Code: https://github.com/orbis-security/pe-malware-ontology"]}}
}

@article{rayyan-242085608,
  title={NeST: The Neuro-Symbolic Transpiler},
  year={2025},
  author={Pfanschilling, V. and Shindo, H. and Dhami, D. S.},
  url={https://www.sciencedirect.com/science/article/pii/S0888613X25000106},
  abstract={… To move towards more complex distributions, we introduce a novel neurosymbolic programming language, Sum Product Loop Language (SPLL), along with the Neuro-Symbolic …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/vektordev/haskell-dppl"]}}
}

@article{rayyan-242085609,
  title={GNNQ: A neuro-symbolic approach to query answering over incomplete knowledge graphs},
  year={2022},
  author={Pflueger, M. and Cucala, D. J. Tena and Kostylev, E. V.},
  abstract={… To address this limitation, we propose in this paper a novel neuro-symbolic approach to inductive query answering over incomplete KGs. Our approach first augments an input KG using …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/KRR-Oxford/GNNQ"]}}
}

@article{rayyan-242085610,
  title={Enhancing Neuro-Symbolic Integration with Focal Loss: A Study on Logic Tensor Networks},
  year={2024},
  author={Piano, L. and Manigrasso, F. and Russo, A. and Morra, L.},
  abstract={… neural networks within Neuro-Symbolic (NeSy) paradigms … , challenges persist in training these NeSy frameworks. Not all … relatively unexplored in the NeSy domain is learning under …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://link.springer.com/chapter/10.1007/978-3-031-71170-1_2", "Code: https://github.com/MalumaDev/FocalLTN"]}}
}

@article{rayyan-242085624,
  title={Accelerating UMR adoption: Neuro-symbolic conversion from AMR-to-UMR with low supervision},
  year={2024},
  author={Post, C. B. and McGregor, M. C. and Pacheco, M. L.},
  url={https://aclanthology.org/2024.dmr-1.15/},
  abstract={… To address this challenge, we propose a modular, neuro-symbolic framework that utilizes an animacy parser to assist logic rules in automatically determining split roles, minimizing the …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/clairepost/AMRtoUMR]"]}}
}

@article{rayyan-242085625,
  title={Cognitive Module Networks for Grounded Reasoning},
  year={2019},
  volume={11654},
  author={Potapov, Alexey and Anatoly, Belikov and Vitaly, Bogdanov and Alexander, Scherbatiy},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={The necessity for neural-symbolic integration becomes evident as more complex problems like visual question answering are beginning to be addressed, which go beyond such limited-domain tasks as classification. Many existing state-of-the-art models are designed for a particular task or even benchmark, while general-purpose approaches are rarely applied to a wide variety of tasks demonstrating high performance. We propose a hybrid neural-symbolic framework, which tightly integrates the knowledge representation and symbolic reasoning mechanisms of the OpenCog cognitive architecture and one of the contemporary deep learning libraries, PyTorch, and show how to implement some existing particular models in our general framework.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/singnet/semantic-vision/tree/master/experiments/opencog/cog_module]"]}}
}

@article{rayyan-242085638,
  title={Neuro-symbolic Training for Reasoning over Spatial Language},
  year={2024},
  author={Premsri, T. and Kordjamshidi, P.},
  abstract={… To alleviate this issue, we propose training the language models with neuro-symbolic techniques … confirm our hypothesis of effective domain transfer based on neuro-symbolic training. …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Website: https://aclanthology.org/2025.findings-naacl.128/", "Paper: https://arxiv.org/pdf/2406.13828", "GitHub: https://github.com/HLR/SpaRTUNQChain"]}}
}

@article{rayyan-242085654,
  title={Differentiable Inductive Logic Programming in High-Dimensional Space},
  year={2023},
  author={Purgał, Stanisław J. and Cerna, David M. and Kaliszyk, Cezary},
  abstract={Synthesizing large logic programs through symbolic Inductive Logic Programming (ILP) typically requires intermediate definitions. However, cluttering the hypothesis space with intensional predicates typically degrades performance. In contrast, gradient descent provides an efficient way to find solutions within such high-dimensional spaces. Neuro-symbolic ILP approaches have not fully exploited this so far. We propose extending the δILP approach to inductive synthesis with large-scale predicate invention, thus allowing us to exploit the efficacy of high-dimensional gradient descent. We show that large-scale predicate invention benefits differentiable inductive synthesis through gradient descent and allows one to learn solutions for tasks beyond the capabilities of existing neuro-symbolic ILP systems. Furthermore, we achieve these results without specifying the precise structure of the solution within the language bias.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2208.06652v4", "repo: https://github.com/Ermine516/DILP2"]}}
}

@article{rayyan-242085655,
  title={Enhancing Medical Knowledge Discovery: A Neuro-symbolic System for Inductive Learning over Medical KGs},
  year={2025},
  author={Purohit, D. and Chudasama, Y. and Vidal, M. E.},
  abstract={… We propose a neuro-symbolic system that enhances medical knowledge discovery by combining symbolic learning from medical ontologies, inductive learning through KGE, and …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://dl.acm.org/doi/abs/10.1145/3701551.3708814?download=true", "code: https://github.com/SDM-TIB/KOSMOS"]}}
}

@article{rayyan-242085659,
  title={Peirce: Unifying material and formal reasoning via llm-driven neuro-symbolic refinement},
  year={2025},
  author={Quan, X. and Valentino, M. and Carvalho, D. S. and Dalal, D.},
  abstract={… In this paper, we introduce PEIRCE, a neuro-symbolic framework designed to unify material and formal inference through an iterative conjecture-criticism process. Within this framework, …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/neuro-symbolic-ai/peirce/]"]}}
}

@article{rayyan-242085660,
  title={Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement},
  year={2024},
  author={Quan, Xin and Marco, Valentino and Dennis Louise, A. and Andre, Freitas},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={An increasing amount of research in Natural Language Inference (NLI) focuses on the application and evaluation of Large Language Models (LLMs) and their reasoning capabilities. Despite their success, however, LLMs are still prone to factual errors and inconsistencies in their explanations, offering limited control and interpretability for inference in complex domains. In this paper, we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques can enhance the logical validity and alignment of ethical explanations produced by LLMs. Specifically, we present an abductive-deductive framework named Logic-Explainer, which integrates LLMs with an external backward-chaining solver to refine step-wise natural language explanations and jointly verify their correctness, reduce incompleteness and minimise redundancy. An extensive empirical analysis demonstrates that Logic-Explainer can improve explanations generated via in-context learning methods and Chain-of-Thought (CoT) on challenging ethical NLI tasks, while, at the same time, producing formal proofs describing and supporting models reasoning. As ethical NLI requires commonsense reasoning to identify underlying moral violations, our results suggest the effectiveness of neuro-symbolic methods for multi-step NLI more broadly, opening new opportunities to enhance the logical consistency, reliability, and alignment of LLMs.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/neuro-symbolic-ai/explanation_based_ethical_reasoning]"]}}
}

@article{rayyan-242085661,
  title={Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving},
  year={2024},
  author={Quan, Xin and Valentino, Marco and Dennis, Louise A. and Freitas, André},
  abstract={Natural language explanations represent a proxy for evaluating explanation-based and multi-step Natural Language Inference (NLI) models. However, assessing the validity of explanations for NLI is challenging as it typically involves the crowd-sourcing of apposite datasets, a process that is time-consuming and prone to logical errors. To address existing limitations, this paper investigates the verification and refinement of natural language explanations through the integration of Large Language Models (LLMs) and Theorem Provers (TPs). Specifically, we present a neuro-symbolic framework, named Explanation-Refiner, that integrates TPs with LLMs to generate and formalise explanatory sentences and suggest potential inference strategies for NLI. In turn, the TP is employed to provide formal guarantees on the logical validity of the explanations and to generate feedback for subsequent improvements. We demonstrate how Explanation-Refiner can be jointly used to evaluate explanatory reasoning, autoformalisation, and error correction mechanisms of state-of-the-art LLMs as well as to automatically enhance the quality of explanations of variable complexity in different domains.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/neuro-symbolic-ai/explanation_refinement]"]}}
}

@article{rayyan-242085663,
  title={HackAtari: Atari Learning Environments for Robust and Continual Reinforcement Learning},
  year={2024},
  author={Delfosse, Quentin and Blüml, Jannis and Gregori, Bjarne and Kristian, Kersting},
  abstract={Artificial agents' adaptability to novelty and alignment with intended behavior is crucial for their effective deployment. Reinforcement learning (RL) leverages novelty as a means of exploration, yet agents often struggle to handle novel situations, hindering generalization. To address these issues, we propose HackAtari, a framework introducing controlled novelty to the most common RL benchmark, the Atari Learning Environment. HackAtari allows us to create novel game scenarios (including simplification for curriculum learning), to swap the game elements' colors, as well as to introduce different reward signals for the agent. We demonstrate that current agents trained on the original environments include robustness failures, and evaluate HackAtari's efficacy in enhancing RL agents' robustness and aligning behavior through experiments using C51 and PPO. Overall, HackAtari can be used to improve the robustness of current and future RL algorithms, allowing Neuro-Symbolic RL, curriculum RL, causal RL, as well as LLM-driven RL. Our work underscores the significance of developing interpretable in RL agents.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/k4ntz/HackAtari"]}}
}

@article{rayyan-242085665,
  title={Constraint Guided Gradient Descent: Guided Training with Inequality Constraints},
  year={2022},
  author={Baelen, Quinten Van and Peter, Karsmakers},
  abstract={Deep learning is typically performed by learning a neural network solely from data in the form of input-output pairs ignoring available domain knowledge. In this work, the Constraint Guided Gradient Descent (CGGD) framework is proposed that enables the injection of domain knowledge into the training procedure. The domain knowledge is assumed to be described as a conjunction of hard inequality constraints which appears to be a natural choice for several applications. Compared to other neuro-symbolic approaches, the proposed method converges to a model that satisfies any inequality constraint on the training data and does not require to first transform the constraints into some ad-hoc term that is added to the learning (optimisation) objective. Under certain conditions, it is shown that CGGD can converges to a model that satisfies the constraints on the training set, while prior work does not necessarily converge to such a model. It is empirically shown on two independent and small data sets that CGGD makes training less dependent on the initialisation of the network and improves the constraint satisfiability on all data.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/KULeuvenADVISE/CGGD"]}}
}

@article{rayyan-242085667,
  title={Learning to Infer Generative Template Programs for Visual Concepts},
  year={2024},
  author={Ritchie, R. Kenny Jones and Chaudhuri, Siddhartha and Daniel},
  abstract={People grasp flexible visual concepts from a few examples. We explore a neurosymbolic system that learns how to infer programs that capture visual concepts in a domain-general fashion. We introduce Template Programs: programmatic expressions from a domain-specific language that specify structural and parametric patterns common to an input concept. Our framework supports multiple concept-related tasks, including few-shot generation and co-segmentation through parsing. We develop a learning paradigm that allows us to train networks that infer Template Programs directly from visual datasets that contain concept groupings. We run experiments across multiple visual domains: 2D layouts, Omniglot characters, and 3D shapes. We find that our method outperforms task-specific alternatives, and performs competitively against domain-specific approaches for the limited domains where they exist.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/rkjones4/TemplatePrograms"]}}
}

@article{rayyan-242085673,
  title={Experimenting an approach to Neuro-Symbolic RL},
  year={2023},
  volume={3585},
  author={Rafanelli, Andrea and Costantini, Stefania and De Gasperis, Giovanni},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180155322&partnerID=40&md5=9ec58a3babc5158986bfe46679bd89ef},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/AAAI-DISIM-UnivAQ/Neural-Logic-Reinforcement-Learning"]}}
}

@article{rayyan-242085696,
  title={Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering},
  year={2019},
  author={Vedantam, Ramakrishna and Desai, Karan and Lee, Stefan and Rohrbach, Marcus and Batra, Dhruv and Devi, Parikh},
  abstract={We propose a new class of probabilistic neural-symbolic models, that have symbolic functional programs as a latent, stochastic variable. Instantiated in the context of visual question answering, our probabilistic formulation offers two key conceptual advantages over prior neural-symbolic models for VQA. Firstly, the programs generated by our model are more understandable while requiring lesser number of teaching examples. Secondly, we show that one can pose counterfactual scenarios to the model, to probe its beliefs on the programs that could lead to a specified answer given an image. Our results on the CLEVR and SHAPES datasets verify our hypotheses, showing that the model gets better program (and answer) prediction accuracy even in the low data regime, and allows one to probe the coherence and consistency of reasoning performed.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Pape: https://arxiv.org/pdf/1902.07864", "https://github.com/kdexd/probnmn-clevr"]}}
}

@article{rayyan-242085702,
  title={Procedural Adherence and Interpretability Through Neuro-Symbolic Generative Agents},
  year={2024},
  author={Rothkopf, Raven and Zeng, Hannah Tongxin and Mark, Santolucito},
  abstract={The surge in popularity of large language models (LLMs) has opened doors for new approaches to the creation of interactive agents. However, managing and interpreting the temporal behavior of such agents over the course of a potentially infinite interaction remain challenging. The stateful, long-term horizon reasoning required for coherent agent behavior does not fit well into the LLM paradigm. We propose a combination of formal logic-based program synthesis and LLM content generation to bring guarantees of procedural adherence and interpretability to generative agent behavior. To illustrate the benefit of procedural adherence and interpretability, we use Temporal Stream Logic (TSL) to generate an automaton that enforces an interpretable, high-level temporal structure on an agent. With the automaton tracking the context of the interaction and making decisions to guide the conversation accordingly, we can drive content generation in a way that allows the LLM to focus on a shorter context window. We evaluated our approach on different tasks involved in creating an interactive agent specialized for generating choose-your-own-adventure games. We found that over all of the tasks, an automaton-enhanced agent with procedural guarantees achieves at least 96% adherence to its temporal constraints, whereas a purely LLM-based agent demonstrates as low as 14.67% adherence.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Author: https://ravenrothkopf.com/publications/", "code: https://github.com/Barnard-PL-Labs/CYOA-TSL", "paper: https://arxiv.org/pdf/2402.16905"]}}
}

@article{rayyan-242085714,
  title={A neuro-symbolic system over knowledge graphs for link prediction},
  year={2024},
  author={Rivas, A. and Collarana, D. and Torrente, M. and Vidal, M. E.},
  abstract={… Results: We assess the performance of the proposed neuro-symbolic system on a … the goal of assessing the accuracy of our proposed neuro-symbolic system. Results of a 5-fold cross-…},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: https://github.com/arivasm/Neuro-Symbolic_Treatment-Response", "https://www.semantic-web-journal.net/system/files/swj3203.pdf"]}}
}

@article{rayyan-242085718,
  title={Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification},
  year={2024},
  author={Vacareanu, Robert and Alam, Fahmida and Islam, Md Asiful and Riaz, Haris and Mihai, Surdeanu},
  abstract={This paper introduces a novel neuro-symbolic architecture for relation classification (RC) that combines rule-based methods with contemporary deep learning techniques. This approach capitalizes on the strengths of both paradigms: the adaptability of rule-based systems and the generalization power of neural networks. Our architecture consists of two components: a declarative rule-based model for transparent classification and a neural component to enhance rule generalizability through semantic text matching. Notably, our semantic matcher is trained in an unsupervised domain-agnostic way, solely with synthetic data. Further, these components are loosely coupled, allowing for rule modifications without retraining the semantic matcher. In our evaluation, we focused on two few-shot relation classification datasets: Few-Shot TACRED and a Few-Shot version of NYT29. We show that our proposed method outperforms previous state-of-the-art models in three out of four settings, despite not seeing any human-annotated training data. Further, we show that our approach remains modular and pliable, i.e., the corresponding rules can be locally modified to improve the overall model. Human interventions to the rules for the TACRED relation 𝚘rg:parents boost the performance on that relation by as much as 26% relative improvement, without negatively impacting the other relations, and without retraining the semantic matching component.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["One of the authors: https://hriaz17.github.io/publications/", "Paper: https://www.cs.jhu.edu/~kevinduh/t/naacl24/final_pdf/paper626.pdf", "Code: https://github.com/hriaz17/softrules"]}}
}

@article{rayyan-242085721,
  title={Concept logic trees: enabling user interaction for transparent image classification and human-in-the-loop learning},
  year={2024},
  volume={54},
  number={5},
  author={Rodriguez, David M. and Cuellar Manuel, P. and Morales Diego, P.},
  abstract={Interpretable deep learning models are increasingly important in domains where transparent decision-making is required. In this field, the interaction of the user with the model can contribute to the interpretability of the model. In this research work, we present an innovative approach that combines soft decision trees, neural symbolic learning, and concept learning to create an image classification model that enhances interpretability and user interaction, control, and intervention. The key novelty of our method relies on the fusion of an interpretable architecture with neural symbolic learning, allowing the incorporation of expert knowledge and user interaction. Furthermore, our solution facilitates the inspection of the model through queries in the form of first-order logic predicates. Our main contribution is a human-in-the-loop model as a result of the fusion of neural symbolic learning and an interpretable architecture. We validate the effectiveness of our approach through comprehensive experimental results, demonstrating competitive performance on challenging datasets when compared to state-of-the-art solutions.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/DavidMrd/LogicConceptSoftTrees"]}}
}

@article{rayyan-242085726,
  title={DeepProbCEP: A neuro-symbolic approach for complex event processing in adversarial settings},
  year={2023},
  volume={215},
  author={Roig Vilamala, Marc and Xing, Tianwei and Taylor, Harrison and Garcia, Luis and Srivastava, Mani and Kaplan, Lance and Preece, Alun and Kimmig, Angelika and Cerutti, Federico},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/dais-ita/DeepProbCEP"]}}
}

@article{rayyan-242085743,
  title={Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World},
  year={2023},
  author={Wu, Rujie and Ma, Xiaojian and Zhang, Zhenliang and Wang, Wei and Li, Qing and Zhu, Song-Chun and Yizhou, Wang},
  abstract={We introduce Bongard-OpenWorld, a new benchmark for evaluating real-world few-shot reasoning for machine vision. It originates from the classical Bongard Problems (BPs): Given two sets of images (positive and negative), the model needs to identify the set that query images belong to by inducing the visual concepts, which is exclusively depicted by images from the positive set. Our benchmark inherits the few-shot concept induction of the original BPs while adding the two novel layers of challenge: 1) open-world free-form concepts, as the visual concepts in Bongard-OpenWorld are unique compositions of terms from an open vocabulary, ranging from object categories to abstract visual attributes and commonsense factual knowledge; 2) real-world images, as opposed to the synthetic diagrams used by many counterparts. In our exploration, Bongard-OpenWorld already imposes a significant challenge to current few-shot reasoning algorithms. We further investigate to which extent the recently introduced Large Language Models (LLMs) and Vision-Language Models (VLMs) can solve our task, by directly probing VLMs, and combining VLMs and LLMs in an interactive reasoning scheme. We even conceived a neuro-symbolic reasoning approach that reconciles LLMs & VLMs with logical reasoning to emulate the human problem-solving process for Bongard Problems. However, none of these approaches manage to close the human-machine gap, as the best learner achieves 64% accuracy while human participants easily reach 91%. We hope Bongard-OpenWorld can help us better understand the limitations of current visual intelligence and facilitate future research on visual agents with stronger few-shot visual reasoning capabilities.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/rujiewu/Bongard-OpenWorld"]}}
}

@article{rayyan-242085745,
  title={Behavior Cloned Transformers are Neurosymbolic Reasoners},
  year={2022},
  author={Wang, Ruoyao and Jansen, Peter and Côté, Marc-Alexandre and Prithviraj, Ammanabrolu},
  abstract={In this work, we explore techniques for augmenting interactive agents with information from symbolic modules, much like humans use tools like calculators and GPS systems to assist with arithmetic and navigation. We test our agent's abilities in text games - challenging benchmarks for evaluating the multi-step reasoning abilities of game agents in grounded, language-based environments. Our experimental study indicates that injecting the actions from these symbolic modules into the action space of a behavior cloned transformer agent increases performance on four text game benchmarks that test arithmetic, navigation, sorting, and common sense reasoning by an average of 22%, allowing an agent to reach the highest possible performance on unseen games. This action injection technique is easily extended to new agents, environments, and symbolic modules.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["http://github.com/cognitiveailab/neurosymbolic/"]}}
}

@article{rayyan-242085746,
  title={MonoForce: Learnable Image-conditioned Physics Engine},
  year={2025},
  author={Agishev, Ruslan and Karel, Zimmermann},
  abstract={We propose a novel model for the prediction of robot trajectories on rough offroad terrain from the onboard camera images. This model enforces the laws of classical mechanics through a physics-aware neural symbolic layer while preserving the ability to learn from large-scale data as it is end-to-end differentiable. The proposed hybrid model integrates a black-box component that predicts robot-terrain interaction forces with a neural-symbolic layer. This layer includes a differentiable physics engine that computes the robot's trajectory by querying these forces at the points of contact with the terrain. As the proposed architecture comprises substantial geometrical and physics priors, the resulting model can also be seen as a learnable physics engine conditioned on real images that delivers 10⁴ trajectories per second. We argue and empirically demonstrate that this architecture reduces the sim-to-real gap and mitigates out-of-distribution sensitivity. The differentiability, in conjunction with the rapid simulation speed, makes the model well-suited for various applications including model predictive control, trajectory shooting, supervised and reinforcement learning or SLAM. The codes and data are publicly available.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/ctu-vras/monoforce"]}}
}

@article{rayyan-242085747,
  title={Enhancing Large Language Models through Neuro-Symbolic Integration and Ontological Reasoning},
  year={2025},
  author={Vsevolodovna, Ruslan Idelfonso Magana and Marco, Monti},
  abstract={Large Language Models (LLMs) demonstrate impressive capabilities in natural language processing but suffer from inaccuracies and logical inconsistencies known as hallucinations. This compromises their reliability, especially in domains requiring factual accuracy. We propose a neuro-symbolic approach integrating symbolic ontological reasoning and machine learning methods to enhance the consistency and reliability of LLM outputs. Our workflow utilizes OWL ontologies, a symbolic reasoner (e.g., HermiT) for consistency checking, and a lightweight machine learning model (logistic regression) for mapping natural language statements into logical forms compatible with the ontology. When inconsistencies between LLM outputs and the ontology are detected, the system generates explanatory feedback to guide the LLM towards a corrected, logically coherent response in an iterative refinement loop. We present a working Python prototype demonstrating this pipeline. Experimental results in a defined domain suggest significant improvements in semantic coherence and factual accuracy of LLM outputs, showcasing the potential of combining LLM fluency with the rigor of formal semantics.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["https://github.com/ruslanmv/Neuro-symbolic-interaction", "Paper: https://arxiv.org/pdf/2504.07640"]}}
}

@article{rayyan-242085753,
  title={Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities of Neurosymbolic AI},
  year={2024},
  author={Wickramarachchi, Ruwan and Henson, Cory and Amit, Sheth},
  abstract={In the era of Generative AI, Neurosymbolic AI is emerging as a powerful approach for tasks spanning from perception to cognition. The use of Neurosymbolic AI has been shown to achieve enhanced capabilities, including improved grounding, alignment, explainability, and reliability. However, due to its nascent stage, there is a lack of widely available real-world benchmark datasets tailored to Neurosymbolic AI tasks. To address this gap and support the evaluation of current and future methods, we introduce DSceneKG - a suite of knowledge graphs of driving scenes built from real-world, high-quality scenes from multiple open autonomous driving datasets. In this article, we detail the construction process of DSceneKG and highlight its application in seven different tasks. DSceneKG is publicly accessible at: https://github.com/ruwantw/DSceneKG},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["https://arxiv.org/pdf/2411.03225", "https://github.com/ruwantw/DSceneKG"]}}
}

@article{rayyan-242085756,
  title={Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification},
  year={2024},
  author={Chinchali, S. P. Sharan and Choi, Minkyu and Shah, Sahil and Goel, Harsh and Omama, Mohammad and Sandeep},
  abstract={Recent advancements in text-to-video models such as Sora, Gen-3, MovieGen, and CogVideoX are pushing the boundaries of synthetic video generation, with adoption seen in fields like robotics, autonomous driving, and entertainment. As these models become prevalent, various metrics and benchmarks have emerged to evaluate the quality of the generated videos. However, these metrics emphasize visual quality and smoothness, neglecting temporal fidelity and text-to-video alignment, which are crucial for safety-critical applications. To address this gap, we introduce NeuS-V, a novel synthetic video evaluation metric that rigorously assesses text-to-video alignment using neuro-symbolic formal verification techniques. Our approach first converts the prompt into a formally defined Temporal Logic (TL) specification and translates the generated video into an automaton representation. Then, it evaluates the text-to-video alignment by formally checking the video automaton against the TL specification. Furthermore, we present a dataset of temporally extended prompts to evaluate state-of-the-art video generation models against our benchmark. We find that NeuS-V demonstrates a higher correlation by over 5x with human evaluations when compared to existing metrics. Our evaluation further reveals that current video generation models perform poorly on these temporally complex prompts, highlighting the need for future work in improving text-to-video generation capabilities.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Author website: https://minkyuchoi-07.github.io/2025/06/11/neusv/#more", "Code: https://github.com/UTAustin-SwarmLab/NeuS-V", "HF: https://huggingface.co/spaces/Syzygianinfern0/NeuS-V", "paper: https://arxiv.org/pdf/2411.16718", "Website: https://utaustin-swarmlab.github.io/NeuS-V/"]}}
}

@article{rayyan-242085761,
  title={Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs},
  year={2019},
  volume={7},
  author={Saha, Amrita and Ahmed, Ansari Ghulam and Abhishek, Laddha and Karthik, Sankaranarayanan and Soumen, Chakrabarti},
  abstract={Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs. Neural Program Induction (NPI) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multi-step executable program. While NPI has been commonly trained with the ``gold'' program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain. There, practically only natural language queries and the corresponding answers can be provided for training. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type. CIPITR solves complex KBQA considerably more accurately than key-value memory networks and neural symbolic machines (NSM). For moderately complex queries requiring 2- to 5-step programs, CIPITR scores at least 3x higher F1 than the competing systems. On one of the hardest class of programs (comparative reasoning) with 5-10 steps, CIPITR outperforms NSM by a factor of 89 andmemory networks by 9 times.(1)},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Website: https://aclanthology.org/Q19-1012/", "paper: https://aclanthology.org/Q19-1012.pdf", "github: https://github.com/CIPITR/CIPITR"]}}
}

@article{rayyan-242085763,
  title={TinyNS: Platform-aware neurosymbolic auto tiny machine learning},
  year={2024},
  author={Saha, S. S. and Sandha, S. S. and Aggarwal, M. and Wang, B.},
  abstract={… , the first platform-aware neurosymbolic architecture search … code for five types of neurosymbolic models, combining the … microcontroller-class neurosymbolic models through …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["paper: https://dl.acm.org/doi/full/10.1145/3603171", "github: https://github.com/nesl/neurosymbolic-tinyml"]}}
}

@article{rayyan-242085764,
  title={System-1.x: Learning to Balance Fast and Slow Planning with Language Models},
  year={2024},
  author={Saha, Swarnadeep and Prasad, Archiki and Justin Chih-Yao, Chen and Hase, Peter and Stengel-Eskin, Elias and Bansal, Mohit},
  abstract={Language models can be used to solve long-horizon planning problems in two distinct modes: a fast 'System-1' mode, directly generating plans without any explicit search or backtracking, and a slow 'System-2' mode, planning step-by-step by explicitly searching over possible actions. While System-2 is typically more effective, it is also more computationally expensive, making it infeasible for long plans or large action spaces. Moreover, isolated System-1 or 2 ignores the user's end goals, failing to provide ways to control the model's behavior. To this end, we propose the System-1.x Planner, a controllable planning framework with LLMs that is capable of generating hybrid plans and balancing between the two planning modes based on the difficulty of the problem at hand. System-1.x consists of (i) a controller, (ii) a System-1 Planner, and (iii) a System-2 Planner. Based on a user-specified hybridization factor (x) governing the mixture between System-1 and 2, the controller decomposes a problem into sub-goals, and classifies them as easy or hard to be solved by either System-1 or 2, respectively. We fine-tune all three components on top of a single base LLM, requiring only search traces as supervision. Experiments with two diverse planning tasks - Maze Navigation and Blocksworld - show that our System-1.x Planner outperforms a System-1 Planner, a System-2 Planner trained to approximate A* search, and also a symbolic planner (A*). We demonstrate the following key properties of our planner: (1) controllability: increasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more search, improving performance, (2) flexibility: by building a neuro-symbolic variant with a neural System-1 and a symbolic System-2, we can use existing symbolic methods, and (3) generalizability: by being able to learn from different search algorithms, our method is robust to the choice of search algorithm.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["paper: https://arxiv.org/pdf/2407.14414", "code: https://github.com/swarnaHub/System-1.x"]}}
}

@article{rayyan-242085772,
  title={Seq2Parse: neurosymbolic parse error repair},
  year={2022},
  author={Sakkas, G. and Endres, M. and Guo, P. J. and Weimer, W.},
  abstract={We present Seq2Parse, a language-agnostic neurosymbolic approach to automatically repairing parse errors. Seq2Parse is based on the insight that Symbolic Error Correcting (EC) …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: https://github.com/gsakkas/seq2parse", "https://ranjitjhala.github.io/static/seq2parse-oopsla22.pdf", "https://dl.acm.org/doi/10.1145/3563330"]}}
}

@article{rayyan-242085775,
  title={BioLinkerAI: Leveraging LLMs to Improve Biomedical Entity Linking and Knowledge Capture},
  year={2025},
  author={Sakor, Ahmad and Kuldeep, Singh and Maria-Esther, Vidal},
  publisher={ASSOC COMPUTING MACHINERY},
  abstract={We introduce BioLinkerAI, a neuro-symbolic framework for biomedical entity linking that integrates symbolic (domain-specific and linguistic rules) and sub-symbolic ( large language models) components. Unlike traditional approaches requiring extensive labeled training data, BioLinkerAI harnesses a knowledge base and rules for candidate generation, while a pre-trained LLM handles final disambiguation. This combination ensures adaptability to diverse biomedical knowledge bases and complex entity mentions. Empirical evaluations show that BioLinkerAI surpasses state-of-the-art benchmarks, notably increasing unseen data accuracy from 65.4 to 78.5 without relying on extensive labeled datasets.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["https://dl.acm.org/doi/10.1145/3701551.3708812", "https://github.com/SDM-TIB/BioLinkerAI - empty need to ask author"]}}
}

@article{rayyan-242085788,
  title={EV-Planner: Energy-Efficient Robot Navigation via Event-Based Physics-Guided Neuromorphic Planner},
  year={2024},
  volume={9},
  number={3},
  author={Sanyal, Sourav and Kumar, Manna Rohan and Kaushik, Roy},
  abstract={Vision-based object tracking is an essential precursor to performing autonomous aerial navigation in order to avoid obstacles. Biologically inspired neuromorphic event cameras are emerging as a powerful alternative to frame-based cameras, due to their ability to asynchronously detect varying intensities (even in poor lighting conditions), high dynamic range, and robustness to motion blur. Spiking neural networks (SNNs) have gained traction for processing events asynchronously in an energy-efficient manner. On the other hand, physics-based artificial intelligence (AI) has gained prominence recently, as they enable embedding system knowledge via physical modeling inside traditional analog neural networks (ANNs). In this letter, we present an event-based physics-guided neuromorphic planner (EV-Planner) to perform obstacle avoidance using neuromorphic event cameras and physics-based AI. We consider the task of autonomous drone navigation where the mission is to detect moving gates and fly through them while avoiding a collision. We use event cameras to perform object detection using a shallow spiking neural network in an unsupervised fashion. Utilizing the physical equations of the brushless DC motors present in the drone rotors, we train a lightweight energy-aware physics-guided neural network (PgNN) with depth inputs. This predicts the optimal flight time responsible for generating near-minimum energy paths. We spawn the drone in the Gazebo simulator and implement a sensor-fused vision-to-planning neuro-symbolic framework using Robot Operating System (ROS). Simulation results for safe collision-free flight trajectories are presented with performance analysis, ablation study and potential future research directions.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["paper: https://arxiv.org/pdf/2307.11349", "github: https://github.com/souravsanyal06/EV-Planner"]}}
}

@article{rayyan-242085796,
  title={Symbolic neural architecture search for differential equations},
  year={2023},
  author={Sasnauskas, P. and Petkevičius, L.},
  url={https://ieeexplore.ieee.org/abstract/document/10354328/},
  abstract={In this paper, we introduce the first use of symbolic integration that leverages the machine learning infrastructure, such as automatic differentiation, to find analytical approximations of …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/PauliusSasnauskas/sasde"]}}
}

@article{rayyan-242085814,
  title={Conditioning score-based generative models by neuro-symbolic constraints},
  year={2023},
  author={Scassola, D. and Saccani, S. and Carbone, G.},
  url={https://ui.adsabs.harvard.edu/abs/2023arXiv230816534S/abstract},
  abstract={… Then, we define a flexible and numerically stable neuro-symbolic framework for encoding soft logical constraints. Combining these two ingredients we obtain a general, but approximate…},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/DavideScassola/score-based-constrained-generation"]}}
}

@article{rayyan-242085815,
  title={Scaling Scientific Knowledge Discovery with Neuro-Symbolic AI and Large Language Models},
  year={2024},
  volume={3759},
  author={Schmidt, Wilma Johanna and Rincon-Yanez, Diego and Kharlamov, Evgeny and Paschke, Adrian},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204727190&partnerID=40&md5=996a09e6a534d56571251a2a78ee1213},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/d1egoprog/KG-SLR4LLM"]}}
}

@article{rayyan-242085817,
  title={QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios},
  year={2024},
  author={Schrader, Timo Pierre and Lange, Lukas and Razniewski, Simon and Friedrich, Annemarie},
  abstract={Reasoning is key to many decision making processes. It requires consolidating a set of rule-like premises that are often associated with degrees of uncertainty and observations to draw conclusions. In this work, we address both the case where premises are specified as numeric probabilistic rules and situations in which humans state their estimates using words expressing degrees of certainty. Existing probabilistic reasoning datasets simplify the task, e.g., by requiring the model to only rank textual alternatives, by including only binary random variables, or by making use of a limited set of templates that result in less varied text. In this work, we present QUITE, a question answering dataset of real-world Bayesian reasoning scenarios with categorical random variables and complex relationships. QUITE provides high-quality natural language verbalizations of premises together with evidence statements and expects the answer to a question in the form of an estimated probability. We conduct an extensive set of experiments, finding that logic-based models outperform out-of-the-box large language models on all reasoning types (causal, evidential, and explaining-away). Our results provide evidence that neuro-symbolic models are a promising direction for improving complex reasoning. We release QUITE and code for training and experiments on Github.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Included"} | USER-NOTES: {"Vladimir"=>["Github: [https://github.com/boschresearch/quite-emnlp24]"]}}
}

@article{rayyan-242085818,
  title={Causality Prediction with Neural-Symbolic Systems: A Case Study in Smart Grids},
  year={2023},
  author={Schreiberhuber, K. and Sabou, M.},
  url={https://repositum.tuwien.at/handle/20.500.12708/190669},
  abstract={… To address this gap, we propose a neural-symbolic architecture that augments symbolic … Experimental results show that the neural-symbolic approach can predict causality knowledge …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>[" https://github.com/Kat-rin-sc/ExpCPSKGE"]}}
}

@article{rayyan-242085821,
  title={Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs},
  year={2023},
  author={Yang, Sen and Li, Xin and Cui, Leyang and Bing, Lidong and Wai, Lam},
  abstract={Two lines of approaches are adopted for complex reasoning with LLMs. One line of work prompts LLMs with various reasoning structures, while the structural outputs can be naturally regarded as intermediate reasoning steps. Another line of work adopt LLM-free declarative solvers to do the reasoning task, rendering higher reasoning accuracy but lacking interpretability due to the black-box nature of the solvers. Aiming to resolve the trade-off between answer accuracy and interpretability, we present a simple extension to the latter line of work. Specifically, we showcase that the intermediate search logs generated by Prolog interpreters can be accessed and interpreted into human-readable reasoning proofs. As long as LLMs correctly translate problem descriptions into Prolog representations, the corresponding reasoning proofs are ensured to be causal and reliable. On two logical reasoning and one arithmetic reasoning datasets, our framework obtains significant improvements in terms of both answer accuracy and reasoning proof accuracy. Our code is released at https://github.com/DAMO-NLP-SG/CaRing},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/DAMO-NLP-SG/CaRing"]}}
}

@article{rayyan-242085826,
  title={Techniques for Symbol Grounding with SATNet},
  year={2021},
  author={Topan, Sever and Rolnick, David and Xujie, Si},
  abstract={Many experts argue that the future of artificial intelligence is limited by the field's ability to integrate symbolic logical reasoning into deep learning architectures. The recently proposed differentiable MAXSAT solver, SATNet, was a breakthrough in its capacity to integrate with a traditional neural network and solve visual reasoning problems. For instance, it can learn the rules of Sudoku purely from image examples. Despite its success, SATNet was shown to succumb to a key challenge in neurosymbolic systems known as the Symbol Grounding Problem: the inability to map visual inputs to symbolic variables without explicit supervision ( label leakage ). In this work, we present a self-supervised pre-training pipeline that enables SATNet to overcome this limitation, thus broadening the class of problems that SATNet architectures can solve to include datasets where no intermediary labels are available at all. We demonstrate that our method allows SATNet to attain full accuracy even with a harder problem setup that prevents any label leakage. We additionally introduce a proofreading method that further improves the performance of SATNet architectures, beating the state-of-the-art on Visual Sudoku.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/locuslab/SATNet,"]}}
}

@article{rayyan-242085834,
  title={Neural Feature-Adaptation for Symbolic Predictions Using Pre-Training and Semantic Loss},
  year={2022},
  author={Shah, Vedant and Agrawal, Aditya and Vig, Lovekesh and Srinivasan, Ashwin and Shroff, Gautam and Verlekar, Tanmay},
  abstract={We are interested in neurosymbolic systems consisting of a high-level symbolic layer for explainable prediction in terms of human-intelligible concepts; and a low-level neural layer for extracting symbols required to generate the symbolic explanation. Real data is often imperfect meaning that even if the symbolic theory remains unchanged, we may still need to address the problem of mapping raw data to high-level symbols, each time there is a change in the data acquisition environment or equipment. Manual (re-)annotation of the raw data each time this happens is laborious and expensive; and automated labelling methods are often imperfect, especially for complex problems. NEUROLOG proposed the use of a semantic loss function that allows an existing feature-based symbolic model to guide the extraction of feature-values from raw data, using `abduction'. However, the experiments demonstrating the use of semantic loss through abduction appear to rely heavily on a domain-specific pre-processing step that enables a prior delineation of feature locations in the raw data. We examine the use of semantic loss in domains where such pre-processing is not possible, or is not obvious. We show that without any prior information about the features, the NEUROLOG approach can continue to predict accurately even with substantially incorrect feature predictions. We show also that prior information about the features in the form of even imperfect pre-training can help correct this situation. These findings are replicated on the original problem considered by NEUROLOG, without the use of feature-delineation. This suggests that symbolic explanations constructed for data in a domain could be re-used in a related domain, by `feature-adaptation' of pre-trained neural extractors using the semantic loss function constrained by abductive feedback.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["paper: https://arxiv.org/pdf/2211.16047", "code: https://bitbucket.org/tsamoura/neurolog/src/master/"]}}
}

@article{rayyan-242085843,
  title={Student Strategy Prediction Using a Neuro-Symbolic Approach},
  year={2021},
  author={Shakya, A. and Rus, V. and Venugopal, D.},
  url={https://eric.ed.gov/?id=ED615630},
  abstract={… AI/Machine Learning research community is Neurosymbolic AI [7] … In this paper, we apply a Neuro-symbolic model to predict … To address this, we propose a Neuro-symbolic model where …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Code: https://github.com/anupshakya07/SSPM", "Paper: https://files.eric.ed.gov/fulltext/ED615630.pdf"]}}
}

@article{rayyan-242085844,
  title={Abductive Learning for Neuro-Symbolic Grounded Imitation},
  year={2025},
  author={Shao, J. J. and Hao, H. R. and Yang, X. W. and Li, Y. F.},
  abstract={Recent learning-to-imitation methods have shown promise in planning by imitating within the observation-action space, yet they remain constrained in open environments, especially for …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["link: https://dl.acm.org/doi/10.1145/3690624.3709344", "website: https://www.lamda.nju.edu.cn/shaojj/KDD25_ABIL/", "code: https://github.com/Hoar012/ABIL-KDD-2025"]}}
}

@article{rayyan-242085845,
  title={Unsupervised Learning of Neuro-symbolic Rules for Generalizable Context-aware Planning in Object Arrangement Tasks},
  year={2024},
  author={Sharma, S. and Tuli, S. and Paul, R.},
  url={https://ieeexplore.ieee.org/abstract/document/10610696/?casa_token=AAEi_jIe16cAAAAA:0CdgAKnh6LjZ1E9q4YPK-UuydcNSSrOst7lapOhlytXR9njwld1O_jjlr0JclSFgLK-syINTHRPACA},
  abstract={As robots tackle complex object arrangement tasks, it becomes imperative for them to be able to generalize to complex worlds and scale with number of objects. This work postulates …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["paper: https://ieeexplore.ieee.org/document/10610696", "code: https://github.com/Sids2k/RLAP"]}}
}

@article{rayyan-242085846,
  title={GoalNet: Inferring Conjunctive Goal Predicates from Human Plan Demonstrations for Robot Instruction Following},
  year={2022},
  author={Sharma, Shreya and Gupta, Jigyasa and Tuli, Shreshth and Rohan, Paul and Mausam},
  abstract={Our goal is to enable a robot to learn how to sequence its actions to perform tasks specified as natural language instructions, given successful demonstrations from a human partner. The ability to plan high-level tasks can be factored as (i) inferring specific goal predicates that characterize the task implied by a language instruction for a given world state and (ii) synthesizing a feasible goal-reaching action-sequence with such predicates. For the former, we leverage a neural network prediction model, while utilizing a symbolic planner for the latter. We introduce a novel neuro-symbolic model, GoalNet, for contextual and task dependent inference of goal predicates from human demonstrations and linguistic task descriptions. GoalNet combines (i) learning, where dense representations are acquired for language instruction and the world state that enables generalization to novel settings and (ii) planning, where the cause-effect modeling by the symbolic planner eschews irrelevant predicates facilitating multi-stage decision making in large domains. GoalNet demonstrates a significant improvement (51%) in the task completion rate in comparison to a state-of-the-art rule-based approach on a benchmark data set displaying linguistic variations, particularly for multi-stage instructions.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["paper: https://arxiv.org/pdf/2205.07081", "code: https://github.com/reail-iitd/goalnet"]}}
}

@article{rayyan-242085857,
  title={Neural Natural Logic Inference for Interpretable Question Answering},
  year={2021},
  author={Shi, Jihao and Xiao, Ding and Li, Du and Ting, Liu and Bing, Qin},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={Many open-domain question answering problems can be cast as a textual entailment task, where a question and candidate answers are concatenated to form hypotheses. A QA system then determines if the supporting knowledge bases, regarded as potential premises, entail the hypotheses. In this paper, we investigate a neural-symbolic QA approach that integrates natural logic reasoning within deep learning architectures, towards developing effective and yet explainable question answering models. The proposed model gradually bridges a hypothesis and candidate premises following natural logic inference steps to build proof paths. Entailment scores between the acquired intermediate hypotheses and candidate premises are measured to determine if a premise entails the hypothesis. As the natural logic reasoning process forms a tree-like, hierarchical structure, we embed hypotheses and premises in a Hyperbolic space rather than Euclidean space to acquire more precise representations. Empirically, our method outperforms prior work on answering multiple-choice science questions, achieving the best results on two publicly available datasets. The natural logic inference process inherently provides evidence to help explain the prediction process.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Included"} | USER-NOTES: {"Bhuvanesh"=>["Website: https://aclanthology.org/2021.emnlp-main.298/", "code: https://github.com/shijihao/neunli"]}}
}

@article{rayyan-242085865,
  title={An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented Dialogue Generation},
  year={2022},
  author={Yang, Shiquan and Zhang, Rui and Erfani, Sarah and Jey Han, Lau},
  abstract={We study the interpretability issue of task-oriented dialogue systems in this paper. Previously, most neural-based task-oriented dialogue systems employ an implicit reasoning strategy that makes the model predictions uninterpretable to humans. To obtain a transparent reasoning process, we introduce neuro-symbolic to perform explicit reasoning that justifies model decisions by reasoning chains. Since deriving reasoning chains requires multi-hop reasoning for task-oriented dialogues, existing neuro-symbolic approaches would induce error propagation due to the one-phase design. To overcome this, we propose a two-phase approach that consists of a hypothesis generator and a reasoner. We first obtain multiple hypotheses, i.e., potential operations to perform the desired task, through the hypothesis generator. Each hypothesis is then verified by the reasoner, and the valid one is selected to conduct the final prediction. The whole system is trained by exploiting raw textual dialogues without using any reasoning chain annotations. Experimental studies on two public benchmark datasets demonstrate that the proposed approach not only achieves better results, but also introduces an interpretable decision process.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/shiquanyang/NS-Dial"]}}
}

@article{rayyan-242085866,
  title={Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry},
  year={2024},
  author={Sinha, Shiven and Prabhu, Ameya and Kumaraguru, Ponnurangam and Bhat, Siddharth and Matthias, Bethge},
  abstract={Proving geometric theorems constitutes a hallmark of visual reasoning combining both intuitive and logical skills. Therefore, automated theorem proving of Olympiad-level geometry problems is considered a notable milestone in human-level automated reasoning. The introduction of AlphaGeometry, a neuro-symbolic model trained with 100 million synthetic samples, marked a major breakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO) problems whereas the reported baseline based on Wu's method solved only ten. In this note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry, and find that Wu's method is surprisingly strong. Wu's method alone can solve 15 problems, and some of them are not solved by any of the other methods. This leads to two key findings: (i) Combining Wu's method with the classic synthetic methods of deductive databases and angle, ratio, and distance chasing solves 21 out of 30 methods by just using a CPU-only laptop with a time limit of 5 minutes per problem. Essentially, this classic method solves just 4 problems less than AlphaGeometry and establishes the first fully symbolic baseline strong enough to rival the performance of an IMO silver medalist. (ii) Wu's method even solves 2 of the 5 problems that AlphaGeometry failed to solve. Thus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art for automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the first AI method which outperforms an IMO gold medalist.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://huggingface.co/datasets/bethgelab/simplegeometry"]}}
}

@article{rayyan-242085867,
  title={HEPHA: A Mixed-Initiative Image Labeling Tool for Specialized Domains},
  year={2025},
  author={Zhou, Shiyuan and Li, Bingxuan and Chen, Xiyuan and Tu, Zhi and Wang, Yifeng and Xiang, Yiwen and Tianyi, Zhang},
  abstract={Image labeling is an important task for training computer vision models. In specialized domains, such as healthcare, it is expensive and challenging to recruit specialists for image labeling. We propose HEPHA, a mixed-initiative image labeling tool that elicits human expertise via inductive logic learning to infer and refine labeling rules. Each rule comprises visual predicates that describe the image. HEPHA enables users to iteratively refine the rules by either direct manipulation through a visual programming interface or by labeling more images. To facilitate rule refinement, HEPHA recommends which rule to edit and which predicate to update. For users unfamiliar with visual programming, HEPHA suggests diverse and informative images to users for further labeling. We conducted a within-subjects user study with 16 participants and compared HEPHA with a variant of HEPHA and a deep learning-based approach. We found that HEPHA outperforms the two baselines in both specialized-domain and general-domain image labeling tasks. Our code is available at https://github.com/Neural-Symbolic-Image-Labeling/NSILWeb.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Neural-Symbolic-ImageLabeling/NSILWeb."]}}
}

@article{rayyan-242085873,
  title={Learning neuro-symbolic skills for bilevel planning},
  year={2022},
  author={Silver, T. and Athalye, A. and Tenenbaum, J. B.},
  abstract={… for learning and planning with neurosymbolic skills. A neuro-symbolic skill consists of a … We propose to learn and plan with neuro-symbolic skills. In this section, we define these …},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub]: https://github.com/Learning-and-Intelligent-Systems/predicators/releases/tag/skill-learning-june-2022"]}}
}

@article{rayyan-242085876,
  title={Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning},
  year={2024},
  author={Gebreegziabher, Simret Araya and Ai, Kuangshi and Zhang, Zheng and Elena, L. Glassman and Li, Toby Jia-Jun},
  abstract={Active Learning (AL) allows models to learn interactively from user feedback. This paper introduces a counterfactual data augmentation approach to AL, particularly addressing the selection of datapoints for user querying, a pivotal concern in enhancing data efficiency. Our approach is inspired by Variation Theory, a theory of human concept learning that emphasizes the essential features of a concept by focusing on what stays the same and what changes. Instead of just querying with existing datapoints, our approach synthesizes artificial datapoints that highlight potential key similarities and differences among labels using a neuro-symbolic pipeline combining large language models (LLMs) and rule-based models. Through an experiment in the example domain of text classification, we show that our approach achieves significantly higher performance when there are fewer annotated data. As the annotated training data gets larger the impact of the generated data starts to diminish showing its capability to address the cold start problem in AL. This research sheds light on integrating theories of human learning into the optimization of AL.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/SimretA/Variation-Theory-in-Counterfactual-Data-Augmentation"]}}
}

@article{rayyan-242085890,
  title={Symbolic Working Memory Enhances Language Models for Complex Rule Application},
  year={2024},
  author={Wang, Siyuan and Wei, Zhongyu and Choi, Yejin and Xiang, Ren},
  abstract={Large Language Models (LLMs) have shown remarkable reasoning performance but struggle with multi-step deductive reasoning involving a series of rule application steps, especially when rules are presented non-sequentially. Our preliminary analysis shows that while LLMs excel in single-step rule application, their performance drops significantly in multi-step scenarios due to the challenge in rule grounding. It requires anchoring the applicable rule and supporting facts at each step, amidst multiple input rules, facts, and inferred facts. To address this, we propose augmenting LLMs with external working memory and introduce a neurosymbolic framework for rule application. The memory stores facts and rules in both natural language and symbolic forms, enabling precise tracking. Utilizing this memory, our framework iteratively performs symbolic rule grounding and LLM-based rule implementation. The former matches predicates and variables of symbolic rules and facts to ground applicable rules at each step. Experiments indicate our framework's effectiveness in rule application and its robustness across various steps and settings \footnote Code and data are available at \url https://github.com/SiyuanWangw/RuleApplication . .},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/SiyuanWangw/RuleApplication"]}}
}

@article{rayyan-242085892,
  title={Scalable Neural-Probabilistic Answer Set Programming},
  year={2024},
  volume={78},
  author={Skryagin, Arseny and Daniel, Ochs and Singh, Dhami Devendra and Kristian, Kersting},
  abstract={The goal of combining the robustness of neural networks and the expressiveness of symbolic methods has rekindled the interest in Neuro-Symbolic AI. Deep Probabilistic Programming Languages (DPPLs) have been developed for probabilistic logic programming to be carried out via the probability estimations of deep neural networks (DNNs). However, recent SOTA DPPL approaches allow only for limited conditional probabilistic queries and do not offer the power of true joint probability estimation. In our work, we propose an easy integration of tractable probabilistic inference within a DPPL. To this end, we introduce SLASH, a novel DPPL that consists of Neural-Probabilistic Predicates (NPPs) and a logic program, united via answer set programming (ASP). NPPs are a novel design principle allowing for combining all deep model types and combinations thereof to be represented as a single probabilistic predicate. In this context, we introduce a novel +/− notation for answering various types of probabilistic queries by adjusting the atom notations of a predicate. To scale well, we show how to prune the stochastically insignificant parts of the (ground) program, speeding up reasoning without sacrificing the predictive performance. We evaluate SLASH on various tasks, including the benchmark task of MNIST addition and Visual Question Answering (VQA).},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included"}}
}

@article{rayyan-242085896,
  title={Ontology-Based Neuro-Symbolic AI: Effects on Prediction Quality and Explainability},
  year={2024},
  author={Smirnov, A. and Ponomarev, A. and Agafonov, A.},
  url={https://ieeexplore.ieee.org/abstract/document/10731866/},
  abstract={… One of the ways of overcoming this limitation is neuro-symbolic approaches, where the neural … This paper focuses on a subset of neuro-symbolic approaches, where domain ontologies …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/cais-lab/revelionn"]}}
}

@article{rayyan-242085900,
  title={Nessy: A neuro-symbolic system for label noise reduction},
  year={2022},
  author={Smirnova, A. and Yang, J. and Yang, D.},
  url={https://ieeexplore.ieee.org/abstract/document/9860090/?casa_token=FgsfHK8t1zgAAAAA:0wweRbJdRSHaf8oa1RCz0YmJJuNoZ7GL_v_zveRlPjxmYTnObzyPqVUantqYgx7CPrFYk9erpW6B0Q},
  abstract={… To address those problems, we introduce Nessy, a neuro-symbolic system that integrates deep probabilistic modeling and symbolic knowledge for label noise reduction. Our deep …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/eXascaleInfolab/Nessy_RE"]}}
}

@article{rayyan-242085916,
  title={A symbolic neural network representation and its application to understanding, verifying, and patching networks},
  year={2019},
  author={Sotoudeh, M. and Thakur, A. V.},
  abstract={Analysis and manipulation of trained neural networks is a challenging and important problem. We propose a symbolic representation for piecewise-linear neural networks and discuss …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/95616ARG/SyReNN"]}}
}

@article{rayyan-242085925,
  title={Recommender systems based on neuro-symbolic knowledge graph embeddings encoding first-order logic rules},
  year={2024},
  author={Spillo, G. and Musto, C. and de Gemmis, M. and Lops, P.},
  abstract={In this paper, we present a knowledge-aware recommendation model based on neuro-symbolic graph embeddings that encode first-order logic rules. Our approach is based on the …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/swapUniba/KARS_NeSy_KGE_with_FOL_rules"]}}
}

@article{rayyan-242085926,
  title={Exploiting Neuro-Symbolic Graph Embeddings based on First-Order Logical Rules for Knowledge-aware Recommendations},
  year={2022},
  author={Spillo, G. and Musto, C. and de Gemmis, M. and Lops, P. and Semeraro, G.},
  url={https://ceur-ws.org/Vol-3419/paper1.pdf},
  abstract={In this paper 1, we discuss a knowledge-aware recommendation framework based on neuro-symbolic graph embeddings that encodes first-order logical (FOL) rules. Our workflow starts …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/giuspillo/RepoNeSyRecSys2022"]}}
}

@article{rayyan-242085927,
  title={Knowledge-aware recommendations based on neuro-symbolic graph embeddings and first-order logical rules},
  year={2022},
  author={Spillo, G. and Musto, C. and Gemmis, M. De and Lops, P.},
  abstract={In this paper, we present a knowledge-aware recommendation framework based on neuro-symbolic graph embeddings that encode first-order logical (FOL) rules. In particular, our …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/swapUniba/Deep_CBRS_Amar"]}}
}

@article{rayyan-242085928,
  title={MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning},
  year={2024},
  author={Sprague, Zayne and Ye, Xi and Bostrom, Kaj and Chaudhuri, Swarat and Durrett, Greg},
  abstract={While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our dataset instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy. We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Zayne-Sprague/MuSR"]}}
}

@article{rayyan-242085929,
  title={DeepPSL: End-to-end perception and reasoning},
  year={2021},
  author={Dasaratha, Sridhar and Puranam, Sai Akhil and Phogat, Karmvir Singh and Tiyyagura, Sunil Reddy and Nigel, P. Duffy},
  abstract={We introduce DeepPSL a variant of probabilistic soft logic (PSL) to produce an end-to-end trainable system that integrates reasoning and perception. PSL represents first-order logic in terms of a convex graphical model - hinge-loss Markov random fields (HL-MRFs). PSL stands out among probabilistic logic frameworks due to its tractability having been applied to systems of more than 1 billion ground rules. The key to our approach is to represent predicates in first-order logic using deep neural networks and then to approximately back-propagate through the HL-MRF and thus train every aspect of the first-order system being represented. We believe that this approach represents an interesting direction for the integration of deep learning and reasoning techniques with applications to knowledge base learning, multi-task learning, and explainability. Evaluation on three different tasks demonstrates that DeepPSL significantly outperforms state-of-the-art neuro-symbolic methods on scalability while achieving comparable or better accuracy.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/linqs/psl-examples/tree/master"]}}
}

@article{rayyan-242085933,
  title={Right for the right concept: Revising neuro-symbolic concepts by interacting with their explanations},
  year={2021},
  author={Stammer, W. and Schramowski, P.},
  url={http://openaccess.thecvf.com/content/CVPR2021/html/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.html},
  abstract={… Triggered by this, we present the first Neuro-Symbolic XIL (NeSy XIL) approach that is … and interact with neurosymbolic explanations. We demonstrate the advantages of NeSy XIL on a …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/mlresearch/NeSyXIL"]}}
}

@article{rayyan-242085939,
  title={Differentiable Fuzzy Neural Networks for Recommender Systems},
  year={2025},
  author={Bartl, Stephan and Innerebner, Kevin and Elisabeth, Lex},
  abstract={As recommender systems become increasingly complex, transparency is essential to increase user trust, accountability, and regulatory compliance. Neuro-symbolic approaches that integrate symbolic reasoning with sub-symbolic learning offer a promising approach toward transparent and user-centric systems. In this work-in-progress, we investigate using fuzzy neural networks (FNNs) as a neuro-symbolic approach for recommendations that learn logic-based rules over predefined, human-readable atoms. Each rule corresponds to a fuzzy logic expression, making the recommender's decision process inherently transparent. In contrast to black-box machine learning methods, our approach reveals the reasoning behind a recommendation while maintaining competitive performance. We evaluate our method on a synthetic and MovieLens 1M datasets and compare it to state-of-the-art recommendation algorithms. Our results demonstrate that our approach accurately captures user behavior while providing a transparent decision-making process. Finally, the differentiable nature of this approach facilitates an integration with other neural models, enabling the development of hybrid, transparent recommender systems.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/stephba/diff-fnn"]}}
}

@article{rayyan-242085945,
  title={Formalizing Consistency and Coherence of Representation Learning},
  year={2022},
  author={Stromfelt, Harald and Luke, Dickens and d'Avila, Garcez Artur and Alessandra, Russo},
  publisher={NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)},
  abstract={In the study of reasoning in neural networks, recent efforts have sought to improve consistency and coherence of sequence models, leading to important developments in the area of neuro-symbolic AI. In symbolic AI, the concepts of consistency and coherence can be defined and verified formally, but for neural networks these definitions are lacking. The provision of such formal definitions is crucial to offer a common basis for the quantitative evaluation and systematic comparison of connectionist, neuro-symbolic and transfer learning approaches. In this paper, we introduce formal definitions of consistency and coherence for neural systems. To illustrate the usefulness of our definitions, we propose a new dynamic relation-decoder model built around the principles of consistency and coherence. We compare our results with several existing relation-decoders using a partial transfer learning task based on a novel data set introduced in this paper. Our experiments show that relation-decoders that maintain consistency over unobserved regions of representation space retain coherence across domains, whilst achieving better transfer learning performance.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/HStromfelt/neurips22-FCA"]}}
}

@article{rayyan-242085956,
  title={A Hybrid Probabilistic Approach for Table Understanding},
  year={2021},
  volume={35},
  author={Sun, Kexuan and Harsha, Rayudu and Jay, Pujara},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={Tables of data are used to record vast amounts of socioeconomic, scientific, and governmental information. Although humans create tables using underlying organizational principles, unfortunately AI systems struggle to understand the contents of these tables. This paper introduces an end-to-end system for table understanding, the process of capturing the relational structure of data in tables. We introduce models that identify cell types, group these cells into blocks of data that serve a similar functional role, and predict the relationships between these blocks. We introduce a hybrid, neuro-symbolic approach, combining embedded representations learned from thousands of tables with probabilistic constraints that capture regularities in how humans organize tables. Our neurosymbolic model is better able to capture positional invariants of headers and enforce homogeneity of data types. One limitation in this research area is the lack of rich datasets for evaluating end-to-end table understanding, so we introduce a new benchmark dataset comprised of 431 diverse tables from data.gov. The evaluation results show that our system achieves the state-of-the-art performance on cell type classification, block identification, and relationship prediction, improving over prior efforts by up to 7% of macro F1 score.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/kianasun/table-understanding-system"]}}
}

@article{rayyan-242085960,
  title={Safe Learning and Verification of Neural Network Controllers for Autonomous Systems},
  year={2022},
  author={Sun, Xiaowu},
  url={https://www.proquest.com/dissertations-theses/safe-learning-verification-neural-network/docview/2767226746/se-2?accountid=28159},
  publisher={University of California, Irvine},
  abstract={The last decade has witnessed tremendous success in using machine learning (ML) to control physical systems, such as autonomous vehicles, drones, and smart cities. On the one hand, learning-based controller synthesis enjoys the scalability and flexibility benefits offered by purely data-driven architectures. Nevertheless, these end-to-end learning approaches suffer from the lack of safety, reliability, and generalization guarantees. On the other hand, control-theoretic and formal-methods techniques enjoy the guarantees of satisfying high-level specifications. Nevertheless, these algorithms need an explicit model of the dynamic systems and suffer from computational complexity whenever the dynamical models are highly nonlinear and complex. The objective of this dissertation is to develop learning algorithms and verification tools that bridge ideas from symbolic control/reasoning techniques to design ML-controlled autonomous systems with certifiable trust and assurance. The contributions of this dissertation are multi-fold. (1) We propose a neurosymbolic framework that integrates machine learning and symbolic techniques in training neural network (NN) controllers for robotic systems to satisfy temporal logic specifications. In particular, the trained NN controllers enjoy strong correctness guarantees when applying to unseen tasks, i.e., the exact task (including the environment, specifications, and dynamic constraints of a robot) is unknown during the training of NNs. (2) We introduce the first framework to formally reason about the safety of autonomous systems equipped with a neural network controller that processes LiDAR images to produce control actions. Given a NN-controlled autonomous system that processes the environment with a LiDAR sensor, our framework computes a set of safe initial states such that the autonomous system is guaranteed to be safe when starting from these initial states. (3) We propose a novel approach called NNSynth that uses machine learning techniques to guide the design of abstraction-based controllers. Thanks to the use of ML, NNSynth achieves significant performance improvement compared to traditional controller synthesis while maintaining probabilistic guarantees in the meantime. (4) We consider the problem of automatically designing neural network architectures and exhibit a systematic methodology for choosing NN architectures that are guaranteed to implement a controller that satisfies the given high-level specification. (5) Finally, we present an efficient multi-robot motion planning algorithm for missions captured by temporal logic specifications in the presence of bounded disturbances and denial-of-service (DoS) attacks.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/jlwu002/VSRL"]}}
}

@article{rayyan-242085961,
  title={Neurosymbolic Motion and Task Planning for Linear Temporal Logic Tasks},
  year={2022},
  author={Sun, Xiaowu and Shoukry, Yasser},
  abstract={This paper presents a neurosymbolic framework to solve motion planning problems for mobile robots involving temporal goals. The temporal goals are described using temporal logic formulas such as Linear Temporal Logic (LTL) to capture complex tasks. The proposed framework trains Neural Network (NN)-based planners that enjoy strong correctness guarantees when applying to unseen tasks, i.e., the exact task (including workspace, LTL formula, and dynamic constraints of a robot) is unknown during the training of NNs. Our approach to achieving theoretical guarantees and computational efficiency is based on two insights. First, we incorporate a symbolic model into the training of NNs such that the resulting NN-based planner inherits the interpretability and correctness guarantees of the symbolic model. Moreover, the symbolic model serves as a discrete "memory", which is necessary for satisfying temporal logic formulas. Second, we train a library of neural networks offline and combine a subset of the trained NNs into a single NN-based planner at runtime when a task is revealed. In particular, we develop a novel constrained NN training procedure, named formal NN training, to enforce that each neural network in the library represents a "symbol" in the symbolic model. As a result, our neurosymbolic framework enjoys the scalability and flexibility benefits of machine learning and inherits the provable guarantees from control-theoretic and formal-methods techniques. We demonstrate the effectiveness of our framework in both simulations and on an actual robotic vehicle, and show that our framework can generalize to unknown tasks where state-of-the-art meta-reinforcement learning techniques fail.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/rcpsl/Neurosymbolic_planning."]}}
}

@article{rayyan-242085962,
  title={Logic Rules as Explanations for Legal Case Retrieval},
  year={2024},
  author={Sun, Zhongxiang and Zhang, Kepu and Yu, Weijie and Wang, Haoyu and Xu, Jun},
  abstract={In this paper, we address the issue of using logic rules to explain the results from legal case retrieval. The task is critical to legal case retrieval because the users (e.g., lawyers or judges) are highly specialized and require the system to provide logical, faithful, and interpretable explanations before making legal decisions. Recently, research efforts have been made to learn explainable legal case retrieval models. However, these methods usually select rationales (key sentences) from the legal cases as explanations, failing to provide faithful and logically correct explanations. In this paper, we propose Neural-Symbolic enhanced Legal Case Retrieval (NS-LCR), a framework that explicitly conducts reasoning on the matching of legal cases through learning case-level and law-level logic rules. The learned rules are then integrated into the retrieval process in a neuro-symbolic manner. Benefiting from the logic and interpretable nature of the logic rules, NS-LCR is equipped with built-in faithful explainability. We also show that NS-LCR is a model-agnostic framework that can be plugged in for multiple legal retrieval models. To showcase NS-LCR's superiority, we enhance existing benchmarks by adding manually annotated logic rules and introducing a novel explainability metric using Large Language Models (LLMs). Our comprehensive experiments reveal NS-LCR's effectiveness for ranking, alongside its proficiency in delivering reliable explanations for legal case retrieval.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ke-01/NS-LCR"]}}
}

@article{rayyan-242085967,
  title={(Neural-Symbolic) Machine Learning for Inconsistency Measurement},
  year={2025},
  author={Weinzierl, Sven and Carl, Cora},
  abstract={We present machine-learning-based approaches for determining the \emph degree of inconsistency – which is a numerical value – for propositional logic knowledge bases. Specifically, we present regression- and neural-based models that learn to predict the values that the inconsistency measures $\incmi$ and $\incat$ would assign to propositional logic knowledge bases. Our main motivation is that computing these values conventionally can be hard complexity-wise. As an important addition, we use specific postulates, that is, properties, of the underlying inconsistency measures to infer symbolic rules, which we combine with the learning-based models in the form of constraints. We perform various experiments and show that a) predicting the degree values is feasible in many situations, and b) including the symbolic constraints deduced from the rationality postulates increases the prediction quality.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/fau-is/MLXIncon"]}}
}

@article{rayyan-242085970,
  title={EdgePrompt: Engineering Guardrail Techniques for Offline LLMs in K-12 Educational Settings},
  year={2025},
  author={Syah, Riza Alaudin and Yoga, Haryanto Christoforus and Emily, Lomempow and Krishna, Malik and Irvan, Putra},
  publisher={Association for Computing Machinery},
  abstract={EdgePrompt is a prompt engineering framework that implements pragmatic guardrails for Large Language Models (LLMs) in the K-12 educational settings through structured prompting inspired by neural-symbolic principles. The system addresses educational disparities in Indonesia's Frontier, Outermost, Underdeveloped (3T) regions by enabling offline-capable content safety controls. It combines: (1) content generation with structured constraint templates, (2) assessment processing with layered validation, and (3) lightweight storage for content and result management. The framework implements a multi-stage verification workflow that maintains safety boundaries while preserving model capabilities in connectivity-constrained environments. Initial deployment targets Grade 5 language instruction, demonstrating effective guardrails through structured prompt engineering without formal symbolic reasoning components.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/build-club-ai-indonesia/edge-prompt"]}}
}

@article{rayyan-242085977,
  title={An Experimental Pipeline for Automated Reasoning in Natural Language (Short Paper)},
  year={2023},
  volume={14132},
  author={Tammet, Tanel and Priit, Jarv and Martin, Verrev and Dirk, Draheim},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={We describe an experimental implementation of a logic-based end-to-end pipeline of performing inference and giving explained answers to questions posed in natural language. The main components of the pipeline are semantic parsing, integration with large knowledge bases, automated reasoning using extended first order logic, and finally the translation of proofs back to natural language. While able to answer relatively simple questions on its own, the implementation is targeting research into building hybrid neurosymbolic systems for gaining trustworthiness and explainability. The end goal is to combine machine learning and large language models with the components of the implementation and to use the automated reasoner as an interface between natural language and external tools like database systems and scientific calculations.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["http://github.com/tammet/nlpsolver."]}}
}

@article{rayyan-242085980,
  title={Rule: neural-symbolic knowledge graph reasoning with rule embedding},
  year={2022},
  author={Tang, X. and Zhu, S. C. and Liang, Y. and Zhang, M.},
  url={https://openreview.net/forum?id=UBSPGUwjNV},
  publisher={openreview.net},
  abstract={… (1) We design a novel paradigm of neural-symbolic KG reasoning models to combine logical rules with KG embedding. To our best knowledge, this is the first attempt to embed entities, …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/XiaojuanTang/RulE"]}}
}

@article{rayyan-242085981,
  title={Multi-Granularity Modularized Network for Abstract Visual Reasoning},
  year={2020},
  author={Tang, Xiangru and Wang, Haoyuan and Pan, Xiang and Qi, Jiyang},
  abstract={Abstract visual reasoning connects mental abilities to the physical world, which is a crucial factor in cognitive development. Most toddlers display sensitivity to this skill, but it is not easy for machines. Aimed at it, we focus on the Raven Progressive Matrices Test, designed to measure cognitive reasoning. Recent work designed some black-boxes to solve it in an end-to-end fashion, but they are incredibly complicated and difficult to explain. Inspired by cognitive studies, we propose a Multi-Granularity Modularized Network (MMoN) to bridge the gap between the processing of raw sensory information and symbolic reasoning. Specifically, it learns modularized reasoning functions to model the semantic rule from the visual grounding in a neuro-symbolic and semi-supervision way. To comprehensively evaluate MMoN, our experiments are conducted on the dataset of both seen and unseen reasoning rules. The result shows that MMoN is well suited for abstract visual reasoning and also explainable on the generalization test.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/creeper121386/RAVENtest"]}}
}

@article{rayyan-242086000,
  title={DeepStochLog: Neural Stochastic Logic Programming},
  year={2021},
  author={Winters, Thomas and Marra, Giuseppe and Manhaeve, Robin and Luc De, Raedt},
  abstract={Recent advances in neural symbolic learning, such as DeepProbLog, extend probabilistic logic programs with neural predicates. Like graphical models, these probabilistic logic programs define a probability distribution over possible worlds, for which inference is computationally hard. We propose DeepStochLog, an alternative neural symbolic framework based on stochastic definite clause grammars, a type of stochastic logic program, which defines a probability distribution over possible derivations. More specifically, we introduce neural grammar rules into stochastic definite clause grammars to create a framework that can be trained end-to-end. We show that inference and learning in neural stochastic logic programming scale much better than for neural probabilistic logic programs. Furthermore, the experimental evaluation shows that DeepStochLog achieves state-of-the-art results on challenging neural symbolic learning tasks.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ML-KULeuven/deepstochlog"]}}
}

@article{rayyan-242086029,
  title={Solving olympiad geometry without human demonstrations},
  year={2024},
  volume={625},
  number={7995},
  author={Trinh, T. H. and Wu, Y. and Le, Q. V. and He, H. and Luong, T.},
  abstract={Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning(1-4), owing to their reputed difficulty among the world's best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges(1,5), resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/google-deepmind/alphageometry"]}}
}

@article{rayyan-242086048,
  title={Constraint guided gradient descent: Training with inequality constraints with applications in regression and semantic segmentation},
  year={2023},
  volume={556},
  author={Van Baelen, Quinten and Peter, Karsmakers},
  abstract={Deep learning is typically performed by learning a neural network solely from data in the form of input-output pairs ignoring available domain knowledge. In this work, the Constraint Guided Gradient Descent (CGGD) framework is proposed that enables the injection of domain knowledge into the training procedure. The domain knowledge is assumed to be described as a conjunction of hard inequality constraints which appears to be a natural choice for several applications. Compared to other neuro-symbolic approaches, the proposed method converges to a point that makes an arbitrarily small error with respect to any inequality constraint on the training data and does not require to first transform the constraints into some ad-hoc term that is added to the learning (optimization) objective. It is empirically shown on four independent and small data sets that CGGD makes training less dependent on the initialization of the network, improves the constraint satisfiability on all data, improves the generalization of the model to unseen data, and relaxes the need for annotated data. Moreover, the method is tested for a regression and a semantic segmentation task.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/KULeuvenADVISE/CGGD"]}}
}

@article{rayyan-242086052,
  title={The DeepProbCEP system for neuro-symbolic complex event recognition},
  year={2024},
  author={Varsou, P.},
  url={https://dione.lib.unipi.gr/xmlui/handle/unipi/16166},
  publisher={dione.lib.unipi.gr},
  abstract={This research delves into the intersection of neural networks and symbolic reasoning, particularly focusing on the application of neural-symbolic learning and reasoning in Complex …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/marcRoigVilamala/DeepProbCEP"]}}
}

@article{rayyan-242086071,
  title={Neural Task Synthesis for Visual Programming},
  year={2023},
  author={Pădurean, Victor-Alexandru and Tzannetos, Georgios and Adish, Singla},
  abstract={Generative neural models hold great promise in enhancing programming education by synthesizing new content. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visual tasks for these codes. We demonstrate the effectiveness of NeurTaskSyn through an extensive empirical evaluation and a qualitative study on reference tasks taken from the Hour of Code: Classic Maze challenge by Code-dot-org and the Intro to Programming with Karel course by CodeHS-dot-com.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/machine-teaching-group/tmlr2024_neurtasksyn"]}}
}

@article{rayyan-242086081,
  title={Neural-symbolic integration for fairness in AI},
  year={2021},
  author={Wagner, B. and d'Avila Garcez, A. S.},
  url={https://openaccess.city.ac.uk/id/eprint/26151/},
  abstract={… In this paper, we propose an interactive neural-symbolic approach for fairness in AI based on the Logic Tensor Network (LTN) framework. We show that the extraction of symbolic …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["http://github.com/benediktwagner/LTN_fairness."]}}
}

@article{rayyan-242086082,
  title={Neural-symbolic reasoning under open-world and closed-world assumptions},
  year={2022},
  author={Wagner, B. and d'Avila Garcez, A. S.},
  url={https://openaccess.city.ac.uk/id/eprint/28163/},
  abstract={… use of a neurosymbolic approach and evaluate its reasoning capability. We deploy the Logic Tensor Networks neurosymbolic … The use of an iterative neurosymbolic approach improves …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/benediktwagner/ltn-reasoning."]}}
}

@article{rayyan-242086100,
  title={DeepMiR2GO: Inferring Functions of Human MicroRNAs Using a Deep Multi-Label Classification Model},
  year={2019},
  volume={20},
  number={23},
  author={Wang, J. and Zhang, J. and Cai, Y. and Deng, L.},
  abstract={MicroRNAs (miRNAs) are a highly abundant collection of functional non-coding RNAs involved in cellular regulation and various complex human diseases. Although a large number of miRNAs have been identified, most of their physiological functions remain unknown. Computational methods play a vital role in exploring the potential functions of miRNAs. Here, we present DeepMiR2GO, a tool for integrating miRNAs, proteins and diseases, to predict the gene ontology (GO) functions based on multiple deep neuro-symbolic models. DeepMiR2GO starts by integrating the miRNA co-expression network, protein-protein interaction (PPI) network, disease phenotype similarity network, and interactions or associations among them into a global heterogeneous network. Then, it employs an efficient graph embedding strategy to learn potential network representations of the global heterogeneous network as the topological features. Finally, a deep multi-label classification network based on multiple neuro-symbolic models is built and used to annotate the GO terms of miRNAs. The predicted results demonstrate that DeepMiR2GO performs significantly better than other state-of-the-art approaches in terms of precision, recall, and maximum F-measure.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/JChander/DeepMiR2GO"]}}
}

@article{rayyan-242086105,
  title={Neural symbolic representation learning for image captioning},
  year={2021},
  author={Wang, X. and Ma, L. and Fu, Y. and Xue, X.},
  abstract={… neural symbolic representation of the image for the image captioning task. We first parse and convert a given image to neural symbolic … , the neural symbolic representation evolves step …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/xiaomeiyy/NSR_Captioning/"]}}
}

@article{rayyan-242086106,
  title={3D-Aware Visual Question Answering about Parts, Poses and Occlusions},
  year={2023},
  author={Wang, Xingrui and Wufei, Ma and Zhuowan, Li and Adam, Kortylewski and Alan, Yuille},
  publisher={NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)},
  abstract={Despite rapid progress in Visual question answering (VQA), existing datasets and models mainly focus on testing reasoning in 2D. However, it is important that VQA models also understand the 3D structure of visual scenes, for example to support tasks like navigation or manipulation. This includes an understanding of the 3D object pose, their parts and occlusions. In this work, we introduce the task of 3D-aware VQA, which focuses on challenging questions that require a compositional reasoning over the 3D structure of visual scenes. We address 3D-aware VQA from both the dataset and the model perspective. First, we introduce Super-CLEVR-3D, a compositional reasoning dataset that contains questions about object parts, their 3D poses, and occlusions. Second, we propose PO3D-VQA, a 3D-aware VQA model that marries two powerful ideas: probabilistic neural symbolic program execution for reasoning and deep neural networks with 3D generative representations of objects for robust visual recognition. Our experimental results show our model PO3D-VQA outperforms existing methods significantly, but we still observe a significant performance gap compared to 2D VQA benchmarks, indicating that 3D-aware VQA remains an important open research area. The code is available at https://github.com/XingruiWang/3D-Aware-VQA.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/XingruiWang/3D-Aware-VQA"]}}
}

@article{rayyan-242086107,
  title={Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering},
  year={2024},
  author={Wang, Xingrui and Ma, Wufei and Wang, Angtian and Chen, Shuo and Kortylewski, Adam and Yuille, Alan},
  abstract={For vision-language models (VLMs), understanding the dynamic properties of objects and their interactions within 3D scenes from video is crucial for effective reasoning. In this work, we introduce a video question answering dataset SuperCLEVR-Physics that focuses on the dynamics properties of objects. We concentrate on physical concepts - velocity, acceleration, and collisions within 4D scenes, where the model needs to fully understand these dynamics properties and answer the questions built on top of them. From the evaluation of a variety of current VLMs, we find that these models struggle with understanding these dynamic properties due to the lack of explicit knowledge about the spatial structure in 3D and world dynamics in time variants. To demonstrate the importance of an explicit 4D dynamics representation of the scenes in understanding world dynamics, we further propose NS-4Dynamics, a Neural-Symbolic model for reasoning on 4D Dynamics properties under explicit scene representation from videos. Using scene rendering likelihood combining physical prior distribution, the 4D scene parser can estimate the dynamics properties of objects over time to and interpret the observation into 4D scene representation as world states. By further incorporating neural-symbolic reasoning, our approach enables advanced applications in future prediction, factual reasoning, and counterfactual reasoning. Our experiments show that our NS-4Dynamics suppresses previous VLMs in understanding the dynamics properties and answering questions about factual queries, future prediction, and counterfactual reasoning. Moreover, based on the explicit 4D scene representation, our model is effective in reconstructing the 4D scenes and re-simulate the future or counterfactual events.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://xingruiwang.github.io/projects/DynSuperCLEVR/"]}}
}

@article{rayyan-242086108,
  title={Rapid image labeling via neuro-symbolic learning},
  year={2023},
  author={Wang, Y. and Tu, Z. and Xiang, Y. and Zhou, S. and Chen, X. and Li, B.},
  abstract={… To address this challenge, we propose a neuro-symbolic approach called RAPID, which infers image labeling rules from a small amount of labeled data provided by domain experts …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Neural-Symbolic-Image-Labeling/Rapid/"]}}
}

@article{rayyan-242086112,
  title={An LLMs-based neuro-symbolic legal judgment prediction framework for civil cases},
  year={2025},
  author={Wei, B. and Yu, Y. and Gan, L. and Wu, F.},
  abstract={… To address these issues, we propose a new neural-symbolic legal judgment prediction framework for civil case based on LLMs. In this new framework, we adopt a different approach to …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Yyy11181/LLMs-based-Neuro-Symbolic-Framework-for-DWI-cases"]}}
}

@article{rayyan-242086113,
  title={LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints},
  year={2023},
  author={Xu, Weidi and Wang, Jingwei and Xie, Lele and He, Jianshan and Zhou, Hongting and Wang, Taifeng and Wan, Xiaopei and Chen, Jingdong and Qu, Chao and Wei, Chu},
  abstract={Integrating first-order logic constraints (FOLCs) with neural networks is a crucial but challenging problem since it involves modeling intricate correlations to satisfy the constraints. This paper proposes a novel neural layer, LogicMP, whose layers perform mean-field variational inference over an MLN. It can be plugged into any off-the-shelf neural network to encode FOLCs while retaining modularity and efficiency. By exploiting the structure and symmetries in MLNs, we theoretically demonstrate that our well-designed, efficient mean-field iterations effectively mitigate the difficulty of MLN inference, reducing the inference from sequential calculation to a series of parallel tensor operations. Empirical results in three kinds of tasks over graphs, images, and text show that LogicMP outperforms advanced competitors in both performance and efficiency.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/wead-hsu/logicmp"]}}
}

@article{rayyan-242086133,
  title={LLM Meets Bounded Model Checking: Neuro-symbolic Loop Invariant Inference},
  year={2024},
  author={Wu, G. and Cao, W. and Yao, Y. and Wei, H. and Chen, T. and Ma, X.},
  abstract={… Essentially, the interaction between LLM and BMC gives rise to a closed-loop neuro-symbolic … We propose a neuro-symbolic loop invariant inference approach LaM4Inv that synergizes …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/SoftWiser-group/LaM4Inv.git"]}}
}

@article{rayyan-242086134,
  title={PruneSymNet: A Symbolic Neural Network and Pruning Algorithm for Symbolic Regression},
  year={2024},
  author={Wu, Min and Li, Weijun and Yu, Lina and Li, Wenqiang and Liu, Jingyi and Li, Yanjie and Meilan, Hao},
  abstract={Symbolic regression aims to derive interpretable symbolic expressions from data in order to better understand and interpret data. %which plays an important role in knowledge discovery and interpretable machine learning. In this study, a symbolic network called PruneSymNet is proposed for symbolic regression. This is a novel neural network whose activation function consists of common elementary functions and operators. The whole network is differentiable and can be trained by gradient descent method. Each subnetwork in the network corresponds to an expression, and our goal is to extract such subnetworks to get the desired symbolic expression. Therefore, a greedy pruning algorithm is proposed to prune the network into a subnetwork while ensuring the accuracy of data fitting. The proposed greedy pruning algorithm preserves the edge with the least loss in each pruning, but greedy algorithm often can not get the optimal solution. In order to alleviate this problem, we combine beam search during pruning to obtain multiple candidate expressions each time, and finally select the expression with the smallest loss as the final result. It was tested on the public data set and compared with the current popular algorithms. The results showed that the proposed algorithm had better accuracy.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/wumin86/PruneSymNet"]}}
}

@article{rayyan-242086137,
  title={MILE: Memory-Interactive Learning Engine for Neuro-Symbolic Solutions to Mathematical Problems},
  year={2024},
  author={Wu, Y. and Nakayama, H.},
  url={https://ieeexplore.ieee.org/abstract/document/10680497/},
  abstract={… advanced approach to neuro-symbolic mathematical problem solving. We also hope that these methods can be applied to more general neuro-symbolic approaches adopting functional …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/evan-ak/mile"]}}
}

@article{rayyan-242086145,
  title={CAFE: Coarse-to-fine neural symbolic reasoning for explainable recommendation},
  year={2020},
  author={Xian, Y. and Fu, Z. and Zhao, H. and Ge, Y. and Chen, X. and Huang, Q.},
  abstract={… To this end, we propose a CoArse-to-FinE neural symbolic reasoning approach (CAFE). It … , which leverages an inventory of neural symbolic reasoning modules to effectively and …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/orcax/PGPR"]}}
}

@article{rayyan-242086146,
  title={FGeo-HyperGNet: Geometric Problem Solving Integrating Formal Symbolic System and Hypergraph Neural Network},
  year={2024},
  author={Zhang, Xiaokai and Zhu, Na and Qin, Cheng and Li, Yang and Zeng, Zhenbing and Tuo, Leng},
  abstract={Geometric problem solving has always been a long-standing challenge in the fields of automated reasoning and artificial intelligence. We built a neural-symbolic system to automatically perform human-like geometric deductive reasoning. The symbolic part is a formal system built on FormalGeo, which can automatically perform geomertic relational reasoning and algebraic calculations and organize the solving process into a solution hypertree with conditions as hypernodes and theorems as hyperedges. The neural part, called HyperGNet, is a hypergraph neural network based on the attention mechanism, including a encoder to effectively encode the structural and semantic information of the hypertree, and a solver to provide problem-solving guidance. The neural part predicts theorems according to the hypertree, and the symbolic part applies theorems and updates the hypertree, thus forming a predict-apply cycle to ultimately achieve readable and traceable automatic solving of geometric problems. Experiments demonstrate the correctness and effectiveness of this neural-symbolic architecture. We achieved a step-wised accuracy of 87.65% and an overall accuracy of 85.53% on the formalgeo7k datasets.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/BitSecret/HyperGNet"]}}
}

@article{rayyan-242086148,
  title={Neuro-symbolic verification of deep neural networks},
  year={2022},
  author={Xie, X. and Kersting, K. and Neider, D.},
  abstract={… to real-world scenarios, we propose a neurosymbolic framework for verifying deep neural networks. Following the general idea of neuro-symbolic reasoning [d’Avila Garcez et al., 2019; …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/LebronX/Neuro-Symbolic-Verification"]}}
}

@article{rayyan-242086150,
  title={Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep Learning to Enhance Question Answering Quality},
  year={2025},
  author={Kang, Xin and Shteingardt, Veronika and Wang, Yuhan and Dov, Dori},
  abstract={Knowledge representation and reasoning are critical challenges in Artificial Intelligence (AI), particularly in integrating neural and symbolic approaches to achieve explainable and transparent AI systems. Traditional knowledge representation methods often fall short of capturing complex processes and state changes. We introduce Neuro-Conceptual Artificial Intelligence (NCAI), a specialization of the neuro-symbolic AI approach that integrates conceptual modeling using Object-Process Methodology (OPM) ISO 19450:2024 with deep learning to enhance question-answering (QA) quality. By converting natural language text into OPM models using in-context learning, NCAI leverages the expressive power of OPM to represent complex OPM elements-processes, objects, and states-beyond what traditional triplet-based knowledge graphs can easily capture. This rich structured knowledge representation improves reasoning transparency and answer accuracy in an OPM-QA system. We further propose transparency evaluation metrics to quantitatively measure how faithfully the predicted reasoning aligns with OPM-based conceptual logic. Our experiments demonstrate that NCAI outperforms traditional methods, highlighting its potential for advancing neuro-symbolic AI by providing rich knowledge representations, measurable transparency, and improved reasoning.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/kangxin/NCAI"]}}
}

@article{rayyan-242086155,
  title={Neuroplex: Learning to Detect Complex Events in Sensor Networks through Knowledge Injection},
  year={2020},
  author={Xing, Tianwei and Luis, Garcia and Roig, Vilamala Marc and Federico, Cerutti and Lance, Kaplan and Alun, Preece and Mani, Srivastava},
  publisher={ASSOC COMPUTING MACHINERY},
  abstract={Despite the remarkable success in a broad set of sensing applications, state-of-the-art deep learning techniques struggle with complex reasoning tasks across a distributed set of sensors. Unlike recognizing transient complex activities (e.g., human activities such as walking or running) from a single sensor, detecting more complex events with larger spatial and temporal dependencies across multiple sensors is extremely difficult, e.g., utilizing a hospital's sensor network to detect whether a nurse is following a sanitary protocol as they traverse from patient to patient. Training a more complicated model requires a larger amount of data-which is unrealistic considering complex events rarely happen in nature. Moreover, neural networks struggle with reasoning about serial, aperiodic events separated by large quantities in the spatial-temporal dimensions. We propose Neuroplex, a neural-symbolic framework that learns to perform complex reasoning on raw sensory data with the help of high-level, injected human knowledge. Neuroplex decomposes the entire complex learning space into explicit perception and reasoning layers, i.e., by maintaining neural networks to perform low-level perception tasks and neurally reconstructed reasoning models to perform high-level, explainable reasoning. After training the neurally reconstructed reasoning model using human knowledge, Neuroplex allows effective end-to-end training of perception models with an additional semantic loss using only sparse, high-level annotations. Our experiments and evaluation show that Neuroplex is capable of learning to efficiently and effectively detect complex events-which cannot be handled by state-of-the-art neural network models. During the training, Neuroplex not only reduces data annotation requirements by 100x, but also significantly speeds up the learning process for complex event detection by 4x.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/NESL/Neuroplex"]}}
}

@article{rayyan-242086156,
  title={Scope-enhanced Compositional Semantic Parsing for DRT},
  year={2024},
  author={Yang, Xiulin and Groschwitz, Jonas and Koller, Alexander and Johan, Bos},
  abstract={Discourse Representation Theory (DRT) distinguishes itself from other semantic representation frameworks by its ability to model complex semantic and discourse phenomena through structural nesting and variable binding. While seq2seq models hold the state of the art on DRT parsing, their accuracy degrades with the complexity of the sentence, and they sometimes struggle to produce well-formed DRT representations. We introduce the AMS parser, a compositional, neurosymbolic semantic parser for DRT. It rests on a novel mechanism for predicting quantifier scope. We show that the AMS parser reliably produces well-formed outputs and performs well on DRT parsing, especially on complex sentences.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/xiulinyang/compositional_drs_parsing"]}}
}

@article{rayyan-242086160,
  title={Neural-symbolic entangled framework for complex query answering},
  year={2022},
  author={Xu, Z. and Zhang, W. and Ye, P. and Chen, H.},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/0bcfb525c8f8f07ae10a93d0b2a40e00-Abstract-Conference.html},
  abstract={… In this paper, we propose a neural symbolic entangled model, named ENeSy, which enables embedding and symbolic reasoning to enhance each other. The embedding results …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/zjukg/ENeSy."]}}
}

@article{rayyan-242086161,
  title={Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood Mapping on Earth Imagery},
  year={2023},
  author={Xu, Zelin and Tingsong, Xiao and Wenchong, He and Yu, Wang and Zhe, Jiang},
  publisher={ASSOC COMPUTING MACHINERY},
  abstract={Deep learning for Earth imagery plays an increasingly important role in geoscience applications such as agriculture, ecology, and natural disaster management. Still, progress is often hindered by the limited training labels. Given Earth imagery with limited training labels, a base deep neural network model, and a spatial knowledge base with label constraints, our problem is to infer the full labels while training the neural network. The problem is challenging due to the sparse and noisy input labels, spatial uncertainty within the label inference process, and high computational costs associated with a large number of sample locations. Existing works on neuro-symbolic models focus on integrating symbolic logic into neural networks (e.g., loss function, model architecture, and training label augmentation), but these methods do not fully address the challenges of spatial data (e.g., spatial uncertainty, the trade-off between spatial granularity and computational costs). To bridge this gap, we propose a novel Spatial Knowledge-Infused Hierarchical Learning (SKI-HL) framework that iteratively infers sample labels within a multi-resolution hierarchy. Our framework consists of a module to selectively infer labels in different resolutions based on spatial uncertainty and a module to train neural network parameters with uncertainty-aware multi-instance learning. Extensive experiments on real-world flood mapping datasets show that the proposed model outperforms several baseline methods. The code is available at https://github.com/ZelinXu2000/SKI-HL.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ZelinXu2000/SKI-HL"]}}
}

@article{rayyan-242086162,
  title={Spatial-Logic-Aware Weakly Supervised Learning for Flood Mapping on Earth Imagery},
  year={2024},
  author={Xu, Zelin and Tingsong, Xiao and Wenchong, He and Yu, Wang and Zhe, Jiang and Shigang, Chen and Yiqun, Xie and Xiaowei, Jia and Da, Yan and Yang, Zhou},
  publisher={ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
  abstract={Flood mapping on Earth imagery is crucial for disaster management, but its efficacy is hampered by the lack of high-quality training labels. Given high-resolution Earth imagery with coarse and noisy training labels, a base deep neural network model, and a spatial knowledge base with label constraints, our problem is to infer the true high-resolution labels while training neural network parameters. Traditional methods are largely based on specific physical properties and thus fall short of capturing the rich domain constraints expressed by symbolic logic. Neural-symbolic models can capture rich domain knowledge, but existing methods do not address the unique spatial challenges inherent in flood mapping on high-resolution imagery. To fill this gap, we propose a spatial-logic-aware weakly supervised learning framework. Our framework integrates symbolic spatial logic inference into probabilistic learning in a weakly supervised setting. To reduce the time costs of logic inference on vast high-resolution pixels, we propose a multi-resolution spatial reasoning algorithm to infer true labels while training neural network parameters. Evaluations of real-world flood datasets show that our model outperforms several baselines in prediction accuracy. The code is available at https://github.com/spatialdatasciencegroup/SLWSL.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ spatialdatasciencegroup/SLWSL"]}}
}

@article{rayyan-242086163,
  title={ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model},
  year={2024},
  author={Yu, Xuanqing and Sun, Wangtao and Li, Jingwei and Liu, Kang and Liu, Chengbao and Jie, Tan},
  abstract={In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we introduce the Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by integrating dynamic causal rule mining (DCRM) and dual history augmented generation (DHAG). DCRM dynamically constructs causal rules from real-time data, allowing for swift adaptation to new causal relationships. In parallel, DHAG merges short-term and long-term historical contexts, leveraging a bi-branch approach to enrich event prediction. Our framework demonstrates notable performance enhancements across diverse datasets, with significant Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language models (LLMs) for event prediction without necessitating extensive retraining. The ONSEP framework not only advances the field of TKGF but also underscores the potential of neural-symbolic approaches in adapting to dynamic data environments.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/aqSeabiscuit/ONSEP"]}}
}

@article{rayyan-242086164,
  title={Integrating Neural-Symbolic Reasoning With Variational Causal Inference Network for Explanatory Visual Question Answering},
  year={2024},
  volume={46},
  number={12},
  author={Xue, D. and Qian, S. and Xu, C.},
  abstract={Recently, a novel multimodal reasoning task named Explanatory Visual Question Answering (EVQA) has been introduced, which combines answering visual questions with multimodal explanation generation to expound upon the underlying reasoning processes. In contrast to conventional Visual Question Answering (VQA) that merely concentrates on providing answers, EVQA aims to improve the explainability and verifiability of reasoning by providing user-friendly explanations. Despite the improved explainability of inferred results, the existing EVQA models still adopt black-box neural networks to infer results, lacking the explainability of the reasoning process. Moreover, existing EVQA models commonly predict answers and explanations in isolation, overlooking the inherent causal correlation between them. To handle these challenges, we propose a Program-guided Variational Causal Inference Network (Pro-VCIN) that integrates neural-symbolic reasoning with variational causal inference and constructs causal correlations between the predicted answers and explanations. First, we utilize pretrained models to extract visual features and convert questions into the corresponding programs. Second, we propose a multimodal program Transformer to translate programs and the related visual features into coherent and rational explanations of the reasoning processes. Finally, we propose a variational causal inference to construct the target structural causal model and predict answers based on the causal correlation to explanations. Comprehensive experiments conducted on EVQA benchmark datasets reveal the superiority of Pro-VCIN in terms of both performance and explainability over state-of-the-art EVQA methods.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/LivXue/VCIN"]}}
}

@article{rayyan-242086183,
  title={Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer},
  year={2023},
  author={Yang, Zhun and Ishay, Adam and Lee, Joohyung},
  abstract={Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/azreasoners/recurrent_transformer"]}}
}

@article{rayyan-242086184,
  title={Injecting Logical Constraints into Neural Networks via Straight-Through Estimators},
  year={2023},
  author={Yang, Zhun and Lee, Joohyung and Park, Chiyoun},
  abstract={Injecting discrete logical constraints into neural network learning is one of the main challenges in neuro-symbolic AI. We find that a straight-through-estimator, a method introduced to train binary neural networks, could effectively be applied to incorporate logical constraints into neural network learning. More specifically, we design a systematic way to represent discrete logical constraints as a loss function; minimizing this loss using gradient descent via a straight-through-estimator updates the neural network's weights in the direction that the binarized outputs satisfy the logical constraints. The experimental results show that by leveraging GPUs and batch training, this method scales significantly better than existing neuro-symbolic methods that require heavy symbolic computation for computing gradients. Also, we demonstrate that our method applies to different types of neural networks, such as MLP, CNN, and GNN, making them learn with no or fewer labeled data by learning directly from known constraints.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/azreasoners/cl-ste"]}}
}

@article{rayyan-242086187,
  title={Structural generalization is hard for sequence-to-sequence models},
  year={2022},
  author={Yao, Yuekun and Koller, Alexander},
  abstract={Sequence-to-sequence (seq2seq) models have been successful across many NLP tasks, including ones that require predicting linguistic structure. However, recent work on compositional generalization has shown that seq2seq models achieve very low accuracy in generalizing to linguistic structures that were not seen in training. We present new evidence that this is a general limitation of seq2seq models that is present not just in semantic parsing, but also in syntactic parsing and in text-to-text tasks, and that this limitation can often be overcome by neurosymbolic models that have linguistic knowledge built in. We further report on some experiments that give initial answers on the reasons for these limitations.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/coli-saar/Seq2seq-on-COGS"]}}
}

@article{rayyan-242086194,
  title={DANLI: Deliberative Agent for Following Natural Language Instructions},
  year={2022},
  author={Zhang, Yichi and Yang, Jianing and Pan, Jiayi and Storks, Shane and Devraj, Nikhil and Ma, Ziqiao and Yu, Keunwoo Peter and Bao, Yuwei and Joyce, Chai},
  abstract={Recent years have seen an increasing amount of work on embodied AI agents that can perform tasks by following human language instructions. However, most of these agents are reactive, meaning that they simply learn and imitate behaviors encountered in the training data. These reactive agents are insufficient for long-horizon complex tasks. To address this limitation, we propose a neuro-symbolic deliberative agent that, while following language instructions, proactively applies reasoning and planning based on its neural and symbolic representations acquired from past experience (e.g., natural language and egocentric vision). We show that our deliberative agent achieves greater than 70% improvement over reactive baselines on the challenging TEACh benchmark. Moreover, the underlying reasoning and planning processes, together with our modular framework, offer impressive transparency and explainability to the behaviors of the agent. This enables an in-depth understanding of the agent's capabilities, which shed light on challenges and opportunities for future embodied agents for instruction following. The code is available at https://github.com/sled-group/DANLI.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/sled-group/DANLI"]}}
}

@article{rayyan-242086200,
  title={Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models},
  year={2023},
  author={Wang, Yiming and Zhang, Zhuosheng and Zhang, Pei and Yang, Baosong and Rui, Wang},
  abstract={Neural-symbolic methods have demonstrated efficiency in enhancing the reasoning abilities of large language models (LLMs). However, existing methods mainly rely on syntactically mapping natural languages to complete formal languages like Python and SQL. Those methods require that reasoning tasks be convertible into programs, which cater to the computer execution mindset and deviate from human reasoning habits. To broaden symbolic methods' applicability and adaptability in the real world, we propose the Meta-Reasoning from a linguistic perspective. This method empowers LLMs to deconstruct reasoning-independent semantic information into generic symbolic representations, thereby efficiently capturing more generalized reasoning knowledge. We conduct extensive experiments on more than ten datasets encompassing conventional reasoning tasks like arithmetic, symbolic, and logical reasoning, and the more complex interactive reasoning tasks like theory-of-mind reasoning. Experimental results demonstrate that Meta-Reasoning significantly enhances in-context reasoning accuracy, learning efficiency, out-of-domain generalization, and output stability compared to the Chain-of-Thought technique. Code and data are publicly available at \url https://github.com/Alsace08/Meta-Reasoning .},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Alsace08/Meta-Reasoning"]}}
}

@article{rayyan-242086202,
  title={Valid Text-to-SQL Generation with Unification-based DeepStochLog},
  year={2025},
  author={Jiao, Ying and Raedt, Luc De and Giuseppe, Marra},
  abstract={Large language models have been used to translate natural language questions to SQL queries. Without hard constraints on syntax and database schema, they occasionally produce invalid queries that are not executable. These failures limit the usage of these systems in real-life scenarios. We propose a neurosymbolic framework that imposes SQL syntax and schema constraints with unification-based definite clause grammars and thus guarantees the generation of valid queries. Our framework also builds a bi-directional interface to language models to leverage their natural language understanding abilities. The evaluation results on a subset of SQL grammars show that all our output queries are valid. This work is the first step towards extending language models with unification-based grammars. We demonstrate this extension enhances the validity, execution accuracy, and ground truth alignment of the underlying language model by a large margin. Our code is available at https://github.com/ML-KULeuven/deepstochlog-lm.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ML-KULeuven/deepstochlog-lm"]}}
}

@article{rayyan-242086212,
  title={Modeling Low-Resource Health Coaching Dialogues via Neuro-Symbolic Goal Summarization and Text-Units-Text Generation},
  year={2024},
  author={Zhou, Yue and Eugenio, Barbara Di and Ziebart, Brian and Sharp, Lisa and Liu, Bing and Nikolaos, Agadakos},
  abstract={Health coaching helps patients achieve personalized and lifestyle-related goals, effectively managing chronic conditions and alleviating mental health issues. It is particularly beneficial, however cost-prohibitive, for low-socioeconomic status populations due to its highly personalized and labor-intensive nature. In this paper, we propose a neuro-symbolic goal summarizer to support health coaches in keeping track of the goals and a text-units-text dialogue generation model that converses with patients and helps them create and accomplish specific goals for physical activities. Our models outperform previous state-of-the-art while eliminating the need for predefined schema and corresponding annotation. We also propose a new health coaching dataset extending previous work and a metric to measure the unconventionality of the patient's response based on data difficulty, facilitating potential coach alerts during deployment.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/uic-nlp-lab/virtualcoachdata/"]}}
}

@article{rayyan-242086213,
  title={Re-Aligning Language to Visual Objects with an Agentic Workflow},
  year={2025},
  author={Chen, Yuming and Feng, Jiangyan and Zhang, Haodong and Gong, Lijun and Zhu, Feng and Zhao, Rui and Hou, Qibin and Cheng, Ming-Ming and Yibing, Song},
  abstract={Language-based object detection (LOD) aims to align visual objects with language expressions. A large amount of paired data is utilized to improve LOD model generalizations. During the training process, recent studies leverage vision-language models (VLMs) to automatically generate human-like expressions for visual objects, facilitating training data scaling up. In this process, we observe that VLM hallucinations bring inaccurate object descriptions (e.g., object name, color, and shape) to deteriorate VL alignment quality. To reduce VLM hallucinations, we propose an agentic workflow controlled by an LLM to re-align language to visual objects via adaptively adjusting image and text prompts. We name this workflow Real-LOD, which includes planning, tool use, and reflection steps. Given an image with detected objects and VLM raw language expressions, Real-LOD reasons its state automatically and arranges action based on our neural symbolic designs (i.e., planning). The action will adaptively adjust the image and text prompts and send them to VLMs for object re-description (i.e., tool use). Then, we use another LLM to analyze these refined expressions for feedback (i.e., reflection). These steps are conducted in a cyclic form to gradually improve language descriptions for re-aligning to visual objects. We construct a dataset that contains a tiny amount of 0.18M images with re-aligned language expression and train a prevalent LOD model to surpass existing LOD methods by around 50% on the standard benchmarks. Our Real-LOD workflow, with automatic VL refinement, reveals a potential to preserve data quality along with scaling up data quantity, which further improves LOD performance from a data-alignment perspective.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/FishAndWasabi/RealLOD"]}}
}

@article{rayyan-242086220,
  title={Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning},
  year={2025},
  author={Li, Zenan and Li, Zhaoyu and Tang, Wen and Zhang, Xian and Yao, Yuan and Si, Xujie and Yang, Fan and Yang, Kaiyu and Xiaoxing, Ma},
  abstract={Large language models (LLMs) can prove mathematical theorems formally by generating proof steps (𝑎.k.a. tactics) within a proof system. However, the space of possible tactics is vast and complex, while the available training data for formal proofs is limited, posing a significant challenge to LLM-based tactic generation. To address this, we introduce a neuro-symbolic tactic generator that synergizes the mathematical intuition learned by LLMs with domain-specific insights encoded by symbolic methods. The key aspect of this integration is identifying which parts of mathematical reasoning are best suited to LLMs and which to symbolic methods. While the high-level idea of neuro-symbolic integration is broadly applicable to various mathematical problems, in this paper, we focus specifically on Olympiad inequalities (Figure 1). We analyze how humans solve these problems and distill the techniques into two types of tactics: (1) scaling, handled by symbolic methods, and (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with LLMs to prune and rank the proof goals for efficient proof search. We evaluate our framework on 161 challenging inequalities from multiple mathematics competitions, achieving state-of-the-art performance and significantly outperforming existing LLM and symbolic approaches without requiring additional training data.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Lizn-zn/NeqLIPS"]}}
}

@article{rayyan-242086228,
  title={Neuro-symbolic interpretable collaborative filtering for attribute-based recommendation},
  year={2022},
  author={Zhang, W. and Yan, J. and Wang, Z. and Wang, J.},
  abstract={… Neuro-Symbolic Architecture. We propose NS-ICF for modellevel recommendation explanation. To our best knowledge, this is the first neuro-symbolic … with the proposed neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/EdmundYanJ/NS-ICF"]}}
}

@article{rayyan-242086229,
  title={Learning to Binarize Continuous Features for Neuro-Rule Networks},
  year={2023},
  author={Zhang, Wei and Yongxiang, Liu and Zhuo, Wang and Jianyong, Wang},
  publisher={IJCAI-INT JOINT CONF ARTIF INTELL},
  abstract={Neuro-Rule Networks (NRNs) emerge as a promising neuro-symbolic method, enjoyed by the ability to equate fully-connected neural networks with logic rules. To support learning logic rules consisting of boolean variables, converting input features into binary representations is required. Different from discrete features that could be directly transformed by one-hot encodings, continuous features need to be binarized based on some numerical intervals. Existing studies usually select the bound values of intervals based on empirical strategies (e.g., equal-width interval). However, it is not optimal since the bounds are fixed and cannot be optimized to accommodate the ultimate training target. In this paper, we propose AutoInt, an approach that automatically binarizes continuous features and enables the intervals to be optimized with NRNs in an end-to-end fashion. Specifically, AutoInt automatically selects an interval for a given continuous feature in a soft manner to enable a differentiable learning procedure of interval-related parameters. Moreover, it introduces an additional soft K-means clustering loss to make the interval centres approach the original feature value distribution, thus reducing the risk of overfitting intervals. We conduct comprehensive experiments on public datasets and demonstrate the effectiveness of AutoInt in boosting the performance of NRNs.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/yxliu99/AutoInt"]}}
}

@article{rayyan-242086230,
  title={SenticVec: Toward robust and human-centric neurosymbolic sentiment analysis},
  year={2024},
  author={Zhang, X. and Mao, R. and Cambria, E.},
  url={https://aclanthology.org/2024.findings-acl.289/},
  abstract={… In this work, we propose a novel neurosymbolic method for sentiment analysis to tackle … We conducted extensive experiments to show that our neurosymbolic framework for sentiment …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/senticnet/senticvec"]}}
}

@article{rayyan-242086234,
  title={Chameleon: Fast-slow Neuro-symbolic Lane Topology Extraction},
  year={2025},
  author={Zhang, Z. and Li, X. and Zou, S. and Chi, G. and Li, S. and Qiu, X. and Wang, G.},
  abstract={… To address this challenge, we introduce neuro-symbolic methods powered by visionlanguage … (2) Neuro-symbolic reasoning methods for 3D scene understanding fail to integrate visual …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/XR-Lee/neural-symbolic"]}}
}

@article{rayyan-242086236,
  title={An interpretable neuro-symbolic model for raven's progressive matrices reasoning},
  year={2023},
  author={Zhao, S. and You, H. and Zhang, R. Y. and Si, B. and Zhen, Z. and Wan, X.},
  abstract={Raven’s Progressive Matrices (RPM) have been widely used as standard intelligence tests for human participants. Humans solve RPM problems in a hierarchical manner, perceiving …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/ scientific-lab/Toward_Intelligent_Semantic_Reasoning_on_ Raven-s_Progressive_Matrices"]}}
}

@article{rayyan-242086238,
  title={PhysORD: A neuro-symbolic approach for physics-infused motion prediction in off-road driving},
  year={2024},
  author={Zhao, Z. and Li, B. and Du, Y. and Fu, T. and Wang, C.},
  url={https://ieeexplore.ieee.org/abstract/document/10802099/?casa_token=R8h-SN4jm-UAAAAA:czv9clQWJqXCvnlYZCKvdizuw7HcnOzSo52ytdd6Ow6OKzQiXJImrAtOL5C0yOUvJzXMJIDXmU12qw},
  abstract={… By merging the advantages of both methods, neuro-symbolic approaches present a … To bridge this gap, we present PhysORD, a neural-symbolic approach integrating the conservation …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/sair-lab/PhysORD"]}}
}

@article{rayyan-242086239,
  title={Neural-Symbolic Models for Logical Queries on Knowledge Graphs},
  year={2022},
  author={Zhu, Zhaocheng and Galkin, Mikhail and Zhang, Zuobai and Jian, Tang},
  abstract={Answering complex first-order logic (FOL) queries on knowledge graphs is a fundamental task for multi-hop reasoning. Traditional symbolic methods traverse a complete knowledge graph to extract the answers, which provides good interpretation for each step. Recent neural methods learn geometric embeddings for complex queries. These methods can generalize to incomplete knowledge graphs, but their reasoning process is hard to interpret. In this paper, we propose Graph Neural Network Query Executor (GNN-QE), a neural-symbolic model that enjoys the advantages of both worlds. GNN-QE decomposes a complex FOL query into relation projections and logical operations over fuzzy sets, which provides interpretability for intermediate variables. To reason about the missing links, GNN-QE adapts a graph neural network from knowledge graph completion to execute the relation projections, and models the logical operations with product fuzzy logic. Experiments on 3 datasets show that GNN-QE significantly improves over previous state-of-the-art models in answering FOL queries. Meanwhile, GNN-QE can predict the number of answers without explicit supervision, and provide visualizations for intermediate variables.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/DeepGraphLearning/GNN-QE"]}}
}

@article{rayyan-242086242,
  title={Low-Dimensional Hyperbolic Knowledge Graph Embedding for Better Extrapolation to Under-Represented Data},
  year={2024},
  volume={14664},
  author={Zheng, Zhuoxun and Baifan, Zhou and Hui, Yang and Zhipeng, Tan and Arild, Waaler and Evgeny, Kharlamov and Ahmet, Soylu},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Past works have shown knowledge graph embedding (KGE) methods learn from facts in the form of triples and extrapolate to unseen triples. KGE in hyperbolic space can achieve impressive performance even in low-dimensional embedding space. However, existing work limitedly studied extrapolation to under-represented data, including under-represented entities and relations. To this end, we propose HolmE, a general form of KGE method on hyperbolic manifolds. HolmE addresses extrapolation to under-represented entities through a special treatment of the bias term, and extrapolation to under-represented relations by supporting strong composition. We provide empirical evidence that HolmE achieves promising performance in modelling unseen triples, under-represented entities, and under-represented relations. We prove that mainstream KGE methods either: (1) are special cases of HolmE and thus support strong composition; (2) do not support strong composition. The code and data are open-sourced at https://github.com/nsai-uio/HolmE-KGE.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/nsai-uio/HolmE-KGE"]}}
}

@article{rayyan-242086248,
  title={Neurosymbolic AI for personalized sentiment analysis},
  year={2024},
  author={Zhu, L. and Mao, R. and Cambria, E. and Jansen, B. J.},
  abstract={… To this end, we propose a novel neurosymbolic AI framework that leverages seven levels of personalization (see Fig. 2) for personalized sentiment analysis. In particular, such a …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Cyn7hia/Neurosymbolic_AI-PSA"]}}
}

@article{rayyan-242086254,
  title={Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning},
  year={2022},
  author={Li, Zhuowan and Wang, Xingrui and Stengel-Eskin, Elias and Kortylewski, Adam and Ma, Wufei and Durme, Benjamin Van and Alan, Yuille},
  abstract={Visual Question Answering (VQA) models often perform poorly on out-of-distribution data and struggle on domain generalization. Due to the multi-modal nature of this task, multiple factors of variation are intertwined, making generalization difficult to analyze. This motivates us to introduce a virtual benchmark, Super-CLEVR, where different factors in VQA domain shifts can be isolated in order that their effects can be studied independently. Four factors are considered: visual complexity, question redundancy, concept distribution and concept compositionality. With controllably generated data, Super-CLEVR enables us to test VQA methods in situations where the test data differs from the training data along each of these axes. We study four existing methods, including two neural symbolic methods NSCL and NSVQA, and two non-symbolic methods FiLM and mDETR; and our proposed method, probabilistic NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning. P-NSVQA outperforms other methods on three of the four domain shift factors. Our results suggest that disentangling reasoning and perception, combined with probabilistic uncertainty, form a strong VQA model that is more robust to domain shifts. The dataset and code are released at https://github.com/Lizw14/Super-CLEVR.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included"} | USER-NOTES: {"brandon"=>["https://github.com/Lizw14/Super-CLEVR"]}}
}

