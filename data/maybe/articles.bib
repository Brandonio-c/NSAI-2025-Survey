@article{rayyan-242083771,
  title={Supporting Co-Adaptive Machine Teaching through Human Concept Learning and Cognitive Theories},
  year={2025},
  author={Gebreegziabher, Simret Araya and Yukun, Yang and Glassman Elena, L. and Jia-Jun, Li Toby},
  publisher={Association for Computing Machinery},
  abstract={An important challenge in interactive machine learning, particularly in subjective or ambiguous domains, is fostering bi-directional alignment between humans and models. Users teach models their concept definition through data labeling, while refining their own understandings throughout the process. To facilitate this, we introduce Mocha, an interactive machine learning tool informed by two theories of human concept learning and cognition. First, it utilizes a neuro-symbolic pipeline to support Variation Theory-based counterfactual data generation. By asking users to annotate counterexamples that are syntactically and semantically similar to already-annotated data but predicted to have different labels, the system can learn more effectively while helping users understand the model and reflect on their own label definitions. Second, Mocha uses Structural Alignment Theory to present groups of counterexamples, helping users comprehend alignable differences between data items and annotate them in batch. We validated Mocha’s effectiveness and usability through a lab study with 18 participants.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Email sent to author requesting access to the source code. ", "Simret said that the code will be released soon but the NeSy component is based on previous works whose code has been released"]}}
}

@article{rayyan-242083843,
  title={Generative AI Can Be Creative Too},
  year={2024},
  volume={14951},
  author={Agrawal, Pulin and Arpan, Yagnik and Daqi, Dong},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Large Language Models (LLMs) have significantly influenced everyday computational tasks and the pursuit of Artificial General Intelligence (AGI). However, their creativity is limited by the conventional data they learn from, particularly lacking in novelty. To enhance creativity in LLMs, this paper introduces an innovative approach using the Learning Intelligent DecisionAgent (LIDA) cognitive architecture. We describe and implement a multimodal vector embeddings-based LIDA in this paper. A LIDA agent from this implementation is used to demonstrate our proposition to make generative AI more creative, specifically making it more novel. By leveraging episodic memory and attention, the LIDA-based agent can relate memories of recent unrelated events to solve current problems with novelty. Our approach incorporates a neuro-symbolic implementation of a LIDA agent that assists in generating creative ideas while illuminating a prompting technique for LLMs to make them more creative. Comparing responses from a baseline LLM and our LIDA-enhanced agent indicates an improvement in the novelty of the ideas generated.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Seems neurosymbolic, but unable to access the paper. Link: [https://link.springer.com/chapter/10.1007/978-3-031-65572-2_1]"]}}
}

@article{rayyan-242083844,
  title={λ: A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile Manipulation Robotics},
  year={2024},
  author={Jaafar, Ahmed and Raman, Shreyas Sundara and Wei, Yichen and Harithas, Sudarshan and Juliani, Sofia and Wernerfelt, Anneke and Quartey, Benedict and Idrees, Ifrah and Liu, Jason Xinyu and Stefanie, Tellex},
  abstract={Learning to execute long-horizon mobile manipulation tasks is crucial for advancing robotics in household and workplace settings. However, current approaches are typically data-inefficient, underscoring the need for improved models that require realistically sized benchmarks to evaluate their efficiency. To address this, we introduce the LAMBDA ( λ ) benchmark-Long-horizon Actions for Mobile-manipulation Benchmarking of Directed Activities-which evaluates the data efficiency of models on language-conditioned, long-horizon, multi-room, multi-floor, pick-and-place tasks using a dataset of manageable size, more feasible for collection. Our benchmark includes 571 human-collected demonstrations that provide realism and diversity in simulated and real-world settings. Unlike planner-generated data, these trajectories offer natural variability and replay-verifiability, ensuring robust learning and evaluation. We leverage LAMBDA to benchmark current end-to-end learning methods and a modular neuro-symbolic approaches that combines foundation models with task and motion planning. We find that end-to-end methods-even when pretrained-yield lower success rates, while neuro-symbolic methods perform significantly better and require less data.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Maybe"} | USER-NOTES: {"Anh"=>["Source code: https://github.com/h2r/LAMBDA\n\n+ Propose a benchmark dataset; I'm not sure if it's considered a technical contribution.\n+ Accepted at CoRL & RSS workshops but still under review for main conferences. "]}}
}

@article{rayyan-242083846,
  title={Semantic strengthening of neuro-symbolic learning},
  year={2023},
  author={Ahmed, K. and Chang, K. W.},
  url={https://proceedings.mlr.press/v206/ahmed23a.html},
  abstract={Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Maybe"} | USER-NOTES: {"Vladimir"=>["github: [github.com/UCLAStarAI/Semantic-Strengthening.], not publicly available"]}}
}

@article{rayyan-242083848,
  title={Semantic loss functions for neuro-symbolic structured prediction},
  year={2023},
  author={Ahmed, K. and Teso, S. and Morettin, P. and Liello, L. Di},
  url={https://ebooks.iospress.nl/volumearticle/63731},
  abstract={… semantic loss and neuro-symbolic entropy on four struc… “NeSy Entropy”, with “NeSy Entropy” leading to the best performing predictive models. Remarkably, we also observe that “NeSy …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Unclear if codebase is available. Better link to paper. Paper: [https://arxiv.org/abs/2405.07387]"]}}
}

@article{rayyan-242083858,
  title={Differentiable Logic Programming for Distant Supervision},
  year={2024},
  author={Takemura, Akihiro and Katsumi, Inoue},
  abstract={We introduce a new method for integrating neural networks with logic programming in Neural-Symbolic AI (NeSy), aimed at learning with distant supervision, in which direct labels are unavailable. Unlike prior methods, our approach does not depend on symbolic solvers for reasoning about missing labels. Instead, it evaluates logical implications and constraints in a differentiable manner by embedding both neural network outputs and logic programs into matrices. This method facilitates more efficient learning under distant supervision. We evaluated our approach against existing methods while maintaining a constant volume of training data. The findings indicate that our method not only matches or exceeds the accuracy of other methods across various tasks but also speeds up the learning process. These results highlight the potential of our approach to enhance both accuracy and learning efficiency in NeSy applications.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Link: [https://arxiv.org/abs/2408.12591]", "Could not find a codebase, but can maybe reach out to authors. "]}}
}

@article{rayyan-242083876,
  title={SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability},
  year={2025},
  author={Hernández-Espinosa, Alberto and Ozelim, Luan and Felipe, S. Abrahão and Zenil, Hector},
  abstract={We introduce an open-ended test grounded in algorithmic probability that can avoid benchmark contamination in the quantitative evaluation of frontier models in the context of their Artificial General Intelligence (AGI) and Superintelligence (ASI) claims. Unlike other tests, this test does not rely on statistical compression methods (such as GZIP or LZW), which are more closely related to Shannon entropy than to Kolmogorov complexity and are not able to test beyond simple pattern matching. The test challenges aspects of AI, in particular LLMs, related to features of intelligence of fundamental nature such as synthesis and model creation in the context of inverse problems (generating new knowledge from observation). We argue that metrics based on model abstraction and abduction (optimal Bayesian `inference') for predictive `planning' can provide a robust framework for testing intelligence, including natural intelligence (human and animal), narrow AI, AGI, and ASI. We found that LLM model versions tend to be fragile and incremental as a result of memorisation only with progress likely driven by the size of training data. The results were compared with a hybrid neurosymbolic approach that theoretically guarantees universal intelligence based on the principles of algorithmic probability and Kolmogorov complexity. The method outperforms LLMs in a proof-of-concept on short binary sequences. We prove that compression is equivalent and directly proportional to a system's predictive power and vice versa. That is, if a system can better predict it can better compress, and if it can better compress, then it can better predict. Our findings strengthen the suspicion regarding the fundamental limitations of LLMs, exposing them as systems optimised for the perception of mastery over human language.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/AlgoDynLab/SuperintelligenceTest]", "The paper is an evaluation of various types of AI systems including neuro symbolic ones. "]}}
}

@article{rayyan-242083879,
  title={Toward Neurosymbolic Program Comprehension},
  year={2025},
  author={Velasco, Alejandro and Garryyeva, Aya and David, N. Palacio and Mastropaolo, Antonio and Poshyvanyk, Denys},
  abstract={Recent advancements in Large Language Models (LLMs) have paved the way for Large Code Models (LCMs), enabling automation in complex software engineering tasks, such as code generation, software testing, and program comprehension, among others. Tools like GitHub Copilot and ChatGPT have shown substantial benefits in supporting developers across various practices. However, the ambition to scale these models to trillion-parameter sizes, exemplified by GPT-4, poses significant challenges that limit the usage of Artificial Intelligence (AI)-based systems powered by large Deep Learning (DL) models. These include rising computational demands for training and deployment and issues related to trustworthiness, bias, and interpretability. Such factors can make managing these models impractical for many organizations, while their black-box'' nature undermines key aspects, including transparency and accountability. In this paper, we question the prevailing assumption that increasing model parameters is always the optimal path forward, provided there is sufficient new data to learn additional patterns. In particular, we advocate for a Neurosymbolic research direction that combines the strengths of existing},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Email sent requesting access to codebase"]}}
}

@article{rayyan-242083880,
  title={FaçAID: A Transformer Model for Neuro-Symbolic Facade Reconstruction},
  year={2024},
  author={Plocharski, Aleksander and Swidzinski, Jan and Porter-Sobieraj, Joanna and Przemyslaw, Musialski},
  abstract={We introduce a neuro-symbolic transformer-based model that converts flat, segmented facade structures into procedural definitions using a custom-designed split grammar. To facilitate this, we first develop a semi-complex split grammar tailored for architectural facades and then generate a dataset comprising of facades alongside their corresponding procedural representations. This dataset is used to train our transformer model to convert segmented, flat facades into the procedural language of our grammar. During inference, the model applies this learned transformation to new facade segmentations, providing a procedural representation that users can adjust to generate varied facade designs. This method not only automates the conversion of static facade images into dynamic, editable procedural formats but also enhances the design flexibility, allowing for easy modifications.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Email sent requesting code access"]}}
}

@article{rayyan-242083881,
  title={Pro-DG: Procedural Diffusion Guidance for Architectural Facade Generation},
  year={2025},
  author={Plocharski, Aleksander and Swidzinski, Jan and Przemyslaw, Musialski},
  abstract={We present Pro-DG, a framework for procedurally controllable photo-realistic facade generation that combines a procedural shape grammar with diffusion-based image synthesis. Starting from a single input image, we reconstruct its facade layout using grammar rules, then edit that structure through user-defined transformations. As facades are inherently multi-hierarchical structures, we introduce hierarchical matching procedure that aligns facade structures at different levels which is used to introduce control maps to guide a generative diffusion pipeline. This approach retains local appearance fidelity while accommodating large-scale edits such as floor duplication or window rearrangement. We provide a thorough evaluation, comparing Pro-DG against inpainting-based baselines and synthetic ground truths. Our user study and quantitative measurements indicate improved preservation of architectural identity and higher edit accuracy. Our novel method is the first to integrate neuro-symbolically derived shape-grammars for modeling with modern generative model and highlights the broader potential of such approaches for precise and controllable image manipulation.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Email sent requesting access for codebase"]}}
}

@article{rayyan-242083887,
  title={Simple and Effective Transfer Learning for Neuro-Symbolic Integration},
  year={2024},
  author={Daniele, Alessandro and Campari, Tommaso and Malhotra, Sagar and Luciano, Serafini},
  abstract={Deep Learning (DL) techniques have achieved remarkable successes in recent years. However, their ability to generalize and execute reasoning tasks remains a challenge. A potential solution to this issue is Neuro-Symbolic Integration (NeSy), where neural approaches are combined with symbolic reasoning. Most of these methods exploit a neural network to map perceptions to symbols and a logical reasoner to predict the output of the downstream task. These methods exhibit superior generalization capacity compared to fully neural architectures. However, they suffer from several issues, including slow convergence, learning difficulties with complex perception tasks, and convergence to local minima. This paper proposes a simple yet effective method to ameliorate these problems. The key idea involves pretraining a neural model on the downstream task. Then, a NeSy model is trained on the same task via transfer learning, where the weights of the perceptual part are injected from the pretrained network. The key observation of our work is that the neural network fails to generalize only at the level of the symbolic part while being perfectly capable of learning the mapping from perceptions to symbols. We have tested our training strategy on various SOTA NeSy methods and datasets, demonstrating consistent improvements in the aforementioned problems.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Maybe"} | USER-NOTES: {"Anh"=>["Will contact authors to obtain source code. The paper said code is available in supplementary materials, but no supplementary material found."]}}
}

@article{rayyan-242083922,
  title={Robust neuro-symbolic goal and plan recognition},
  year={2023},
  author={Amado, L. and Pereira, R. F. and Meneguzzi, F.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/26408},
  abstract={… In this paper, we develop neuro-symbolic recognition approaches that can combine learning and planning techniques, compensating for noise and missing observations using prior data…},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to the author requesting code access"]}}
}

@article{rayyan-242083940,
  title={Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion},
  year={2024},
  author={Nandi, Ananjan and Kaur, Navdeep and Singla, Parag and , Mausam},
  abstract={High-quality and high-coverage rule sets are imperative to the success of Neuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form the basis of all symbolic inferences. Recent literature builds neural models for generating rule sets, however, preliminary experiments show that they struggle with maintaining high coverage. In this work, we suggest three simple augmentations to existing rule sets: (1) transforming rules to their abductive forms, (2) generating equivalent rules that use inverse forms of constituent relations and (3) random walks that propose new rules. Finally, we prune potentially low quality rules. Experiments over four datasets and five ruleset-baseline settings suggest that these simple augmentations consistently improve results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using rules without augmentations.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Included", "Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/dair-iitd/NS-KGC-AUG]", "Might be too simplistic to qualify as a new contribution"]}}
}

@article{rayyan-242083954,
  title={Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering},
  year={2019},
  author={Bosselut, Antoine and Bras, Ronan Le and Yejin, Choi},
  abstract={Understanding narratives requires reasoning about implicit world knowledge related to the causes, effects, and states of situations described in text. At the core of this challenge is how to access contextually relevant knowledge on demand and reason over it. In this paper, we present initial studies toward zero-shot commonsense question answering by formulating the task as inference over dynamically generated commonsense knowledge graphs. In contrast to previous studies for knowledge integration that rely on retrieval of existing knowledge from static knowledge graphs, our study requires commonsense knowledge integration where contextually relevant knowledge is often not present in existing knowledge bases. Therefore, we present a novel approach that generates contextually-relevant symbolic knowledge structures on demand using generative neural commonsense knowledge models. Empirical results on two datasets demonstrate the efficacy of our neuro-symbolic approach for dynamically constructing knowledge graphs for reasoning. Our approach achieves significant performance boosts over pretrained language models and vanilla knowledge models, all while providing interpretable reasoning paths for its predictions.},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["the paper improves on the previous paper on a \"COMET\" model which could be found [https://github.com/atcbosselut/comet-commonsense] but the code for COMET-DynaGen could not be found. Email has been sent to the author requesting access to the code. "]}}
}

@article{rayyan-242083961,
  title={A neuro-symbolic approach for non-intrusive load monitoring},
  year={2023},
  author={Apriceno, G. and Erculiani, L. and Passerini, A.},
  abstract={… , neuro-symbolic techniques, which combine neural networks with symbolic reasoning, have started to be applied to overcome these issues. In this paper, we devise a neuro-symbolic …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["Could not find contact email of the author"]}}
}

@article{rayyan-242083962,
  title={A neuro-symbolic approach to structured event recognition},
  year={2021},
  author={Apriceno, G. and Passerini, A. and Serafini, L.},
  url={https://iris.unitn.it/handle/11572/330903},
  abstract={… In this paper, we propose a neuro-symbolic approach for structured event recognition from raw data that uses” shallow” annotation on the high-level events and exploits background …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Message sent to the author on LinkedIn"]}}
}

@article{rayyan-242083965,
  title={FLARE: Faithful Logic-Aided Reasoning and Exploration},
  year={2024},
  author={Arakelyan, Erik and Minervini, Pasquale and Verga, Pat and Lewis, Patrick and Augenstein, Isabelle},
  abstract={Modern Question Answering (QA) and Reasoning approaches based on Large Language Models (LLMs) commonly use prompting techniques, such as Chain-of-Thought (CoT), assuming the resulting generation will have a more granular exploration and reasoning over the question space and scope. However, such methods struggle with generating outputs that are faithful to the intermediate chain of reasoning produced by the model. On the other end of the spectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to combine LLMs with external symbolic solvers. While such approaches boast a high degree of faithfulness, they usually require a model trained for code generation and struggle with tasks that are ambiguous or hard to formalise strictly. We introduce \(\textbf{F}\)aithful \(\textbf{L}\)ogic-\(\textbf{A}\)ided \(\textbf{R}\)easoning and \(\textbf{E}\)xploration (\(\textbf{FLARE}\)), a novel interpretable approach for traversing the problem space using task decompositions. We use the LLM to plan a solution, soft-formalise the query into facts and predicates using a logic programming code and simulate that code execution using an exhaustive multi-hop search over the defined space. Our method allows us to compute the faithfulness of the reasoning process w.r.t. the generated code and analyse the steps of the multi-hop search without relying on external solvers. Our methods achieve SOTA results on \(\mathbf{7}\) out of \(\mathbf{9}\) diverse reasoning benchmarks. We also show that model faithfulness positively correlates with overall performance and further demonstrate that \(\textbf{FLARE}\) allows pinpointing the decisive factors sufficient for and leading to the correct answer with optimal reasoning during the multi-hop search.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to author requesting code access"]}}
}

@article{rayyan-242083970,
  title={Neuro-symbolic ai approaches for sensor-based human activity recognition},
  year={2024},
  author={Arrotta, L.},
  url={https://air.unimi.it/handle/2434/1022155},
  publisher={air.unimi.it},
  abstract={… NeSy solutions proposed to enhance sensorbased HAR. The initial chapters focus on NeSy … For this reason, we propose a NeSy method that relies on symbolic reasoning to tackle data …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["its a thesis"]}}
}

@article{rayyan-242083971,
  title={Contextgpt: Infusing llms knowledge into neuro-symbolic activity recognition models},
  year={2024},
  author={Arrotta, L. and Bettini, C. and Civitarese, G.},
  url={https://ieeexplore.ieee.org/abstract/document/10595652/?casa_token=8ZSci_NT56UAAAAA:w5mPx3Yjs0RJfPgvBGdZsC3a7iqkPDBmycjtxynb6mC8x1c3tjJ9t0Ov0LOCXikEFrcu-edUeWvBGw},
  abstract={… We believe that NeuroSymbolic AI (NeSy) could be coupled with such approaches to further mitigate data scarcity when fine-tuning pre-trained HAR models with limited labeled data. …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to author"]}}
}

@article{rayyan-242083972,
  title={Neuro-Symbolic Approaches for Context-Aware Human Activity Recognition},
  year={2023},
  author={Arrotta, L. and Civitarese, G. and Bettini, C.},
  abstract={… In this section, we re-formulate existing Neuro-Symbolic AI (NeSy) approaches … NeSy approach in an appropriate way. In particular, we consider two state-of-the-art approaches for NeSy …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to author"]}}
}

@article{rayyan-242083973,
  title={Semantic loss: A new neuro-symbolic approach for context-aware human activity recognition},
  year={2024},
  author={Arrotta, L. and Civitarese, G. and Bettini, C.},
  abstract={… Additionally, NeSy approaches for context-aware HAR have never … NeSy methods and analyze each approach’s strengths and weaknesses. Our semantic loss remains the only NeSy …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242083974,
  title={Knowledge Infusion for Context-Aware Sensor-Based Human Activity Recognition},
  year={2022},
  author={Arrotta, Luca and Gabriele, Civitarese and Claudio, Bettini},
  publisher={IEEE},
  abstract={Neuro-symbolic AI methods aim at integrating the capabilities of data-driven deep learning solutions with the ones of more traditional symbolic approaches. These techniques have been poorly explored in the sensor-based Human Activity Recognition (HAR) research field, even if they could lead to multiple benefits such as improving model interpretability and reducing the amount of labeled data that is necessary to reliably train the model. In this paper, we propose DUSTIN, a novel knowledge infusion approach for sensor-based HAR. DUSTIN concatenates the features automatically extracted by a CNN model from raw sensor data and high-level context data with the ones inferred by a knowledge-based reasoner. In particular, the symbolic features encode common-sense knowledge about the activities which are consistent with the context of the user, and they are infused within the model before the classification layer. We experimentally evaluated DUSTIN on a HAR dataset of mobile devices sensor data that includes 14 different activities performed by 26 users. Our results show that DUSTIN outperforms state-of-the-art neuro-symbolic approaches, with the advantage of requiring a limited amount of training data and training epochs to reach satisfying recognition rates.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242083975,
  title={Probabilistic knowledge infusion through symbolic features for context-aware activity recognition},
  year={2023},
  volume={91},
  author={Arrotta, Luca and Gabriele, Civitarese and Claudio, Bettini},
  abstract={In the general machine learning domain, solutions based on the integration of deep learning models with knowledge-based approaches are emerging. Indeed, such hybrid systems have the advantage of improving the recognition rate and the model's inter-pretability. At the same time, they require a significantly reduced amount of labeled data to reliably train the model. However, these techniques have been poorly explored in the sensor-based Human Activity Recognition (HAR) domain. The common-sense knowledge about activity execution can potentially improve purely data-driven approaches. While a few knowledge infusion approaches have been proposed for HAR, they rely on rigid logic formalisms that do not take into account uncertainty. In this paper, we propose P-NIMBUS, a novel knowledge infusion approach for sensor-based HAR that relies on probabilistic reasoning. A probabilistic ontology is in charge of computing symbolic features that are combined with the features automatically extracted by a CNN model from raw sensor data and high-level context data. In particular, the symbolic features encode probabilistic common-sense knowledge about the activities consistent with the user's surrounding context. These features are infused within the model before the classification layer. We experimentally evaluated P-NIMBUS on a HAR dataset of mobile devices sensor data that includes 14 different activities performed by 25 users. Our results show that P-NIMBUS outperforms state-of-the-art neuro-symbolic approaches, with the advantage of requiring a limited amount of training data to reach satisfying recognition rates (i.e., more than 80% of F1-score with only 20% of labeled data).(c) 2023 Elsevier B.V. All rights reserved.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242083980,
  title={Improving Neural-based Classification with Logical Background Knowledge},
  year={2024},
  author={Ledaguenel, Arthur and Hudelot, Céline and Mostepha, Khouadjia},
  abstract={Neurosymbolic AI is a growing field of research aiming to combine neural networks learning capabilities with the reasoning abilities of symbolic systems. This hybridization can take many shapes. In this paper, we propose a new formalism for supervised multi-label classification with propositional background knowledge. We introduce a new neurosymbolic technique called semantic conditioning at inference, which only constrains the system during inference while leaving the training unaffected. We discuss its theoritical and practical advantages over two other popular neurosymbolic techniques: semantic conditioning and semantic regularization. We develop a new multi-scale methodology to evaluate how the benefits of a neurosymbolic technique evolve with the scale of the network. We then evaluate experimentally and compare the benefits of all three techniques across model scales on several datasets. Our results demonstrate that semantic conditioning at inference can be used to build more accurate neural-based systems with fewer resources while guaranteeing the semantic consistency of outputs.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242084000,
  title={Open research Knowledge Graph: a large-scale neuro-symbolic Knowledge organization system},
  year={2025},
  author={Auer, S. and D'Souza, J. and Farfar, K. E.},
  abstract={… This article presents the implementation of a neuro-symbolic system within the Open Research … Our findings suggest that neuro-symbolic integration enhances the ORKG’s ability to …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/ORKG]", "seems like a documentation for a software tool rather than a research paper to me. "]}}
}

@article{rayyan-242084008,
  title={Interaction with Industrial Digital Twin Using Neuro-Symbolic Reasoning},
  year={2023},
  volume={23},
  number={3},
  author={Aziz, Siyaev and Valiev, Dilmurod and Geun-Sik, Jo},
  url={https://www.proquest.com/scholarly-journals/interaction-with-industrial-digital-twin-using/docview/2774973277/se-2?accountid=28159},
  abstract={Digital twins have revolutionized manufacturing and maintenance, allowing us to interact with virtual yet realistic representations of the physical world in simulations to identify potential problems or opportunities for improvement. However, traditional digital twins do not have the ability to communicate with humans using natural language, which limits their potential usefulness. Although conventional natural language processing methods have proven to be effective in solving certain tasks, neuro-symbolic AI offers a new approach that leads to more robust and versatile solutions. In this paper, we propose neuro-symbolic reasoning (NSR)-a fundamental method for interacting with 3D digital twins using natural language. The method understands user requests and contexts to manipulate 3D components of digital twins and is able to read maintenance manuals and implement installations and removal procedures autonomously. A practical neuro-symbolic dataset of machine-understandable manuals, 3D models, and user queries is collected to train the neuro-symbolic reasoning interaction mechanism. The evaluation demonstrates that NSR can execute user commands accurately, achieving 96.2% accuracy on test data. The proposed method has industrial importance since it provides the technology to perform maintenance procedures, request information from manuals, and serve as a tool to interact with complex virtual machinery using natural language.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242084038,
  title={Confidence-based interactable neural-symbolic visual question answering},
  year={2024},
  author={Bao, Y. and Xing, T. and Chen, X.},
  url={https://www.sciencedirect.com/science/article/pii/S0925231223011141?casa_token=STdehrfjKUkAAAAA:hxYV1iU28xHTroVRSYEG-diM-cPyY1tyKFdBprlssmaC3sp2diSxq7lIHa7SWaPzNa5rb4wj},
  abstract={… One promising method for this task is neural-symbolic (NS) learning, which leverages the … To address this limitation, we propose a confidence-based neural-symbolic (CBNS) approach, …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Maybe"} | USER-NOTES: {"Vladimir"=>["Abstract seems interesting, requested access for PDF."]}}
}

@article{rayyan-242084060,
  title={A hybrid neuro-symbolic approach for text-based games using inductive logic programming},
  year={2021},
  author={Basu, K. and Murugesan, K. and Atzeni, M.},
  url={https://www.researchgate.net/profile/Kinjal-Basu-2/publication/358749169_A_Hybrid_Neuro-Symbolic_Approach_for_Text-Based_Games_using_Inductive_Logic_Programming/links/6213bb79eb735c508ae7b510/A-Hybrid-Neuro-Symbolic-Approach-for-Text-Based-Games-using-Ind},
  abstract={… have designed a hybrid neurosymbolic framework for TBGs that … We show that the agents that incorporate the neuro-symbolic … In this paper, we introduce a hybrid neuro-symbolic (HNS) …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["email sent to the corresponding author"]}}
}

@article{rayyan-242084061,
  title={Neuro-Symbolic Agent with ASP for Robust Exception Learning in Text-Based Games},
  year={2024},
  volume={3799},
  author={Basu, Kinjal},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208532708&partnerID=40&md5=8f483ef0704fc4c5d919f1a99240de4d},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084068,
  title={Neurosymbolic repair for low-code formula languages},
  year={2022},
  author={Bavishi, R. and Joshi, H. and Cambronero, J. and Fariha, A.},
  abstract={… We present LaMirage, a neurosymbolic approach that combines the strengths of both symbolic techniques (effective enumeration) and deep learning (natural ranking and long-range …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084071,
  title={Learning to Solve Abstract Reasoning Problems with Neurosymbolic Program Synthesis and Task Generation},
  year={2024},
  author={Bednarek, J. and Krawiec, K.},
  abstract={… This study introduces TransCoder, a neurosymbolic architecture that relies on programmatic representations to detect and capture relevant patterns in low-level representation of the …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084106,
  title={Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams},
  year={2025},
  author={Fazzinga, Bettina and Flesca, Sergio and Furfaro, Filippo and Pontieri, Luigi and Francesco, Scala},
  abstract={Monitoring and analyzing process traces is a critical task for modern companies and organizations. In scenarios where there is a gap between trace events and reference business activities, this entails an interpretation problem, amounting to translating each event of any ongoing trace into the corresponding step of the activity instance. Building on a recent approach that frames the interpretation problem as an acceptance problem within an Abstract Argumentation Framework (AAF), one can elegantly analyze plausible event interpretations (possibly in an aggregated form), as well as offer explanations for those that conflict with prior process knowledge. Since, in settings where event-to-activity mapping is highly uncertain (or simply under-specified) this reasoning-based approach may yield lowly-informative results and heavy computation, one can think of discovering a sequencetagging model, trained to suggest highly-probable candidate event interpretations in a context-aware way. However, training such a model optimally may require using a large amount of manually-annotated example traces. Considering the urgent need of developing Green AI solutions enabling environmental and societal sustainability (with reduced labor/computational costs and carbon footprint), we propose a data/computation-efficient neuro-symbolic approach to the problem, where the candidate interpretations returned by the example-driven sequence tagger is refined by the AAF-based reasoner. This allows us to also leverage prior knowledge to compensate for the scarcity of example data, as confirmed by experimental results; clearly, this property is particularly useful in settings where data annotation and model optimization costs are subject to stringent constraints.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242084111,
  title={Neuro-symbolic program corrector for introductory programming assignments},
  year={2018},
  author={Bhatia, S. and Kohli, P. and Singh, R.},
  abstract={… In this paper, we propose a novel Neuro-symbolic approach that combines neural networks with constraint-based reasoning. Specifically, our method first uses a Recurrent Neural …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242084138,
  title={A neuro-symbolic artificial intelligence network intrusion detection system},
  year={2024},
  author={Bizzarri, A. and Jalaian, B. and Riguzzi, F.},
  url={https://ieeexplore.ieee.org/abstract/document/10637618/?casa_token=mERLo8U_yzMAAAAA:K1aRhtOFuwFJosWX0K37zkIz4cetL6mvCNzbKLfjhPJk3-l9-OjgwuIXlaTfF2oBl-3IWE9qq5Tqqw},
  abstract={Ever-changing cyber threats require strong and flexible network security solutions. This paper suggests a new method to improve the performance of detecting both known and …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084139,
  title={Neuro-Symbolic Integration for Open Set Recognition in Network Intrusion Detection},
  year={2024},
  author={Bizzarri, A. and Yu, C. E. and Jalaian, B. and Riguzzi, F.},
  abstract={… We propose a neuro-symbolic integration approach that combines deep learning and symbolic methods, enhancing deep embedding for clustering with custom loss functions and …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Here is the link to the paper. It is in this compiled document. [https://books.google.com/books?hl=en&lr=&id=boQ7EQAAQBAJ&oi=fnd&pg=PA50&dq=Neuro-Symbolic+Integration+for+Open+Set+Recognition+in+Network+Intrusion+Detection&ots=WaxTvf3djE&sig=NAX2kRnTIcdT11eroQ7OwS72ovY#v=onepage&q=Neuro-Symbolic%20Integration%20for%20Open%20Set%20Recognition%20in%20Network%20Intrusion%20Detection&f=false]", "email sent"]}}
}

@article{rayyan-242084140,
  title={LogicRank: Logic Induced Reranking for Generative Text-to-Image Systems},
  year={2022},
  author={Deiseroth, Björn and Schramowski, Patrick and Shindo, Hikaru and Dhami, Devendra Singh and Kristian, Kersting},
  abstract={Text-to-image models have recently achieved remarkable success with seemingly accurate samples in photo-realistic quality. However as state-of-the-art language models still struggle evaluating precise statements consistently, so do language model based image generation processes. In this work we showcase problems of state-of-the-art text-to-image models like DALL-E with generating accurate samples from statements related to the draw bench benchmark. Furthermore we show that CLIP is not able to rerank those generated samples consistently. To this end we propose LogicRank, a neuro-symbolic reasoning framework that can result in a more accurate ranking-system for such precision-demanding settings. LogicRank integrates smoothly into the generation process of text-to-image models and moreover can be used to further fine-tune towards a more logical precise model.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084141,
  title={An Intrinsically Explainable Approach to Detecting Vertebral Compression Fractures in CT Scans via Neurosymbolic Modeling},
  year={2024},
  author={Inigo, Blanca and Shen, Yiqing and Benjamin, D. Killeen and Song, Michelle and Krieger, Axel and Bradley, Christopher and Unberath, Mathias},
  abstract={Vertebral compression fractures (VCFs) are a common and potentially serious consequence of osteoporosis. Yet, they often remain undiagnosed. Opportunistic screening, which involves automated analysis of medical imaging data acquired primarily for other purposes, is a cost-effective method to identify undiagnosed VCFs. In high-stakes scenarios like opportunistic medical diagnosis, model interpretability is a key factor for the adoption of AI recommendations. Rule-based methods are inherently explainable and closely align with clinical guidelines, but they are not immediately applicable to high-dimensional data such as CT scans. To address this gap, we introduce a neurosymbolic approach for VCF detection in CT volumes. The proposed model combines deep learning (DL) for vertebral segmentation with a shape-based algorithm (SBA) that analyzes vertebral height distributions in salient anatomical regions. This allows for the definition of a rule set over the height distributions to detect VCFs. Evaluation of VerSe19 dataset shows that our method achieves an accuracy of 96% and a sensitivity of 91% in VCF detection. In comparison, a black box model, DenseNet, achieved an accuracy of 95% and sensitivity of 91% in the same dataset. Our results demonstrate that our intrinsically explainable approach can match or surpass the performance of black box deep neural networks while providing additional insights into why a prediction was made. This transparency can enhance clinician's trust thus, supporting more informed decision-making in VCF diagnosis and treatment planning.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent", "Github: [https://github.com/binigoromillo/vertebra_feature_extractor]"]}}
}

@article{rayyan-242084148,
  title={Context-Dependent Semantic Parsing for Temporal Relation Extraction},
  year={2021},
  author={Su, Bo-Ying and Hsu, Shang-Ling and Lai, Kuan-Yin and Jane Yung-jen, Hsu},
  abstract={Extracting temporal relations among events from unstructured text has extensive applications, such as temporal reasoning and question answering. While it is difficult, recent development of Neural-symbolic methods has shown promising results on solving similar tasks. Current temporal relation extraction methods usually suffer from limited expressivity and inconsistent relation inference. For example, in TimeML annotations, the concept of intersection is absent. Additionally, current methods do not guarantee the consistency among the predicted annotations. In this work, we propose SMARTER, a neural semantic parser, to extract temporal information in text effectively. SMARTER parses natural language to an executable logical form representation, based on a custom typed lambda calculus. In the training phase, dynamic programming on denotations (DPD) technique is used to provide weak supervision on logical forms. In the inference phase, SMARTER generates a temporal relation graph by executing the logical form. As a result, our neural semantic parser produces logical forms capturing the temporal information of text precisely. The accurate logical form representations of an event given the context ensure the correctness of the extracted relations.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084269,
  title={A Neurosymbolic Approach to Adaptive Feature Extraction in SLAM},
  year={2024},
  author={Chandio, Y. and Khan, M. A. and Selialia, K.},
  url={https://ieeexplore.ieee.org/abstract/document/10802379/?casa_token=ei4-2BKHymUAAAAA:OR56z-cH1E7vC0MncEnxFkVGBe5Is1s8KUrnNSoFabUsRUYX-mPgwFYvF9vRVyPXhLO_HabTGEXevg},
  abstract={… , we propose leveraging the neurosymbolic program synthesis … Our neurosymbolic architecture then undertakes adaptive … Our evaluations demonstrate that our approach, neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084272,
  title={Neural Symbolic AI For POMDP Games},
  year={2022},
  author={Chao, J. and Chao, W. S. and Lange, D. S.},
  url={https://ieeexplore.ieee.org/abstract/document/10089273/?casa_token=vaSxksQUUu4AAAAA:67uOlF7-N7cLNsFWAzUj88w6WghJNkCi2fJNZOYbNYn8tgVOdVcIV-DJ_dPEIvB6rxYvh2I5PDorjw},
  abstract={This paper demonstrates the difficulties of solving partially observable Markov decision process (POMDP) games with pure deep reinforcement learning. And shows that combining the …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084273,
  title={Log2NS: Enhancing Deep Learning Based Analysis of Logs With Formal to Prevent Survivorship Bias},
  year={2021},
  author={Thimmisetty, Charanraj and Tiwari, Praveen and de la Iglesia, Didac Gil and Ramanan, Nandini and Sayer, Marjorie and Ananthakrishnan, Viswesh and Claudionor Nunes, Jr., Coelho},
  abstract={Analysis of large observational data sets generated by a reactive system is a common challenge in debugging system failures and determining their root cause. One of the major problems is that these observational data suffer from survivorship bias. Examples include analyzing traffic logs from networks, and simulation logs from circuit design. In such applications, users want to detect non-spurious correlations from observational data and obtain actionable insights about them. In this paper, we introduce log to Neuro-symbolic (Log2NS), a framework that combines probabilistic analysis from machine learning (ML) techniques on observational data with certainties derived from symbolic reasoning on an underlying formal model. We apply the proposed framework to network traffic debugging by employing the following steps. To detect patterns in network logs, we first generate global embedding vector representations of entities such as IP addresses, ports, and applications. Next, we represent large log flow entries as clusters that make it easier for the user to visualize and detect interesting scenarios that will be further analyzed. To generalize these patterns, Log2NS provides an ability to query from static logs and correlation engines for positive instances, as well as formal reasoning for negative and unseen instances. By combining the strengths of deep learning and symbolic methods, Log2NS provides a very powerful reasoning and debugging tool for log-based data. Empirical evaluations on a real internal data set demonstrate the capabilities of Log2NS.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084300,
  title={Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension},
  year={2019},
  author={Chen, X. and Liang, C. and Yu, A. W. and Zhou, D. and Song, D.},
  url={https://openreview.net/forum?id=ryxjnREFwH},
  abstract={… In this work, we study neural symbolic approaches for reading comprehension tasks that require discrete reasoning over the text (Dua et al., 2019; Hu et al., 2019; Andor et al., 2019; …},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Excluded", "Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084336,
  title={Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent Semantic Communications},
  year={2022},
  author={Thomas, Christo Kurisummoottil and Walid, Saad},
  abstract={Semantic communication (SC) aims to communicate reliably with minimal data transfer while simultaneously providing seamless connectivity to heterogeneous services and users. In this paper, a novel emergent SC (ESC) system framework is proposed and is composed of a signaling game for emergent language design and a neuro-symbolic (NeSy) artificial intelligence (AI) approach for causal reasoning. In order to design the language, the signaling game is solved using an alternating maximization between the communicating node's utilities. The emergent language helps create a context-aware transmit vocabulary (minimal semantic representation) and aids the reasoning process (enabling generalization to unseen scenarios) by splitting complex messages into simpler reasoning tasks for the receiver. The causal description at the transmitter is then modeled (a neural component) as a posterior distribution of the relevant attributes present in the data. Using the reconstructed causal state, the receiver evaluates a set of logical formulas (symbolic part) to execute its task. The nodes NeSy reasoning components are implemented by the recently proposed AI tool called Generative Flow Networks, and they are optimized for higher semantic reliability. The ESC system is designed to enhance the novel metrics of semantic information, reliability, distortion and similarity that are designed using rigorous algebraic properties from category theory thereby generalizing the metrics beyond Shannon's notion of uncertainty. Simulation results validate the ability of ESC to communicate efficiently (with reduced bits) and achieve better semantic reliability than conventional wireless and state-of-the-art systems that do not exploit causal reasoning capabilities.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084339,
  title={Scalable Neural Symbolic Regression using Control Variables},
  year={2023},
  author={Chu, X. and Zhao, H. and Xu, E. and Qi, H. and Chen, M. and Shao, H.},
  abstract={… In this paper, we propose ScaleSR, a novel neural symbolic regression with control … propose ScaleSR, a simple and effective neural symbolic regression method using control variables; …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084340,
  title={Beyond LLMs: Advancing the Landscape of Complex Reasoning},
  year={2024},
  author={Chu-Carroll, Jennifer and Beck, Andrew and Burnham, Greg and David, O. S. Melville and Nachman, David and Özcan, A. Erdem and Ferrucci, David},
  abstract={Since the advent of Large Language Models a few years ago, they have often been considered the de facto solution for many AI problems. However, in addition to the many deficiencies of LLMs that prevent them from broad industry adoption, such as reliability, cost, and speed, there is a whole class of common real world problems that Large Language Models perform poorly on, namely, constraint satisfaction and optimization problems. These problems are ubiquitous and current solutions are highly specialized and expensive to implement. At Elemental Cognition, we developed our EC AI platform which takes a neuro-symbolic approach to solving constraint satisfaction and optimization problems. The platform employs, at its core, a precise and high performance logical reasoning engine, and leverages LLMs for knowledge acquisition and user interaction. This platform supports developers in specifying application logic in natural and concise language while generating application user interfaces to interact with users effectively. We evaluated LLMs against systems built on the EC AI platform in three domains and found the EC AI systems to significantly outperform LLMs on constructing valid and optimal solutions, on validating proposed solutions, and on repairing invalid solutions.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent"]}}
}

@article{rayyan-242084361,
  title={Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic},
  year={2024},
  author={Pryor, Connor and Yuan, Quan and Liu, Jeremiah and Kazemi, Mehran and Ramachandran, Deepak and Bedrax-Weiss, Tania and Lise, Getoor},
  abstract={Dialog Structure Induction (DSI) is the task of inferring the latent dialog structure (i.e., a set of dialog states and their temporal transitions) of a given goal-oriented dialog. It is a critical component for modern dialog system design and discourse analysis. Existing DSI approaches are often purely data-driven, deploy models that infer latent states without access to domain knowledge, underperform when the training corpus is limited/noisy, or have difficulty when test dialogs exhibit distributional shifts from the training domain. This work explores a neural-symbolic approach as a potential solution to these problems. We introduce Neural Probabilistic Soft Logic Dialogue Structure Induction (NEUPSL DSI), a principled approach that injects symbolic knowledge into the latent space of a generative neural model. We conduct a thorough empirical investigation on the effect of NEUPSL DSI learning on hidden representation quality, few-shot learning, and out-of-domain generalization performance. Over three dialog structure induction datasets and across unsupervised and semi-supervised settings for standard and cross-domain generalization, the injection of symbolic knowledge using NEUPSL DSI provides a consistent boost in performance over the canonical baselines.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Maybe"} | USER-NOTES: {"Vladimir"=>["Email sent"]}}
}

@article{rayyan-242084368,
  title={Recover: A neuro-symbolic framework for failure detection and recovery},
  year={2024},
  author={Cornelio, C. and Diab, M.},
  url={https://ieeexplore.ieee.org/abstract/document/10801853/?casa_token=jlugj8kfsIgAAAAA:GgXYLVDvk4sdWedsvIkuENaubAa-RVxxFhV1pk-EIdtO_KXggoMnO3Tmeg774wOuNnGwwL3y16fx_g},
  abstract={Recognizing failures during task execution and implementing recovery procedures is challenging in robotics. Traditional approaches rely on the availability of extensive data or a tight …},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Maybe"} | USER-NOTES: {"Vladimir"=>["There's a supplementary materials page here: [https://recover-ontothor.github.io/], but no code."]}}
}

@article{rayyan-242084380,
  title={The role of foundation models in neuro-symbolic learning and reasoning},
  year={2024},
  author={Cunnington, D. and Law, M. and Lobo, J. and Russo, A.},
  abstract={… Neuro-Symbolic AI (NeSy) holds promise to ensure the safe … to enhance the performance in NeSy tasks, whilst reducing … , and can scale to complex NeSy tasks. Finally, we highlight the …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Daniel"]}}
}

@article{rayyan-242084381,
  title={Towards neural-symbolic learning to support human-agent operations},
  year={2021},
  author={Cunnington, D. and Law, M. and Russo, A.},
  url={https://ieeexplore.ieee.org/abstract/document/9626876/},
  abstract={… Abstract-This paper investigates neural-symbolic policy learning for information fusion in … Secondly, we introduce a neural-symbolic integration for policy learning and demonstrate …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to daniel"]}}
}

@article{rayyan-242084383,
  title={NSL: Hybrid Interpretable Learning From Noisy Raw Data},
  year={2021},
  author={Cunnington, Daniel and Russo, Alessandra and Law, Mark and Lobo, Jorge and Kaplan, Lance},
  abstract={Inductive Logic Programming (ILP) systems learn generalised, interpretable rules in a data-efficient manner utilising existing background knowledge. However, current ILP systems require training examples to be specified in a structured logical format. Neural networks learn from unstructured data, although their learned models may be difficult to interpret and are vulnerable to data perturbations at run-time. This paper introduces a hybrid neural-symbolic learning framework, called NSL, that learns interpretable rules from labelled unstructured data. NSL combines pre-trained neural networks for feature extraction with FastLAS, a state-of-the-art ILP system for rule learning under the answer set semantics. Features extracted by the neural components define the structured context of labelled examples and the confidence of the neural predictions determines the level of noise of the examples. Using the scoring function of FastLAS, NSL searches for short, interpretable rules that generalise over such noisy examples. We evaluate our framework on propositional and first-order classification tasks using the MNIST dataset as raw data. Specifically, we demonstrate that NSL is able to learn robust rules from perturbed MNIST data and achieve comparable or superior accuracy when compared to neural network and random forest baselines whilst being more general and interpretable.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Dan"]}}
}

@article{rayyan-242084385,
  title={Multimodal event processing: A neural-symbolic paradigm for the internet of multimedia things},
  year={2022},
  author={Curry, E. and Salwala, D. and Dhingra, P.},
  url={https://ieeexplore.ieee.org/abstract/document/9681901/},
  abstract={With the Internet of Multimedia Things (IoMT) becoming a reality, new approaches are needed to process real-time multimodal event streams. Existing approaches to event processing …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to edward"]}}
}

@article{rayyan-242084387,
  title={Multi-objective automatic analysis of lung ultrasound data from COVID-19 patients by means of deep learning and decision trees},
  year={2023},
  volume={133},
  author={Custode, L. L. and Mento, F. and Tursi, F. and Smargiassi, A. and Inchingolo, R. and Perrone, T. and Demi, L. and Iacca, G.},
  abstract={COVID-19 raised the need for automatic medical diagnosis, to increase the physicians' efficiency in managing the pandemic. Among all the techniques for evaluating the status of the lungs of a patient with COVID-19, lung ultrasound (LUS) offers several advantages: portability, cost-effectiveness, safety. Several works approached the automatic detection of LUS imaging patterns related COVID-19 by using deep neural networks (DNNs). However, the decision processes based on DNNs are not fully explainable, which generally results in a lack of trust from physicians. This, in turn, slows down the adoption of such systems. In this work, we use two previously built DNNs as feature extractors at the frame level, and automatically synthesize, by means of an evolutionary algorithm, a decision tree (DT) that aggregates in an interpretable way the predictions made by the DNNs, returning the severity of the patients' conditions according to a LUS score of prognostic value. Our results show that our approach performs comparably or better than previously reported aggregation techniques based on an empiric combination of frame-level predictions made by DNNs. Furthermore, when we analyze the evolved DTs, we discover properties about the DNNs used as feature extractors. We make our data publicly available for further development and reproducibility.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to giovanni"]}}
}

@article{rayyan-242084404,
  title={LOA: Logical Optimal Actions for Text-based Interaction Games},
  year={2021},
  author={Kimura, Daiki and Chaudhury, Subhajit and Ono, Masaki and Tatsubori, Michiaki and Agravante, Don Joven and Munawar, Asim and Wachi, Akifumi and Kohita, Ryosuke and Alexander, Gray},
  abstract={We present Logical Optimal Actions (LOA), an action decision architecture of reinforcement learning applications with a neuro-symbolic framework which is a combination of neural network and symbolic knowledge acquisition approach for natural language interaction games. The demonstration for LOA experiments consists of a web-based interactive platform for text-based games and visualization for acquired knowledge for improving interpretability for trained rules. This demonstration also provides a comparison module with other neuro-symbolic approaches as well as non-symbolic state-of-the-art agent models on the same text-based games. Our LOA also provides open-sourced implementation in Python for the reinforcement learning environment to facilitate an experiment for studying neuro-symbolic agents. Code: https://github.com/ibm/loa},
  note={RAYYAN-INCLUSION: {"Haowei"=>"Maybe"} | USER-NOTES: {"Haowei"=>["github: https://github.com/ibm/loa"]}}
}

@article{rayyan-242084491,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  year={2022},
  author={Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Ed},
  abstract={Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99% using just 14 exemplars, compared to only 16% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["might be worth investigating more as it is a foundational paper"]}}
}

@article{rayyan-242084498,
  title={Robust Cuckoo Search Enabled Fuzzy Neuro Symbolic Reasoning-Based Alzheimer’s Disease Prediction at Their Earlier Stages},
  year={2022},
  author={Dhanusha, C. and Senthil Kumar, A. V. and Giridhar Akula, V. S.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["might be worth investigating but no contact email provided"]}}
}

@article{rayyan-242084523,
  title={Symbolic/neural recognition of cursive amounts on bank cheques},
  year={1995},
  volume={1},
  author={Dodel, J. P. and Shinghal, R.},
  note={RAYYAN-INCLUSION: {"Vladimir"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Vladimir"=>["Code is in the pdf, not much used."]}}
}

@article{rayyan-242084535,
  title={Sphere Neural-Networks for Rational Reasoning},
  year={2024},
  author={Dong, Tiansi and Jamnik, Mateja and Liò, Pietro},
  abstract={The success of Large Language Models (LLMs), e.g., ChatGPT, is witnessed by their planetary popularity, their capability of human-like communication, and also by their steadily improved reasoning performance. However, it remains unclear whether LLMs reason. It is an open problem how traditional neural networks can be qualitatively extended to go beyond the statistic paradigm and achieve high-level cognition. Here, we present a novel qualitative extension by generalising computational building blocks from vectors to spheres. We propose Sphere Neural Networks (SphNNs) for human-like reasoning through model construction and inspection, and develop SphNN for syllogistic reasoning, a microcosm of human rationality. SphNN is a hierarchical neuro-symbolic Kolmogorov-Arnold geometric GNN, and uses a neuro-symbolic transition map of neighbourhood spatial relations to transform the current sphere configuration towards the target. SphNN is the first neural model that can determine the validity of long-chained syllogistic reasoning in one epoch without training data, with the worst computational complexity of O(N). SphNN can evolve into various types of reasoning, such as spatio-temporal reasoning, logical reasoning with negation and disjunction, event reasoning, neuro-symbolic unification, and humour understanding (the highest level of cognition). All these suggest a new kind of Herbert A. Simon's scissors with two neural blades. SphNNs will tremendously enhance interdisciplinary collaborations to develop the two neural blades and realise deterministic neural reasoning and human-bounded rationality and elevate LLMs to reliable psychological AI. This work suggests that the non-zero radii of spheres are the missing components that prevent traditional deep-learning systems from reaching the realm of rational reasoning and cause LLMs to be trapped in the swamp of hallucination.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242084536,
  title={Word Sense Disambiguation as a Game of Neurosymbolic Darts},
  year={2023},
  author={Dong, Tiansi and Rafet, Sifa},
  abstract={Word Sense Disambiguation (WSD) is one of the hardest tasks in natural language understanding and knowledge engineering. The glass ceiling of 80% F1 score is recently achieved through supervised deep-learning, enriched by a variety of knowledge graphs. Here, we propose a novel neurosymbolic methodology that is able to push the F1 score above 90%. The core of our methodology is a neurosymbolic sense embedding, in terms of a configuration of nested balls in n-dimensional space. The centre point of a ball well-preserves word embedding, which partially fix the locations of balls. Inclusion relations among balls precisely encode symbolic hypernym relations among senses, and enable simple logic deduction among sense embeddings, which cannot be realised before. We trained a Transformer to learn the mapping from a contextualized word embedding to its sense ball embedding, just like playing the game of darts (a game of shooting darts into a dartboard). A series of experiments are conducted by utilizing pre-training n-ball embeddings, which have the coverage of around 70% training data and 75% testing data in the benchmark WSD corpus. The F1 scores in experiments range from 90.1% to 100.0% in all six groups of test data-sets (each group has 4 testing data with different sizes of n-ball embeddings). Our novel neurosymbolic methodology has the potential to break the ceiling of deep-learning approaches for WSD. Limitations and extensions of our current works are listed.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent. "]}}
}

@article{rayyan-242084543,
  title={TAM-SenticNet: A Neuro-Symbolic AI approach for early depression detection via social media analysis},
  year={2024},
  author={Dou, R. and Kang, X.},
  url={https://www.sciencedirect.com/science/article/pii/S0045790623004950?casa_token=haVKuTBtaPUAAAAA:5OTRdh7BTbQLDxGllC4eEXqCpe_g60w7paVr46zuPL7-Hs7L68z1vik2hw7rDAgj30ZxhMLg},
  abstract={This paper introduces TAM-SenticNet, a Neuro-Symbolic AI framework uniquely designed for early depression detection through social media content analysis. Merging neural …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Rongyu."]}}
}

@article{rayyan-242084544,
  title={NeSyMoF: A Neuro-Symbolic Model for Motion Forecasting},
  year={2024},
  author={Doula, A. and Yin, H. and Mühlhäuser, M.},
  url={https://ieeexplore.ieee.org/abstract/document/10801779/?casa_token=sN9O6Q0lqJUAAAAA:BqFBDQgKacnkiXdOEP1Hq9Can58SftNoOP0bhUUsZg4K9iSYIj_7CzoW2S_64MyCHWtKAGelq6_SAg},
  abstract={… Data processing in NeSyMoF involves extracting pertinent features from the agent’s environment and channeling them into a neuro-symbolic reasoning module. The neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Achref."]}}
}

@article{rayyan-242084546,
  title={Neuro-symbolic constraint programming for structured prediction},
  year={2021},
  author={Dragone, P. and Teso, S. and Passerini, A.},
  abstract={We propose Nester, a method for injecting neural networks into constrained structured predictors. The job of the neural network(s) is to compute an initial, raw prediction that is …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Paolo and Stefano. "]}}
}

@article{rayyan-242084563,
  title={S-reinforce: A neuro-symbolic policy gradient approach for interpretable reinforcement learning},
  year={2023},
  author={Dutta, R. and Wang, Q. and Singh, A. and Kumarjiguda, D.},
  abstract={This paper presents a novel RL algorithm, S-REINFORCE, which is designed to generate interpretable policies for dynamic decision-making tasks. The proposed algorithm leverages …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Rajdeep."]}}
}

@article{rayyan-242084564,
  title={PyReason: Software for Open World Temporal Logic},
  year={2023},
  author={Aditya, Dyuman and Mukherji, Kaustuv and Balasubramanian, Srikar and Chaudhary, Abhiraj and Paulo, Shakarian},
  abstract={The growing popularity of neuro symbolic reasoning has led to the adoption of various forms of differentiable (i.e., fuzzy) first order logic. We introduce PyReason, a software framework based on generalized annotated logic that both captures the current cohort of differentiable logics and temporal extensions to support inference over finite periods of time with capabilities for open world reasoning. Further, PyReason is implemented to directly support reasoning over graphical structures (e.g., knowledge graphs, social networks, biological networks, etc.), produces fully explainable traces of inference, and includes various practical features such as type checking and a memory-efficient implementation. This paper reviews various extensions of generalized annotated logic integrated into our implementation, our modern, efficient Python-based implementation that conducts exact yet scalable deductive inference, and a suite of experiments. PyReason is available at: github.com/lab-v2/pyreason.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Github: [https://github.com/lab-v2/pyreason]", "It is a powerful software framework for NeSy systems. They do provide some evaluation on two datasets. But I am not sure if they provide any new NeSy method. "]}}
}

@article{rayyan-242084568,
  title={On the Capabilities of Pointer Networks for Deep Deductive Reasoning},
  year={2021},
  author={Ebrahimi, Monireh and Eberhart, Aaron and Hitzler, Pascal},
  abstract={The importance of building neural networks that can learn to reason has been well recognized in the neuro-symbolic community. In this paper, we apply neural pointer networks for conducting reasoning over symbolic knowledge bases. In doing so, we explore the benefits and limitations of encoder-decoder architectures in general and pointer networks in particular for developing accurate, generalizable and robust neuro-symbolic reasoners. Based on our experimental results, pointer networks performs remarkably well across multiple reasoning tasks while outperforming the previously reported state of the art by a significant margin. We observe that the Pointer Networks preserve their performance even when challenged with knowledge graphs of the domain/vocabulary it has never encountered before. To the best of our knowledge, this is the first study on neuro-symbolic reasoning using Pointer Networks. We hope our impressive results on these reasoning problems will encourage broader exploration of pointer networks' capabilities for reasoning over more complex logics and for other neuro-symbolic problems.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Monireh"]}}
}

@article{rayyan-242084574,
  title={Neural-Symbolic Integration: A Compositional Perspective},
  year={2020},
  author={Tsamoura, Efthymia and Loizos, Michael},
  abstract={Despite significant progress in the development of neural-symbolic frameworks, the question of how to integrate a neural and a symbolic system in a \emph compositional manner remains open. Our work seeks to fill this gap by treating these two systems as black boxes to be integrated as modules into a single architecture, without making assumptions on their internal structure and semantics. Instead, we expect only that each module exposes certain methods for accessing the functions that the module implements: the symbolic module exposes a deduction method for computing the function's output on a given input, and an abduction method for computing the function's inputs for a given output; the neural module exposes a deduction method for computing the function's output on a given input, and an induction method for updating the function given input-output training instances. We are, then, able to show that a symbolic module - with any choice for syntax and semantics, as long as the deduction and abduction methods are exposed - can be cleanly integrated with a neural module, and facilitate the latter's efficient training, achieving empirical performance that exceeds that of previous work.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to efthymia."]}}
}

@article{rayyan-242084576,
  title={Intelligent Traffic Monitoring with Hybrid AI},
  year={2022},
  author={Qasemi, Ehsan and Alessandro, Oltramari},
  abstract={Challenges in Intelligent Traffic Monitoring (ITMo) are exacerbated by the large quantity and modalities of data and the need for the utilization of state-of-the-art (SOTA) reasoners. We formulate the problem of ITMo and introduce HANS, a neuro-symbolic architecture for multi-modal context understanding, and its application to ITMo. HANS utilizes knowledge graph technology to serve as a backbone for SOTA reasoning in the traffic domain. Through case studies, we show how HANS addresses the challenges associated with traffic monitoring while being able to integrate with a wide range of reasoning methods},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Ehsan. "]}}
}

@article{rayyan-242084590,
  title={Neuro-Symbolic Learning for Galois Groups: Unveiling Probabilistic Trends in Polynomials},
  year={2025},
  author={Shaska, Elira and Tony, Shaska},
  abstract={This paper presents a neurosymbolic approach to classifying Galois groups of polynomials, integrating classical Galois theory with machine learning to address challenges in algebraic computation. By combining neural networks with symbolic reasoning we develop a model that outperforms purely numerical methods in accuracy and interpretability. Focusing on sextic polynomials with height ≤ 6, we analyze a database of 53,972 irreducible examples, uncovering novel distributional trends, such as the 20 sextic polynomials with Galois group C\_6 spanning just seven invariant-defined equivalence classes. These findings offer the first empirical insights into Galois group probabilities under height constraints and lay the groundwork for exploring solvability by radicals. Demonstrating AI's potential to reveal patterns beyond traditional symbolic techniques, this work paves the way for future research in computational algebra, with implications for probabilistic conjectures and higher degree classifications.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Elira. "]}}
}

@article{rayyan-242084592,
  title={Dynamic Path Planning for Autonomous Vehicles: A Neuro-Symbolic Approach},
  year={2024},
  volume={3},
  author={Elrasas, Omar and Ehab, Nourhan and Mansy, Yasmin and Mougy, Amr El},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["could not find author email. "]}}
}

@article{rayyan-242084608,
  title={Neuro-Symbolic Program Synthesis for Multi-Hop Natural Language Navigation},
  year={2024},
  author={English, William and Simon, Dominic and Ahmed, Rubel and Jha, Sumit and Ewetz, Rickard},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to william. "]}}
}

@article{rayyan-242084622,
  title={Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language},
  year={2024},
  author={Faghihi, H. R. and Nafar, A. and Uszok, A. and Karimian, H.},
  abstract={… We aim to facilitate the development of neuro-symbolic models … supports the development of neuro-symbolic models instead of … to create complex declarative neuro-symbolic models. …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Hossein. "]}}
}

@article{rayyan-242084623,
  title={The Role of Semantic Parsing in Understanding Procedural Text},
  year={2023},
  author={Faghihi, Hossein Rajaby and Parisa, Kordjamshidi and Man, Teng Choh and James, Allen},
  publisher={ASSOC COMPUTATIONAL LINGUISTICS-ACL},
  abstract={In this paper, we investigate whether symbolic semantic representations, extracted from deep semantic parsers, can help reasoning over the states of involved entities in a procedural text. We consider a deep semantic parser (TRIPS) and semantic role labeling as two sources of semantic parsing knowledge. First, we propose PROPOLIS, a symbolic parsing-based procedural reasoning framework. Second, we integrate semantic parsing information into state-of-the-art neural models to conduct procedural reasoning. Our experiments indicate that explicitly incorporating such semantic knowledge improves procedural understanding. This paper presents new metrics for evaluating procedural reasoning tasks that clarify the challenges and identify differences among neural, symbolic, and integrated models.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Ishan"=>["the provided repo is empty so author was contacted to update the repo", "Github: [https://github.com/HLR/ProceduralSemanticParsing]"]}}
}

@article{rayyan-242084630,
  title={StackSight: Unveiling webassembly through large language models and neurosymbolic chain-of-thought decompilation},
  year={2024},
  author={Fang, W. and Zhou, Z. and He, J. and Wang, W.},
  abstract={… In this paper, we propose StackSight, a novel neurosymbolic approach that combines Large Language Models (LLMs) with advanced program analysis to decompile complex …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Email sent to weike."]}}
}

@article{rayyan-242084633,
  title={Neural-Symbolic Commonsense Reasoner with Relation Predictors},
  year={2021},
  author={Moghimifar, Farhad and Qu, Lizhen and Zhuo, Yue and Haffari, Gholamreza and Mahsa, Baktashmotlagh},
  abstract={Commonsense reasoning aims to incorporate sets of commonsense facts, retrieved from Commonsense Knowledge Graphs (CKG), to draw conclusion about ordinary situations. The dynamic nature of commonsense knowledge postulates models capable of performing multi-hop reasoning over new situations. This feature also results in having large-scale sparse Knowledge Graphs, where such reasoning process is needed to predict relations between new events. However, existing approaches in this area are limited by considering CKGs as a limited set of facts, thus rendering them unfit for reasoning over new unseen situations and events. In this paper, we present a neural-symbolic reasoner, which is capable of reasoning over large-scale dynamic CKGs. The logic rules for reasoning over CKGs are learned during training by our model. In addition to providing interpretable explanation, the learned logic rules help to generalise prediction to newly introduced events. Experimental results on the task of link prediction on CKGs prove the effectiveness of our model by outperforming the state-of-the-art models.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Farhad."]}}
}

@article{rayyan-242084639,
  title={A novel hybrid approach for text encoding: Cognitive Attention To Syntax model to detect online misinformation},
  year={2023},
  volume={148},
  author={Faye, Geraud and Wassila, Ouerdane and Guillaume, Gadek and Souhir, Gahbiche and Sylvain, Gatepaille},
  abstract={Most approaches for text encoding rely on the attention mechanism, at the core of the transformers architecture and large language models. The understanding of this mechanism is still limited and present inconvenients such as lack of interpretability, large requirements of data and low generalization. Based on current understanding of the attention mechanism, we propose CATS (Cognitive Attention To Syntax), a neurosymbolic attention encoding approach based on the syntactic understanding of texts. This approach has on-par to better performance compared to classical attention and displays expected advantages of neurosymbolic AI such as better functioning with little data and better explainability. This layer has been tested on the task of misinformation detection but is general and could be used in any task involving natural language processing.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Geraud. "]}}
}

@article{rayyan-242084651,
  title={Generating new concepts with hybrid neuro-symbolic models},
  year={2020},
  author={Feinman, R. and Lake, B. M.},
  abstract={… as a case study for exploring neurosymbolic models of concept … their position on the neurosymbolic spectrum and the fidelity in … We find that a hybrid neuro-symbolic architecture with …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Reuben."]}}
}

@article{rayyan-242084660,
  title={Identification of Entailment and Contradiction Relations between Natural Language Sentences: A Neurosymbolic Approach},
  year={2024},
  author={Feng, X. and Hunter, A.},
  abstract={Natural language inference (NLI), also known as Recognizing Textual Entailment (RTE), is an important aspect of natural language understanding. Most research now uses machine …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Xuyao."]}}
}

@article{rayyan-242084667,
  title={ECATS: Explainable-by-Design Concept-Based Anomaly Detection for Time Series},
  year={2024},
  volume={14980},
  author={Ferfoglia, Irene and Gaia, Saveri and Laura, Nenzi and Luca, Bortolussi},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Deep learning methods for time series have already reached excellent performances in both prediction and classification tasks, including anomaly detection. However, the complexity inherent in Cyber Physical Systems (CPS) creates a challenge when it comes to explainability methods. To overcome this inherent lack of interpretability, we propose ECATS, a concept-based neuro-symbolic architecture where concepts are represented as Signal Temporal Logic (STL) formulae. Leveraging kernel-based methods for STL, concept embeddings are learnt in an unsupervised manner through a cross-attention mechanism. The network makes class predictions through these concept embeddings, allowing for a meaningful explanation to be naturally extracted for each input. Our preliminary experiments with simple CPS-based datasets show that our model is able to achieve great classification performance while ensuring local interpretability.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Irene. "]}}
}

@article{rayyan-242084672,
  title={Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation},
  year={2024},
  author={Hillerstrom, Fieke and Gertjan, Burghouts},
  abstract={Many inductive logic programming (ILP) methods are incapable of learning programs from probabilistic background knowledge, e.g. coming from sensory data or neural networks with probabilities. We propose Propper, which handles flawed and probabilistic background knowledge by extending ILP with a combination of neurosymbolic inference, a continuous criterion for hypothesis selection (BCE) and a relaxation of the hypothesis constrainer (NoisyCombo). For relational patterns in noisy images, Propper can learn programs from as few as 8 examples. It outperforms binary ILP and statistical models such as a Graph Neural Network.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["Email sent to Fieke. "]}}
}

@article{rayyan-242084690,
  title={Bayesian polynomial neural networks and polynomial neural ordinary differential equations},
  year={2024},
  volume={20},
  number={10},
  author={Fronk, Colby and Jaewoong, Yun and Prashant, Singh and Linda, Petzold},
  abstract={Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs. Polynomial neural ordinary differential equations (ODEs) are a recent approach for symbolic regression of dynamical systems governed by polynomials. However, they are limited in that they provide maximum likelihood point estimates of the model parameters. The domain expert using system identification often desires a specified level of confidence or range of parameter values that best fit the data. In this work, we use Bayesian inference to provide posterior probability distributions of the parameters in polynomial neural ODEs. To date, there are no studies that attempt to identify the best Bayesian inference method for neural ODEs and symbolic neural ODEs. To address this need, we explore and compare three different approaches for estimating the posterior distributions of weights and biases of the polynomial neural network: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. We have also developed lightweight JAX code to estimate posterior probability distributions using the Laplace approximation.},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to colby."]}}
}

@article{rayyan-242084691,
  title={AnyNav: Visual Neuro-Symbolic Friction Learning for Off-road Navigation},
  year={2025},
  author={Fu, T. and Zhan, Z. and Zhao, Z. and Su, S. and Lin, X. and Esfahani, E. T.},
  abstract={… friction estimation framework grounded in neuro-symbolic principles, integrating neural … These results mark an important step toward developing neuro-symbolic spatial intelligence …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to Taimeng. "]}}
}

@article{rayyan-242084703,
  title={A symbolic-neural reasoning model for visual question answering},
  year={2023},
  author={Gao, J. and Blair, A. and Pagnucco, M.},
  url={https://ieeexplore.ieee.org/abstract/document/10191538/?casa_token=nKToZJRTpfIAAAAA:WIYBVbgaKA_QpjmlhSlh7gxciasnV_nKVR-FgoDsdJEdCkT1czOySPUk6YYUDONWQEG2HbB9BGGiJA},
  abstract={… , we introduce a hybrid symbolic-neural reasoning system that … Our findings indicate that our hybrid symbolic-neural rea… an innovative hybrid symbolicneural reasoning model that can …},
  note={RAYYAN-INCLUSION: {"Ishan"=>"Maybe"} | USER-NOTES: {"Ishan"=>["email sent to jingying"]}}
}

@article{rayyan-242084743,
  title={Neuro-Symbolic Scene Graph Conditioning for Synthetic Image Dataset Generation},
  year={2025},
  author={Savazzi, Giacomo and Lomurno, Eugenio and Sbrolli, Cristian and Chiatti, Agnese and Matteo, Matteucci},
  abstract={As machine learning models increase in scale and complexity, obtaining sufficient training data has become a critical bottleneck due to acquisition costs, privacy constraints, and data scarcity in specialised domains. While synthetic data generation has emerged as a promising alternative, a notable performance gap remains compared to models trained on real data, particularly as task complexity grows. Concurrently, Neuro-Symbolic methods, which combine neural networks' learning strengths with symbolic reasoning's structured representations, have demonstrated significant potential across various cognitive tasks. This paper explores the utility of Neuro-Symbolic conditioning for synthetic image dataset generation, focusing specifically on improving the performance of Scene Graph Generation models. The research investigates whether structured symbolic representations in the form of scene graphs can enhance synthetic data quality through explicit encoding of relational constraints. The results demonstrate that Neuro-Symbolic conditioning yields significant improvements of up to +2.59% in standard Recall metrics and +2.83% in No Graph Constraint Recall metrics when used for dataset augmentation. These findings establish that merging Neuro-Symbolic and generative approaches produces synthetic data with complementary structural information that enhances model performance when combined with real data, providing a novel approach to overcome data scarcity limitations even for complex visual reasoning tasks.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Relevant paper. However could not find a code base. Marking as maybe as a potential follow-up with the authors. "]}}
}

@article{rayyan-242084751,
  title={Extraction, insertion and refinement of symbolic rules in dynamically driven recurrent neural networks},
  year={1993},
  author={Giles, C. L. and Omlin, C. W.},
  abstract={Recurrent neural networks readily process, learn and generate temporal sequences. In addition, they have been shown to have impressive computational power. Recurrent neural …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Seems relevant. Unable to access full paper from journal, so unclear if code is available."]}}
}

@article{rayyan-242084756,
  title={T-Norms Driven Loss Functions for Machine Learning},
  year={2019},
  author={Marra, Giuseppe and Giannini, Francesco and Diligenti, Michelangelo and Maggini, Marco and Marco, Gori},
  abstract={Neural-symbolic approaches have recently gained popularity to inject prior knowledge into a learner without requiring it to induce this knowledge from data. These approaches can potentially learn competitive solutions with a significant reduction of the amount of supervised data. A large class of neural-symbolic approaches is based on First-Order Logic to represent prior knowledge, relaxed to a differentiable form using fuzzy logic. This paper shows that the loss function expressing these neural-symbolic learning tasks can be unambiguously determined given the selection of a t-norm generator. When restricted to supervised learning, the presented theoretical apparatus provides a clean justification to the popular cross-entropy loss, which has been shown to provide faster convergence and to reduce the vanishing gradient problem in very deep structures. However, the proposed learning formulation extends the advantages of the cross-entropy loss to the general knowledge that can be represented by a neural-symbolic method. Therefore, the methodology allows the development of a novel class of loss functions, which are shown in the experimental results to lead to faster convergence rates than the approaches previously proposed in the literature.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Seems relevant. Unable to find code. We can follow-up with authors. "]}}
}

@article{rayyan-242084760,
  title={Neuro-symbolic semantic learning for chemistry},
  year={2023},
  author={Glauer, M. and Mossakowski, T. and Neuhaus, F.},
  url={https://ebooks.iospress.nl/volumearticle/63730},
  abstract={… A challenge for the neuro-symbolic field is how to use the … In this chapter we describe a general neuro-symbolic architecture for … -layered architecture for neuro-symbolic integration, with …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Bhuvanesh"=>["Relevant, but seems unlikely we will find code. Will need to reach out to author for code. Article is behind a journal paywall. Author has other papers where he has publicized code. "]}}
}

@article{rayyan-242084774,
  title={Analogical Reasoning Within a Conceptual Hyperspace},
  year={2024},
  author={Goldowsky, Howard and Sarathy, Vasanth},
  abstract={We propose an approach to analogical inference that marries the neuro-symbolic computational power of complex-sampled hyperdimensional computing (HDC) with Conceptual Spaces Theory (CST), a promising theory of semantic meaning. CST sketches, at an abstract level, approaches to analogical inference that go beyond the standard predicate-based structure mapping theories. But it does not describe how such an approach can be operationalized. We propose a concrete HDC-based architecture that computes several types of analogy classified by CST. We present preliminary proof-of-concept experimental results within a toy domain and describe how it can perform category-based and property-based analogical reasoning.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Unclear if this is exactly relevant. Cursory mention of NeSy. No implementation found. "]}}
}

@article{rayyan-242084777,
  title={Towards adaptive user-centered neuro-symbolic learning for multimodal interaction with autonomous systems},
  year={2023},
  author={Gomaa, A. and Feld, M.},
  abstract={Recent advances in deep learning and data-driven approaches have facilitated the perception of objects and their environments in a perceptual subsymbolic manner. Thus, these …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2309.05787],", "Unable to find code, but seems relevant so marking as maybe"]}}
}

@article{rayyan-242084790,
  title={Knowledge Enhanced Neural Networks for Point Cloud Semantic Segmentation},
  year={2023},
  volume={15},
  number={10},
  author={Grilli, Eleonora and Alessandro, Daniele and Maarten, Bassier and Fabio, Remondino and Luciano, Serafini},
  abstract={Deep learning approaches have sparked much interest in the AI community during the last decade, becoming state-of-the-art in domains such as pattern recognition, computer vision, and data analysis. However, these methods are highly demanding in terms of training data, which is often a major issue in the geospatial and remote sensing fields. One possible solution to this problem comes from the Neuro-Symbolic Integration field (NeSy), where multiple methods have been defined to incorporate background knowledge into the neural network's learning pipeline. One such method is KENN (Knowledge Enhanced Neural Networks), which injects logical knowledge into the neural network's structure through additional final layers. Empirically, KENN showed comparable or better results than other NeSy frameworks in various tasks while being more scalable. Therefore, we propose the usage of KENN for point cloud semantic segmentation tasks, where it has immense potential to resolve issues with small sample sizes and unbalanced classes. While other works enforce the knowledge constraints in post-processing, to the best of our knowledge, no previous methods have injected inject such knowledge into the learning pipeline through the use of a NeSy framework. The experiment results over different datasets demonstrate that the introduction of knowledge rules enhances the performance of the original network and achieves state-of-the-art levels of accuracy, even with subideal training data.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://www.mdpi.com/2072-4292/15/10/2590]", "Mentions that code is available, so we can ask author: \"The theoretical framework and code implementation of neuro-symbolic logic for 3D point cloud semantic segmentation;\""]}}
}

@article{rayyan-242084801,
  title={Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition},
  year={2021},
  author={Sun, Guangzhi and Zhang, Chao and Philip, C. Woodland},
  abstract={Contextual knowledge is important for real-world automatic speech recognition (ASR) applications. In this paper, a novel tree-constrained pointer generator (TCPGen) component is proposed that incorporates such knowledge as a list of biasing words into both attention-based encoder-decoder and transducer end-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing words into an efficient prefix tree to serve as its symbolic input and creates a neural shortcut between the tree and the final ASR output distribution to facilitate recognising biasing words during decoding. Systems were trained and evaluated on the Librispeech corpus where biasing words were extracted at the scales of an utterance, a chapter, or a book to simulate different application scenarios. Experimental results showed that TCPGen consistently improved word error rates (WERs) compared to the baselines, and in particular, achieved significant WER reductions on the biasing words. TCPGen is highly efficient: it can handle 5,000 biasing words and distractors and only add a small overhead to memory use and computation cost.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2109.00627], ", "Code was unable to be found. Marking as maybe so we can ask authors"]}}
}

@article{rayyan-242084802,
  title={First-order Logic Learning in Artificial Neural Networks},
  year={2010},
  author={Guillame-Bert, Mathieu and Krysia, Broda and d'Avila, Garcez Artur},
  publisher={IEEE},
  abstract={Artificial Neural Networks have previously been applied in neuro-symbolic learning to learn ground logic program rules. However, there are few results of learning relations using neuro-symbolic learning. This paper presents the system PAN, which can learn relations. The inputs to PAN are one or more atoms, representing the conditions of a logic rule, and the output is the conclusion of the rule. The symbolic inputs may include functional terms of arbitrary depth and arity, and the output may include terms constructed from the input functors. Symbolic inputs are encoded as an integer using an invertible encoding function, which is used in reverse to extract the output terms. The main advance of this system is a convention to allow construction of Artificial Neural Networks able to learn rules with the same power of expression as first order definite clauses. The system is tested on three examples and the results are discussed.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://spiral.imperial.ac.uk/server/api/core/bitstreams/e8b240cc-b30b-4608-b0fc-2b9225f03c04/content]", "Relevant, but no code available. Likely authors could provide. "]}}
}

@article{rayyan-242084814,
  title={Human-Oriented Fuzzy-Based Assessments of Knowledge Graph Embeddings for Fake News Detection},
  year={2025},
  volume={1176},
  author={Gutierrez-Batista, Karel and Diego, Rincon-Yanez and Sabrina, Senatore},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={In the era of information overload, distinguishing between real and fake news is a critical challenge, particularly in public social networking domains. For this purpose, an approach based on the synergy accomplished by a Neurosymbolic AI system, powered with Fuzzy Logic techniques, is introduced to achieve understandable fact-checking classification results. The work proposes a fact-checking approach based on Knowledge Graph Embedding (KGE) techniques. It extracts the involved entities from textual data in the form of triples that, projected in a vector space, form graphs that effectively highlight contextual information. The classification results are interpreted by exploiting fuzzy set modelling, which aims to improve the presentation of the final results. Specifically, we use the Hits@N metric to design fuzzy variables whose linguistic terms reflect news distribution. Then, by exploiting fuzzy rule design, human-like classification performance evaluation is provided. Through experimental evaluation of the benchmark dataset, our approach shows its effectiveness in discriminating between real and fake news, enhanced by straightforward explanations driven by the fuzzy rule design.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Seems relevant. no code available, but recent paper so we can ask author. "]}}
}

@article{rayyan-242084835,
  title={Toward Foundation Models for Online Complex Event Detection in CPS-IoT: A Case Study},
  year={2025},
  author={Han, Liying and Gaofeng, Dong and Xiaomin, Ouyang and Lance, Kaplan and Federico, Cerutti and Mani, Srivastava},
  publisher={Association for Computing Machinery},
  abstract={Complex events (CEs) play a crucial role in CPS-IoT applications, enabling high-level decision-making in domains such as smart monitoring and autonomous systems. However, most existing models focus on short-span perception tasks, lacking the long-term reasoning required for CE detection. CEs consist of sequences of short-time atomic events (AEs) governed by spatiotemporal dependencies. Detecting them is difficult due to long, noisy sensor data and the challenge of filtering out irrelevant AEs while capturing meaningful patterns. This work explores CE detection as a case study for CPS-IoT foundation models capable of long-term reasoning. We evaluate three approaches: (1) leveraging large language models (LLMs), (2) employing various neural architectures that learn CE rules from data, and (3) adopting a neurosymbolic approach that integrates neural models with symbolic engines embedding human knowledge. Our results show that the state-space model, Mamba, which belongs to the second category, outperforms all methods in accuracy and generalization to longer, unseen sensor traces. These findings suggest that state-space models could be a strong backbone for CPS-IoT foundation models for long-span reasoning tasks.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2503.12282]", "This is marginally related - there is one experiment on NeSy. It's also a recent paper, so we may need to ask for the code repo. "]}}
}

@article{rayyan-242084846,
  title={Programmatic Video Prediction Using Large Language Models},
  year={2025},
  author={Tang, Hao and Ellis, Kevin and Lohit, Suhas and Michael, J. Jones and Chatterjee, Moitreya},
  abstract={The task of estimating the world model describing the dynamics of a real world process assumes immense importance for anticipating and preparing for future outcomes. For applications such as video surveillance, robotics applications, autonomous driving, etc. this objective entails synthesizing plausible visual futures, given a few frames of a video to set the visual context. Towards this end, we propose ProgGen, which undertakes the task of video frame prediction by representing the dynamics of the video using a set of neuro-symbolic, human-interpretable set of states (one per frame) by leveraging the inductive biases of Large (Vision) Language Models (LLM/VLM). In particular, ProgGen utilizes LLM/VLM to synthesize programs: (i) to estimate the states of the video, given the visual context (i.e. the frames); (ii) to predict the states corresponding to future time steps by estimating the transition dynamics; (iii) to render the predicted states as visual RGB-frames. Empirical evaluations reveal that our proposed method outperforms competing techniques at the task of video frame prediction in two challenging environments: (i) PhyWorld (ii) Cart Pole. Additionally, ProgGen permits counter-factual reasoning and interpretable video generation attesting to its effectiveness and generalizability for video generation tasks.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2505.14948]. ", "Was just accepted and presented at ICLR 2025, so given how recent, we can probably ask authors for code. "]}}
}

@article{rayyan-242084855,
  title={Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe Self-Driving in Non-Stationary Environments},
  year={2023},
  author={Lei, Haozhe and Quanyan, Zhu},
  abstract={In the area of learning-driven artificial intelligence advancement, the integration of machine learning (ML) into self-driving (SD) technology stands as an impressive engineering feat. Yet, in real-world applications outside the confines of controlled laboratory scenarios, the deployment of self-driving technology assumes a life-critical role, necessitating heightened attention from researchers towards both safety and efficiency. To illustrate, when a self-driving model encounters an unfamiliar environment in real-time execution, the focus must not solely revolve around enhancing its anticipated performance; equal consideration must be given to ensuring its execution or real-time adaptation maintains a requisite level of safety. This study introduces an algorithm for online meta-reinforcement learning, employing lookahead symbolic constraints based on \emph Neurosymbolic Meta-Reinforcement Lookahead Learning (NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes the efficiency of online adaptations with the overarching goal of ensuring long-term safety. Experimental results demonstrate NUMERLA confers the self-driving agent with the capacity for real-time adaptability, leading to safe and self-adaptive driving under non-stationary urban human-vehicle interaction scenarios.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2309.02328]", "No code - we can ask authors "]}}
}

@article{rayyan-242084856,
  title={ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing},
  year={2024},
  author={Lei, Haozhe and Ge, Yunfei and Quanyan, Zhu},
  abstract={The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2411.00217]", "Author's GitHub Profile: [https://github.com/Panshark?tab=repositories]", "No Code - we can ask authors later"]}}
}

@article{rayyan-242084857,
  title={Multimodal neurosymbolic approach for explainable deepfake detection},
  year={2024},
  author={Haq, I. U. and Malik, K. M. and Muhammad, K.},
  abstract={… Hence, this article proposes a novel neurosymbolic deepfake detection framework that exploits the … deepfakes and highlight the potential of a neurosymbolic approach for expandability. …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Source: [https://dl.acm.org/doi/10.1145/3624748]", "Unable to evaluate due to journal gate"]}}
}

@article{rayyan-242084861,
  title={Neuro-symbolic meta reinforcement learning for trading},
  year={2023},
  author={Harini, S. I. and Shroff, G. and Srinivasan, A. and Faldu, P.},
  abstract={We model short-duration (eg day) trading in financial markets as a sequential decision-making problem under uncertainty, with the added complication of continual concept-drift. We, …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2302.08996]", "No codebase. "]}}
}

@article{rayyan-242084865,
  title={Improving Rare Tree Species Classification Using Domain Knowledge},
  year={2023},
  volume={20},
  author={Harmon, Ira and Sergio, Marconi and Ben, Weinstein and Yang, Bai and Zhe, Wang Daisy and Ethan, White and Stephanie, Bohlman},
  abstract={Forest inventory forms the foundation of forest management. Remote sensing (RS) is an efficient means of measuring forest parameters at scale. Remotely sensed species classification can be used to estimate species abundances, distributions, and to better approximate metrics such as aboveground biomass. State-of-the-art methods of RS species classification rely on deep-learning models such as convolutional neural networks (CNNs). These models have two major drawbacks: they require large samples of each species to classify well and they lack explainability. Therefore, rare species are poorly classified causing poor approximations of their associated parameters. We show that the classification of rare species can be improved by as much as eight F1-points using a neuro-symbolic (NS) approach that combines CNNs with an NS framework. The framework allows for the incorporation of domain knowledge into the model through the use of mathematically represented rules, improving model explainability.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["no codebase. Can maybe ask author"]}}
}

@article{rayyan-242084866,
  title={Injecting Domain Knowledge Into Deep Neural Networks for Tree Crown Delineation},
  year={2022},
  volume={60},
  author={Harmon, Ira and Sergio, Marconi and Ben, Weinstein and Sarah, Graves and Zhe, Wang Daisy and Alina, Zare and Stephanie, Bohlman and Aditya, Singh and Ethan, White},
  abstract={Automated individual tree crown (ITC) delineation plays an important role in forest remote sensing. Accurate ITC delineation benefits biomass estimation, allometry estimation, and species classification among other forest-related tasks, all of which are used to monitor forest health and make important decisions in forest management. In this article, we introduce neuro-symbolic DeepForest, a convolutional neural network (CNN)-based ITC delineation algorithm that uses a neuro-symbolic framework to inject domain knowledge (represented as rules written in probabilistic soft logic) into a CNN. We create rules that encode concepts for competition, allometry, constrained growth, mean ITC area, and crown color. Our results show that the delineation model learns from the annotated training data as well as the rules and that under some conditions, the injection of rules improves model performance and affects model bias. We then analyze the effects of each rule on its related aspects of model performance. We find that the addition of domain data can improve F1 by as much as four F1 points, reduce the Kullback-Leibler divergence (KL-divergence) between ground-truth and predicted area distributions, and reduce the aggregate error in area between ground-truth and predicted delineations.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Link: [https://ieeexplore.ieee.org/document/9927472]", "Author has other papers where code has been provided so we need to reach out to author for code. "]}}
}

@article{rayyan-242084868,
  title={A neurosymbolic approach to the verification of temporal logic properties of learning-enabled control systems},
  year={2023},
  author={Hashemi, N. and Hoxha, B. and Yamaguchi, T.},
  abstract={Signal Temporal Logic (STL) has become a popular tool for expressing formal requirements of Cyber-Physical Systems (CPS). The problem of verifying STL properties of neural network…},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://arxiv.org/pdf/2303.05394]", "Unable to find code - maybe should reach out to author"]}}
}

@article{rayyan-242084869,
  title={LB4TL: A Smooth Semantics for Temporal Logic to Train Neural Feedback Controllers},
  year={2024},
  volume={58},
  number={11},
  author={Hashemi, Navid and Samuel, Williams and Bardh, Hoxha and Danil, Prokhorov and Georgios, Fainekos and Jyotirmoy, Deshmukh},
  abstract={This paper presents a framework for training neural network (NN) -based feedback controllers for autonomous agents with deterministic nonlinear dynamics to satisfy task objectives and safety constraints expressed in discrete-time Signal Temporal Logic (DT-STL). Control synthesis that uses the robustness semantics of DT-STL poses challenges due to its non-convexity, non-differentiability, and recursive definition, in particular when it is used to train NN-based controllers. We introduce a smooth neuro-symbolic computation graph to encode DT-STL robustness to represent a smooth approximation of the robustness, enabling the use of powerful stochastic gradient descent and backpropagation-based optimization for training. Our approximation guarantees that it lower bounds the robustness value of a given DT-STL formula, and shows orders of magnitude improvement over existing smooth approximations when applied to control synthesis. We demonstrate our approach on planning to satisfy complex spatiotemporal and sequential tasks, and show scalability with formula complexity. Copyright (c) 2024 The Authors.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: [https://www.sciencedirect.com/science/article/pii/S2405896324005445]", "No code - need to reach out to author for more information"]}}
}

@article{rayyan-242084887,
  title={V-LoL: A Diagnostic Dataset for Visual Logical Learning},
  year={2024},
  author={Helff, Lukas and Stammer, Wolfgang and Shindo, Hikaru and Devendra Singh, Dhami and Kersting, Kristian},
  abstract={Despite the successes of recent developments in visual AI, different shortcomings still exist; from missing exact logical reasoning, to abstract generalization abilities, to understanding complex and noisy scenes. Unfortunately, existing benchmarks, were not designed to capture more than a few of these aspects. Whereas deep learning datasets focus on visually complex data but simple visual reasoning tasks, inductive logic datasets involve complex logical learning tasks, however, lack the visual component. To address this, we propose the diagnostic visual logical learning dataset, V-LoL, that seamlessly combines visual and logical challenges. Notably, we introduce the first instantiation of V-LoL, V-LoL-Train, - a visual rendition of a classic benchmark in symbolic AI, the Michalski train problem. By incorporating intricate visual scenes and flexible logical reasoning tasks within a versatile framework, V-LoL-Train provides a platform for investigating a wide range of visual logical learning challenges. We evaluate a variety of AI systems including traditional symbolic AI, neural AI, as well as neuro-symbolic AI. Our evaluations demonstrate that even SOTA AI faces difficulties in dealing with visual logical learning challenges, highlighting unique advantages and limitations of each methodology. Overall, V-LoL opens up new avenues for understanding and enhancing current abilities in visual logical learning for AI systems.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["This is a dataset. So unsure if we should include it or not. ", "Website: [https://sites.google.com/view/v-lol]"]}}
}

@article{rayyan-242084924,
  title={Experimental Comparison between Neural-Symbolic Question-Answering Methods},
  year={2023},
  author={Hoang, Hieu and Nguyen, Triet and Ho, Nguyen and Tran, Dung A. and Ho, Van Long and Nguyen, Hien D.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Excluded", "Bhuvanesh"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Bhuvanesh"=>["Paper is a comparison of two other techniques. Unsure if it should be included. "]}}
}

@article{rayyan-242085001,
  title={SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning},
  year={2025},
  author={Amador, Ivo and Nina, Gierasimczuk},
  abstract={We propose a learning architecture that allows symbolic control and guidance in reinforcement learning with deep neural networks. We introduce SymDQN, a novel modular approach that augments the existing Dueling Deep Q-Networks (DuelDQN) architecture with modules based on the neuro-symbolic framework of Logic Tensor Networks (LTNs). The modules guide action policy learning and allow reinforcement learning agents to display behaviour consistent with reasoning about the environment. Our experiment is an ablation study performed on the modules. It is conducted in a reinforcement learning environment of a 5x5 grid navigated by an agent that encounters various shapes, each associated with a given reward. The underlying DuelDQN attempts to learn the optimal behaviour of the agent in this environment, while the modules facilitate shape recognition and reward prediction. We show that our architecture significantly improves learning, both in terms of performance and the precision of the agent. The modularity of SymDQN allows reflecting on the intricacies and complexities of combining neural and symbolic approaches in reinforcement learning.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2504.02654", "Recent publication so code may not be available yet. "]}}
}

@article{rayyan-242085011,
  title={Influence of Backdoor Paths on Causal Link Prediction},
  year={2024},
  author={Jaimini, Utkarshani and Henson, Cory and Sheth, Amit},
  abstract={The current method for predicting causal links in knowledge graphs uses weighted causal relations. For a given link between cause-effect entities, the presence of a confounder affects the causal link prediction, which can lead to spurious and inaccurate results. We aim to block these confounders using backdoor path adjustment. Backdoor paths are non-causal association flows that connect the 𝑐𝑎𝑢𝑠𝑒-𝑒𝑛𝑡𝑖𝑡𝑦 to the 𝑒𝑓𝑓𝑒𝑐𝑡-𝑒𝑛𝑡𝑖𝑡𝑦 through other variables. Removing these paths ensures a more accurate prediction of causal links. This paper proposes CausalLPBack, a novel approach to causal link prediction that eliminates backdoor paths and uses knowledge graph link prediction methods. It extends the representation of causality in a neuro-symbolic framework, enabling the adoption and use of traditional causal AI concepts and methods. We demonstrate our approach using a causal reasoning benchmark dataset of simulated videos. The evaluation involves a unique dataset splitting method called the Markov-based split that's relevant for causal link prediction. The evaluation of the proposed approach demonstrates atleast 30% in MRR and 16% in Hits@K inflated performance for causal link prediction that is due to the bias introduced by backdoor paths for both baseline and weighted causal relations.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["GitHub: https://github.com/utkarshani/CausalLPBack", "GitHub available, but no code. Need to ask author."], "brandon"=>["https://github.com/utkarshani/CausalLPBack"]}}
}

@article{rayyan-242085012,
  title={Neuro-Symbolic Reasoning for Multimodal Referring Expression Comprehension in HMI Systems},
  year={2024},
  author={Jain, A. and Kondapally, A. R. and Yamada, K.},
  abstract={… , we propose a hybrid neuro-symbolic model combining deep … for HMI systems, an interpretable neuro-symbolic model, and an … Thus, we propose a hybrid neuro-symbolic approach to …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Excluded", "Bhuvanesh"=>"Maybe"} | RAYYAN-EXCLUSION-REASONS: no-codebase | USER-NOTES: {"Bhuvanesh"=>["We will need to contact them for access. Link: https://link.springer.com/article/10.1007/s00354-024-00243-8#data-availability"]}}
}

@article{rayyan-242085123,
  title={Computational Lexical Resources for Explainable Natural Language Understanding},
  year={2023},
  author={Kazeminejad, Ghazaleh},
  url={https://www.proquest.com/dissertations-theses/computational-lexical-resources-explainable/docview/2814213805/se-2?accountid=28159},
  publisher={University of Colorado at Boulder},
  abstract={Procedural texts describe dynamic state changes that occur during a step-by-step process (e.g. an instruction manual, photosynthesis, or a baking recipe). As a subtask of procedural text understanding, entity state tracking aims to automatically analyze such documents, identifying relevant information that allows entities’ states and locations to be tracked during a process. This NLP task suffers from the scarcity of annotated data, mainly because obtaining such annotations is difficult and time-consuming. For instance, annotators often rely on commonsense knowledge to annotate implicit information. Recent approaches have successfully incorporated external world knowledge. In particular, Zhang et al. (2021) [111] present a neuro-symbolic model, where commonsense knowledge about entities from ConceptNet is leveraged to guide the model. The model uses a BERT encoder fine-tuned on raw procedural texts to predict entity state changes. We re-implement this model as our baseline, and add linguistic knowledge to allow the model to have access to the lexical semantic information encoded in verbs, using VerbNet. We modify the multi-stage training method presented by [111], and compare the sources of knowledge in the LM fine-tuning step in different experimental settings. The evaluation results on the ProPara dataset [21] show improvements over the baseline, verifying the effectiveness of introducing event semantics over and above commonsense knowledge about entities. In addition, we develop a purely symbolic model for entity state tracking that uses a simple set of case statements, and is informed mostly by linguistic knowledge retrieved from various computational lexical resources. We show that our purely symbolic model is generalizable and explainable and achieves state-of-the-art results on the Recipes dataset [10].},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["This is a PhD Dissertation - I'm not sure if we want to use these in our review. "]}}
}

@article{rayyan-242085125,
  title={ESGSenticNet: A Neurosymbolic Knowledge Base for Corporate Sustainability Analysis},
  year={2025},
  author={Ong, Keane and Mao, Rui and Xing, Frank and Satapathy, Ranjan and Sulaeman, Johan and Cambria, Erik and Gianmarco, Mengaldo},
  abstract={Evaluating corporate sustainability performance is essential to drive sustainable business practices, amid the need for a more sustainable economy. However, this is hindered by the complexity and volume of corporate sustainability data (i.e. sustainability disclosures), not least by the effectiveness of the NLP tools used to analyse them. To this end, we identify three primary challenges - immateriality, complexity, and subjectivity, that exacerbate the difficulty of extracting insights from sustainability disclosures. To address these issues, we introduce ESGSenticNet, a publicly available knowledge base for sustainability analysis. ESGSenticNet is constructed from a neurosymbolic framework that integrates specialised concept parsing, GPT-4o inference, and semi-supervised label propagation, together with a hierarchical taxonomy. This approach culminates in a structured knowledge base of 44k knowledge triplets - ('halve carbon emission', supports, 'emissions control'), for effective sustainability analysis. Experiments indicate that ESGSenticNet, when deployed as a lexical method, more effectively captures relevant and actionable sustainability information from sustainability disclosures compared to state of the art baselines. Besides capturing a high number of unique ESG topic terms, ESGSenticNet outperforms baselines on the ESG relatedness and ESG action orientation of these terms by 26% and 31% respectively. These metrics describe the extent to which topic terms are related to ESG, and depict an action toward ESG. Moreover, when deployed as a lexical method, ESGSenticNet does not require any training, possessing a key advantage in its simplicity for non-technical stakeholders.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper :https://arxiv.org/pdf/2501.15720", "\"o address these issues, we introduce ESGSenticNet, a publicly available knowledge base for sustainability analysis.\" - They claim their tool is publicly available. It is unclear if the code is available.", "Marking as maybe"]}}
}

@article{rayyan-242085144,
  title={Spatiotemporal Event Graphs for Dynamic Scene Understanding},
  year={2023},
  author={Khan, Salman},
  abstract={Dynamic scene understanding is the ability of a computer system to interpret and make sense of the visual information present in a video of a real-world scene. In this thesis, we present a series of frameworks for dynamic scene understanding starting from road event detection from an autonomous driving perspective to complex video activity detection, followed by continual learning approaches for the life-long learning of the models. Firstly, we introduce the ROad event Awareness Dataset (ROAD) for Autonomous Driving, to our knowledge the first of its kind. Due to the lack of datasets equipped with formally specified logical requirements, we also introduce the ROad event Awareness Dataset with logical Requirements (ROAD-R), the first publicly available dataset for autonomous driving with requirements expressed as logical constraints, as a tool for driving neurosymbolic research in the area. Next, we extend event detection to holistic scene understanding by proposing two complex activity detection methods. In the first method, we present a deformable, spatiotemporal scene graph approach, consisting of three main building blocks: action tube detection, a 3D deformable RoI pooling layer designed for learning the flexible, deformable geometry of the constituent action tubes, and a scene graph constructed by considering all parts as nodes and connecting them based on different semantics. In a second approach evolving from the first, we propose a hybrid graph neural network that combines attention applied to a graph encoding of the local (short-term) dynamic scene with a temporal graph modelling the overall long-duration activity. Finally, the last part of the thesis is about presenting a new continual semi-supervised learning (CSSL) paradigm.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://arxiv.org/abs/2312.07621", "This is a thesis - unclear if we should be looking at these. "]}}
}

@article{rayyan-242085158,
  title={A Neural-Symbolic Framework for Mental Simulation},
  year={2020},
  author={Kissner, Michael},
  abstract={We present a neural-symbolic framework for observing the environment and continuously learning visual semantics and intuitive physics to reproduce them in an interactive simulation. The framework consists of five parts, a neural-symbolic hybrid network based on capsules for inverse graphics, an episodic memory to store observations, an interaction network for intuitive physics, a meta-learning agent that continuously improves the framework and a querying language that acts as the framework's interface for simulation. By means of lifelong meta-learning, the capsule network is expanded and trained continuously, in order to better adapt to its environment with each iteration. This enables it to learn new semantics using a few-shot approach and with minimal input from an oracle over its lifetime. From what it learned through observation, the part for intuitive physics infers all the required physical properties of the objects in a scene, enabling predictions. Finally, a custom query language ties all parts together, which allows to perform various mental simulation tasks, such as navigation, sorting and simulation of a game environment, with which we illustrate the potential of our novel approach.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Maybe"} | USER-NOTES: {"brandon"=>["https://github.com/Kayzaks/VividNet", "duplicate of \"A neural-symbolic architecture for inverse graphics improved by lifelong meta-learning\""]}}
}

@article{rayyan-242085159,
  title={Adding Intuitive Physics to Neural-Symbolic Capsules Using Interaction Networks},
  year={2019},
  author={Kissner, Michael and Mayer, Helmut},
  abstract={Many current methods to learn intuitive physics are based on interaction networks and similar approaches. However, they rely on information that has proven difficult to estimate directly from image data in the past. We aim to narrow this gap by inferring all the semantic information needed from raw pixel data in the form of a scene-graph. Our approach is based on neural-symbolic capsules, which identify which objects in the scene are static, dynamic, elastic or rigid, possible joints between them, as well as their collision information. By integrating all this with interaction networks, we demonstrate how our method is able to learn intuitive physics directly from image sequences and apply its knowledge to new scenes and objects, resulting in an inverse-simulation pipeline.},
  note={RAYYAN-INCLUSION: {"brandon"=>"Maybe"} | USER-NOTES: {"brandon"=>["https://github.com/Kayzaks/VividNet", "duplicate of \"A neural-symbolic architecture for inverse graphics improved by lifelong meta-learning\""]}}
}

@article{rayyan-242085190,
  title={Disentangling Visual Priors: Unsupervised Learning of Scene Interpretations with Compositional Autoencoder},
  year={2024},
  volume={14979},
  author={Krawiec, Krzysztof and Antoni, Nowinowski},
  publisher={SPRINGER INTERNATIONAL PUBLISHING AG},
  abstract={Contemporary deep learning architectures lack principled means for capturing and handling fundamental visual concepts, like objects, shapes, geometric transforms, and other higher-level structures. We propose a neurosymbolic architecture that uses a domain-specific language to capture selected priors of image formation, including object shape, appearance, categorization, and geometric transforms. We express template programs in that language and learn their parameterization with features extracted from the scene by a convolutional neural network. When executed, the parameterized program produces geometric primitives which are rendered and assessed for correspondence with the scene content and trained via auto-association with gradient. We confront our approach with a baseline method on a synthetic benchmark and demonstrate its capacity to disentangle selected aspects of the image formation process, learn from small data, correct inference in the presence of noise, and out-of-sample generalization.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2409.09716", "Could not find code base. Is a publication from Sep. 2024, so maybe we can still reach out to author"]}}
}

@article{rayyan-242085221,
  title={Continual reasoning: non-monotonic reasoning in neurosymbolic AI using continual learning},
  year={2023},
  author={Kyriakopoulos, S. and Garcez, A. S.},
  abstract={… In this paper, we show that by combining a neural-symbolic system with methods from … , a new methodology for the application of neural-symbolic systems to reasoning tasks. Continual …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2305.02171", "No codebase. From NeSY 2023 conference, so maybe can ask author for the code. "]}}
}

@article{rayyan-242085222,
  title={Automated Theorem Provers Help Improve Large Language Model Reasoning},
  year={2024},
  author={McGinness, Lachlan and Peter, Baumgartner},
  abstract={In this paper we demonstrate how logic programming systems and Automated first-order logic Theorem Provers (ATPs) can improve the accuracy of Large Language Models (LLMs) for logical reasoning tasks where the baseline performance is given by direct LLM solutions. We first evaluate LLM reasoning on steamroller problems using the PRONTOQA benchmark. We show how accuracy can be improved with a neuro-symbolic architecture where the LLM acts solely as a front-end for translating a given problem into a formal logic language and an automated reasoning engine is called for solving it. However, this approach critically hinges on the correctness of the LLM translation. To assess this translation correctness, we secondly define a framework of syntactic and semantic error categories. We implemented the framework and used it to identify errors that LLMs make in the benchmark domain. Based on these findings, we thirdly extended our method with capabilities for automatically correcting syntactic and semantic errors. For semantic error correction we integrate first-order logic ATPs, which is our main and novel contribution. We demonstrate that this approach reduces semantic errors significantly and further increases the accurracy of LLM logical reasoning.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2408.03492", "Unable to find code, but paper is semi-recent, so we can reach out to authors. "]}}
}

@article{rayyan-242085230,
  title={The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling Probabilistic Social Inferences from Linguistic Inputs},
  year={2023},
  author={Ying, Lance and Katherine, M. Collins and Wei, Megan and Zhang, Cedegao E. and Zhi-Xuan, Tan and Weller, Adrian and Tenenbaum, Joshua B. and Wong, Lionel},
  abstract={Human beings are social creatures. We routinely reason about other agents, and a crucial component of this social reasoning is inferring people's goals as we learn about their actions. In many settings, we can perform intuitive but reliable goal inference from language descriptions of agents, actions, and the background environments. In this paper, we study this process of language driving and influencing social reasoning in a probabilistic goal inference domain. We propose a neuro-symbolic model that carries out goal inference from linguistic inputs of agent scenarios. The neuro part is a large language model (LLM) that translates language descriptions to code representations, and the symbolic part is a Bayesian inverse planning engine. To test our model, we design and run a human experiment on a linguistic goal inference task. Our model closely matches human response patterns and better predicts human judgements than using an LLM alone.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2306.14325", "Couldn't find codebase, but seems interesting so maybe follow-up with author. "]}}
}

@article{rayyan-242085241,
  title={Explainable Moral Values: a neuro-symbolic approach to value classification},
  year={2024},
  author={Lazzari, N. and Giorgis, S. De and Gangemi, A.},
  abstract={This work explores the integration of ontology-based reasoning and Machine Learning techniques for explainable value classification. By relying on an ontological formalization of …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2410.12631", "No code, but they provide a link to a visualization: http://xmv.geomeaning.com/", "Maybe, we can ask the authors. "]}}
}

@article{rayyan-242085242,
  title={Sandra-A Neuro-Symbolic Reasoner Based On Descriptions And Situations},
  year={2024},
  author={Lazzari, N. and Giorgis, S. De and Gangemi, A.},
  abstract={This paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2402.00591", "No codebase, but recent enough we can ask author. (mar 2024)"]}}
}

@article{rayyan-242085285,
  title={Neurosymbolic Programming in Scallop: Principles and Practice},
  year={2024},
  author={Li, Z. and Huang, J. and Liu, J. and Naik, M.},
  url={https://www.nowpublishers.com/article/Details/PGL-059},
  abstract={… As the field of neurosymbolic AI continues to evolve, we anticipate that more diverse and innovative compositions will emerge, broadening the scope and applications of neurosymbolic …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://www.cis.upenn.edu/~jianih/res/papers/scallop_principles_practice.pdf", "Link: https://ieeexplore.ieee.org/document/10848379", "Related paper: https://arxiv.org/pdf/2304.04812", "GitHub: https://github.com/scallop-lang/scallop", "This is a paper on how to use Scallop. It may be interesting to investigate scallop as well. ", "Though, this is not research."]}}
}

@article{rayyan-242085288,
  title={Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model},
  year={2024},
  author={Li, Z. and Song, R. and Sun, C. and Xu, W. and Yu, Z.},
  url={https://aclanthology.org/2024.findings-acl.233/},
  abstract={Finding interpretable factors for stock returns is the most vital issue in the empirical asset pricing domain. As data-driven methods, existing factor mining models can be categorized into …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://aclanthology.org/2024.findings-acl.233/", "Can't find code, but seems like an interesting and recent paper, so we can ask author"]}}
}

@article{rayyan-242085290,
  title={Neuro-symbolic data generation for math reasoning},
  year={2024},
  author={Li, Z. and Zhou, Z. and Yao, Y. and Zhang, X. and Li, Y. F.},
  url={https://proceedings.neurips.cc/paper_files/paper/2024/hash/29d319f7c1513c9ecd81d3a6e9632a6e-Abstract-Conference.html},
  abstract={… To address this dilemma, we propose a novel neuro-symbolic framework that automatically generates high-quality, supervised mathematical data. The merit of this paradigm lies in …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2412.04857", "No code, but published recently December 2024, so we can ask author"]}}
}

@article{rayyan-242085294,
  title={Argumentation Computation with Large Language Models : A Benchmark Study},
  year={2024},
  author={Li, Zhaoqun and Fang, Xiaotong and Chen, Chen and Li, Mengze and Liao, Beishui},
  abstract={In recent years, large language models (LLMs) have made significant advancements in neuro-symbolic computing. However, the combination of LLM with argumentation computation remains an underexplored domain, despite its considerable potential for real-world applications requiring defeasible reasoning. In this paper, we aim to investigate the capability of LLMs in determining the extensions of various abstract argumentation semantics. To achieve this, we develop and curate a benchmark comprising diverse abstract argumentation frameworks, accompanied by detailed explanations of algorithms for computing extensions. Subsequently, we fine-tune LLMs on the proposed benchmark, focusing on two fundamental extension-solving tasks. As a comparative baseline, LLMs are evaluated using a chain-of-thought approach, where they struggle to accurately compute semantics. In the experiments, we demonstrate that the process explanation plays a crucial role in semantics computation learning. Models trained with explanations show superior generalization accuracy compared to those trained solely with question-answer pairs. Furthermore, by leveraging the self-explanation capabilities of LLMs, our approach provides detailed illustrations that mitigate the lack of transparency typically associated with neural networks. Our findings contribute to the broader understanding of LLMs' potential in argumentation computation, offering promising avenues for further research in this domain.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2412.16725", "Potentially there was code here: https://github.com/AromaticHydrocarbon/Argumentation-Computation-with-Large-Language-Models", "We need to probably ask authors. "]}}
}

@article{rayyan-242085394,
  title={Using DeepProbLog to perform Complex Event Processing on an Audio Stream},
  year={2021},
  author={Vilamala, Marc Roig and Xing, Tianwei and Taylor, Harrison and Garcia, Luis and Srivastava, Mani and Kaplan, Lance and Preece, Alun and Kimmig, Angelika and Federico, Cerutti},
  abstract={In this paper, we present an approach to Complex Event Processing (CEP) that is based on DeepProbLog. This approach has the following objectives: (i) allowing the use of subsymbolic data as an input, (ii) retaining the flexibility and modularity on the definitions of complex event rules, (iii) allowing the system to be trained in an end-to-end manner and (iv) being robust against noisily labelled data. Our approach makes use of DeepProbLog to create a neuro-symbolic architecture that combines a neural network to process the subsymbolic data with a probabilistic logic layer to allow the user to define the rules for the complex events. We demonstrate that our approach is capable of detecting complex events from an audio stream. We also demonstrate that our approach is capable of training even with a dataset that has a moderate proportion of noisy data.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Maybe"} | USER-NOTES: {"Anh"=>["This paper tested existing Neuro-Symbolic method on a different task. They do not present any new methodology. Potential duplication."]}}
}

@article{rayyan-242085520,
  title={GNS: Solving Plane Geometry Problems by Neural-Symbolic Reasoning with Multi-Modal LLMs},
  year={2025},
  author={Ning, M. and Zhou, Z. and Wang, Q. and Huang, X.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/34679},
  abstract={… We introduce GNS, a neural-symbolic framework for MLLMs to solve plane geometry problems. To enhance the solving capability, GNS consists of four main modules as shown in Fig. 2 …},
  note={RAYYAN-INCLUSION: {"brandon"=>"Included", "Anh"=>"Maybe"} | USER-NOTES: {"brandon"=>["https://github.com/ning-mz/GNS"], "Anh"=>["[GitHub] https://github.com/ning-mz/GNS", "Code seems to be incomplete / not fully released"]}}
}

@article{rayyan-242085556,
  title={Neural Retrieval Through Entities and Text Understanding},
  year={2024},
  author={Oza, Pooja Himanshu},
  url={https://www.proquest.com/dissertations-theses/neural-retrieval-through-entities-text/docview/3106354178/se-2?accountid=28159},
  publisher={University of New Hampshire},
  abstract={For various artificial intelligence systems, automatic text understanding algorithms that go beyond mere pattern recognition are helpful. For instance, understanding web pages is beneficial for Information Retrieval (IR) systems to retrieve relevant information. In the most common form, IR systems retrieve relevant information as entities or documents in response to keywords-based queries. Traditional IR models use lexical matching between the query terms and document terms to identify relevant documents. With the emergence of neural networks, Neural IR approaches utilize deep learning techniques to learn high-dimensional representations of documents and queries that go beyond term matching.On the other hand, with the development of symbolic knowledge graphs (KGs), the IR models leverage the semantic information in the form of entities or concepts (e.g., relations, name, description, type, etc.) to retrieve relevant information. Entities are physical objects or things, such as people, places, organizations, etc., representing world knowledge. Traditionally, lexical matching between the query terms and semantic information of entities (e.g., related entities, name, description, type, etc.) is used to recognize the relevant information.This thesis aims to advance state-of-the-art text understanding by developing novel neuro-symbolic algorithms that combine the strengths of two paradigms: the symbolic knowledge graph and the textual documents. Our goal is to leverage the interplay between textual documents and the semantic information of entities to retrieve relevant information. In the first part of this thesis, we devise algorithms to understand how to best utilize the relations between symbolic entities in textual documents to identify relevant entities. In the second part of the thesis, we explore the intricacies of the connections between the symbolic knowledge and the textual documents to generate neuro-symbolic representations for identifying relevant information in the form of entities and documents. To achieve this, we develop novel neuro-symbolic models that identify relevant connections between symbolic knowledge and textual documents and leverage these connections to retrieve relevant information.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Link: https://scholars.unh.edu/dissertation/2860/", "Looks like a thesis - are we including this? "]}}
}

@article{rayyan-242085596,
  title={Federated Neuro-Symbolic Learning},
  year={2023},
  author={Xing, Pengwei and Lu, Songtao and Han, Yu},
  abstract={Neuro-symbolic learning (NSL) models complex symbolic rule patterns into latent variable distributions by neural networks, which reduces rule search space and generates unseen rules to improve downstream task performance. Centralized NSL learning involves directly acquiring data from downstream tasks, which is not feasible for federated learning (FL). To address this limitation, we shift the focus from such a one-to-one interactive neuro-symbolic paradigm to one-to-many Federated Neuro-Symbolic Learning framework (FedNSL) with latent variables as the FL communication medium. Built on the basis of our novel reformulation of the NSL theory, FedNSL is capable of identifying and addressing rule distribution heterogeneity through a simple and effective Kullback-Leibler (KL) divergence constraint on rule distribution applicable under the FL setting. It further theoretically adjusts variational expectation maximization (V-EM) to reduce the rule search space across domains. This is the first incorporation of distribution-coupled bilevel optimization into FL. Extensive experiments based on both synthetic and real-world data demonstrate significant advantages of FedNSL compared to five state-of-the-art methods. It outperforms the best baseline by 17% and 29% in terms of unbalanced average training accuracy and unseen average testing accuracy, respectively.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2308.15324", "Could not find code, but seems like it should be available. We can reach out to the authors. "]}}
}

@article{rayyan-242085606,
  title={Semantic Data Representation for Explainable Windows Malware Detection Models},
  year={2024},
  author={Švec, Peter and Balogh, Štefan and Homola, Martin and Kľuka, Ján and Tomáš, Bisták},
  abstract={Ontologies are a standard tool for creating semantic schemata in many knowledge intensive domains of human interest. They are becoming increasingly important also in the areas that have been until very recently dominated by subsymbolic knowledge representation and machine-learning (ML) based data processing. One such area is information security, and specifically, malware detection. We thus propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE - the Windows binary format) malware files. This ontology is inspired by the structure of the EMBER dataset, which focuses on the static malware analysis of PE files. With this proposal, we hope to provide a unified semantic representation for the existing and future},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/abs/2403.11669", "Seems interesting. Mostly a qualitative analysis and then some quantiative at the end. Recent enough, that we can ask author for code. "]}}
}

@article{rayyan-242085618,
  title={Neuro-Symbolic Transformation of Architectural Facades into Procedural Representations},
  year={2024},
  author={Plocharski, Aleksander and Jan, Swidzinski and Joanna, Porter-Sobieraj and Przemyslaw, Musialski},
  publisher={ASSOC COMPUTING MACHINERY},
  abstract={We introduce a neuro-symbolic transformer model that converts flat, segmented facade structures into procedural definitions using a custom-designed split grammar. To facilitate this, we first develop a split grammar tailored for architectural facades and generate a dataset of facades alongside their procedural representations. This dataset is used to train our transformer model to convert segmented, flat facades into the procedural language of our grammar.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["https://dl.acm.org/doi/10.1145/3641234.3671063", "https://facaid.github.io/", "Says code should be available on website, so we need to reach out to author"]}}
}

@article{rayyan-242085699,
  title={Neuro-Symbolic AI for Sensor-based Human Performance Prediction: System Architectures and Applications},
  year={2022},
  author={Ramo, Ines Filipa Fernandes and Gianini, Gabriele and Damiani, Ernesto},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["https://air.unimi.it/retrieve/b7f12d3a-6517-4932-80dd-cdc20ba66873/phd_unimi_R12822.pdf ", "This is a thesis. "]}}
}

@article{rayyan-242085706,
  title={RuleBoost: A Neuro-Symbolic Framework for Robust Deepfake Detection},
  year={2024},
  author={Raza, M. A. and Malik, K. M. and Haq, I. U.},
  url={https://ieeexplore.ieee.org/abstract/document/10744498/?casa_token=QwYR9z7QTegAAAAA:kK8sx6QQIKvEQr-LIasBaWr_UpDDO86HmRcW20QQVUN9_dcQziXiB2-hW4sZk2Kjr49PwqYna1QYYw},
  abstract={… To address this gap, we introduce RuleBoost, a novel NeuroSymbolic AI based framework … To figure out the difference NeuroSymbolic approach makes, we also analyze the samples …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://ieeexplore.ieee.org/abstract/document/10744498", "Recent, so maybe we can ask author for code"]}}
}

@article{rayyan-242085717,
  title={An Empirical Study of the Role of Incompleteness and Ambiguity in Interactions with Large Language Models},
  year={2025},
  author={Naik, Riya and Srinivasan, Ashwin and He, Estrid and Swati, Agarwal},
  abstract={Natural language as a medium for human-computer interaction has long been anticipated, has been undergoing a sea-change with the advent of Large Language Models (LLMs) with startling capacities for processing and generating language. Many of us now treat LLMs as modern-day oracles, asking it almost any kind of question. Unlike its Delphic predecessor, consulting an LLM does not have to be a single-turn activity (ask a question, receive an answer, leave); and - also unlike the Pythia - it is widely acknowledged that answers from LLMs can be improved with additional context. In this paper, we aim to study when we need multi-turn interactions with LLMs to successfully get a question answered; or conclude that a question is unanswerable. We present a neural symbolic framework that models the interactions between human and LLM agents. Through the proposed framework, we define incompleteness and ambiguity in the questions as properties deducible from the messages exchanged in the interaction, and provide results from benchmark problems, in which the answer-correctness is shown to depend on whether or not questions demonstrate the presence of incompleteness or ambiguity (according to the properties we identify). Our results show multi-turn interactions are usually required for datasets which have a high proportion of incompleteness or ambiguous questions; and that that increasing interaction length has the effect of reducing incompleteness or ambiguity. The results also suggest that our measures of incompleteness and ambiguity can be useful tools for characterising interactions with an LLM on question-answeringproblems},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2503.17936", "Recent so maybe we can ask authors"]}}
}

@article{rayyan-242085752,
  title={An Evaluation of Knowledge Graph Embeddings for Autonomous Driving Data: Experience and Practice},
  year={2020},
  author={Wickramarachchi, Ruwan and Henson, Cory and Amit, Sheth},
  abstract={The autonomous driving (AD) industry is exploring the use of knowledge graphs (KGs) to manage the vast amount of heterogeneous data generated from vehicular sensors. The various types of equipped sensors include video, LIDAR and RADAR. Scene understanding is an important topic in AD which requires consideration of various aspects of a scene, such as detected objects, events, time and location. Recent work on knowledge graph embeddings (KGEs) - an approach that facilitates neuro-symbolic fusion - has shown to improve the predictive performance of machine learning models. With the expectation that neuro-symbolic fusion through KGEs will improve scene understanding, this research explores the generation and evaluation of KGEs for autonomous driving data. We also present an investigation of the relationship between the level of informational detail in a KG and the quality of its derivative embeddings. By systematically evaluating KGEs along four dimensions - i.e. quality metrics},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://ceur-ws.org/Vol-2600/paper3.pdf", "code: https://github.com/ruwantw/DSceneKG"]}}
}

@article{rayyan-242085757,
  title={Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models},
  year={2025},
  author={Mahmud, Saaduddin and Goldfajn, Dorian Benhamou and Shlomo, Zilberstein},
  abstract={Distributed Constraint Optimization Problems (DCOPs) offer a powerful framework for multi-agent coordination but often rely on labor-intensive, manual problem construction. To address this, we introduce VL-DCOPs, a framework that takes advantage of large multimodal foundation models (LFMs) to automatically generate constraints from both visual and linguistic instructions. We then introduce a spectrum of agent archetypes for solving},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Paper: https://arxiv.org/pdf/2501.14189", "Recent, so maybe under review"]}}
}

@article{rayyan-242085766,
  title={Neural Networks as Universal Finite-State Machines: A Constructive Deterministic Finite Automaton Theory},
  year={2025},
  author={Sahil Rajesh, Dhayalkar},
  abstract={We present a complete theoretical and empirical framework establishing feedforward neural networks as universal finite-state machines (N-FSMs). Our results prove that finite-depth ReLU and threshold networks can exactly simulate deterministic finite automata (DFAs) by unrolling state transitions into depth-wise neural layers, with formal characterizations of required depth, width, and state compression. We demonstrate that DFA transitions are linearly separable, binary threshold activations allow exponential compression, and Myhill-Nerode equivalence classes can be embedded into continuous latent spaces while preserving separability. We also formalize the expressivity boundary: fixed-depth feedforward networks cannot recognize non-regular languages requiring unbounded memory. Unlike prior heuristic or probing-based studies, we provide constructive proofs and design explicit DFA-unrolled neural architectures that empirically validate every claim. Our results bridge deep learning, automata theory, and neural-symbolic computation, offering a rigorous blueprint for how discrete symbolic processes can be realized in continuous neural systems.},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Mix of theory and empirical", "paper: https://arxiv.org/pdf/2505.11694", "Recent, so can ask author"]}}
}

@article{rayyan-242085773,
  title={Neurosymbolic Modular Refinement Type Inference},
  year={2025},
  author={Sakkas, G. and Sahu, P. and Ong, K. and Jhala, R.},
  url={https://ranjitjhala.github.io/static/icse25-neurosymbolic-refinement-inference.pdf},
  abstract={… We present LHC, a neurosymbolic agent that uses LLMs to automatically generate … -tuning and carefully chosen contexts, our neurosymbolic agent generates refinement types for up to …},
  note={RAYYAN-INCLUSION: {"Bhuvanesh"=>"Maybe"} | USER-NOTES: {"Bhuvanesh"=>["Author: https://gsakkas.github.io/", "Most recent pub, so probably not available on Github yet"]}}
}

@article{rayyan-242085888,
  title={WALL-E: World Alignment by Rule Learning Improves World Model-based LLM Agents},
  year={2024},
  author={Zhou, Siyu and Zhou, Tianyi and Yang, Yijun and Long, Guodong and Ye, Deheng and Jiang, Jing and Chengqi, Zhang},
  abstract={Can large language models (LLMs) directly serve as powerful world models for model-based agents? While the gaps between the prior knowledge of LLMs and the specified environment's dynamics do exist, our study reveals that the gaps can be bridged by aligning an LLM with its deployed environment and such world alignment can be efficiently achieved by rule learning on LLMs. Given the rich prior knowledge of LLMs, only a few additional rules suffice to align LLM predictions with the specified environment dynamics. To this end, we propose a neurosymbolic approach to learn these rules gradient-free through LLMs, by inducing, updating, and pruning rules based on comparisons of agent-explored trajectories and world model predictions. The resulting world model is composed of the LLM and the learned rules. Our embodied LLM agent WALL-E is built upon model-predictive control (MPC). By optimizing look-ahead actions based on the precise world model, MPC significantly improves exploration and learning efficiency. Compared to existing LLM agents, WALL-E's reasoning only requires a few principal rules rather than verbose buffered trajectories being included in the LLM input. On open-world challenges in Minecraft and ALFWorld, WALL-E achieves higher success rates than existing methods, with lower costs on replanning time and the number of tokens used for reasoning. In Minecraft, WALL-E exceeds baselines by 15-30% in success rate while costing 8-20 fewer replanning rounds and only 60-80% of tokens. In ALFWorld, its success rate surges to a new record high of 95% only after 6 iterations.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Maybe"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/elated-sawyer/WALL-E", "Code seems to be incomplete / not fully released. However, main authors are from UMD (Tianyi & his students), so we can reach out to them."]}}
}

@article{rayyan-242085889,
  title={WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents},
  year={2025},
  author={Zhou, Siyu and Zhou, Tianyi and Yang, Yijun and Long, Guodong and Ye, Deheng and Jiang, Jing and Chengqi, Zhang},
  abstract={Can we build accurate world models out of large language models (LLMs)? How can world models benefit LLM agents? The gap between the prior knowledge of LLMs and the specified environment's dynamics usually bottlenecks LLMs' performance as world models. To bridge the gap, we propose a training-free world alignment that learns an environment's symbolic knowledge complementary to LLMs. The symbolic knowledge covers action rules, knowledge graphs, and scene graphs, which are extracted by LLMs from exploration trajectories and encoded into executable codes to regulate LLM agents' policies. We further propose an RL-free, model-based agent WALL-E 2.0 through the model-predictive control (MPC) framework. Unlike classical MPC requiring costly optimization on the fly, we adopt an LLM agent as an efficient look-ahead optimizer of future steps' actions by interacting with the neurosymbolic world model. While the LLM agent's strong heuristics make it an efficient planner in MPC, the quality of its planned actions is also secured by the accurate predictions of the aligned world model. They together considerably improve learning efficiency in a new environment. On open-world challenges in Mars (Minecraft like) and ALFWorld (embodied indoor environments), WALL-E 2.0 significantly outperforms existing methods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and by at least 61.7% in score. In ALFWorld, it achieves a new record 98% success rate after only 4 iterations.},
  note={RAYYAN-INCLUSION: {"Anh"=>"Maybe"} | USER-NOTES: {"Anh"=>["[GitHub] https://github.com/elated-sawyer/WALL-E", "Code seems to be incomplete / not fully released. However, main authors are from UMD (Tianyi & his students), so we can reach out to them."]}}
}

